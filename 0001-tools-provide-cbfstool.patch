From 1908e29741dec2e71abb37779655c2f7f27898ce Mon Sep 17 00:00:00 2001
From: Heinrich Schuchardt <xypron.glpk@gmx.de>
Date: Sun, 6 Oct 2019 22:42:44 +0200
Subject: [PATCH 1/1] tools: provide cbfstool

'make tests' requires cbfstool. But this file is not built by U-Boot.

cbfstool can be built from https://github.com/coreboot/coreboot.git
after copying some include files from
https://github.com/coreboot/vboot.git but that is too much of a hassle.

Let's deliver cbfstool with U-Boot.

Signed-off-by: Heinrich Schuchardt <xypron.glpk@gmx.de>
---
 tools/Makefile                                |    2 +
 tools/cbfstool/2sha1.c                        |  292 ++
 tools/cbfstool/2sha256.c                      |  334 ++
 tools/cbfstool/2sha512.c                      |  346 ++
 tools/cbfstool/2sha_utility.c                 |  213 ++
 tools/cbfstool/LzFind.c                       |  761 +++++
 tools/cbfstool/LzmaDec.c                      |  993 ++++++
 tools/cbfstool/LzmaEnc.c                      | 2136 ++++++++++++
 tools/cbfstool/Makefile                       |   80 +
 tools/cbfstool/ProcessorBind.h                |  102 +
 tools/cbfstool/cbfs-mkpayload.c               |  456 +++
 tools/cbfstool/cbfs-mkstage.c                 |  474 +++
 tools/cbfstool/cbfs-payload-linux.c           |  334 ++
 tools/cbfstool/cbfs.c                         |  377 +++
 tools/cbfstool/cbfs.h                         |  257 ++
 tools/cbfstool/cbfs_image.c                   | 2046 ++++++++++++
 tools/cbfstool/cbfs_image.h                   |  207 ++
 tools/cbfstool/cbfs_sections.h                |   55 +
 tools/cbfstool/cbfstool.c                     | 1817 ++++++++++
 tools/cbfstool/coff.h                         |  119 +
 tools/cbfstool/common.c                       |  218 ++
 tools/cbfstool/common.h                       |  240 ++
 tools/cbfstool/commonlib/cbfs.h               |   86 +
 tools/cbfstool/commonlib/cbfs_serialized.h    |  241 ++
 tools/cbfstool/commonlib/compiler.h           |   64 +
 tools/cbfstool/commonlib/compression.h        |   32 +
 tools/cbfstool/commonlib/endian.h             |  261 ++
 tools/cbfstool/commonlib/fsp.h                |   30 +
 tools/cbfstool/commonlib/helpers.h            |  140 +
 tools/cbfstool/commonlib/loglevel.h           |  172 +
 tools/cbfstool/commonlib/mem_pool.h           |   67 +
 tools/cbfstool/commonlib/region.h             |  272 ++
 tools/cbfstool/commonlib/rmodule-defs.h       |   57 +
 tools/cbfstool/compress.c                     |  124 +
 tools/cbfstool/console/console.h              |   44 +
 tools/cbfstool/edk2/Base.h                    | 1018 ++++++
 .../cbfstool/edk2/Guid/FirmwareFileSystem2.h  |   40 +
 tools/cbfstool/edk2/Guid/WinCertificate.h     |  128 +
 .../cbfstool/edk2/IndustryStandard/PeImage.h  |  756 +++++
 .../cbfstool/edk2/IntelFspPkg/FspInfoHeader.h |  159 +
 tools/cbfstool/edk2/Library/HobLib.h          |  506 +++
 tools/cbfstool/edk2/Pi/PiBootMode.h           |   42 +
 tools/cbfstool/edk2/Pi/PiFirmwareFile.h       |  494 +++
 tools/cbfstool/edk2/Pi/PiFirmwareVolume.h     |  234 ++
 tools/cbfstool/edk2/Pi/PiHob.h                |  452 +++
 tools/cbfstool/edk2/Protocol/GraphicsOutput.h |  276 ++
 tools/cbfstool/edk2/Uefi/UefiBaseType.h       |  301 ++
 tools/cbfstool/edk2/Uefi/UefiMultiPhase.h     |  193 ++
 tools/cbfstool/edk2/Uefi/uefi_types.h         |  131 +
 tools/cbfstool/edk2/uefi_types.h              |  131 +
 tools/cbfstool/elf.h                          | 2935 +++++++++++++++++
 tools/cbfstool/elfheaders.c                   | 1470 +++++++++
 tools/cbfstool/elfparsing.h                   |  133 +
 tools/cbfstool/fdt.h                          |   34 +
 tools/cbfstool/flashmap/fmap.h                |  175 +
 tools/cbfstool/flashmap/valstr.h              |   78 +
 tools/cbfstool/fmap.c                         |  684 ++++
 tools/cbfstool/fmd.h                          |  146 +
 tools/cbfstool/fsp_relocate.c                 |  553 ++++
 tools/cbfstool/fv.h                           |   47 +
 tools/cbfstool/kv_pair.c                      |  221 ++
 tools/cbfstool/linux.h                        |  190 ++
 tools/cbfstool/linux_trampoline.c             |   16 +
 tools/cbfstool/linux_trampoline.h             |   36 +
 tools/cbfstool/lz4.c                          | 1567 +++++++++
 tools/cbfstool/lz4.c.inc                      |  280 ++
 tools/cbfstool/lz4/lib/lz4.h                  |  360 ++
 tools/cbfstool/lz4/lib/lz4frame.h             |  303 ++
 tools/cbfstool/lz4/lib/lz4frame_static.h      |   81 +
 tools/cbfstool/lz4/lib/lz4hc.h                |  189 ++
 tools/cbfstool/lz4/lib/xxhash.h               |  192 ++
 tools/cbfstool/lz4_wrapper.c                  |  201 ++
 tools/cbfstool/lz4frame.c                     | 1479 +++++++++
 tools/cbfstool/lz4hc.c                        |  748 +++++
 tools/cbfstool/lzma.c                         |  192 ++
 tools/cbfstool/lzma/C/LzFind.h                |  107 +
 tools/cbfstool/lzma/C/LzHash.h                |   54 +
 tools/cbfstool/lzma/C/LzmaDec.h               |  214 ++
 tools/cbfstool/lzma/C/LzmaEnc.h               |   72 +
 tools/cbfstool/lzma/C/Types.h                 |  148 +
 tools/cbfstool/mem_pool.c                     |   45 +
 tools/cbfstool/partitioned_file.c             |  368 +++
 tools/cbfstool/partitioned_file.h             |  161 +
 tools/cbfstool/region.c                       |  516 +++
 tools/cbfstool/rmodule.c                      |  883 +++++
 tools/cbfstool/rmodule.h                      |   95 +
 tools/cbfstool/swab.h                         |   56 +
 tools/cbfstool/valstr.c                       |   66 +
 tools/cbfstool/vboot/2api.h                   |  804 +++++
 tools/cbfstool/vboot/2common.h                |  303 ++
 tools/cbfstool/vboot/2constants.h             |   83 +
 tools/cbfstool/vboot/2crypto.h                |   76 +
 tools/cbfstool/vboot/2fw_hash_tags.h          |   41 +
 tools/cbfstool/vboot/2gbb.h                   |   46 +
 tools/cbfstool/vboot/2gbb_flags.h             |   87 +
 tools/cbfstool/vboot/2id.h                    |   37 +
 tools/cbfstool/vboot/2recovery_reasons.h      |  253 ++
 tools/cbfstool/vboot/2return_codes.h          |  922 ++++++
 tools/cbfstool/vboot/2sha.h                   |  229 ++
 tools/cbfstool/vboot/2struct.h                |  340 ++
 tools/cbfstool/vboot/2sysincludes.h           |   28 +
 tools/cbfstool/vboot/fmap.h                   |   57 +
 tools/cbfstool/vboot/kv_pair.h                |  157 +
 tools/cbfstool/vboot/vb2_api.h                |   42 +
 tools/cbfstool/vboot/vb2_sha.h                |   13 +
 tools/cbfstool/xdr.c                          |  152 +
 tools/cbfstool/xxhash.c                       |  962 ++++++
 107 files changed, 38037 insertions(+)
 create mode 100644 tools/cbfstool/2sha1.c
 create mode 100644 tools/cbfstool/2sha256.c
 create mode 100644 tools/cbfstool/2sha512.c
 create mode 100644 tools/cbfstool/2sha_utility.c
 create mode 100644 tools/cbfstool/LzFind.c
 create mode 100644 tools/cbfstool/LzmaDec.c
 create mode 100644 tools/cbfstool/LzmaEnc.c
 create mode 100644 tools/cbfstool/Makefile
 create mode 100644 tools/cbfstool/ProcessorBind.h
 create mode 100644 tools/cbfstool/cbfs-mkpayload.c
 create mode 100644 tools/cbfstool/cbfs-mkstage.c
 create mode 100644 tools/cbfstool/cbfs-payload-linux.c
 create mode 100644 tools/cbfstool/cbfs.c
 create mode 100644 tools/cbfstool/cbfs.h
 create mode 100644 tools/cbfstool/cbfs_image.c
 create mode 100644 tools/cbfstool/cbfs_image.h
 create mode 100644 tools/cbfstool/cbfs_sections.h
 create mode 100644 tools/cbfstool/cbfstool.c
 create mode 100644 tools/cbfstool/coff.h
 create mode 100644 tools/cbfstool/common.c
 create mode 100644 tools/cbfstool/common.h
 create mode 100644 tools/cbfstool/commonlib/cbfs.h
 create mode 100644 tools/cbfstool/commonlib/cbfs_serialized.h
 create mode 100644 tools/cbfstool/commonlib/compiler.h
 create mode 100644 tools/cbfstool/commonlib/compression.h
 create mode 100644 tools/cbfstool/commonlib/endian.h
 create mode 100644 tools/cbfstool/commonlib/fsp.h
 create mode 100644 tools/cbfstool/commonlib/helpers.h
 create mode 100644 tools/cbfstool/commonlib/loglevel.h
 create mode 100644 tools/cbfstool/commonlib/mem_pool.h
 create mode 100644 tools/cbfstool/commonlib/region.h
 create mode 100644 tools/cbfstool/commonlib/rmodule-defs.h
 create mode 100644 tools/cbfstool/compress.c
 create mode 100644 tools/cbfstool/console/console.h
 create mode 100644 tools/cbfstool/edk2/Base.h
 create mode 100644 tools/cbfstool/edk2/Guid/FirmwareFileSystem2.h
 create mode 100644 tools/cbfstool/edk2/Guid/WinCertificate.h
 create mode 100644 tools/cbfstool/edk2/IndustryStandard/PeImage.h
 create mode 100644 tools/cbfstool/edk2/IntelFspPkg/FspInfoHeader.h
 create mode 100644 tools/cbfstool/edk2/Library/HobLib.h
 create mode 100644 tools/cbfstool/edk2/Pi/PiBootMode.h
 create mode 100644 tools/cbfstool/edk2/Pi/PiFirmwareFile.h
 create mode 100644 tools/cbfstool/edk2/Pi/PiFirmwareVolume.h
 create mode 100644 tools/cbfstool/edk2/Pi/PiHob.h
 create mode 100644 tools/cbfstool/edk2/Protocol/GraphicsOutput.h
 create mode 100644 tools/cbfstool/edk2/Uefi/UefiBaseType.h
 create mode 100644 tools/cbfstool/edk2/Uefi/UefiMultiPhase.h
 create mode 100644 tools/cbfstool/edk2/Uefi/uefi_types.h
 create mode 100644 tools/cbfstool/edk2/uefi_types.h
 create mode 100644 tools/cbfstool/elf.h
 create mode 100644 tools/cbfstool/elfheaders.c
 create mode 100644 tools/cbfstool/elfparsing.h
 create mode 100644 tools/cbfstool/fdt.h
 create mode 100644 tools/cbfstool/flashmap/fmap.h
 create mode 100644 tools/cbfstool/flashmap/valstr.h
 create mode 100644 tools/cbfstool/fmap.c
 create mode 100644 tools/cbfstool/fmd.h
 create mode 100644 tools/cbfstool/fsp_relocate.c
 create mode 100644 tools/cbfstool/fv.h
 create mode 100644 tools/cbfstool/kv_pair.c
 create mode 100644 tools/cbfstool/linux.h
 create mode 100644 tools/cbfstool/linux_trampoline.c
 create mode 100644 tools/cbfstool/linux_trampoline.h
 create mode 100644 tools/cbfstool/lz4.c
 create mode 100644 tools/cbfstool/lz4.c.inc
 create mode 100644 tools/cbfstool/lz4/lib/lz4.h
 create mode 100644 tools/cbfstool/lz4/lib/lz4frame.h
 create mode 100644 tools/cbfstool/lz4/lib/lz4frame_static.h
 create mode 100644 tools/cbfstool/lz4/lib/lz4hc.h
 create mode 100644 tools/cbfstool/lz4/lib/xxhash.h
 create mode 100644 tools/cbfstool/lz4_wrapper.c
 create mode 100644 tools/cbfstool/lz4frame.c
 create mode 100644 tools/cbfstool/lz4hc.c
 create mode 100644 tools/cbfstool/lzma.c
 create mode 100644 tools/cbfstool/lzma/C/LzFind.h
 create mode 100644 tools/cbfstool/lzma/C/LzHash.h
 create mode 100644 tools/cbfstool/lzma/C/LzmaDec.h
 create mode 100644 tools/cbfstool/lzma/C/LzmaEnc.h
 create mode 100644 tools/cbfstool/lzma/C/Types.h
 create mode 100644 tools/cbfstool/mem_pool.c
 create mode 100644 tools/cbfstool/partitioned_file.c
 create mode 100644 tools/cbfstool/partitioned_file.h
 create mode 100644 tools/cbfstool/region.c
 create mode 100644 tools/cbfstool/rmodule.c
 create mode 100644 tools/cbfstool/rmodule.h
 create mode 100644 tools/cbfstool/swab.h
 create mode 100644 tools/cbfstool/valstr.c
 create mode 100644 tools/cbfstool/vboot/2api.h
 create mode 100644 tools/cbfstool/vboot/2common.h
 create mode 100644 tools/cbfstool/vboot/2constants.h
 create mode 100644 tools/cbfstool/vboot/2crypto.h
 create mode 100644 tools/cbfstool/vboot/2fw_hash_tags.h
 create mode 100644 tools/cbfstool/vboot/2gbb.h
 create mode 100644 tools/cbfstool/vboot/2gbb_flags.h
 create mode 100644 tools/cbfstool/vboot/2id.h
 create mode 100644 tools/cbfstool/vboot/2recovery_reasons.h
 create mode 100644 tools/cbfstool/vboot/2return_codes.h
 create mode 100644 tools/cbfstool/vboot/2sha.h
 create mode 100644 tools/cbfstool/vboot/2struct.h
 create mode 100644 tools/cbfstool/vboot/2sysincludes.h
 create mode 100644 tools/cbfstool/vboot/fmap.h
 create mode 100644 tools/cbfstool/vboot/kv_pair.h
 create mode 100644 tools/cbfstool/vboot/vb2_api.h
 create mode 100644 tools/cbfstool/vboot/vb2_sha.h
 create mode 100644 tools/cbfstool/xdr.c
 create mode 100644 tools/cbfstool/xxhash.c

diff --git a/tools/Makefile b/tools/Makefile
index 24581adccd..ecfa4f281c 100644
--- a/tools/Makefile
+++ b/tools/Makefile
@@ -17,6 +17,8 @@ endif
 
 subdir-$(HOST_TOOLS_ALL) += gdb
 
+subdir-$(CONFIG_FS_CBFS) += cbfstool
+
 # Merge all the different vars for envcrc into one
 ENVCRC-$(CONFIG_ENV_IS_EMBEDDED) = y
 ENVCRC-$(CONFIG_ENV_IS_IN_EEPROM) = y
diff --git a/tools/cbfstool/2sha1.c b/tools/cbfstool/2sha1.c
new file mode 100644
index 0000000000..a241414372
--- /dev/null
+++ b/tools/cbfstool/2sha1.c
@@ -0,0 +1,292 @@
+/* Copyright (c) 2014 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * SHA-1 implementation largely based on libmincrypt in the the Android
+ * Open Source Project (platorm/system/core.git/libmincrypt/sha.c
+ */
+
+#include "2common.h"
+#include "2sha.h"
+#include "2sysincludes.h"
+
+/*
+ * Some machines lack byteswap.h and endian.h. These have to use the
+ * slower code, even if they're little-endian.
+ */
+
+#if defined(HAVE_ENDIAN_H) && defined(HAVE_LITTLE_ENDIAN)
+
+/*
+ * This version is about 28% faster than the generic version below,
+ * but assumes little-endianness.
+ */
+static uint32_t ror27(uint32_t val)
+{
+	return (val >> 27) | (val << 5);
+}
+
+static uint32_t ror2(uint32_t val)
+{
+	return (val >> 2) | (val << 30);
+}
+
+static uint32_t ror31(uint32_t val)
+{
+	return (val >> 31) | (val << 1);
+}
+
+static void sha1_transform(struct vb2_sha1_context *ctx)
+{
+	/* Note that this array uses 80*4=320 bytes of stack */
+	uint32_t W[80];
+	register uint32_t A, B, C, D, E;
+	int t;
+
+	A = ctx->state[0];
+	B = ctx->state[1];
+	C = ctx->state[2];
+	D = ctx->state[3];
+	E = ctx->state[4];
+
+#define SHA_F1(A,B,C,D,E,t)				\
+	E += ror27(A) +					\
+		(W[t] = bswap_32(ctx->buf.w[t])) +	\
+		(D^(B&(C^D))) + 0x5A827999;		\
+	B = ror2(B);
+
+	for (t = 0; t < 15; t += 5) {
+		SHA_F1(A,B,C,D,E,t + 0);
+		SHA_F1(E,A,B,C,D,t + 1);
+		SHA_F1(D,E,A,B,C,t + 2);
+		SHA_F1(C,D,E,A,B,t + 3);
+		SHA_F1(B,C,D,E,A,t + 4);
+	}
+	SHA_F1(A,B,C,D,E,t + 0);  /* 16th one, t == 15 */
+
+#undef SHA_F1
+
+#define SHA_F1(A,B,C,D,E,t)						\
+	E += ror27(A) +							\
+		(W[t] = ror31(W[t-3] ^ W[t-8] ^ W[t-14] ^ W[t-16])) +	\
+		(D^(B&(C^D))) + 0x5A827999;				\
+	B = ror2(B);
+
+	SHA_F1(E,A,B,C,D,t + 1);
+	SHA_F1(D,E,A,B,C,t + 2);
+	SHA_F1(C,D,E,A,B,t + 3);
+	SHA_F1(B,C,D,E,A,t + 4);
+
+#undef SHA_F1
+
+#define SHA_F2(A,B,C,D,E,t)						\
+	E += ror27(A) +							\
+		(W[t] = ror31(W[t-3] ^ W[t-8] ^ W[t-14] ^ W[t-16])) +	\
+		(B^C^D) + 0x6ED9EBA1;					\
+	B = ror2(B);
+
+	for (t = 20; t < 40; t += 5) {
+		SHA_F2(A,B,C,D,E,t + 0);
+		SHA_F2(E,A,B,C,D,t + 1);
+		SHA_F2(D,E,A,B,C,t + 2);
+		SHA_F2(C,D,E,A,B,t + 3);
+		SHA_F2(B,C,D,E,A,t + 4);
+	}
+
+#undef SHA_F2
+
+#define SHA_F3(A,B,C,D,E,t)						\
+	E += ror27(A) +							\
+		(W[t] = ror31(W[t-3] ^ W[t-8] ^ W[t-14] ^ W[t-16])) +	\
+		((B&C)|(D&(B|C))) + 0x8F1BBCDC;				\
+	B = ror2(B);
+
+	for (; t < 60; t += 5) {
+		SHA_F3(A,B,C,D,E,t + 0);
+		SHA_F3(E,A,B,C,D,t + 1);
+		SHA_F3(D,E,A,B,C,t + 2);
+		SHA_F3(C,D,E,A,B,t + 3);
+		SHA_F3(B,C,D,E,A,t + 4);
+	}
+
+#undef SHA_F3
+
+#define SHA_F4(A,B,C,D,E,t)						\
+	E += ror27(A) +							\
+		(W[t] = ror31(W[t-3] ^ W[t-8] ^ W[t-14] ^ W[t-16])) +	\
+		(B^C^D) + 0xCA62C1D6;					\
+	B = ror2(B);
+
+	for (; t < 80; t += 5) {
+		SHA_F4(A,B,C,D,E,t + 0);
+		SHA_F4(E,A,B,C,D,t + 1);
+		SHA_F4(D,E,A,B,C,t + 2);
+		SHA_F4(C,D,E,A,B,t + 3);
+		SHA_F4(B,C,D,E,A,t + 4);
+	}
+
+#undef SHA_F4
+
+	ctx->state[0] += A;
+	ctx->state[1] += B;
+	ctx->state[2] += C;
+	ctx->state[3] += D;
+	ctx->state[4] += E;
+}
+
+void vb2_sha1_update(struct vb2_sha1_context *ctx,
+		     const uint8_t *data,
+		     uint32_t size)
+{
+	int i = ctx->count % sizeof(ctx->buf);
+	const uint8_t *p = (const uint8_t*)data;
+
+	ctx->count += size;
+
+	while (size > sizeof(ctx->buf) - i) {
+		memcpy(&ctx->buf.b[i], p, sizeof(ctx->buf) - i);
+		size -= sizeof(ctx->buf) - i;
+		p += sizeof(ctx->buf) - i;
+		sha1_transform(ctx);
+		i = 0;
+	}
+
+	while (size--) {
+		ctx->buf.b[i++] = *p++;
+		if (i == sizeof(ctx->buf)) {
+			sha1_transform(ctx);
+			i = 0;
+		}
+	}
+}
+
+uint8_t *vb2_sha1_finalize(struct vb2_sha1_context *ctx)
+{
+	uint32_t cnt = ctx->count * 8;
+	int i;
+
+	vb2_sha1_update(ctx, (uint8_t*)"\x80", 1);
+	while ((ctx->count % sizeof(ctx->buf)) != (sizeof(ctx->buf) - 8)) {
+		vb2_sha1_update(ctx, (uint8_t*)"\0", 1);
+	}
+
+	for (i = 0; i < 8; ++i) {
+		uint8_t tmp = cnt >> ((7 - i) * 8);
+		vb2_sha1_update(ctx, &tmp, 1);
+	}
+
+	for (i = 0; i < 5; i++) {
+		ctx->buf.w[i] = bswap_32(ctx->state[i]);
+	}
+
+	return ctx->buf.b;
+}
+
+#else   /* #if defined(HAVE_ENDIAN_H) && defined(HAVE_LITTLE_ENDIAN) */
+
+#define rol(bits, value) (((value) << (bits)) | ((value) >> (32 - (bits))))
+
+static void sha1_transform(struct vb2_sha1_context *ctx)
+{
+	/* Note that this array uses 80*4=320 bytes of stack */
+	uint32_t W[80];
+	uint32_t A, B, C, D, E;
+	uint8_t *p = ctx->buf;
+	int t;
+
+	for(t = 0; t < 16; ++t) {
+		uint32_t tmp = *p++ << 24;
+		tmp |= *p++ << 16;
+		tmp |= *p++ << 8;
+		tmp |= *p++;
+		W[t] = tmp;
+	}
+
+	for(; t < 80; t++) {
+		W[t] = rol(1,W[t-3] ^ W[t-8] ^ W[t-14] ^ W[t-16]);
+	}
+
+	A = ctx->state[0];
+	B = ctx->state[1];
+	C = ctx->state[2];
+	D = ctx->state[3];
+	E = ctx->state[4];
+
+	for(t = 0; t < 80; t++) {
+		uint32_t tmp = rol(5,A) + E + W[t];
+
+		if (t < 20)
+			tmp += (D^(B&(C^D))) + 0x5A827999;
+		else if ( t < 40)
+			tmp += (B^C^D) + 0x6ED9EBA1;
+		else if ( t < 60)
+			tmp += ((B&C)|(D&(B|C))) + 0x8F1BBCDC;
+		else
+			tmp += (B^C^D) + 0xCA62C1D6;
+
+		E = D;
+		D = C;
+		C = rol(30,B);
+		B = A;
+		A = tmp;
+	}
+
+	ctx->state[0] += A;
+	ctx->state[1] += B;
+	ctx->state[2] += C;
+	ctx->state[3] += D;
+	ctx->state[4] += E;
+}
+
+void vb2_sha1_update(struct vb2_sha1_context *ctx,
+		     const uint8_t *data,
+		     uint32_t size)
+{
+	int i = (int)(ctx->count % sizeof(ctx->buf));
+	const uint8_t* p = (const uint8_t*) data;
+
+	ctx->count += size;
+
+	while (size--) {
+		ctx->buf[i++] = *p++;
+		if (i == sizeof(ctx->buf)) {
+			sha1_transform(ctx);
+			i = 0;
+		}
+	}
+}
+
+void vb2_sha1_finalize(struct vb2_sha1_context *ctx, uint8_t *digest)
+{
+	uint32_t cnt = ctx->count << 3;
+	int i;
+
+	vb2_sha1_update(ctx, (uint8_t*)"\x80", 1);
+	while ((ctx->count % sizeof(ctx->buf)) != (sizeof(ctx->buf) - 8)) {
+		vb2_sha1_update(ctx, (uint8_t*)"\0", 1);
+	}
+	for (i = 0; i < 8; ++i) {
+		uint8_t tmp = (uint8_t)((uint64_t)cnt >> ((7 - i) * 8));
+		vb2_sha1_update(ctx, &tmp, 1);
+	}
+
+	for (i = 0; i < 5; i++) {
+		uint32_t tmp = ctx->state[i];
+		*digest++ = (uint8_t)(tmp >> 24);
+		*digest++ = (uint8_t)(tmp >> 16);
+		*digest++ = (uint8_t)(tmp >> 8);
+		*digest++ = (uint8_t)(tmp >> 0);
+	}
+}
+
+#endif /* endianness */
+
+void vb2_sha1_init(struct vb2_sha1_context *ctx)
+{
+	ctx->state[0] = 0x67452301;
+	ctx->state[1] = 0xefcdab89;
+	ctx->state[2] = 0x98badcfe;
+	ctx->state[3] = 0x10325476;
+	ctx->state[4] = 0xc3d2e1f0;
+	ctx->count = 0;
+}
diff --git a/tools/cbfstool/2sha256.c b/tools/cbfstool/2sha256.c
new file mode 100644
index 0000000000..139745f409
--- /dev/null
+++ b/tools/cbfstool/2sha256.c
@@ -0,0 +1,334 @@
+/* SHA-256 and SHA-512 implementation based on code by Oliver Gay
+ * <olivier.gay@a3.epfl.ch> under a BSD-style license. See below.
+ */
+
+/*
+ * FIPS 180-2 SHA-224/256/384/512 implementation
+ * Last update: 02/02/2007
+ * Issue date:  04/30/2005
+ *
+ * Copyright (C) 2005, 2007 Olivier Gay <olivier.gay@a3.epfl.ch>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. Neither the name of the project nor the names of its contributors
+ *    may be used to endorse or promote products derived from this software
+ *    without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE PROJECT AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE PROJECT OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ */
+
+#include "2common.h"
+#include "2sha.h"
+#include "2sysincludes.h"
+
+#define SHFR(x, n)    (x >> n)
+#define ROTR(x, n)   ((x >> n) | (x << ((sizeof(x) << 3) - n)))
+#define ROTL(x, n)   ((x << n) | (x >> ((sizeof(x) << 3) - n)))
+#define CH(x, y, z)  ((x & y) ^ (~x & z))
+#define MAJ(x, y, z) ((x & y) ^ (x & z) ^ (y & z))
+
+#define SHA256_F1(x) (ROTR(x,  2) ^ ROTR(x, 13) ^ ROTR(x, 22))
+#define SHA256_F2(x) (ROTR(x,  6) ^ ROTR(x, 11) ^ ROTR(x, 25))
+#define SHA256_F3(x) (ROTR(x,  7) ^ ROTR(x, 18) ^ SHFR(x,  3))
+#define SHA256_F4(x) (ROTR(x, 17) ^ ROTR(x, 19) ^ SHFR(x, 10))
+
+#define UNPACK32(x, str)				\
+	{						\
+		*((str) + 3) = (uint8_t) ((x)      );	\
+		*((str) + 2) = (uint8_t) ((x) >>  8);	\
+		*((str) + 1) = (uint8_t) ((x) >> 16);	\
+		*((str) + 0) = (uint8_t) ((x) >> 24);	\
+	}
+
+#define PACK32(str, x)						\
+	{							\
+		*(x) =   ((uint32_t) *((str) + 3)      )	\
+			| ((uint32_t) *((str) + 2) <<  8)       \
+			| ((uint32_t) *((str) + 1) << 16)       \
+			| ((uint32_t) *((str) + 0) << 24);      \
+	}
+
+/* Macros used for loops unrolling */
+
+#define SHA256_SCR(i)						\
+	{							\
+		w[i] =  SHA256_F4(w[i -  2]) + w[i -  7]	\
+			+ SHA256_F3(w[i - 15]) + w[i - 16];	\
+	}
+
+#define SHA256_EXP(a, b, c, d, e, f, g, h, j)				\
+	{								\
+		t1 = wv[h] + SHA256_F2(wv[e]) + CH(wv[e], wv[f], wv[g]) \
+			+ sha256_k[j] + w[j];				\
+		t2 = SHA256_F1(wv[a]) + MAJ(wv[a], wv[b], wv[c]);       \
+		wv[d] += t1;                                            \
+		wv[h] = t1 + t2;                                        \
+	}
+
+static const uint32_t sha256_h0[8] = {
+	0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,
+	0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19
+};
+
+static const uint32_t sha256_k[64] = {
+	0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,
+	0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
+	0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,
+	0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
+	0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,
+	0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
+	0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,
+	0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
+	0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,
+	0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
+	0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3,
+	0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
+	0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5,
+	0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
+	0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,
+	0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
+};
+
+/* SHA-256 implementation */
+void vb2_sha256_init(struct vb2_sha256_context *ctx)
+{
+#ifndef UNROLL_LOOPS
+	int i;
+	for (i = 0; i < 8; i++) {
+		ctx->h[i] = sha256_h0[i];
+	}
+#else
+	ctx->h[0] = sha256_h0[0]; ctx->h[1] = sha256_h0[1];
+	ctx->h[2] = sha256_h0[2]; ctx->h[3] = sha256_h0[3];
+	ctx->h[4] = sha256_h0[4]; ctx->h[5] = sha256_h0[5];
+	ctx->h[6] = sha256_h0[6]; ctx->h[7] = sha256_h0[7];
+#endif /* !UNROLL_LOOPS */
+
+	ctx->size = 0;
+	ctx->total_size = 0;
+}
+
+static void vb2_sha256_transform(struct vb2_sha256_context *ctx,
+				 const uint8_t *message,
+				 unsigned int block_nb)
+{
+	/* Note that these arrays use 72*4=288 bytes of stack */
+	uint32_t w[64];
+	uint32_t wv[8];
+	uint32_t t1, t2;
+	const unsigned char *sub_block;
+	int i;
+
+#ifndef UNROLL_LOOPS
+	int j;
+#endif
+
+	for (i = 0; i < (int) block_nb; i++) {
+		sub_block = message + (i << 6);
+
+#ifndef UNROLL_LOOPS
+		for (j = 0; j < 16; j++) {
+			PACK32(&sub_block[j << 2], &w[j]);
+		}
+
+		for (j = 16; j < 64; j++) {
+			SHA256_SCR(j);
+		}
+
+		for (j = 0; j < 8; j++) {
+			wv[j] = ctx->h[j];
+		}
+
+		for (j = 0; j < 64; j++) {
+			t1 = wv[7] + SHA256_F2(wv[4]) + CH(wv[4], wv[5], wv[6])
+				+ sha256_k[j] + w[j];
+			t2 = SHA256_F1(wv[0]) + MAJ(wv[0], wv[1], wv[2]);
+			wv[7] = wv[6];
+			wv[6] = wv[5];
+			wv[5] = wv[4];
+			wv[4] = wv[3] + t1;
+			wv[3] = wv[2];
+			wv[2] = wv[1];
+			wv[1] = wv[0];
+			wv[0] = t1 + t2;
+		}
+
+		for (j = 0; j < 8; j++) {
+			ctx->h[j] += wv[j];
+		}
+#else
+		PACK32(&sub_block[ 0], &w[ 0]); PACK32(&sub_block[ 4], &w[ 1]);
+		PACK32(&sub_block[ 8], &w[ 2]); PACK32(&sub_block[12], &w[ 3]);
+		PACK32(&sub_block[16], &w[ 4]); PACK32(&sub_block[20], &w[ 5]);
+		PACK32(&sub_block[24], &w[ 6]); PACK32(&sub_block[28], &w[ 7]);
+		PACK32(&sub_block[32], &w[ 8]); PACK32(&sub_block[36], &w[ 9]);
+		PACK32(&sub_block[40], &w[10]); PACK32(&sub_block[44], &w[11]);
+		PACK32(&sub_block[48], &w[12]); PACK32(&sub_block[52], &w[13]);
+		PACK32(&sub_block[56], &w[14]); PACK32(&sub_block[60], &w[15]);
+
+		SHA256_SCR(16); SHA256_SCR(17); SHA256_SCR(18); SHA256_SCR(19);
+		SHA256_SCR(20); SHA256_SCR(21); SHA256_SCR(22); SHA256_SCR(23);
+		SHA256_SCR(24); SHA256_SCR(25); SHA256_SCR(26); SHA256_SCR(27);
+		SHA256_SCR(28); SHA256_SCR(29); SHA256_SCR(30); SHA256_SCR(31);
+		SHA256_SCR(32); SHA256_SCR(33); SHA256_SCR(34); SHA256_SCR(35);
+		SHA256_SCR(36); SHA256_SCR(37); SHA256_SCR(38); SHA256_SCR(39);
+		SHA256_SCR(40); SHA256_SCR(41); SHA256_SCR(42); SHA256_SCR(43);
+		SHA256_SCR(44); SHA256_SCR(45); SHA256_SCR(46); SHA256_SCR(47);
+		SHA256_SCR(48); SHA256_SCR(49); SHA256_SCR(50); SHA256_SCR(51);
+		SHA256_SCR(52); SHA256_SCR(53); SHA256_SCR(54); SHA256_SCR(55);
+		SHA256_SCR(56); SHA256_SCR(57); SHA256_SCR(58); SHA256_SCR(59);
+		SHA256_SCR(60); SHA256_SCR(61); SHA256_SCR(62); SHA256_SCR(63);
+
+		wv[0] = ctx->h[0]; wv[1] = ctx->h[1];
+		wv[2] = ctx->h[2]; wv[3] = ctx->h[3];
+		wv[4] = ctx->h[4]; wv[5] = ctx->h[5];
+		wv[6] = ctx->h[6]; wv[7] = ctx->h[7];
+
+		SHA256_EXP(0,1,2,3,4,5,6,7, 0); SHA256_EXP(7,0,1,2,3,4,5,6, 1);
+		SHA256_EXP(6,7,0,1,2,3,4,5, 2); SHA256_EXP(5,6,7,0,1,2,3,4, 3);
+		SHA256_EXP(4,5,6,7,0,1,2,3, 4); SHA256_EXP(3,4,5,6,7,0,1,2, 5);
+		SHA256_EXP(2,3,4,5,6,7,0,1, 6); SHA256_EXP(1,2,3,4,5,6,7,0, 7);
+		SHA256_EXP(0,1,2,3,4,5,6,7, 8); SHA256_EXP(7,0,1,2,3,4,5,6, 9);
+		SHA256_EXP(6,7,0,1,2,3,4,5,10); SHA256_EXP(5,6,7,0,1,2,3,4,11);
+		SHA256_EXP(4,5,6,7,0,1,2,3,12); SHA256_EXP(3,4,5,6,7,0,1,2,13);
+		SHA256_EXP(2,3,4,5,6,7,0,1,14); SHA256_EXP(1,2,3,4,5,6,7,0,15);
+		SHA256_EXP(0,1,2,3,4,5,6,7,16); SHA256_EXP(7,0,1,2,3,4,5,6,17);
+		SHA256_EXP(6,7,0,1,2,3,4,5,18); SHA256_EXP(5,6,7,0,1,2,3,4,19);
+		SHA256_EXP(4,5,6,7,0,1,2,3,20); SHA256_EXP(3,4,5,6,7,0,1,2,21);
+		SHA256_EXP(2,3,4,5,6,7,0,1,22); SHA256_EXP(1,2,3,4,5,6,7,0,23);
+		SHA256_EXP(0,1,2,3,4,5,6,7,24); SHA256_EXP(7,0,1,2,3,4,5,6,25);
+		SHA256_EXP(6,7,0,1,2,3,4,5,26); SHA256_EXP(5,6,7,0,1,2,3,4,27);
+		SHA256_EXP(4,5,6,7,0,1,2,3,28); SHA256_EXP(3,4,5,6,7,0,1,2,29);
+		SHA256_EXP(2,3,4,5,6,7,0,1,30); SHA256_EXP(1,2,3,4,5,6,7,0,31);
+		SHA256_EXP(0,1,2,3,4,5,6,7,32); SHA256_EXP(7,0,1,2,3,4,5,6,33);
+		SHA256_EXP(6,7,0,1,2,3,4,5,34); SHA256_EXP(5,6,7,0,1,2,3,4,35);
+		SHA256_EXP(4,5,6,7,0,1,2,3,36); SHA256_EXP(3,4,5,6,7,0,1,2,37);
+		SHA256_EXP(2,3,4,5,6,7,0,1,38); SHA256_EXP(1,2,3,4,5,6,7,0,39);
+		SHA256_EXP(0,1,2,3,4,5,6,7,40); SHA256_EXP(7,0,1,2,3,4,5,6,41);
+		SHA256_EXP(6,7,0,1,2,3,4,5,42); SHA256_EXP(5,6,7,0,1,2,3,4,43);
+		SHA256_EXP(4,5,6,7,0,1,2,3,44); SHA256_EXP(3,4,5,6,7,0,1,2,45);
+		SHA256_EXP(2,3,4,5,6,7,0,1,46); SHA256_EXP(1,2,3,4,5,6,7,0,47);
+		SHA256_EXP(0,1,2,3,4,5,6,7,48); SHA256_EXP(7,0,1,2,3,4,5,6,49);
+		SHA256_EXP(6,7,0,1,2,3,4,5,50); SHA256_EXP(5,6,7,0,1,2,3,4,51);
+		SHA256_EXP(4,5,6,7,0,1,2,3,52); SHA256_EXP(3,4,5,6,7,0,1,2,53);
+		SHA256_EXP(2,3,4,5,6,7,0,1,54); SHA256_EXP(1,2,3,4,5,6,7,0,55);
+		SHA256_EXP(0,1,2,3,4,5,6,7,56); SHA256_EXP(7,0,1,2,3,4,5,6,57);
+		SHA256_EXP(6,7,0,1,2,3,4,5,58); SHA256_EXP(5,6,7,0,1,2,3,4,59);
+		SHA256_EXP(4,5,6,7,0,1,2,3,60); SHA256_EXP(3,4,5,6,7,0,1,2,61);
+		SHA256_EXP(2,3,4,5,6,7,0,1,62); SHA256_EXP(1,2,3,4,5,6,7,0,63);
+
+		ctx->h[0] += wv[0]; ctx->h[1] += wv[1];
+		ctx->h[2] += wv[2]; ctx->h[3] += wv[3];
+		ctx->h[4] += wv[4]; ctx->h[5] += wv[5];
+		ctx->h[6] += wv[6]; ctx->h[7] += wv[7];
+#endif /* !UNROLL_LOOPS */
+	}
+}
+
+void vb2_sha256_update(struct vb2_sha256_context *ctx,
+		       const uint8_t *data,
+		       uint32_t size)
+{
+	unsigned int block_nb;
+	unsigned int new_size, rem_size, tmp_size;
+	const uint8_t *shifted_data;
+
+	tmp_size = VB2_SHA256_BLOCK_SIZE - ctx->size;
+	rem_size = size < tmp_size ? size : tmp_size;
+
+	memcpy(&ctx->block[ctx->size], data, rem_size);
+
+	if (ctx->size + size < VB2_SHA256_BLOCK_SIZE) {
+		ctx->size += size;
+		return;
+	}
+
+	new_size = size - rem_size;
+	block_nb = new_size / VB2_SHA256_BLOCK_SIZE;
+
+	shifted_data = data + rem_size;
+
+	vb2_sha256_transform(ctx, ctx->block, 1);
+	vb2_sha256_transform(ctx, shifted_data, block_nb);
+
+	rem_size = new_size % VB2_SHA256_BLOCK_SIZE;
+
+	memcpy(ctx->block, &shifted_data[block_nb << 6],
+	       rem_size);
+
+	ctx->size = rem_size;
+	ctx->total_size += (block_nb + 1) << 6;
+}
+
+void vb2_sha256_finalize(struct vb2_sha256_context *ctx, uint8_t *digest)
+{
+	unsigned int block_nb;
+	unsigned int pm_size;
+	unsigned int size_b;
+#ifndef UNROLL_LOOPS
+	int i;
+#endif
+
+	block_nb = (1 + ((VB2_SHA256_BLOCK_SIZE - 9)
+			 < (ctx->size % VB2_SHA256_BLOCK_SIZE)));
+
+	size_b = (ctx->total_size + ctx->size) << 3;
+	pm_size = block_nb << 6;
+
+	memset(ctx->block + ctx->size, 0, pm_size - ctx->size);
+	ctx->block[ctx->size] = 0x80;
+	UNPACK32(size_b, ctx->block + pm_size - 4);
+
+	vb2_sha256_transform(ctx, ctx->block, block_nb);
+
+#ifndef UNROLL_LOOPS
+	for (i = 0 ; i < 8; i++) {
+		UNPACK32(ctx->h[i], &digest[i << 2]);
+	}
+#else
+	UNPACK32(ctx->h[0], &digest[ 0]);
+	UNPACK32(ctx->h[1], &digest[ 4]);
+	UNPACK32(ctx->h[2], &digest[ 8]);
+	UNPACK32(ctx->h[3], &digest[12]);
+	UNPACK32(ctx->h[4], &digest[16]);
+	UNPACK32(ctx->h[5], &digest[20]);
+	UNPACK32(ctx->h[6], &digest[24]);
+	UNPACK32(ctx->h[7], &digest[28]);
+#endif /* !UNROLL_LOOPS */
+}
+
+void vb2_sha256_extend(const uint8_t *from, const uint8_t *by, uint8_t *to)
+{
+	struct vb2_sha256_context dc;
+	int i;
+
+	for (i = 0; i < 8; i++) {
+		 PACK32(from, &dc.h[i]);
+		 from += 4;
+	}
+
+	vb2_sha256_transform(&dc, by, 1);
+
+	for (i = 0; i < 8; i++) {
+		 UNPACK32(dc.h[i], to);
+		 to += 4;
+	}
+}
diff --git a/tools/cbfstool/2sha512.c b/tools/cbfstool/2sha512.c
new file mode 100644
index 0000000000..ee78ec2bc6
--- /dev/null
+++ b/tools/cbfstool/2sha512.c
@@ -0,0 +1,346 @@
+/* SHA-256 and SHA-512 implementation based on code by Oliver Gay
+ * <olivier.gay@a3.epfl.ch> under a BSD-style license. See below.
+ */
+
+/*
+ * FIPS 180-2 SHA-224/256/384/512 implementation
+ * Last update: 02/02/2007
+ * Issue date:  04/30/2005
+ *
+ * Copyright (C) 2005, 2007 Olivier Gay <olivier.gay@a3.epfl.ch>
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. Neither the name of the project nor the names of its contributors
+ *    may be used to endorse or promote products derived from this software
+ *    without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE PROJECT AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE PROJECT OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ */
+
+#include "2common.h"
+#include "2sha.h"
+#include "2sysincludes.h"
+
+#define SHFR(x, n)    (x >> n)
+#define ROTR(x, n)   ((x >> n) | (x << ((sizeof(x) << 3) - n)))
+#define ROTL(x, n)   ((x << n) | (x >> ((sizeof(x) << 3) - n)))
+#define CH(x, y, z)  ((x & y) ^ (~x & z))
+#define MAJ(x, y, z) ((x & y) ^ (x & z) ^ (y & z))
+
+#define SHA512_F1(x) (ROTR(x, 28) ^ ROTR(x, 34) ^ ROTR(x, 39))
+#define SHA512_F2(x) (ROTR(x, 14) ^ ROTR(x, 18) ^ ROTR(x, 41))
+#define SHA512_F3(x) (ROTR(x,  1) ^ ROTR(x,  8) ^ SHFR(x,  7))
+#define SHA512_F4(x) (ROTR(x, 19) ^ ROTR(x, 61) ^ SHFR(x,  6))
+
+#define UNPACK32(x, str)				\
+	{						\
+		*((str) + 3) = (uint8_t) ((x)      );	\
+		*((str) + 2) = (uint8_t) ((x) >>  8);	\
+		*((str) + 1) = (uint8_t) ((x) >> 16);	\
+		*((str) + 0) = (uint8_t) ((x) >> 24);	\
+	}
+
+#define UNPACK64(x, str)					\
+	{							\
+		*((str) + 7) = (uint8_t) x;			\
+		*((str) + 6) = (uint8_t) ((uint64_t)x >> 8);	\
+		*((str) + 5) = (uint8_t) ((uint64_t)x >> 16);	\
+		*((str) + 4) = (uint8_t) ((uint64_t)x >> 24);	\
+		*((str) + 3) = (uint8_t) ((uint64_t)x >> 32);	\
+		*((str) + 2) = (uint8_t) ((uint64_t)x >> 40);	\
+		*((str) + 1) = (uint8_t) ((uint64_t)x >> 48);	\
+		*((str) + 0) = (uint8_t) ((uint64_t)x >> 56);	\
+	}
+
+#define PACK64(str, x)						\
+	{							\
+		*(x) =   ((uint64_t) *((str) + 7)      )	\
+			| ((uint64_t) *((str) + 6) <<  8)       \
+			| ((uint64_t) *((str) + 5) << 16)       \
+			| ((uint64_t) *((str) + 4) << 24)       \
+			| ((uint64_t) *((str) + 3) << 32)       \
+			| ((uint64_t) *((str) + 2) << 40)       \
+			| ((uint64_t) *((str) + 1) << 48)       \
+			| ((uint64_t) *((str) + 0) << 56);      \
+	}
+
+/* Macros used for loops unrolling */
+
+#define SHA512_SCR(i)						\
+	{							\
+		w[i] =  SHA512_F4(w[i -  2]) + w[i -  7]	\
+			+ SHA512_F3(w[i - 15]) + w[i - 16];	\
+	}
+
+#define SHA512_EXP(a, b, c, d, e, f, g ,h, j)				\
+	{								\
+		t1 = wv[h] + SHA512_F2(wv[e]) + CH(wv[e], wv[f], wv[g]) \
+			+ sha512_k[j] + w[j];				\
+		t2 = SHA512_F1(wv[a]) + MAJ(wv[a], wv[b], wv[c]);       \
+		wv[d] += t1;                                            \
+		wv[h] = t1 + t2;                                        \
+	}
+
+static const uint64_t sha512_h0[8] = {
+	0x6a09e667f3bcc908ULL, 0xbb67ae8584caa73bULL,
+	0x3c6ef372fe94f82bULL, 0xa54ff53a5f1d36f1ULL,
+	0x510e527fade682d1ULL, 0x9b05688c2b3e6c1fULL,
+	0x1f83d9abfb41bd6bULL, 0x5be0cd19137e2179ULL
+};
+
+static const uint64_t sha512_k[80] = {
+	0x428a2f98d728ae22ULL, 0x7137449123ef65cdULL,
+	0xb5c0fbcfec4d3b2fULL, 0xe9b5dba58189dbbcULL,
+	0x3956c25bf348b538ULL, 0x59f111f1b605d019ULL,
+	0x923f82a4af194f9bULL, 0xab1c5ed5da6d8118ULL,
+	0xd807aa98a3030242ULL, 0x12835b0145706fbeULL,
+	0x243185be4ee4b28cULL, 0x550c7dc3d5ffb4e2ULL,
+	0x72be5d74f27b896fULL, 0x80deb1fe3b1696b1ULL,
+	0x9bdc06a725c71235ULL, 0xc19bf174cf692694ULL,
+	0xe49b69c19ef14ad2ULL, 0xefbe4786384f25e3ULL,
+	0x0fc19dc68b8cd5b5ULL, 0x240ca1cc77ac9c65ULL,
+	0x2de92c6f592b0275ULL, 0x4a7484aa6ea6e483ULL,
+	0x5cb0a9dcbd41fbd4ULL, 0x76f988da831153b5ULL,
+	0x983e5152ee66dfabULL, 0xa831c66d2db43210ULL,
+	0xb00327c898fb213fULL, 0xbf597fc7beef0ee4ULL,
+	0xc6e00bf33da88fc2ULL, 0xd5a79147930aa725ULL,
+	0x06ca6351e003826fULL, 0x142929670a0e6e70ULL,
+	0x27b70a8546d22ffcULL, 0x2e1b21385c26c926ULL,
+	0x4d2c6dfc5ac42aedULL, 0x53380d139d95b3dfULL,
+	0x650a73548baf63deULL, 0x766a0abb3c77b2a8ULL,
+	0x81c2c92e47edaee6ULL, 0x92722c851482353bULL,
+	0xa2bfe8a14cf10364ULL, 0xa81a664bbc423001ULL,
+	0xc24b8b70d0f89791ULL, 0xc76c51a30654be30ULL,
+	0xd192e819d6ef5218ULL, 0xd69906245565a910ULL,
+	0xf40e35855771202aULL, 0x106aa07032bbd1b8ULL,
+	0x19a4c116b8d2d0c8ULL, 0x1e376c085141ab53ULL,
+	0x2748774cdf8eeb99ULL, 0x34b0bcb5e19b48a8ULL,
+	0x391c0cb3c5c95a63ULL, 0x4ed8aa4ae3418acbULL,
+	0x5b9cca4f7763e373ULL, 0x682e6ff3d6b2b8a3ULL,
+	0x748f82ee5defb2fcULL, 0x78a5636f43172f60ULL,
+	0x84c87814a1f0ab72ULL, 0x8cc702081a6439ecULL,
+	0x90befffa23631e28ULL, 0xa4506cebde82bde9ULL,
+	0xbef9a3f7b2c67915ULL, 0xc67178f2e372532bULL,
+	0xca273eceea26619cULL, 0xd186b8c721c0c207ULL,
+	0xeada7dd6cde0eb1eULL, 0xf57d4f7fee6ed178ULL,
+	0x06f067aa72176fbaULL, 0x0a637dc5a2c898a6ULL,
+	0x113f9804bef90daeULL, 0x1b710b35131c471bULL,
+	0x28db77f523047d84ULL, 0x32caab7b40c72493ULL,
+	0x3c9ebe0a15c9bebcULL, 0x431d67c49c100d4cULL,
+	0x4cc5d4becb3e42b6ULL, 0x597f299cfc657e2aULL,
+	0x5fcb6fab3ad6faecULL, 0x6c44198c4a475817ULL
+};
+
+/* SHA-512 implementation */
+
+void vb2_sha512_init(struct vb2_sha512_context *ctx)
+{
+#ifdef UNROLL_LOOPS_SHA512
+	ctx->h[0] = sha512_h0[0]; ctx->h[1] = sha512_h0[1];
+	ctx->h[2] = sha512_h0[2]; ctx->h[3] = sha512_h0[3];
+	ctx->h[4] = sha512_h0[4]; ctx->h[5] = sha512_h0[5];
+	ctx->h[6] = sha512_h0[6]; ctx->h[7] = sha512_h0[7];
+#else
+	int i;
+
+	for (i = 0; i < 8; i++)
+		ctx->h[i] = sha512_h0[i];
+#endif /* UNROLL_LOOPS_SHA512 */
+
+	ctx->size = 0;
+	ctx->total_size = 0;
+}
+
+static void vb2_sha512_transform(struct vb2_sha512_context *ctx,
+				 const uint8_t *message,
+				 unsigned int block_nb)
+{
+	/* Note that these arrays use 88*8=704 bytes of stack */
+	uint64_t w[80];
+	uint64_t wv[8];
+	uint64_t t1, t2;
+	const uint8_t *sub_block;
+	int i, j;
+
+	for (i = 0; i < (int) block_nb; i++) {
+		sub_block = message + (i << 7);
+
+#ifdef UNROLL_LOOPS_SHA512
+		PACK64(&sub_block[  0], &w[ 0]);
+		PACK64(&sub_block[  8], &w[ 1]);
+		PACK64(&sub_block[ 16], &w[ 2]);
+		PACK64(&sub_block[ 24], &w[ 3]);
+		PACK64(&sub_block[ 32], &w[ 4]);
+		PACK64(&sub_block[ 40], &w[ 5]);
+		PACK64(&sub_block[ 48], &w[ 6]);
+		PACK64(&sub_block[ 56], &w[ 7]);
+		PACK64(&sub_block[ 64], &w[ 8]);
+		PACK64(&sub_block[ 72], &w[ 9]);
+		PACK64(&sub_block[ 80], &w[10]);
+		PACK64(&sub_block[ 88], &w[11]);
+		PACK64(&sub_block[ 96], &w[12]);
+		PACK64(&sub_block[104], &w[13]);
+		PACK64(&sub_block[112], &w[14]);
+		PACK64(&sub_block[120], &w[15]);
+
+		SHA512_SCR(16); SHA512_SCR(17); SHA512_SCR(18); SHA512_SCR(19);
+		SHA512_SCR(20); SHA512_SCR(21); SHA512_SCR(22); SHA512_SCR(23);
+		SHA512_SCR(24); SHA512_SCR(25); SHA512_SCR(26); SHA512_SCR(27);
+		SHA512_SCR(28); SHA512_SCR(29); SHA512_SCR(30); SHA512_SCR(31);
+		SHA512_SCR(32); SHA512_SCR(33); SHA512_SCR(34); SHA512_SCR(35);
+		SHA512_SCR(36); SHA512_SCR(37); SHA512_SCR(38); SHA512_SCR(39);
+		SHA512_SCR(40); SHA512_SCR(41); SHA512_SCR(42); SHA512_SCR(43);
+		SHA512_SCR(44); SHA512_SCR(45); SHA512_SCR(46); SHA512_SCR(47);
+		SHA512_SCR(48); SHA512_SCR(49); SHA512_SCR(50); SHA512_SCR(51);
+		SHA512_SCR(52); SHA512_SCR(53); SHA512_SCR(54); SHA512_SCR(55);
+		SHA512_SCR(56); SHA512_SCR(57); SHA512_SCR(58); SHA512_SCR(59);
+		SHA512_SCR(60); SHA512_SCR(61); SHA512_SCR(62); SHA512_SCR(63);
+		SHA512_SCR(64); SHA512_SCR(65); SHA512_SCR(66); SHA512_SCR(67);
+		SHA512_SCR(68); SHA512_SCR(69); SHA512_SCR(70); SHA512_SCR(71);
+		SHA512_SCR(72); SHA512_SCR(73); SHA512_SCR(74); SHA512_SCR(75);
+		SHA512_SCR(76); SHA512_SCR(77); SHA512_SCR(78); SHA512_SCR(79);
+
+		wv[0] = ctx->h[0]; wv[1] = ctx->h[1];
+		wv[2] = ctx->h[2]; wv[3] = ctx->h[3];
+		wv[4] = ctx->h[4]; wv[5] = ctx->h[5];
+		wv[6] = ctx->h[6]; wv[7] = ctx->h[7];
+
+		j = 0;
+
+		do {
+			SHA512_EXP(0,1,2,3,4,5,6,7,j); j++;
+			SHA512_EXP(7,0,1,2,3,4,5,6,j); j++;
+			SHA512_EXP(6,7,0,1,2,3,4,5,j); j++;
+			SHA512_EXP(5,6,7,0,1,2,3,4,j); j++;
+			SHA512_EXP(4,5,6,7,0,1,2,3,j); j++;
+			SHA512_EXP(3,4,5,6,7,0,1,2,j); j++;
+			SHA512_EXP(2,3,4,5,6,7,0,1,j); j++;
+			SHA512_EXP(1,2,3,4,5,6,7,0,j); j++;
+		} while (j < 80);
+
+		ctx->h[0] += wv[0]; ctx->h[1] += wv[1];
+		ctx->h[2] += wv[2]; ctx->h[3] += wv[3];
+		ctx->h[4] += wv[4]; ctx->h[5] += wv[5];
+		ctx->h[6] += wv[6]; ctx->h[7] += wv[7];
+#else
+		for (j = 0; j < 16; j++) {
+			PACK64(&sub_block[j << 3], &w[j]);
+		}
+
+		for (j = 16; j < 80; j++) {
+			SHA512_SCR(j);
+		}
+
+		for (j = 0; j < 8; j++) {
+			wv[j] = ctx->h[j];
+		}
+
+		for (j = 0; j < 80; j++) {
+			t1 = wv[7] + SHA512_F2(wv[4]) + CH(wv[4], wv[5], wv[6])
+				+ sha512_k[j] + w[j];
+			t2 = SHA512_F1(wv[0]) + MAJ(wv[0], wv[1], wv[2]);
+			wv[7] = wv[6];
+			wv[6] = wv[5];
+			wv[5] = wv[4];
+			wv[4] = wv[3] + t1;
+			wv[3] = wv[2];
+			wv[2] = wv[1];
+			wv[1] = wv[0];
+			wv[0] = t1 + t2;
+		}
+
+		for (j = 0; j < 8; j++)
+			ctx->h[j] += wv[j];
+#endif /* UNROLL_LOOPS_SHA512 */
+	}
+}
+
+void vb2_sha512_update(struct vb2_sha512_context *ctx,
+		       const uint8_t *data,
+		       uint32_t size)
+{
+	unsigned int block_nb;
+	unsigned int new_size, rem_size, tmp_size;
+	const uint8_t *shifted_data;
+
+	tmp_size = VB2_SHA512_BLOCK_SIZE - ctx->size;
+	rem_size = size < tmp_size ? size : tmp_size;
+
+	memcpy(&ctx->block[ctx->size], data, rem_size);
+
+	if (ctx->size + size < VB2_SHA512_BLOCK_SIZE) {
+		ctx->size += size;
+		return;
+	}
+
+	new_size = size - rem_size;
+	block_nb = new_size / VB2_SHA512_BLOCK_SIZE;
+
+	shifted_data = data + rem_size;
+
+	vb2_sha512_transform(ctx, ctx->block, 1);
+	vb2_sha512_transform(ctx, shifted_data, block_nb);
+
+	rem_size = new_size % VB2_SHA512_BLOCK_SIZE;
+
+	memcpy(ctx->block, &shifted_data[block_nb << 7],
+	       rem_size);
+
+	ctx->size = rem_size;
+	ctx->total_size += (block_nb + 1) << 7;
+}
+
+void vb2_sha512_finalize(struct vb2_sha512_context *ctx, uint8_t *digest)
+{
+	unsigned int block_nb;
+	unsigned int pm_size;
+	unsigned int size_b;
+
+#ifndef UNROLL_LOOPS_SHA512
+	int i;
+#endif
+
+	block_nb = 1 + ((VB2_SHA512_BLOCK_SIZE - 17)
+			< (ctx->size % VB2_SHA512_BLOCK_SIZE));
+
+	size_b = (ctx->total_size + ctx->size) << 3;
+	pm_size = block_nb << 7;
+
+	memset(ctx->block + ctx->size, 0, pm_size - ctx->size);
+	ctx->block[ctx->size] = 0x80;
+	UNPACK32(size_b, ctx->block + pm_size - 4);
+
+	vb2_sha512_transform(ctx, ctx->block, block_nb);
+
+#ifdef UNROLL_LOOPS_SHA512
+	UNPACK64(ctx->h[0], &digest[ 0]);
+	UNPACK64(ctx->h[1], &digest[ 8]);
+	UNPACK64(ctx->h[2], &digest[16]);
+	UNPACK64(ctx->h[3], &digest[24]);
+	UNPACK64(ctx->h[4], &digest[32]);
+	UNPACK64(ctx->h[5], &digest[40]);
+	UNPACK64(ctx->h[6], &digest[48]);
+	UNPACK64(ctx->h[7], &digest[56]);
+#else
+	for (i = 0 ; i < 8; i++)
+		UNPACK64(ctx->h[i], &digest[i << 3]);
+#endif /* UNROLL_LOOPS_SHA512 */
+}
diff --git a/tools/cbfstool/2sha_utility.c b/tools/cbfstool/2sha_utility.c
new file mode 100644
index 0000000000..a267eddefc
--- /dev/null
+++ b/tools/cbfstool/2sha_utility.c
@@ -0,0 +1,213 @@
+/* Copyright (c) 2014 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * Utility functions for message digest functions.
+ */
+
+#include "2common.h"
+#include "2sha.h"
+#include "2sysincludes.h"
+
+#if VB2_SUPPORT_SHA1
+#define CTH_SHA1 VB2_HASH_SHA1
+#else
+#define CTH_SHA1 VB2_HASH_INVALID
+#endif
+
+#if VB2_SUPPORT_SHA256
+#define CTH_SHA256 VB2_HASH_SHA256
+#else
+#define CTH_SHA256 VB2_HASH_INVALID
+#endif
+
+#if VB2_SUPPORT_SHA512
+#define CTH_SHA512 VB2_HASH_SHA512
+#else
+#define CTH_SHA512 VB2_HASH_INVALID
+#endif
+
+static const uint8_t crypto_to_hash[] = {
+	CTH_SHA1,
+	CTH_SHA256,
+	CTH_SHA512,
+	CTH_SHA1,
+	CTH_SHA256,
+	CTH_SHA512,
+	CTH_SHA1,
+	CTH_SHA256,
+	CTH_SHA512,
+	CTH_SHA1,
+	CTH_SHA256,
+	CTH_SHA512,
+	CTH_SHA1,
+	CTH_SHA256,
+	CTH_SHA512,
+	CTH_SHA1,
+	CTH_SHA256,
+	CTH_SHA512,
+};
+
+enum vb2_hash_algorithm vb2_crypto_to_hash(uint32_t algorithm)
+{
+	if (algorithm < ARRAY_SIZE(crypto_to_hash))
+		return crypto_to_hash[algorithm];
+	else
+		return VB2_HASH_INVALID;
+}
+
+vb2_error_t vb2_digest_size(enum vb2_hash_algorithm hash_alg)
+{
+	switch (hash_alg) {
+#if VB2_SUPPORT_SHA1
+	case VB2_HASH_SHA1:
+		return VB2_SHA1_DIGEST_SIZE;
+#endif
+#if VB2_SUPPORT_SHA256
+	case VB2_HASH_SHA256:
+		return VB2_SHA256_DIGEST_SIZE;
+#endif
+#if VB2_SUPPORT_SHA512
+	case VB2_HASH_SHA512:
+		return VB2_SHA512_DIGEST_SIZE;
+#endif
+	default:
+		return 0;
+	}
+}
+
+vb2_error_t vb2_hash_block_size(enum vb2_hash_algorithm alg)
+{
+	switch (alg) {
+#if VB2_SUPPORT_SHA1
+	case VB2_HASH_SHA1:
+		return VB2_SHA1_BLOCK_SIZE;
+#endif
+#if VB2_SUPPORT_SHA256
+	case VB2_HASH_SHA256:
+		return VB2_SHA256_BLOCK_SIZE;
+#endif
+#if VB2_SUPPORT_SHA512
+	case VB2_HASH_SHA512:
+		return VB2_SHA512_BLOCK_SIZE;
+#endif
+	default:
+		return 0;
+	}
+}
+
+const char *vb2_get_hash_algorithm_name(enum vb2_hash_algorithm alg)
+{
+	switch (alg) {
+#if VB2_SUPPORT_SHA1
+	case VB2_HASH_SHA1:
+		return VB2_SHA1_ALG_NAME;
+#endif
+#if VB2_SUPPORT_SHA256
+	case VB2_HASH_SHA256:
+		return VB2_SHA256_ALG_NAME;
+#endif
+#if VB2_SUPPORT_SHA512
+	case VB2_HASH_SHA512:
+		return VB2_SHA512_ALG_NAME;
+#endif
+	default:
+		return VB2_INVALID_ALG_NAME;
+	}
+}
+
+vb2_error_t vb2_digest_init(struct vb2_digest_context *dc,
+			    enum vb2_hash_algorithm hash_alg)
+{
+	dc->hash_alg = hash_alg;
+	dc->using_hwcrypto = 0;
+
+	switch (dc->hash_alg) {
+#if VB2_SUPPORT_SHA1
+	case VB2_HASH_SHA1:
+		vb2_sha1_init(&dc->sha1);
+		return VB2_SUCCESS;
+#endif
+#if VB2_SUPPORT_SHA256
+	case VB2_HASH_SHA256:
+		vb2_sha256_init(&dc->sha256);
+		return VB2_SUCCESS;
+#endif
+#if VB2_SUPPORT_SHA512
+	case VB2_HASH_SHA512:
+		vb2_sha512_init(&dc->sha512);
+		return VB2_SUCCESS;
+#endif
+	default:
+		return VB2_ERROR_SHA_INIT_ALGORITHM;
+	}
+}
+
+vb2_error_t vb2_digest_extend(struct vb2_digest_context *dc, const uint8_t *buf,
+			      uint32_t size)
+{
+	switch (dc->hash_alg) {
+#if VB2_SUPPORT_SHA1
+	case VB2_HASH_SHA1:
+		vb2_sha1_update(&dc->sha1, buf, size);
+		return VB2_SUCCESS;
+#endif
+#if VB2_SUPPORT_SHA256
+	case VB2_HASH_SHA256:
+		vb2_sha256_update(&dc->sha256, buf, size);
+		return VB2_SUCCESS;
+#endif
+#if VB2_SUPPORT_SHA512
+	case VB2_HASH_SHA512:
+		vb2_sha512_update(&dc->sha512, buf, size);
+		return VB2_SUCCESS;
+#endif
+	default:
+		return VB2_ERROR_SHA_EXTEND_ALGORITHM;
+	}
+}
+
+vb2_error_t vb2_digest_finalize(struct vb2_digest_context *dc, uint8_t *digest,
+				uint32_t digest_size)
+{
+	if (digest_size < vb2_digest_size(dc->hash_alg))
+		return VB2_ERROR_SHA_FINALIZE_DIGEST_SIZE;
+
+	switch (dc->hash_alg) {
+#if VB2_SUPPORT_SHA1
+	case VB2_HASH_SHA1:
+		vb2_sha1_finalize(&dc->sha1, digest);
+		return VB2_SUCCESS;
+#endif
+#if VB2_SUPPORT_SHA256
+	case VB2_HASH_SHA256:
+		vb2_sha256_finalize(&dc->sha256, digest);
+		return VB2_SUCCESS;
+#endif
+#if VB2_SUPPORT_SHA512
+	case VB2_HASH_SHA512:
+		vb2_sha512_finalize(&dc->sha512, digest);
+		return VB2_SUCCESS;
+#endif
+	default:
+		return VB2_ERROR_SHA_FINALIZE_ALGORITHM;
+	}
+}
+
+vb2_error_t vb2_digest_buffer(const uint8_t *buf, uint32_t size,
+			      enum vb2_hash_algorithm hash_alg, uint8_t *digest,
+			      uint32_t digest_size)
+{
+	struct vb2_digest_context dc;
+	vb2_error_t rv;
+
+	rv = vb2_digest_init(&dc, hash_alg);
+	if (rv)
+		return rv;
+
+	rv = vb2_digest_extend(&dc, buf, size);
+	if (rv)
+		return rv;
+
+	return vb2_digest_finalize(&dc, digest, digest_size);
+}
diff --git a/tools/cbfstool/LzFind.c b/tools/cbfstool/LzFind.c
new file mode 100644
index 0000000000..103b26f3e6
--- /dev/null
+++ b/tools/cbfstool/LzFind.c
@@ -0,0 +1,761 @@
+/* LzFind.c -- Match finder for LZ algorithms
+2009-04-22 : Igor Pavlov : Public domain */
+
+#include <string.h>
+
+#include "lzma/C/LzFind.h"
+#include "lzma/C/LzHash.h"
+
+#define kEmptyHashValue 0
+#define kMaxValForNormalize ((uint32_t)0xFFFFFFFF)
+#define kNormalizeStepMin (1 << 10) /* it must be power of 2 */
+#define kNormalizeMask (~(kNormalizeStepMin - 1))
+#define kMaxHistorySize ((uint32_t)3 << 30)
+
+#define kStartMaxLen 3
+
+static void LzInWindow_Free(struct CMatchFinder *p, struct ISzAlloc *alloc)
+{
+  if (!p->directInput)
+  {
+    alloc->Free(alloc, p->bufferBase);
+    p->bufferBase = 0;
+  }
+}
+
+/* keepSizeBefore + keepSizeAfter + keepSizeReserv must be < 4G) */
+
+static int LzInWindow_Create(struct CMatchFinder *p, uint32_t keepSizeReserv, struct ISzAlloc *alloc)
+{
+  uint32_t blockSize = p->keepSizeBefore + p->keepSizeAfter + keepSizeReserv;
+  if (p->directInput)
+  {
+    p->blockSize = blockSize;
+    return 1;
+  }
+  if (p->bufferBase == 0 || p->blockSize != blockSize)
+  {
+    LzInWindow_Free(p, alloc);
+    p->blockSize = blockSize;
+    p->bufferBase = (uint8_t *)alloc->Alloc(alloc, (size_t)blockSize);
+  }
+  return (p->bufferBase != 0);
+}
+
+uint8_t *MatchFinder_GetPointerToCurrentPos(struct CMatchFinder *p) { return p->buffer; }
+static uint8_t MatchFinder_GetIndexByte(struct CMatchFinder *p, int32_t bindex) { return p->buffer[bindex]; }
+
+static uint32_t MatchFinder_GetNumAvailableBytes(struct CMatchFinder *p) { return p->streamPos - p->pos; }
+
+void MatchFinder_ReduceOffsets(struct CMatchFinder *p, uint32_t subValue)
+{
+  p->posLimit -= subValue;
+  p->pos -= subValue;
+  p->streamPos -= subValue;
+}
+
+static void MatchFinder_ReadBlock(struct CMatchFinder *p)
+{
+  if (p->streamEndWasReached || p->result != SZ_OK)
+    return;
+  if (p->directInput)
+  {
+    uint32_t curSize = 0xFFFFFFFF - p->streamPos;
+    if (curSize > p->directInputRem)
+      curSize = (uint32_t)p->directInputRem;
+    p->directInputRem -= curSize;
+    p->streamPos += curSize;
+    if (p->directInputRem == 0)
+      p->streamEndWasReached = 1;
+    return;
+  }
+  for (;;)
+  {
+    uint8_t *dest = p->buffer + (p->streamPos - p->pos);
+    size_t size = (p->bufferBase + p->blockSize - dest);
+    if (size == 0)
+      return;
+    p->result = p->stream->Read(p->stream, dest, &size);
+    if (p->result != SZ_OK)
+      return;
+    if (size == 0)
+    {
+      p->streamEndWasReached = 1;
+      return;
+    }
+    p->streamPos += (uint32_t)size;
+    if (p->streamPos - p->pos > p->keepSizeAfter)
+      return;
+  }
+}
+
+void MatchFinder_MoveBlock(struct CMatchFinder *p)
+{
+  memmove(p->bufferBase,
+    p->buffer - p->keepSizeBefore,
+    (size_t)(p->streamPos - p->pos + p->keepSizeBefore));
+  p->buffer = p->bufferBase + p->keepSizeBefore;
+}
+
+int MatchFinder_NeedMove(struct CMatchFinder *p)
+{
+  if (p->directInput)
+    return 0;
+  /* if (p->streamEndWasReached) return 0; */
+  return ((size_t)(p->bufferBase + p->blockSize - p->buffer) <= p->keepSizeAfter);
+}
+
+void MatchFinder_ReadIfRequired(struct CMatchFinder *p)
+{
+  if (p->streamEndWasReached)
+    return;
+  if (p->keepSizeAfter >= p->streamPos - p->pos)
+    MatchFinder_ReadBlock(p);
+}
+
+static void MatchFinder_CheckAndMoveAndRead(struct CMatchFinder *p)
+{
+  if (MatchFinder_NeedMove(p))
+    MatchFinder_MoveBlock(p);
+  MatchFinder_ReadBlock(p);
+}
+
+static void MatchFinder_SetDefaultSettings(struct CMatchFinder *p)
+{
+  p->cutValue = 32;
+  p->btMode = 1;
+  p->numHashBytes = 4;
+  p->bigHash = 0;
+}
+
+#define kCrcPoly 0xEDB88320
+
+void MatchFinder_Construct(struct CMatchFinder *p)
+{
+  uint32_t i;
+  p->bufferBase = 0;
+  p->directInput = 0;
+  p->hash = 0;
+  MatchFinder_SetDefaultSettings(p);
+
+  for (i = 0; i < 256; i++)
+  {
+    uint32_t r = i;
+    int j;
+    for (j = 0; j < 8; j++)
+      r = (r >> 1) ^ (kCrcPoly & ~((r & 1) - 1));
+    p->crc[i] = r;
+  }
+}
+
+static void MatchFinder_FreeThisClassMemory(struct CMatchFinder *p, struct ISzAlloc *alloc)
+{
+  alloc->Free(alloc, p->hash);
+  p->hash = 0;
+}
+
+void MatchFinder_Free(struct CMatchFinder *p, struct ISzAlloc *alloc)
+{
+  MatchFinder_FreeThisClassMemory(p, alloc);
+  LzInWindow_Free(p, alloc);
+}
+
+static CLzRef* AllocRefs(uint32_t num, struct ISzAlloc *alloc)
+{
+  size_t sizeInuint8_ts = (size_t)num * sizeof(CLzRef);
+  if (sizeInuint8_ts / sizeof(CLzRef) != num)
+    return 0;
+  return (CLzRef *)alloc->Alloc(alloc, sizeInuint8_ts);
+}
+
+int MatchFinder_Create(struct CMatchFinder *p, uint32_t historySize,
+    uint32_t keepAddBufferBefore, uint32_t matchMaxLen, uint32_t keepAddBufferAfter,
+    struct ISzAlloc *alloc)
+{
+  uint32_t sizeReserv;
+  if (historySize > kMaxHistorySize)
+  {
+    MatchFinder_Free(p, alloc);
+    return 0;
+  }
+  sizeReserv = historySize >> 1;
+  if (historySize > ((uint32_t)2 << 30))
+    sizeReserv = historySize >> 2;
+  sizeReserv += (keepAddBufferBefore + matchMaxLen + keepAddBufferAfter) / 2 + (1 << 19);
+
+  p->keepSizeBefore = historySize + keepAddBufferBefore + 1;
+  p->keepSizeAfter = matchMaxLen + keepAddBufferAfter;
+  /* we need one additional byte, since we use MoveBlock after pos++ and before dictionary using */
+  if (LzInWindow_Create(p, sizeReserv, alloc))
+  {
+    uint32_t newCyclicBufferSize = historySize + 1;
+    uint32_t hs;
+    p->matchMaxLen = matchMaxLen;
+    {
+      p->fixedHashSize = 0;
+      if (p->numHashBytes == 2)
+        hs = (1 << 16) - 1;
+      else
+      {
+        hs = historySize - 1;
+        hs |= (hs >> 1);
+        hs |= (hs >> 2);
+        hs |= (hs >> 4);
+        hs |= (hs >> 8);
+        hs >>= 1;
+        hs |= 0xFFFF; /* don't change it! It's required for Deflate */
+        if (hs > (1 << 24))
+        {
+          if (p->numHashBytes == 3)
+            hs = (1 << 24) - 1;
+          else
+            hs >>= 1;
+        }
+      }
+      p->hashMask = hs;
+      hs++;
+      if (p->numHashBytes > 2) p->fixedHashSize += kHash2Size;
+      if (p->numHashBytes > 3) p->fixedHashSize += kHash3Size;
+      if (p->numHashBytes > 4) p->fixedHashSize += kHash4Size;
+      hs += p->fixedHashSize;
+    }
+
+    {
+      uint32_t prevSize = p->hashSizeSum + p->numSons;
+      uint32_t newSize;
+      p->historySize = historySize;
+      p->hashSizeSum = hs;
+      p->cyclicBufferSize = newCyclicBufferSize;
+      p->numSons = (p->btMode ? newCyclicBufferSize * 2 : newCyclicBufferSize);
+      newSize = p->hashSizeSum + p->numSons;
+      if (p->hash != 0 && prevSize == newSize)
+        return 1;
+      MatchFinder_FreeThisClassMemory(p, alloc);
+      p->hash = AllocRefs(newSize, alloc);
+      if (p->hash != 0)
+      {
+        p->son = p->hash + p->hashSizeSum;
+        return 1;
+      }
+    }
+  }
+  MatchFinder_Free(p, alloc);
+  return 0;
+}
+
+static void MatchFinder_SetLimits(struct CMatchFinder *p)
+{
+  uint32_t limit = kMaxValForNormalize - p->pos;
+  uint32_t limit2 = p->cyclicBufferSize - p->cyclicBufferPos;
+  if (limit2 < limit)
+    limit = limit2;
+  limit2 = p->streamPos - p->pos;
+  if (limit2 <= p->keepSizeAfter)
+  {
+    if (limit2 > 0)
+      limit2 = 1;
+  }
+  else
+    limit2 -= p->keepSizeAfter;
+  if (limit2 < limit)
+    limit = limit2;
+  {
+    uint32_t lenLimit = p->streamPos - p->pos;
+    if (lenLimit > p->matchMaxLen)
+      lenLimit = p->matchMaxLen;
+    p->lenLimit = lenLimit;
+  }
+  p->posLimit = p->pos + limit;
+}
+
+void MatchFinder_Init(struct CMatchFinder *p)
+{
+  uint32_t i;
+  for (i = 0; i < p->hashSizeSum; i++)
+    p->hash[i] = kEmptyHashValue;
+  p->cyclicBufferPos = 0;
+  p->buffer = p->bufferBase;
+  p->pos = p->streamPos = p->cyclicBufferSize;
+  p->result = SZ_OK;
+  p->streamEndWasReached = 0;
+  MatchFinder_ReadBlock(p);
+  MatchFinder_SetLimits(p);
+}
+
+static uint32_t MatchFinder_GetSubValue(struct CMatchFinder *p)
+{
+  return (p->pos - p->historySize - 1) & kNormalizeMask;
+}
+
+void MatchFinder_Normalize3(uint32_t subValue, CLzRef *items, uint32_t numItems)
+{
+  uint32_t i;
+  for (i = 0; i < numItems; i++)
+  {
+    uint32_t value = items[i];
+    if (value <= subValue)
+      value = kEmptyHashValue;
+    else
+      value -= subValue;
+    items[i] = value;
+  }
+}
+
+static void MatchFinder_Normalize(struct CMatchFinder *p)
+{
+  uint32_t subValue = MatchFinder_GetSubValue(p);
+  MatchFinder_Normalize3(subValue, p->hash, p->hashSizeSum + p->numSons);
+  MatchFinder_ReduceOffsets(p, subValue);
+}
+
+static void MatchFinder_CheckLimits(struct CMatchFinder *p)
+{
+  if (p->pos == kMaxValForNormalize)
+    MatchFinder_Normalize(p);
+  if (!p->streamEndWasReached && p->keepSizeAfter == p->streamPos - p->pos)
+    MatchFinder_CheckAndMoveAndRead(p);
+  if (p->cyclicBufferPos == p->cyclicBufferSize)
+    p->cyclicBufferPos = 0;
+  MatchFinder_SetLimits(p);
+}
+
+static uint32_t * Hc_GetMatchesSpec(uint32_t lenLimit, uint32_t curMatch, uint32_t pos, const uint8_t *cur, CLzRef *son,
+    uint32_t _cyclicBufferPos, uint32_t _cyclicBufferSize, uint32_t cutValue,
+    uint32_t *distances, uint32_t maxLen)
+{
+  son[_cyclicBufferPos] = curMatch;
+  for (;;)
+  {
+    uint32_t delta = pos - curMatch;
+    if (cutValue-- == 0 || delta >= _cyclicBufferSize)
+      return distances;
+    {
+      const uint8_t *pb = cur - delta;
+      curMatch = son[_cyclicBufferPos - delta + ((delta > _cyclicBufferPos) ? _cyclicBufferSize : 0)];
+      if (pb[maxLen] == cur[maxLen] && *pb == *cur)
+      {
+        uint32_t len = 0;
+        while (++len != lenLimit)
+          if (pb[len] != cur[len])
+            break;
+        if (maxLen < len)
+        {
+          *distances++ = maxLen = len;
+          *distances++ = delta - 1;
+          if (len == lenLimit)
+            return distances;
+        }
+      }
+    }
+  }
+}
+
+uint32_t * GetMatchesSpec1(uint32_t lenLimit, uint32_t curMatch, uint32_t pos, const uint8_t *cur, CLzRef *son,
+    uint32_t _cyclicBufferPos, uint32_t _cyclicBufferSize, uint32_t cutValue,
+    uint32_t *distances, uint32_t maxLen)
+{
+  CLzRef *ptr0 = son + (_cyclicBufferPos << 1) + 1;
+  CLzRef *ptr1 = son + (_cyclicBufferPos << 1);
+  uint32_t len0 = 0, len1 = 0;
+  for (;;)
+  {
+    uint32_t delta = pos - curMatch;
+    if (cutValue-- == 0 || delta >= _cyclicBufferSize)
+    {
+      *ptr0 = *ptr1 = kEmptyHashValue;
+      return distances;
+    }
+    {
+      CLzRef *pair = son + ((_cyclicBufferPos - delta + ((delta > _cyclicBufferPos) ? _cyclicBufferSize : 0)) << 1);
+      const uint8_t *pb = cur - delta;
+      uint32_t len = (len0 < len1 ? len0 : len1);
+      if (pb[len] == cur[len])
+      {
+        if (++len != lenLimit && pb[len] == cur[len])
+          while (++len != lenLimit)
+            if (pb[len] != cur[len])
+              break;
+        if (maxLen < len)
+        {
+          *distances++ = maxLen = len;
+          *distances++ = delta - 1;
+          if (len == lenLimit)
+          {
+            *ptr1 = pair[0];
+            *ptr0 = pair[1];
+            return distances;
+          }
+        }
+      }
+      if (pb[len] < cur[len])
+      {
+        *ptr1 = curMatch;
+        ptr1 = pair + 1;
+        curMatch = *ptr1;
+        len1 = len;
+      }
+      else
+      {
+        *ptr0 = curMatch;
+        ptr0 = pair;
+        curMatch = *ptr0;
+        len0 = len;
+      }
+    }
+  }
+}
+
+static void SkipMatchesSpec(uint32_t lenLimit, uint32_t curMatch, uint32_t pos, const uint8_t *cur, CLzRef *son,
+    uint32_t _cyclicBufferPos, uint32_t _cyclicBufferSize, uint32_t cutValue)
+{
+  CLzRef *ptr0 = son + (_cyclicBufferPos << 1) + 1;
+  CLzRef *ptr1 = son + (_cyclicBufferPos << 1);
+  uint32_t len0 = 0, len1 = 0;
+  for (;;)
+  {
+    uint32_t delta = pos - curMatch;
+    if (cutValue-- == 0 || delta >= _cyclicBufferSize)
+    {
+      *ptr0 = *ptr1 = kEmptyHashValue;
+      return;
+    }
+    {
+      CLzRef *pair = son + ((_cyclicBufferPos - delta + ((delta > _cyclicBufferPos) ? _cyclicBufferSize : 0)) << 1);
+      const uint8_t *pb = cur - delta;
+      uint32_t len = (len0 < len1 ? len0 : len1);
+      if (pb[len] == cur[len])
+      {
+        while (++len != lenLimit)
+          if (pb[len] != cur[len])
+            break;
+        {
+          if (len == lenLimit)
+          {
+            *ptr1 = pair[0];
+            *ptr0 = pair[1];
+            return;
+          }
+        }
+      }
+      if (pb[len] < cur[len])
+      {
+        *ptr1 = curMatch;
+        ptr1 = pair + 1;
+        curMatch = *ptr1;
+        len1 = len;
+      }
+      else
+      {
+        *ptr0 = curMatch;
+        ptr0 = pair;
+        curMatch = *ptr0;
+        len0 = len;
+      }
+    }
+  }
+}
+
+#define MOVE_POS \
+  ++p->cyclicBufferPos; \
+  p->buffer++; \
+  if (++p->pos == p->posLimit) MatchFinder_CheckLimits(p);
+
+#define MOVE_POS_RET MOVE_POS return offset;
+
+static void MatchFinder_MovePos(struct CMatchFinder *p) { MOVE_POS; }
+
+#define GET_MATCHES_HEADER2(minLen, ret_op) \
+  uint32_t lenLimit; uint32_t hashValue; const uint8_t *cur; uint32_t curMatch; \
+  lenLimit = p->lenLimit; { if (lenLimit < minLen) { MatchFinder_MovePos(p); ret_op; }} \
+  cur = p->buffer;
+
+#define GET_MATCHES_HEADER(minLen) GET_MATCHES_HEADER2(minLen, return 0)
+#define SKIP_HEADER(minLen)        GET_MATCHES_HEADER2(minLen, continue)
+
+#define MF_PARAMS(p) p->pos, p->buffer, p->son, p->cyclicBufferPos, p->cyclicBufferSize, p->cutValue
+
+#define GET_MATCHES_FOOTER(offset, maxLen) \
+  offset = (uint32_t)(GetMatchesSpec1(lenLimit, curMatch, MF_PARAMS(p), \
+  distances + offset, maxLen) - distances); MOVE_POS_RET;
+
+#define SKIP_FOOTER \
+  SkipMatchesSpec(lenLimit, curMatch, MF_PARAMS(p)); MOVE_POS;
+
+static uint32_t Bt2_MatchFinder_GetMatches(struct CMatchFinder *p, uint32_t *distances)
+{
+  uint32_t offset;
+  GET_MATCHES_HEADER(2)
+  HASH2_CALC;
+  curMatch = p->hash[hashValue];
+  p->hash[hashValue] = p->pos;
+  offset = 0;
+  GET_MATCHES_FOOTER(offset, 1)
+}
+
+uint32_t Bt3Zip_MatchFinder_GetMatches(struct CMatchFinder *p, uint32_t *distances)
+{
+  uint32_t offset;
+  GET_MATCHES_HEADER(3)
+  HASH_ZIP_CALC;
+  curMatch = p->hash[hashValue];
+  p->hash[hashValue] = p->pos;
+  offset = 0;
+  GET_MATCHES_FOOTER(offset, 2)
+}
+
+static uint32_t Bt3_MatchFinder_GetMatches(struct CMatchFinder *p, uint32_t *distances)
+{
+  uint32_t hash2Value, delta2, maxLen, offset;
+  GET_MATCHES_HEADER(3)
+
+  HASH3_CALC;
+
+  delta2 = p->pos - p->hash[hash2Value];
+  curMatch = p->hash[kFix3HashSize + hashValue];
+
+  p->hash[hash2Value] =
+  p->hash[kFix3HashSize + hashValue] = p->pos;
+
+
+  maxLen = 2;
+  offset = 0;
+  if (delta2 < p->cyclicBufferSize && *(cur - delta2) == *cur)
+  {
+    for (; maxLen != lenLimit; maxLen++)
+      if (cur[(ptrdiff_t)maxLen - delta2] != cur[maxLen])
+        break;
+    distances[0] = maxLen;
+    distances[1] = delta2 - 1;
+    offset = 2;
+    if (maxLen == lenLimit)
+    {
+      SkipMatchesSpec(lenLimit, curMatch, MF_PARAMS(p));
+      MOVE_POS_RET;
+    }
+  }
+  GET_MATCHES_FOOTER(offset, maxLen)
+}
+
+static uint32_t Bt4_MatchFinder_GetMatches(struct CMatchFinder *p, uint32_t *distances)
+{
+  uint32_t hash2Value, hash3Value, delta2, delta3, maxLen, offset;
+  GET_MATCHES_HEADER(4)
+
+  HASH4_CALC;
+
+  delta2 = p->pos - p->hash[                hash2Value];
+  delta3 = p->pos - p->hash[kFix3HashSize + hash3Value];
+  curMatch = p->hash[kFix4HashSize + hashValue];
+
+  p->hash[                hash2Value] =
+  p->hash[kFix3HashSize + hash3Value] =
+  p->hash[kFix4HashSize + hashValue] = p->pos;
+
+  maxLen = 1;
+  offset = 0;
+  if (delta2 < p->cyclicBufferSize && *(cur - delta2) == *cur)
+  {
+    distances[0] = maxLen = 2;
+    distances[1] = delta2 - 1;
+    offset = 2;
+  }
+  if (delta2 != delta3 && delta3 < p->cyclicBufferSize && *(cur - delta3) == *cur)
+  {
+    maxLen = 3;
+    distances[offset + 1] = delta3 - 1;
+    offset += 2;
+    delta2 = delta3;
+  }
+  if (offset != 0)
+  {
+    for (; maxLen != lenLimit; maxLen++)
+      if (cur[(ptrdiff_t)maxLen - delta2] != cur[maxLen])
+        break;
+    distances[offset - 2] = maxLen;
+    if (maxLen == lenLimit)
+    {
+      SkipMatchesSpec(lenLimit, curMatch, MF_PARAMS(p));
+      MOVE_POS_RET;
+    }
+  }
+  if (maxLen < 3)
+    maxLen = 3;
+  GET_MATCHES_FOOTER(offset, maxLen)
+}
+
+static uint32_t Hc4_MatchFinder_GetMatches(struct CMatchFinder *p, uint32_t *distances)
+{
+  uint32_t hash2Value, hash3Value, delta2, delta3, maxLen, offset;
+  GET_MATCHES_HEADER(4)
+
+  HASH4_CALC;
+
+  delta2 = p->pos - p->hash[                hash2Value];
+  delta3 = p->pos - p->hash[kFix3HashSize + hash3Value];
+  curMatch = p->hash[kFix4HashSize + hashValue];
+
+  p->hash[                hash2Value] =
+  p->hash[kFix3HashSize + hash3Value] =
+  p->hash[kFix4HashSize + hashValue] = p->pos;
+
+  maxLen = 1;
+  offset = 0;
+  if (delta2 < p->cyclicBufferSize && *(cur - delta2) == *cur)
+  {
+    distances[0] = maxLen = 2;
+    distances[1] = delta2 - 1;
+    offset = 2;
+  }
+  if (delta2 != delta3 && delta3 < p->cyclicBufferSize && *(cur - delta3) == *cur)
+  {
+    maxLen = 3;
+    distances[offset + 1] = delta3 - 1;
+    offset += 2;
+    delta2 = delta3;
+  }
+  if (offset != 0)
+  {
+    for (; maxLen != lenLimit; maxLen++)
+      if (cur[(ptrdiff_t)maxLen - delta2] != cur[maxLen])
+        break;
+    distances[offset - 2] = maxLen;
+    if (maxLen == lenLimit)
+    {
+      p->son[p->cyclicBufferPos] = curMatch;
+      MOVE_POS_RET;
+    }
+  }
+  if (maxLen < 3)
+    maxLen = 3;
+  offset = (uint32_t)(Hc_GetMatchesSpec(lenLimit, curMatch, MF_PARAMS(p),
+    distances + offset, maxLen) - (distances));
+  MOVE_POS_RET
+}
+
+uint32_t Hc3Zip_MatchFinder_GetMatches(struct CMatchFinder *p, uint32_t *distances)
+{
+  uint32_t offset;
+  GET_MATCHES_HEADER(3)
+  HASH_ZIP_CALC;
+  curMatch = p->hash[hashValue];
+  p->hash[hashValue] = p->pos;
+  offset = (uint32_t)(Hc_GetMatchesSpec(lenLimit, curMatch, MF_PARAMS(p),
+    distances, 2) - (distances));
+  MOVE_POS_RET
+}
+
+static void Bt2_MatchFinder_Skip(struct CMatchFinder *p, uint32_t num)
+{
+  do
+  {
+    SKIP_HEADER(2)
+    HASH2_CALC;
+    curMatch = p->hash[hashValue];
+    p->hash[hashValue] = p->pos;
+    SKIP_FOOTER
+  }
+  while (--num != 0);
+}
+
+void Bt3Zip_MatchFinder_Skip(struct CMatchFinder *p, uint32_t num)
+{
+  do
+  {
+    SKIP_HEADER(3)
+    HASH_ZIP_CALC;
+    curMatch = p->hash[hashValue];
+    p->hash[hashValue] = p->pos;
+    SKIP_FOOTER
+  }
+  while (--num != 0);
+}
+
+static void Bt3_MatchFinder_Skip(struct CMatchFinder *p, uint32_t num)
+{
+  do
+  {
+    uint32_t hash2Value;
+    SKIP_HEADER(3)
+    HASH3_CALC;
+    curMatch = p->hash[kFix3HashSize + hashValue];
+    p->hash[hash2Value] =
+    p->hash[kFix3HashSize + hashValue] = p->pos;
+    SKIP_FOOTER
+  }
+  while (--num != 0);
+}
+
+static void Bt4_MatchFinder_Skip(struct CMatchFinder *p, uint32_t num)
+{
+  do
+  {
+    uint32_t hash2Value, hash3Value;
+    SKIP_HEADER(4)
+    HASH4_CALC;
+    curMatch = p->hash[kFix4HashSize + hashValue];
+    p->hash[                hash2Value] =
+    p->hash[kFix3HashSize + hash3Value] = p->pos;
+    p->hash[kFix4HashSize + hashValue] = p->pos;
+    SKIP_FOOTER
+  }
+  while (--num != 0);
+}
+
+static void Hc4_MatchFinder_Skip(struct CMatchFinder *p, uint32_t num)
+{
+  do
+  {
+    uint32_t hash2Value, hash3Value;
+    SKIP_HEADER(4)
+    HASH4_CALC;
+    curMatch = p->hash[kFix4HashSize + hashValue];
+    p->hash[                hash2Value] =
+    p->hash[kFix3HashSize + hash3Value] =
+    p->hash[kFix4HashSize + hashValue] = p->pos;
+    p->son[p->cyclicBufferPos] = curMatch;
+    MOVE_POS
+  }
+  while (--num != 0);
+}
+
+void Hc3Zip_MatchFinder_Skip(struct CMatchFinder *p, uint32_t num)
+{
+  do
+  {
+    SKIP_HEADER(3)
+    HASH_ZIP_CALC;
+    curMatch = p->hash[hashValue];
+    p->hash[hashValue] = p->pos;
+    p->son[p->cyclicBufferPos] = curMatch;
+    MOVE_POS
+  }
+  while (--num != 0);
+}
+
+void MatchFinder_CreateVTable(struct CMatchFinder *p, struct IMatchFinder *vTable)
+{
+  vTable->Init = (Mf_Init_Func)MatchFinder_Init;
+  vTable->GetIndexByte = (Mf_GetIndexByte_Func)MatchFinder_GetIndexByte;
+  vTable->GetNumAvailableBytes = (Mf_GetNumAvailableBytes_Func)MatchFinder_GetNumAvailableBytes;
+  vTable->GetPointerToCurrentPos = (Mf_GetPointerToCurrentPos_Func)MatchFinder_GetPointerToCurrentPos;
+  if (!p->btMode)
+  {
+    vTable->GetMatches = (Mf_GetMatches_Func)Hc4_MatchFinder_GetMatches;
+    vTable->Skip = (Mf_Skip_Func)Hc4_MatchFinder_Skip;
+  }
+  else if (p->numHashBytes == 2)
+  {
+    vTable->GetMatches = (Mf_GetMatches_Func)Bt2_MatchFinder_GetMatches;
+    vTable->Skip = (Mf_Skip_Func)Bt2_MatchFinder_Skip;
+  }
+  else if (p->numHashBytes == 3)
+  {
+    vTable->GetMatches = (Mf_GetMatches_Func)Bt3_MatchFinder_GetMatches;
+    vTable->Skip = (Mf_Skip_Func)Bt3_MatchFinder_Skip;
+  }
+  else
+  {
+    vTable->GetMatches = (Mf_GetMatches_Func)Bt4_MatchFinder_GetMatches;
+    vTable->Skip = (Mf_Skip_Func)Bt4_MatchFinder_Skip;
+  }
+}
diff --git a/tools/cbfstool/LzmaDec.c b/tools/cbfstool/LzmaDec.c
new file mode 100644
index 0000000000..bef1a3bf50
--- /dev/null
+++ b/tools/cbfstool/LzmaDec.c
@@ -0,0 +1,993 @@
+/* LzmaDec.c -- LZMA Decoder
+2009-09-20 : Igor Pavlov : Public domain */
+
+#include "lzma/C/LzmaDec.h"
+
+#include <string.h>
+
+#define kNumTopBits 24
+#define kTopValue ((uint32_t)1 << kNumTopBits)
+
+#define kNumBitModelTotalBits 11
+#define kBitModelTotal (1 << kNumBitModelTotalBits)
+#define kNumMoveBits 5
+
+#define RC_INIT_SIZE 5
+
+#define NORMALIZE if (range < kTopValue) { range <<= 8; code = (code << 8) | (*buf++); }
+
+#define IF_BIT_0(p) ttt = *(p); NORMALIZE; bound = (range >> kNumBitModelTotalBits) * ttt; if (code < bound)
+#define UPDATE_0(p) range = bound; *(p) = (CLzmaProb)(ttt + ((kBitModelTotal - ttt) >> kNumMoveBits));
+#define UPDATE_1(p) range -= bound; code -= bound; *(p) = (CLzmaProb)(ttt - (ttt >> kNumMoveBits));
+#define GET_BIT2(p, i, A0, A1) IF_BIT_0(p) \
+  { UPDATE_0(p); i = (i + i); A0; } else \
+  { UPDATE_1(p); i = (i + i) + 1; A1; }
+#define GET_BIT(p, i) GET_BIT2(p, i, ; , ;)
+
+#define TREE_GET_BIT(probs, i) { GET_BIT((probs + i), i); }
+#define TREE_DECODE(probs, limit, i) \
+  { i = 1; do { TREE_GET_BIT(probs, i); } while (i < limit); i -= limit; }
+
+#define TREE_6_DECODE(probs, i) \
+  { i = 1; \
+  TREE_GET_BIT(probs, i); \
+  TREE_GET_BIT(probs, i); \
+  TREE_GET_BIT(probs, i); \
+  TREE_GET_BIT(probs, i); \
+  TREE_GET_BIT(probs, i); \
+  TREE_GET_BIT(probs, i); \
+  i -= 0x40; }
+
+#define NORMALIZE_CHECK if (range < kTopValue) { if (buf >= bufLimit) return DUMMY_ERROR; range <<= 8; code = (code << 8) | (*buf++); }
+
+#define IF_BIT_0_CHECK(p) ttt = *(p); NORMALIZE_CHECK; bound = (range >> kNumBitModelTotalBits) * ttt; if (code < bound)
+#define UPDATE_0_CHECK range = bound;
+#define UPDATE_1_CHECK range -= bound; code -= bound;
+#define GET_BIT2_CHECK(p, i, A0, A1) IF_BIT_0_CHECK(p) \
+  { UPDATE_0_CHECK; i = (i + i); A0; } else \
+  { UPDATE_1_CHECK; i = (i + i) + 1; A1; }
+#define GET_BIT_CHECK(p, i) GET_BIT2_CHECK(p, i, ; , ;)
+#define TREE_DECODE_CHECK(probs, limit, i) \
+  { i = 1; do { GET_BIT_CHECK(probs + i, i) } while (i < limit); i -= limit; }
+
+
+#define kNumPosBitsMax 4
+#define kNumPosStatesMax (1 << kNumPosBitsMax)
+
+#define kLenNumLowBits 3
+#define kLenNumLowSymbols (1 << kLenNumLowBits)
+#define kLenNumMidBits 3
+#define kLenNumMidSymbols (1 << kLenNumMidBits)
+#define kLenNumHighBits 8
+#define kLenNumHighSymbols (1 << kLenNumHighBits)
+
+#define LenChoice 0
+#define LenChoice2 (LenChoice + 1)
+#define LenLow (LenChoice2 + 1)
+#define LenMid (LenLow + (kNumPosStatesMax << kLenNumLowBits))
+#define LenHigh (LenMid + (kNumPosStatesMax << kLenNumMidBits))
+#define kNumLenProbs (LenHigh + kLenNumHighSymbols)
+
+
+#define kNumStates 12
+#define kNumLitStates 7
+
+#define kStartPosModelIndex 4
+#define kEndPosModelIndex 14
+#define kNumFullDistances (1 << (kEndPosModelIndex >> 1))
+
+#define kNumPosSlotBits 6
+#define kNumLenToPosStates 4
+
+#define kNumAlignBits 4
+#define kAlignTableSize (1 << kNumAlignBits)
+
+#define kMatchMinLen 2
+#define kMatchSpecLenStart (kMatchMinLen + kLenNumLowSymbols + kLenNumMidSymbols + kLenNumHighSymbols)
+
+#define IsMatch 0
+#define IsRep (IsMatch + (kNumStates << kNumPosBitsMax))
+#define IsRepG0 (IsRep + kNumStates)
+#define IsRepG1 (IsRepG0 + kNumStates)
+#define IsRepG2 (IsRepG1 + kNumStates)
+#define IsRep0Long (IsRepG2 + kNumStates)
+#define PosSlot (IsRep0Long + (kNumStates << kNumPosBitsMax))
+#define SpecPos (PosSlot + (kNumLenToPosStates << kNumPosSlotBits))
+#define Align (SpecPos + kNumFullDistances - kEndPosModelIndex)
+#define LenCoder (Align + kAlignTableSize)
+#define RepLenCoder (LenCoder + kNumLenProbs)
+#define Literal (RepLenCoder + kNumLenProbs)
+
+#define LZMA_BASE_SIZE 1846
+#define LZMA_LIT_SIZE 768
+
+#define LzmaProps_GetNumProbs(p) ((uint32_t)LZMA_BASE_SIZE + (LZMA_LIT_SIZE << ((p)->lc + (p)->lp)))
+
+#if Literal != LZMA_BASE_SIZE
+StopCompilingDueBUG
+#endif
+
+#define LZMA_DIC_MIN (1 << 12)
+
+/* First LZMA-symbol is always decoded.
+And it decodes new LZMA-symbols while (buf < bufLimit), but "buf" is without last normalization
+Out:
+  Result:
+    SZ_OK - OK
+    SZ_ERROR_DATA - Error
+  p->remainLen:
+    < kMatchSpecLenStart : normal remain
+    = kMatchSpecLenStart : finished
+    = kMatchSpecLenStart + 1 : Flush marker
+    = kMatchSpecLenStart + 2 : State Init Marker
+*/
+
+static int LzmaDec_DecodeReal(struct CLzmaDec *p, size_t limit_parm, const uint8_t *bufLimit)
+{
+  CLzmaProb *probs = p->probs;
+
+  unsigned state = p->state;
+  uint32_t rep0 = p->reps[0], rep1 = p->reps[1], rep2 = p->reps[2], rep3 = p->reps[3];
+  unsigned pbMask = ((unsigned)1 << (p->prop.pb)) - 1;
+  unsigned lpMask = ((unsigned)1 << (p->prop.lp)) - 1;
+  unsigned lc = p->prop.lc;
+
+  uint8_t *dic = p->dic;
+  size_t dicBufSize = p->dicBufSize;
+  size_t dicPos = p->dicPos;
+
+  uint32_t processedPos = p->processedPos;
+  uint32_t checkDicSize = p->checkDicSize;
+  unsigned len = 0;
+
+  const uint8_t *buf = p->buf;
+  uint32_t range = p->range;
+  uint32_t code = p->code;
+
+  do
+  {
+    CLzmaProb *prob;
+    uint32_t bound;
+    unsigned ttt;
+    unsigned posState = processedPos & pbMask;
+
+    prob = probs + IsMatch + (state << kNumPosBitsMax) + posState;
+    IF_BIT_0(prob)
+    {
+      unsigned symbol;
+      UPDATE_0(prob);
+      prob = probs + Literal;
+      if (checkDicSize != 0 || processedPos != 0)
+        prob += (LZMA_LIT_SIZE * (((processedPos & lpMask) << lc) +
+        (dic[(dicPos == 0 ? dicBufSize : dicPos) - 1] >> (8 - lc))));
+
+      if (state < kNumLitStates)
+      {
+        state -= (state < 4) ? state : 3;
+        symbol = 1;
+        do { GET_BIT(prob + symbol, symbol) } while (symbol < 0x100);
+      }
+      else
+      {
+        unsigned matchuint8_t = p->dic[(dicPos - rep0) + ((dicPos < rep0) ? dicBufSize : 0)];
+        unsigned offs = 0x100;
+        state -= (state < 10) ? 3 : 6;
+        symbol = 1;
+        do
+        {
+          unsigned bit;
+          CLzmaProb *probLit;
+          matchuint8_t <<= 1;
+          bit = (matchuint8_t & offs);
+          probLit = prob + offs + bit + symbol;
+          GET_BIT2(probLit, symbol, offs &= ~bit, offs &= bit)
+        }
+        while (symbol < 0x100);
+      }
+      dic[dicPos++] = (uint8_t)symbol;
+      processedPos++;
+      continue;
+    }
+    else
+    {
+      UPDATE_1(prob);
+      prob = probs + IsRep + state;
+      IF_BIT_0(prob)
+      {
+        UPDATE_0(prob);
+        state += kNumStates;
+        prob = probs + LenCoder;
+      }
+      else
+      {
+        UPDATE_1(prob);
+        if (checkDicSize == 0 && processedPos == 0)
+          return SZ_ERROR_DATA;
+        prob = probs + IsRepG0 + state;
+        IF_BIT_0(prob)
+        {
+          UPDATE_0(prob);
+          prob = probs + IsRep0Long + (state << kNumPosBitsMax) + posState;
+          IF_BIT_0(prob)
+          {
+            UPDATE_0(prob);
+            dic[dicPos] = dic[(dicPos - rep0) + ((dicPos < rep0) ? dicBufSize : 0)];
+            dicPos++;
+            processedPos++;
+            state = state < kNumLitStates ? 9 : 11;
+            continue;
+          }
+          UPDATE_1(prob);
+        }
+        else
+        {
+          uint32_t distance;
+          UPDATE_1(prob);
+          prob = probs + IsRepG1 + state;
+          IF_BIT_0(prob)
+          {
+            UPDATE_0(prob);
+            distance = rep1;
+          }
+          else
+          {
+            UPDATE_1(prob);
+            prob = probs + IsRepG2 + state;
+            IF_BIT_0(prob)
+            {
+              UPDATE_0(prob);
+              distance = rep2;
+            }
+            else
+            {
+              UPDATE_1(prob);
+              distance = rep3;
+              rep3 = rep2;
+            }
+            rep2 = rep1;
+          }
+          rep1 = rep0;
+          rep0 = distance;
+        }
+        state = state < kNumLitStates ? 8 : 11;
+        prob = probs + RepLenCoder;
+      }
+      {
+        unsigned limit, offset;
+        CLzmaProb *probLen = prob + LenChoice;
+        IF_BIT_0(probLen)
+        {
+          UPDATE_0(probLen);
+          probLen = prob + LenLow + (posState << kLenNumLowBits);
+          offset = 0;
+          limit = (1 << kLenNumLowBits);
+        }
+        else
+        {
+          UPDATE_1(probLen);
+          probLen = prob + LenChoice2;
+          IF_BIT_0(probLen)
+          {
+            UPDATE_0(probLen);
+            probLen = prob + LenMid + (posState << kLenNumMidBits);
+            offset = kLenNumLowSymbols;
+            limit = (1 << kLenNumMidBits);
+          }
+          else
+          {
+            UPDATE_1(probLen);
+            probLen = prob + LenHigh;
+            offset = kLenNumLowSymbols + kLenNumMidSymbols;
+            limit = (1 << kLenNumHighBits);
+          }
+        }
+        TREE_DECODE(probLen, limit, len);
+        len += offset;
+      }
+
+      if (state >= kNumStates)
+      {
+        uint32_t distance;
+        prob = probs + PosSlot +
+            ((len < kNumLenToPosStates ? len : kNumLenToPosStates - 1) << kNumPosSlotBits);
+        TREE_6_DECODE(prob, distance);
+        if (distance >= kStartPosModelIndex)
+        {
+          unsigned posSlot = (unsigned)distance;
+          int numDirectBits = (int)(((distance >> 1) - 1));
+          distance = (2 | (distance & 1));
+          if (posSlot < kEndPosModelIndex)
+          {
+            distance <<= numDirectBits;
+            prob = probs + SpecPos + distance - posSlot - 1;
+            {
+              uint32_t mask = 1;
+              unsigned i = 1;
+              do
+              {
+                GET_BIT2(prob + i, i, ; , distance |= mask);
+                mask <<= 1;
+              }
+              while (--numDirectBits != 0);
+            }
+          }
+          else
+          {
+            numDirectBits -= kNumAlignBits;
+            do
+            {
+              NORMALIZE
+              range >>= 1;
+
+              {
+                uint32_t t;
+                code -= range;
+                t = (0 - ((uint32_t)code >> 31)); /* (uint32_t)((int32_t)code >> 31) */
+                distance = (distance << 1) + (t + 1);
+                code += range & t;
+              }
+              /*
+              distance <<= 1;
+              if (code >= range)
+              {
+                code -= range;
+                distance |= 1;
+              }
+              */
+            }
+            while (--numDirectBits != 0);
+            prob = probs + Align;
+            distance <<= kNumAlignBits;
+            {
+              unsigned i = 1;
+              GET_BIT2(prob + i, i, ; , distance |= 1);
+              GET_BIT2(prob + i, i, ; , distance |= 2);
+              GET_BIT2(prob + i, i, ; , distance |= 4);
+              GET_BIT2(prob + i, i, ; , distance |= 8);
+            }
+            if (distance == (uint32_t)0xFFFFFFFF)
+            {
+              len += kMatchSpecLenStart;
+              state -= kNumStates;
+              break;
+            }
+          }
+        }
+        rep3 = rep2;
+        rep2 = rep1;
+        rep1 = rep0;
+        rep0 = distance + 1;
+        if (checkDicSize == 0)
+        {
+          if (distance >= processedPos)
+            return SZ_ERROR_DATA;
+        }
+        else if (distance >= checkDicSize)
+          return SZ_ERROR_DATA;
+        state = (state < kNumStates + kNumLitStates) ? kNumLitStates : kNumLitStates + 3;
+      }
+
+      len += kMatchMinLen;
+
+      if (limit_parm == dicPos)
+        return SZ_ERROR_DATA;
+      {
+        size_t rem = limit_parm - dicPos;
+        unsigned curLen = ((rem < len) ? (unsigned)rem : len);
+        size_t pos = (dicPos - rep0) + ((dicPos < rep0) ? dicBufSize : 0);
+
+        processedPos += curLen;
+
+        len -= curLen;
+        if (pos + curLen <= dicBufSize)
+        {
+          uint8_t *dest = dic + dicPos;
+          ptrdiff_t src = (ptrdiff_t)pos - (ptrdiff_t)dicPos;
+          const uint8_t *lim = dest + curLen;
+          dicPos += curLen;
+          do
+            *(dest) = (uint8_t)*(dest + src);
+          while (++dest != lim);
+        }
+        else
+        {
+          do
+          {
+            dic[dicPos++] = dic[pos];
+            if (++pos == dicBufSize)
+              pos = 0;
+          }
+          while (--curLen != 0);
+        }
+      }
+    }
+  }
+  while (dicPos < limit_parm && buf < bufLimit);
+  NORMALIZE;
+  p->buf = buf;
+  p->range = range;
+  p->code = code;
+  p->remainLen = len;
+  p->dicPos = dicPos;
+  p->processedPos = processedPos;
+  p->reps[0] = rep0;
+  p->reps[1] = rep1;
+  p->reps[2] = rep2;
+  p->reps[3] = rep3;
+  p->state = state;
+
+  return SZ_OK;
+}
+
+static void LzmaDec_WriteRem(struct CLzmaDec *p, size_t limit)
+{
+  if (p->remainLen != 0 && p->remainLen < kMatchSpecLenStart)
+  {
+    uint8_t *dic = p->dic;
+    size_t dicPos = p->dicPos;
+    size_t dicBufSize = p->dicBufSize;
+    unsigned len = p->remainLen;
+    uint32_t rep0 = p->reps[0];
+    if (limit - dicPos < len)
+      len = (unsigned)(limit - dicPos);
+
+    if (p->checkDicSize == 0 && p->prop.dicSize - p->processedPos <= len)
+      p->checkDicSize = p->prop.dicSize;
+
+    p->processedPos += len;
+    p->remainLen -= len;
+    while (len-- != 0)
+    {
+      dic[dicPos] = dic[(dicPos - rep0) + ((dicPos < rep0) ? dicBufSize : 0)];
+      dicPos++;
+    }
+    p->dicPos = dicPos;
+  }
+}
+
+static int LzmaDec_DecodeReal2(struct CLzmaDec *p, size_t limit, const uint8_t *bufLimit)
+{
+  do
+  {
+    size_t limit2 = limit;
+    if (p->checkDicSize == 0)
+    {
+      uint32_t rem = p->prop.dicSize - p->processedPos;
+      if (limit - p->dicPos > rem)
+        limit2 = p->dicPos + rem;
+    }
+    RINOK(LzmaDec_DecodeReal(p, limit2, bufLimit));
+    if (p->processedPos >= p->prop.dicSize)
+      p->checkDicSize = p->prop.dicSize;
+    LzmaDec_WriteRem(p, limit);
+  }
+  while (p->dicPos < limit && p->buf < bufLimit && p->remainLen < kMatchSpecLenStart);
+
+  if (p->remainLen > kMatchSpecLenStart)
+  {
+    p->remainLen = kMatchSpecLenStart;
+  }
+  return 0;
+}
+
+enum ELzmaDummy
+{
+  DUMMY_ERROR, /* unexpected end of input stream */
+  DUMMY_LIT,
+  DUMMY_MATCH,
+  DUMMY_REP
+};
+
+static enum ELzmaDummy LzmaDec_TryDummy(const struct CLzmaDec *p, const uint8_t *buf, size_t inSize)
+{
+  uint32_t range = p->range;
+  uint32_t code = p->code;
+  const uint8_t *bufLimit = buf + inSize;
+  CLzmaProb *probs = p->probs;
+  unsigned state = p->state;
+  enum ELzmaDummy res;
+
+  {
+    CLzmaProb *prob;
+    uint32_t bound;
+    unsigned ttt;
+    unsigned posState = (p->processedPos) & ((1 << p->prop.pb) - 1);
+
+    prob = probs + IsMatch + (state << kNumPosBitsMax) + posState;
+    IF_BIT_0_CHECK(prob)
+    {
+      UPDATE_0_CHECK
+
+      /* if (bufLimit - buf >= 7) return DUMMY_LIT; */
+
+      prob = probs + Literal;
+      if (p->checkDicSize != 0 || p->processedPos != 0)
+        prob += (LZMA_LIT_SIZE *
+          ((((p->processedPos) & ((1 << (p->prop.lp)) - 1)) << p->prop.lc) +
+          (p->dic[(p->dicPos == 0 ? p->dicBufSize : p->dicPos) - 1] >> (8 - p->prop.lc))));
+
+      if (state < kNumLitStates)
+      {
+        unsigned symbol = 1;
+        do { GET_BIT_CHECK(prob + symbol, symbol) } while (symbol < 0x100);
+      }
+      else
+      {
+        unsigned matchuint8_t = p->dic[p->dicPos - p->reps[0] +
+            ((p->dicPos < p->reps[0]) ? p->dicBufSize : 0)];
+        unsigned offs = 0x100;
+        unsigned symbol = 1;
+        do
+        {
+          unsigned bit;
+          CLzmaProb *probLit;
+          matchuint8_t <<= 1;
+          bit = (matchuint8_t & offs);
+          probLit = prob + offs + bit + symbol;
+          GET_BIT2_CHECK(probLit, symbol, offs &= ~bit, offs &= bit)
+        }
+        while (symbol < 0x100);
+      }
+      res = DUMMY_LIT;
+    }
+    else
+    {
+      unsigned len;
+      UPDATE_1_CHECK;
+
+      prob = probs + IsRep + state;
+      IF_BIT_0_CHECK(prob)
+      {
+        UPDATE_0_CHECK;
+        state = 0;
+        prob = probs + LenCoder;
+        res = DUMMY_MATCH;
+      }
+      else
+      {
+        UPDATE_1_CHECK;
+        res = DUMMY_REP;
+        prob = probs + IsRepG0 + state;
+        IF_BIT_0_CHECK(prob)
+        {
+          UPDATE_0_CHECK;
+          prob = probs + IsRep0Long + (state << kNumPosBitsMax) + posState;
+          IF_BIT_0_CHECK(prob)
+          {
+            UPDATE_0_CHECK;
+            NORMALIZE_CHECK;
+            return DUMMY_REP;
+          }
+          else
+          {
+            UPDATE_1_CHECK;
+          }
+        }
+        else
+        {
+          UPDATE_1_CHECK;
+          prob = probs + IsRepG1 + state;
+          IF_BIT_0_CHECK(prob)
+          {
+            UPDATE_0_CHECK;
+          }
+          else
+          {
+            UPDATE_1_CHECK;
+            prob = probs + IsRepG2 + state;
+            IF_BIT_0_CHECK(prob)
+            {
+              UPDATE_0_CHECK;
+            }
+            else
+            {
+              UPDATE_1_CHECK;
+            }
+          }
+        }
+        state = kNumStates;
+        prob = probs + RepLenCoder;
+      }
+      {
+        unsigned limit, offset;
+        CLzmaProb *probLen = prob + LenChoice;
+        IF_BIT_0_CHECK(probLen)
+        {
+          UPDATE_0_CHECK;
+          probLen = prob + LenLow + (posState << kLenNumLowBits);
+          offset = 0;
+          limit = 1 << kLenNumLowBits;
+        }
+        else
+        {
+          UPDATE_1_CHECK;
+          probLen = prob + LenChoice2;
+          IF_BIT_0_CHECK(probLen)
+          {
+            UPDATE_0_CHECK;
+            probLen = prob + LenMid + (posState << kLenNumMidBits);
+            offset = kLenNumLowSymbols;
+            limit = 1 << kLenNumMidBits;
+          }
+          else
+          {
+            UPDATE_1_CHECK;
+            probLen = prob + LenHigh;
+            offset = kLenNumLowSymbols + kLenNumMidSymbols;
+            limit = 1 << kLenNumHighBits;
+          }
+        }
+        TREE_DECODE_CHECK(probLen, limit, len);
+        len += offset;
+      }
+
+      if (state < 4)
+      {
+        unsigned posSlot;
+        prob = probs + PosSlot +
+            ((len < kNumLenToPosStates ? len : kNumLenToPosStates - 1) <<
+            kNumPosSlotBits);
+        TREE_DECODE_CHECK(prob, 1 << kNumPosSlotBits, posSlot);
+        if (posSlot >= kStartPosModelIndex)
+        {
+          int numDirectBits = ((posSlot >> 1) - 1);
+
+          /* if (bufLimit - buf >= 8) return DUMMY_MATCH; */
+
+          if (posSlot < kEndPosModelIndex)
+          {
+            prob = probs + SpecPos + ((2 | (posSlot & 1)) << numDirectBits) - posSlot - 1;
+          }
+          else
+          {
+            numDirectBits -= kNumAlignBits;
+            do
+            {
+              NORMALIZE_CHECK
+              range >>= 1;
+              code -= range & (((code - range) >> 31) - 1);
+              /* if (code >= range) code -= range; */
+            }
+            while (--numDirectBits != 0);
+            prob = probs + Align;
+            numDirectBits = kNumAlignBits;
+          }
+          {
+            unsigned i = 1;
+            do
+            {
+              GET_BIT_CHECK(prob + i, i);
+            }
+            while (--numDirectBits != 0);
+          }
+        }
+      }
+    }
+  }
+  NORMALIZE_CHECK;
+  return res;
+}
+
+
+static void LzmaDec_InitRc(struct CLzmaDec *p, const uint8_t *data)
+{
+  p->code = ((uint32_t)data[1] << 24) | ((uint32_t)data[2] << 16) | ((uint32_t)data[3] << 8) | ((uint32_t)data[4]);
+  p->range = 0xFFFFFFFF;
+  p->needFlush = 0;
+}
+
+static void LzmaDec_InitDicAndState(struct CLzmaDec *p, bool initDic, bool initState)
+{
+  p->needFlush = 1;
+  p->remainLen = 0;
+  p->tempBufSize = 0;
+
+  if (initDic)
+  {
+    p->processedPos = 0;
+    p->checkDicSize = 0;
+    p->needInitState = 1;
+  }
+  if (initState)
+    p->needInitState = 1;
+}
+
+void LzmaDec_Init(struct CLzmaDec *p)
+{
+  p->dicPos = 0;
+  LzmaDec_InitDicAndState(p, true, true);
+}
+
+static void LzmaDec_InitStateReal(struct CLzmaDec *p)
+{
+  uint32_t numProbs = Literal + ((uint32_t)LZMA_LIT_SIZE << (p->prop.lc + p->prop.lp));
+  uint32_t i;
+  CLzmaProb *probs = p->probs;
+  for (i = 0; i < numProbs; i++)
+    probs[i] = kBitModelTotal >> 1;
+  p->reps[0] = p->reps[1] = p->reps[2] = p->reps[3] = 1;
+  p->state = 0;
+  p->needInitState = 0;
+}
+
+SRes LzmaDec_DecodeToDic(struct CLzmaDec *p, size_t dicLimit, const uint8_t *src, size_t *srcLen,
+    enum ELzmaFinishMode finishMode, enum ELzmaStatus *status)
+{
+  size_t inSize = *srcLen;
+  (*srcLen) = 0;
+  LzmaDec_WriteRem(p, dicLimit);
+
+  *status = LZMA_STATUS_NOT_SPECIFIED;
+
+  while (p->remainLen != kMatchSpecLenStart)
+  {
+      int checkEndMarkNow;
+
+      if (p->needFlush != 0)
+      {
+        for (; inSize > 0 && p->tempBufSize < RC_INIT_SIZE; (*srcLen)++, inSize--)
+          p->tempBuf[p->tempBufSize++] = *src++;
+        if (p->tempBufSize < RC_INIT_SIZE)
+        {
+          *status = LZMA_STATUS_NEEDS_MORE_INPUT;
+          return SZ_OK;
+        }
+        if (p->tempBuf[0] != 0)
+          return SZ_ERROR_DATA;
+
+        LzmaDec_InitRc(p, p->tempBuf);
+        p->tempBufSize = 0;
+      }
+
+      checkEndMarkNow = 0;
+      if (p->dicPos >= dicLimit)
+      {
+        if (p->remainLen == 0 && p->code == 0)
+        {
+          *status = LZMA_STATUS_MAYBE_FINISHED_WITHOUT_MARK;
+          return SZ_OK;
+        }
+        if (finishMode == LZMA_FINISH_ANY)
+        {
+          *status = LZMA_STATUS_NOT_FINISHED;
+          return SZ_OK;
+        }
+        if (p->remainLen != 0)
+        {
+          *status = LZMA_STATUS_NOT_FINISHED;
+          return SZ_ERROR_DATA;
+        }
+        checkEndMarkNow = 1;
+      }
+
+      if (p->needInitState)
+        LzmaDec_InitStateReal(p);
+
+      if (p->tempBufSize == 0)
+      {
+        size_t processed;
+        const uint8_t *bufLimit;
+        if (inSize < LZMA_REQUIRED_INPUT_MAX || checkEndMarkNow)
+        {
+          int dummyRes = LzmaDec_TryDummy(p, src, inSize);
+          if (dummyRes == DUMMY_ERROR)
+          {
+            memcpy(p->tempBuf, src, inSize);
+            p->tempBufSize = (unsigned)inSize;
+            (*srcLen) += inSize;
+            *status = LZMA_STATUS_NEEDS_MORE_INPUT;
+            return SZ_OK;
+          }
+          if (checkEndMarkNow && dummyRes != DUMMY_MATCH)
+          {
+            *status = LZMA_STATUS_NOT_FINISHED;
+            return SZ_ERROR_DATA;
+          }
+          bufLimit = src;
+        }
+        else
+          bufLimit = src + inSize - LZMA_REQUIRED_INPUT_MAX;
+        p->buf = src;
+        if (LzmaDec_DecodeReal2(p, dicLimit, bufLimit) != 0)
+          return SZ_ERROR_DATA;
+        processed = (size_t)(p->buf - src);
+        (*srcLen) += processed;
+        src += processed;
+        inSize -= processed;
+      }
+      else
+      {
+        unsigned rem = p->tempBufSize, lookAhead = 0;
+        while (rem < LZMA_REQUIRED_INPUT_MAX && lookAhead < inSize)
+          p->tempBuf[rem++] = src[lookAhead++];
+        p->tempBufSize = rem;
+        if (rem < LZMA_REQUIRED_INPUT_MAX || checkEndMarkNow)
+        {
+          int dummyRes = LzmaDec_TryDummy(p, p->tempBuf, rem);
+          if (dummyRes == DUMMY_ERROR)
+          {
+            (*srcLen) += lookAhead;
+            *status = LZMA_STATUS_NEEDS_MORE_INPUT;
+            return SZ_OK;
+          }
+          if (checkEndMarkNow && dummyRes != DUMMY_MATCH)
+          {
+            *status = LZMA_STATUS_NOT_FINISHED;
+            return SZ_ERROR_DATA;
+          }
+        }
+        p->buf = p->tempBuf;
+        if (LzmaDec_DecodeReal2(p, dicLimit, p->buf) != 0)
+          return SZ_ERROR_DATA;
+        lookAhead -= (rem - (unsigned)(p->buf - p->tempBuf));
+        (*srcLen) += lookAhead;
+        src += lookAhead;
+        inSize -= lookAhead;
+        p->tempBufSize = 0;
+      }
+  }
+  if (p->code == 0)
+    *status = LZMA_STATUS_FINISHED_WITH_MARK;
+  return (p->code == 0) ? SZ_OK : SZ_ERROR_DATA;
+}
+
+SRes LzmaDec_DecodeToBuf(struct CLzmaDec *p, uint8_t *dest, size_t *destLen, const uint8_t *src, size_t *srcLen, enum ELzmaFinishMode finishMode, enum ELzmaStatus *status)
+{
+  size_t outSize = *destLen;
+  size_t inSize = *srcLen;
+  *srcLen = *destLen = 0;
+  for (;;)
+  {
+    size_t inSizeCur = inSize, outSizeCur, dicPos;
+    enum ELzmaFinishMode curFinishMode;
+    SRes res;
+    if (p->dicPos == p->dicBufSize)
+      p->dicPos = 0;
+    dicPos = p->dicPos;
+    if (outSize > p->dicBufSize - dicPos)
+    {
+      outSizeCur = p->dicBufSize;
+      curFinishMode = LZMA_FINISH_ANY;
+    }
+    else
+    {
+      outSizeCur = dicPos + outSize;
+      curFinishMode = finishMode;
+    }
+
+    res = LzmaDec_DecodeToDic(p, outSizeCur, src, &inSizeCur, curFinishMode, status);
+    src += inSizeCur;
+    inSize -= inSizeCur;
+    *srcLen += inSizeCur;
+    outSizeCur = p->dicPos - dicPos;
+    memcpy(dest, p->dic + dicPos, outSizeCur);
+    dest += outSizeCur;
+    outSize -= outSizeCur;
+    *destLen += outSizeCur;
+    if (res != 0)
+      return res;
+    if (outSizeCur == 0 || outSize == 0)
+      return SZ_OK;
+  }
+}
+
+void LzmaDec_FreeProbs(struct CLzmaDec *p, struct ISzAlloc *alloc)
+{
+  alloc->Free(alloc, p->probs);
+  p->probs = 0;
+}
+
+static void LzmaDec_FreeDict(struct CLzmaDec *p, struct ISzAlloc *alloc)
+{
+  alloc->Free(alloc, p->dic);
+  p->dic = 0;
+}
+
+void LzmaDec_Free(struct CLzmaDec *p, struct ISzAlloc *alloc)
+{
+  LzmaDec_FreeProbs(p, alloc);
+  LzmaDec_FreeDict(p, alloc);
+}
+
+SRes LzmaProps_Decode(struct CLzmaProps *p, const uint8_t *data, unsigned size)
+{
+  uint32_t dicSize;
+  uint8_t d;
+
+  if (size < LZMA_PROPS_SIZE)
+    return SZ_ERROR_UNSUPPORTED;
+  else
+    dicSize = data[1] | ((uint32_t)data[2] << 8) | ((uint32_t)data[3] << 16) | ((uint32_t)data[4] << 24);
+
+  if (dicSize < LZMA_DIC_MIN)
+    dicSize = LZMA_DIC_MIN;
+  p->dicSize = dicSize;
+
+  d = data[0];
+  if (d >= (9 * 5 * 5))
+    return SZ_ERROR_UNSUPPORTED;
+
+  p->lc = d % 9;
+  d /= 9;
+  p->pb = d / 5;
+  p->lp = d % 5;
+
+  return SZ_OK;
+}
+
+static SRes LzmaDec_AllocateProbs2(struct CLzmaDec *p, const struct CLzmaProps *propNew, struct ISzAlloc *alloc)
+{
+  uint32_t numProbs = LzmaProps_GetNumProbs(propNew);
+  if (p->probs == 0 || numProbs != p->numProbs)
+  {
+    LzmaDec_FreeProbs(p, alloc);
+    p->probs = (CLzmaProb *)alloc->Alloc(alloc, numProbs * sizeof(CLzmaProb));
+    p->numProbs = numProbs;
+    if (p->probs == 0)
+      return SZ_ERROR_MEM;
+  }
+  return SZ_OK;
+}
+
+SRes LzmaDec_AllocateProbs(struct CLzmaDec *p, const uint8_t *props, unsigned propsSize, struct ISzAlloc *alloc)
+{
+  struct CLzmaProps propNew;
+  RINOK(LzmaProps_Decode(&propNew, props, propsSize));
+  RINOK(LzmaDec_AllocateProbs2(p, &propNew, alloc));
+  p->prop = propNew;
+  return SZ_OK;
+}
+
+SRes LzmaDec_Allocate(struct CLzmaDec *p, const uint8_t *props, unsigned propsSize, struct ISzAlloc *alloc)
+{
+  struct CLzmaProps propNew;
+  size_t dicBufSize;
+  RINOK(LzmaProps_Decode(&propNew, props, propsSize));
+  RINOK(LzmaDec_AllocateProbs2(p, &propNew, alloc));
+  dicBufSize = propNew.dicSize;
+  if (p->dic == 0 || dicBufSize != p->dicBufSize)
+  {
+    LzmaDec_FreeDict(p, alloc);
+    p->dic = (uint8_t *)alloc->Alloc(alloc, dicBufSize);
+    if (p->dic == 0)
+    {
+      LzmaDec_FreeProbs(p, alloc);
+      return SZ_ERROR_MEM;
+    }
+  }
+  p->dicBufSize = dicBufSize;
+  p->prop = propNew;
+  return SZ_OK;
+}
+
+SRes LzmaDecode(uint8_t *dest, size_t *destLen, const uint8_t *src, size_t *srcLen,
+    const uint8_t *propData, unsigned propSize, enum ELzmaFinishMode finishMode,
+    enum ELzmaStatus *status, struct ISzAlloc *alloc)
+{
+  struct CLzmaDec p;
+  SRes res;
+  size_t inSize = *srcLen;
+  size_t outSize = *destLen;
+  *srcLen = *destLen = 0;
+  if (inSize < RC_INIT_SIZE)
+    return SZ_ERROR_INPUT_EOF;
+
+  LzmaDec_Construct(&p);
+  res = LzmaDec_AllocateProbs(&p, propData, propSize, alloc);
+  if (res != 0)
+    return res;
+  p.dic = dest;
+  p.dicBufSize = outSize;
+
+  LzmaDec_Init(&p);
+
+  *srcLen = inSize;
+  res = LzmaDec_DecodeToDic(&p, outSize, src, srcLen, finishMode, status);
+
+  if (res == SZ_OK && *status == LZMA_STATUS_NEEDS_MORE_INPUT)
+    res = SZ_ERROR_INPUT_EOF;
+
+  (*destLen) = p.dicPos;
+  LzmaDec_FreeProbs(&p, alloc);
+  return res;
+}
diff --git a/tools/cbfstool/LzmaEnc.c b/tools/cbfstool/LzmaEnc.c
new file mode 100644
index 0000000000..a54fae7e6c
--- /dev/null
+++ b/tools/cbfstool/LzmaEnc.c
@@ -0,0 +1,2136 @@
+/* LzmaEnc.c -- LZMA Encoder
+2009-11-24 : Igor Pavlov : Public domain */
+
+#include <string.h>
+
+#include "lzma/C/LzmaEnc.h"
+
+#include "lzma/C/LzFind.h"
+
+#define kBlockSizeMax ((1 << LZMA_NUM_BLOCK_SIZE_BITS) - 1)
+
+#define kBlockSize (9 << 10)
+#define kUnpackBlockSize (1 << 18)
+#define kMatchArraySize (1 << 21)
+#define kMatchRecordMaxSize ((LZMA_MATCH_LEN_MAX * 2 + 3) * LZMA_MATCH_LEN_MAX)
+
+#define kNumMaxDirectBits (31)
+
+#define kNumTopBits 24
+#define kTopValue ((uint32_t)1 << kNumTopBits)
+
+#define kNumBitModelTotalBits 11
+#define kBitModelTotal (1 << kNumBitModelTotalBits)
+#define kNumMoveBits 5
+#define kProbInitValue (kBitModelTotal >> 1)
+
+#define kNumMoveReducingBits 4
+#define kNumBitPriceShiftBits 4
+#define kBitPrice (1 << kNumBitPriceShiftBits)
+
+void LzmaEncProps_Init(struct CLzmaEncProps *p)
+{
+  p->level = 5;
+  p->dictSize = p->mc = 0;
+  p->lc = p->lp = p->pb = p->algo = p->fb = p->btMode = p->numHashBytes = p->numThreads = -1;
+  p->writeEndMark = 0;
+}
+
+void LzmaEncProps_Normalize(struct CLzmaEncProps *p)
+{
+  int level = p->level;
+  if (level < 0) level = 5;
+  p->level = level;
+  if (p->dictSize == 0) p->dictSize = (level <= 5 ? (1 << (level * 2 + 14)) : (level == 6 ? (1 << 25) : (1 << 26)));
+  if (p->lc < 0) p->lc = 3;
+  if (p->lp < 0) p->lp = 0;
+  if (p->pb < 0) p->pb = 2;
+  if (p->algo < 0) p->algo = (level < 5 ? 0 : 1);
+  if (p->fb < 0) p->fb = (level < 7 ? 32 : 64);
+  if (p->btMode < 0) p->btMode = (p->algo == 0 ? 0 : 1);
+  if (p->numHashBytes < 0) p->numHashBytes = 4;
+  if (p->mc == 0)  p->mc = (16 + (p->fb >> 1)) >> (p->btMode ? 0 : 1);
+  if (p->numThreads < 0)
+    p->numThreads = 1;
+}
+
+uint32_t LzmaEncProps_GetDictSize(const struct CLzmaEncProps *props2)
+{
+  struct CLzmaEncProps props = *props2;
+  LzmaEncProps_Normalize(&props);
+  return props.dictSize;
+}
+
+#define kNumLogBits (9 + (int)sizeof(size_t) / 2)
+#define kDicLogSizeMaxCompress ((kNumLogBits - 1) * 2 + 7)
+
+static void LzmaEnc_FastPosInit(uint8_t *g_FastPos)
+{
+  int c = 2, slotFast;
+  g_FastPos[0] = 0;
+  g_FastPos[1] = 1;
+
+  for (slotFast = 2; slotFast < kNumLogBits * 2; slotFast++)
+  {
+    uint32_t k = (1 << ((slotFast >> 1) - 1));
+    uint32_t j;
+    for (j = 0; j < k; j++, c++)
+      g_FastPos[c] = (uint8_t)slotFast;
+  }
+}
+
+#define BSR2_RET(pos, res) { uint32_t macro_i = 6 + ((kNumLogBits - 1) & \
+  (0 - (((((uint32_t)1 << (kNumLogBits + 6)) - 1) - pos) >> 31))); \
+  res = p->g_FastPos[pos >> macro_i] + (macro_i * 2); }
+/*
+#define BSR2_RET(pos, res) { res = (pos < (1 << (kNumLogBits + 6))) ? \
+  p->g_FastPos[pos >> 6] + 12 : \
+  p->g_FastPos[pos >> (6 + kNumLogBits - 1)] + (6 + (kNumLogBits - 1)) * 2; }
+*/
+
+#define GetPosSlot1(pos) p->g_FastPos[pos]
+#define GetPosSlot2(pos, res) { BSR2_RET(pos, res); }
+#define GetPosSlot(pos, res) { if (pos < kNumFullDistances) res = p->g_FastPos[pos]; else BSR2_RET(pos, res); }
+
+#define LZMA_NUM_REPS 4
+
+typedef unsigned CState;
+
+struct COptimal
+{
+  uint32_t price;
+
+  CState state;
+  int prev1IsChar;
+  int prev2;
+
+  uint32_t posPrev2;
+  uint32_t backPrev2;
+
+  uint32_t posPrev;
+  uint32_t backPrev;
+  uint32_t backs[LZMA_NUM_REPS];
+};
+
+#define kNumOpts (1 << 12)
+
+#define kNumLenToPosStates 4
+#define kNumPosSlotBits 6
+#define kDicLogSizeMin 0
+#define kDicLogSizeMax 32
+#define kDistTableSizeMax (kDicLogSizeMax * 2)
+
+
+#define kNumAlignBits 4
+#define kAlignTableSize (1 << kNumAlignBits)
+#define kAlignMask (kAlignTableSize - 1)
+
+#define kStartPosModelIndex 4
+#define kEndPosModelIndex 14
+#define kNumPosModels (kEndPosModelIndex - kStartPosModelIndex)
+
+#define kNumFullDistances (1 << (kEndPosModelIndex >> 1))
+
+typedef uint16_t CLzmaProb;
+
+
+#define LZMA_PB_MAX 4
+#define LZMA_LC_MAX 8
+#define LZMA_LP_MAX 4
+
+#define LZMA_NUM_PB_STATES_MAX (1 << LZMA_PB_MAX)
+
+
+#define kLenNumLowBits 3
+#define kLenNumLowSymbols (1 << kLenNumLowBits)
+#define kLenNumMidBits 3
+#define kLenNumMidSymbols (1 << kLenNumMidBits)
+#define kLenNumHighBits 8
+#define kLenNumHighSymbols (1 << kLenNumHighBits)
+
+#define kLenNumSymbolsTotal (kLenNumLowSymbols + kLenNumMidSymbols + kLenNumHighSymbols)
+
+#define LZMA_MATCH_LEN_MIN 2
+#define LZMA_MATCH_LEN_MAX (LZMA_MATCH_LEN_MIN + kLenNumSymbolsTotal - 1)
+
+#define kNumStates 12
+
+struct CLenEnc
+{
+  CLzmaProb choice;
+  CLzmaProb choice2;
+  CLzmaProb low[LZMA_NUM_PB_STATES_MAX << kLenNumLowBits];
+  CLzmaProb mid[LZMA_NUM_PB_STATES_MAX << kLenNumMidBits];
+  CLzmaProb high[kLenNumHighSymbols];
+};
+
+struct CLenPriceEnc
+{
+  struct CLenEnc p;
+  uint32_t prices[LZMA_NUM_PB_STATES_MAX][kLenNumSymbolsTotal];
+  uint32_t tableSize;
+  uint32_t counters[LZMA_NUM_PB_STATES_MAX];
+};
+
+struct CRangeEnc
+{
+  uint32_t range;
+  uint8_t cache;
+  uint64_t low;
+  uint64_t cacheSize;
+  uint8_t *buf;
+  uint8_t *bufLim;
+  uint8_t *bufBase;
+  struct ISeqOutStream *outStream;
+  uint64_t processed;
+  SRes res;
+};
+
+struct CSaveState
+{
+  CLzmaProb *litProbs;
+
+  CLzmaProb isMatch[kNumStates][LZMA_NUM_PB_STATES_MAX];
+  CLzmaProb isRep[kNumStates];
+  CLzmaProb isRepG0[kNumStates];
+  CLzmaProb isRepG1[kNumStates];
+  CLzmaProb isRepG2[kNumStates];
+  CLzmaProb isRep0Long[kNumStates][LZMA_NUM_PB_STATES_MAX];
+
+  CLzmaProb posSlotEncoder[kNumLenToPosStates][1 << kNumPosSlotBits];
+  CLzmaProb posEncoders[kNumFullDistances - kEndPosModelIndex];
+  CLzmaProb posAlignEncoder[1 << kNumAlignBits];
+
+  struct CLenPriceEnc lenEnc;
+  struct CLenPriceEnc repLenEnc;
+
+  uint32_t reps[LZMA_NUM_REPS];
+  uint32_t state;
+};
+
+struct CLzmaEnc
+{
+  struct IMatchFinder matchFinder;
+  void *matchFinderObj;
+
+  struct CMatchFinder matchFinderBase;
+
+  uint32_t optimumEndIndex;
+  uint32_t optimumCurrentIndex;
+
+  uint32_t longestMatchLength;
+  uint32_t numPairs;
+  uint32_t numAvail;
+  struct COptimal opt[kNumOpts];
+
+  #ifndef LZMA_LOG_BSR
+  uint8_t g_FastPos[1 << kNumLogBits];
+  #endif
+
+  uint32_t ProbPrices[kBitModelTotal >> kNumMoveReducingBits];
+  uint32_t matches[LZMA_MATCH_LEN_MAX * 2 + 2 + 1];
+  uint32_t numFastuint8_ts;
+  uint32_t additionalOffset;
+  uint32_t reps[LZMA_NUM_REPS];
+  uint32_t state;
+
+  uint32_t posSlotPrices[kNumLenToPosStates][kDistTableSizeMax];
+  uint32_t distancesPrices[kNumLenToPosStates][kNumFullDistances];
+  uint32_t alignPrices[kAlignTableSize];
+  uint32_t alignPriceCount;
+
+  uint32_t distTableSize;
+
+  unsigned lc, lp, pb;
+  unsigned lpMask, pbMask;
+
+  CLzmaProb *litProbs;
+
+  CLzmaProb isMatch[kNumStates][LZMA_NUM_PB_STATES_MAX];
+  CLzmaProb isRep[kNumStates];
+  CLzmaProb isRepG0[kNumStates];
+  CLzmaProb isRepG1[kNumStates];
+  CLzmaProb isRepG2[kNumStates];
+  CLzmaProb isRep0Long[kNumStates][LZMA_NUM_PB_STATES_MAX];
+
+  CLzmaProb posSlotEncoder[kNumLenToPosStates][1 << kNumPosSlotBits];
+  CLzmaProb posEncoders[kNumFullDistances - kEndPosModelIndex];
+  CLzmaProb posAlignEncoder[1 << kNumAlignBits];
+
+  struct CLenPriceEnc lenEnc;
+  struct CLenPriceEnc repLenEnc;
+
+  unsigned lclp;
+
+  bool fastMode;
+
+  struct CRangeEnc rc;
+
+  bool writeEndMark;
+  uint64_t nowPos64;
+  uint32_t matchPriceCount;
+  bool finished;
+  bool multiThread;
+
+  SRes result;
+  uint32_t dictSize;
+  uint32_t matchFinderCycles;
+
+  int needInit;
+
+  struct CSaveState saveState;
+};
+
+/*static void LzmaEnc_SaveState(CLzmaEncHandle pp)
+{
+  CLzmaEnc *p = (CLzmaEnc *)pp;
+  CSaveState *dest = &p->saveState;
+  int i;
+  dest->lenEnc = p->lenEnc;
+  dest->repLenEnc = p->repLenEnc;
+  dest->state = p->state;
+
+  for (i = 0; i < kNumStates; i++)
+  {
+    memcpy(dest->isMatch[i], p->isMatch[i], sizeof(p->isMatch[i]));
+    memcpy(dest->isRep0Long[i], p->isRep0Long[i], sizeof(p->isRep0Long[i]));
+  }
+  for (i = 0; i < kNumLenToPosStates; i++)
+    memcpy(dest->posSlotEncoder[i], p->posSlotEncoder[i], sizeof(p->posSlotEncoder[i]));
+  memcpy(dest->isRep, p->isRep, sizeof(p->isRep));
+  memcpy(dest->isRepG0, p->isRepG0, sizeof(p->isRepG0));
+  memcpy(dest->isRepG1, p->isRepG1, sizeof(p->isRepG1));
+  memcpy(dest->isRepG2, p->isRepG2, sizeof(p->isRepG2));
+  memcpy(dest->posEncoders, p->posEncoders, sizeof(p->posEncoders));
+  memcpy(dest->posAlignEncoder, p->posAlignEncoder, sizeof(p->posAlignEncoder));
+  memcpy(dest->reps, p->reps, sizeof(p->reps));
+  memcpy(dest->litProbs, p->litProbs, (0x300 << p->lclp) * sizeof(CLzmaProb));
+}*/
+
+/*static void LzmaEnc_RestoreState(CLzmaEncHandle pp)
+{
+  CLzmaEnc *dest = (CLzmaEnc *)pp;
+  const CSaveState *p = &dest->saveState;
+  int i;
+  dest->lenEnc = p->lenEnc;
+  dest->repLenEnc = p->repLenEnc;
+  dest->state = p->state;
+
+  for (i = 0; i < kNumStates; i++)
+  {
+    memcpy(dest->isMatch[i], p->isMatch[i], sizeof(p->isMatch[i]));
+    memcpy(dest->isRep0Long[i], p->isRep0Long[i], sizeof(p->isRep0Long[i]));
+  }
+  for (i = 0; i < kNumLenToPosStates; i++)
+    memcpy(dest->posSlotEncoder[i], p->posSlotEncoder[i], sizeof(p->posSlotEncoder[i]));
+  memcpy(dest->isRep, p->isRep, sizeof(p->isRep));
+  memcpy(dest->isRepG0, p->isRepG0, sizeof(p->isRepG0));
+  memcpy(dest->isRepG1, p->isRepG1, sizeof(p->isRepG1));
+  memcpy(dest->isRepG2, p->isRepG2, sizeof(p->isRepG2));
+  memcpy(dest->posEncoders, p->posEncoders, sizeof(p->posEncoders));
+  memcpy(dest->posAlignEncoder, p->posAlignEncoder, sizeof(p->posAlignEncoder));
+  memcpy(dest->reps, p->reps, sizeof(p->reps));
+  memcpy(dest->litProbs, p->litProbs, (0x300 << dest->lclp) * sizeof(CLzmaProb));
+}*/
+
+SRes LzmaEnc_SetProps(CLzmaEncHandle pp, const struct CLzmaEncProps *props2)
+{
+  struct CLzmaEnc *p = (struct CLzmaEnc *)pp;
+  struct CLzmaEncProps props = *props2;
+  LzmaEncProps_Normalize(&props);
+
+  if (props.lc > LZMA_LC_MAX || props.lp > LZMA_LP_MAX || props.pb > LZMA_PB_MAX ||
+      props.dictSize > (1 << kDicLogSizeMaxCompress) || props.dictSize > (1 << 30))
+    return SZ_ERROR_PARAM;
+  p->dictSize = props.dictSize;
+  p->matchFinderCycles = props.mc;
+  {
+    unsigned fb = props.fb;
+    if (fb < 5)
+      fb = 5;
+    if (fb > LZMA_MATCH_LEN_MAX)
+      fb = LZMA_MATCH_LEN_MAX;
+    p->numFastuint8_ts = fb;
+  }
+  p->lc = props.lc;
+  p->lp = props.lp;
+  p->pb = props.pb;
+  p->fastMode = (props.algo == 0);
+  p->matchFinderBase.btMode = props.btMode;
+  {
+    uint32_t numHashBytes = 4;
+    if (props.btMode)
+    {
+      if (props.numHashBytes < 2)
+        numHashBytes = 2;
+      else if (props.numHashBytes < 4)
+        numHashBytes = props.numHashBytes;
+    }
+    p->matchFinderBase.numHashBytes = numHashBytes;
+  }
+
+  p->matchFinderBase.cutValue = props.mc;
+
+  p->writeEndMark = props.writeEndMark;
+
+  return SZ_OK;
+}
+
+static const int kLiteralNextStates[kNumStates] = {0, 0, 0, 0, 1, 2, 3, 4,  5,  6,   4, 5};
+static const int kMatchNextStates[kNumStates]   = {7, 7, 7, 7, 7, 7, 7, 10, 10, 10, 10, 10};
+static const int kRepNextStates[kNumStates]     = {8, 8, 8, 8, 8, 8, 8, 11, 11, 11, 11, 11};
+static const int kShortRepNextStates[kNumStates]= {9, 9, 9, 9, 9, 9, 9, 11, 11, 11, 11, 11};
+
+#define IsCharState(s) ((s) < 7)
+
+#define GetLenToPosState(len) (((len) < kNumLenToPosStates + 1) ? (len) - 2 : kNumLenToPosStates - 1)
+
+#define kInfinityPrice (1 << 30)
+
+static void RangeEnc_Construct(struct CRangeEnc *p)
+{
+  p->outStream = 0;
+  p->bufBase = 0;
+}
+
+#define RangeEnc_GetProcessed(p) ((p)->processed + ((p)->buf - (p)->bufBase) + (p)->cacheSize)
+
+#define RC_BUF_SIZE (1 << 16)
+static int RangeEnc_Alloc(struct CRangeEnc *p, struct ISzAlloc *alloc)
+{
+  if (p->bufBase == 0)
+  {
+    p->bufBase = (uint8_t *)alloc->Alloc(alloc, RC_BUF_SIZE);
+    if (p->bufBase == 0)
+      return 0;
+    p->bufLim = p->bufBase + RC_BUF_SIZE;
+  }
+  return 1;
+}
+
+static void RangeEnc_Free(struct CRangeEnc *p, struct ISzAlloc *alloc)
+{
+  alloc->Free(alloc, p->bufBase);
+  p->bufBase = 0;
+}
+
+static void RangeEnc_Init(struct CRangeEnc *p)
+{
+  /* Stream.Init(); */
+  p->low = 0;
+  p->range = 0xFFFFFFFF;
+  p->cacheSize = 1;
+  p->cache = 0;
+
+  p->buf = p->bufBase;
+
+  p->processed = 0;
+  p->res = SZ_OK;
+}
+
+static void RangeEnc_FlushStream(struct CRangeEnc *p)
+{
+  size_t num;
+  if (p->res != SZ_OK)
+    return;
+  num = p->buf - p->bufBase;
+  if (num != p->outStream->Write(p->outStream, p->bufBase, num))
+    p->res = SZ_ERROR_WRITE;
+  p->processed += num;
+  p->buf = p->bufBase;
+}
+
+static void RangeEnc_ShiftLow(struct CRangeEnc *p)
+{
+  if ((uint32_t)p->low < (uint32_t)0xFF000000 || (int)(p->low >> 32) != 0)
+  {
+    uint8_t temp = p->cache;
+    do
+    {
+      uint8_t *buf = p->buf;
+      *buf++ = (uint8_t)(temp + (uint8_t)(p->low >> 32));
+      p->buf = buf;
+      if (buf == p->bufLim)
+        RangeEnc_FlushStream(p);
+      temp = 0xFF;
+    }
+    while (--p->cacheSize != 0);
+    p->cache = (uint8_t)((uint32_t)p->low >> 24);
+  }
+  p->cacheSize++;
+  p->low = (uint32_t)p->low << 8;
+}
+
+static void RangeEnc_FlushData(struct CRangeEnc *p)
+{
+  int i;
+  for (i = 0; i < 5; i++)
+    RangeEnc_ShiftLow(p);
+}
+
+static void RangeEnc_EncodeDirectBits(struct CRangeEnc *p, uint32_t value, int numBits)
+{
+  do
+  {
+    p->range >>= 1;
+    p->low += p->range & (0 - ((value >> --numBits) & 1));
+    if (p->range < kTopValue)
+    {
+      p->range <<= 8;
+      RangeEnc_ShiftLow(p);
+    }
+  }
+  while (numBits != 0);
+}
+
+static void RangeEnc_EncodeBit(struct CRangeEnc *p, CLzmaProb *prob, uint32_t symbol)
+{
+  uint32_t ttt = *prob;
+  uint32_t newBound = (p->range >> kNumBitModelTotalBits) * ttt;
+  if (symbol == 0)
+  {
+    p->range = newBound;
+    ttt += (kBitModelTotal - ttt) >> kNumMoveBits;
+  }
+  else
+  {
+    p->low += newBound;
+    p->range -= newBound;
+    ttt -= ttt >> kNumMoveBits;
+  }
+  *prob = (CLzmaProb)ttt;
+  if (p->range < kTopValue)
+  {
+    p->range <<= 8;
+    RangeEnc_ShiftLow(p);
+  }
+}
+
+static void LitEnc_Encode(struct CRangeEnc *p, CLzmaProb *probs, uint32_t symbol)
+{
+  symbol |= 0x100;
+  do
+  {
+    RangeEnc_EncodeBit(p, probs + (symbol >> 8), (symbol >> 7) & 1);
+    symbol <<= 1;
+  }
+  while (symbol < 0x10000);
+}
+
+static void LitEnc_EncodeMatched(struct CRangeEnc *p, CLzmaProb *probs, uint32_t symbol, uint32_t matchuint8_t)
+{
+  uint32_t offs = 0x100;
+  symbol |= 0x100;
+  do
+  {
+    matchuint8_t <<= 1;
+    RangeEnc_EncodeBit(p, probs + (offs + (matchuint8_t & offs) + (symbol >> 8)), (symbol >> 7) & 1);
+    symbol <<= 1;
+    offs &= ~(matchuint8_t ^ symbol);
+  }
+  while (symbol < 0x10000);
+}
+
+static void LzmaEnc_InitPriceTables(uint32_t *ProbPrices)
+{
+  uint32_t i;
+  for (i = (1 << kNumMoveReducingBits) / 2; i < kBitModelTotal; i += (1 << kNumMoveReducingBits))
+  {
+    const int kCyclesBits = kNumBitPriceShiftBits;
+    uint32_t w = i;
+    uint32_t bitCount = 0;
+    int j;
+    for (j = 0; j < kCyclesBits; j++)
+    {
+      w = w * w;
+      bitCount <<= 1;
+      while (w >= ((uint32_t)1 << 16))
+      {
+        w >>= 1;
+        bitCount++;
+      }
+    }
+    ProbPrices[i >> kNumMoveReducingBits] = ((kNumBitModelTotalBits << kCyclesBits) - 15 - bitCount);
+  }
+}
+
+
+#define GET_PRICE(prob, symbol) \
+  p->ProbPrices[((prob) ^ (((-(int)(symbol))) & (kBitModelTotal - 1))) >> kNumMoveReducingBits];
+
+#define GET_PRICEa(prob, symbol) \
+  ProbPrices[((prob) ^ ((-((int)(symbol))) & (kBitModelTotal - 1))) >> kNumMoveReducingBits];
+
+#define GET_PRICE_0(prob) p->ProbPrices[(prob) >> kNumMoveReducingBits]
+#define GET_PRICE_1(prob) p->ProbPrices[((prob) ^ (kBitModelTotal - 1)) >> kNumMoveReducingBits]
+
+#define GET_PRICE_0a(prob) ProbPrices[(prob) >> kNumMoveReducingBits]
+#define GET_PRICE_1a(prob) ProbPrices[((prob) ^ (kBitModelTotal - 1)) >> kNumMoveReducingBits]
+
+static uint32_t LitEnc_GetPrice(const CLzmaProb *probs, uint32_t symbol, uint32_t *ProbPrices)
+{
+  uint32_t price = 0;
+  symbol |= 0x100;
+  do
+  {
+    price += GET_PRICEa(probs[symbol >> 8], (symbol >> 7) & 1);
+    symbol <<= 1;
+  }
+  while (symbol < 0x10000);
+  return price;
+}
+
+static uint32_t LitEnc_GetPriceMatched(const CLzmaProb *probs, uint32_t symbol, uint32_t matchuint8_t, uint32_t *ProbPrices)
+{
+  uint32_t price = 0;
+  uint32_t offs = 0x100;
+  symbol |= 0x100;
+  do
+  {
+    matchuint8_t <<= 1;
+    price += GET_PRICEa(probs[offs + (matchuint8_t & offs) + (symbol >> 8)], (symbol >> 7) & 1);
+    symbol <<= 1;
+    offs &= ~(matchuint8_t ^ symbol);
+  }
+  while (symbol < 0x10000);
+  return price;
+}
+
+
+static void RcTree_Encode(struct CRangeEnc *rc, CLzmaProb *probs, int numBitLevels, uint32_t symbol)
+{
+  uint32_t m = 1;
+  int i;
+  for (i = numBitLevels; i != 0;)
+  {
+    uint32_t bit;
+    i--;
+    bit = (symbol >> i) & 1;
+    RangeEnc_EncodeBit(rc, probs + m, bit);
+    m = (m << 1) | bit;
+  }
+}
+
+static void RcTree_ReverseEncode(struct CRangeEnc *rc, CLzmaProb *probs, int numBitLevels, uint32_t symbol)
+{
+  uint32_t m = 1;
+  int i;
+  for (i = 0; i < numBitLevels; i++)
+  {
+    uint32_t bit = symbol & 1;
+    RangeEnc_EncodeBit(rc, probs + m, bit);
+    m = (m << 1) | bit;
+    symbol >>= 1;
+  }
+}
+
+static uint32_t RcTree_GetPrice(const CLzmaProb *probs, int numBitLevels, uint32_t symbol, uint32_t *ProbPrices)
+{
+  uint32_t price = 0;
+  symbol |= (1 << numBitLevels);
+  while (symbol != 1)
+  {
+    price += GET_PRICEa(probs[symbol >> 1], symbol & 1);
+    symbol >>= 1;
+  }
+  return price;
+}
+
+static uint32_t RcTree_ReverseGetPrice(const CLzmaProb *probs, int numBitLevels, uint32_t symbol, uint32_t *ProbPrices)
+{
+  uint32_t price = 0;
+  uint32_t m = 1;
+  int i;
+  for (i = numBitLevels; i != 0; i--)
+  {
+    uint32_t bit = symbol & 1;
+    symbol >>= 1;
+    price += GET_PRICEa(probs[m], bit);
+    m = (m << 1) | bit;
+  }
+  return price;
+}
+
+
+static void LenEnc_Init(struct CLenEnc *p)
+{
+  unsigned i;
+  p->choice = p->choice2 = kProbInitValue;
+  for (i = 0; i < (LZMA_NUM_PB_STATES_MAX << kLenNumLowBits); i++)
+    p->low[i] = kProbInitValue;
+  for (i = 0; i < (LZMA_NUM_PB_STATES_MAX << kLenNumMidBits); i++)
+    p->mid[i] = kProbInitValue;
+  for (i = 0; i < kLenNumHighSymbols; i++)
+    p->high[i] = kProbInitValue;
+}
+
+static void LenEnc_Encode(struct CLenEnc *p, struct CRangeEnc *rc, uint32_t symbol, uint32_t posState)
+{
+  if (symbol < kLenNumLowSymbols)
+  {
+    RangeEnc_EncodeBit(rc, &p->choice, 0);
+    RcTree_Encode(rc, p->low + (posState << kLenNumLowBits), kLenNumLowBits, symbol);
+  }
+  else
+  {
+    RangeEnc_EncodeBit(rc, &p->choice, 1);
+    if (symbol < kLenNumLowSymbols + kLenNumMidSymbols)
+    {
+      RangeEnc_EncodeBit(rc, &p->choice2, 0);
+      RcTree_Encode(rc, p->mid + (posState << kLenNumMidBits), kLenNumMidBits, symbol - kLenNumLowSymbols);
+    }
+    else
+    {
+      RangeEnc_EncodeBit(rc, &p->choice2, 1);
+      RcTree_Encode(rc, p->high, kLenNumHighBits, symbol - kLenNumLowSymbols - kLenNumMidSymbols);
+    }
+  }
+}
+
+static void LenEnc_SetPrices(struct CLenEnc *p, uint32_t posState, uint32_t numSymbols, uint32_t *prices, uint32_t *ProbPrices)
+{
+  uint32_t a0 = GET_PRICE_0a(p->choice);
+  uint32_t a1 = GET_PRICE_1a(p->choice);
+  uint32_t b0 = a1 + GET_PRICE_0a(p->choice2);
+  uint32_t b1 = a1 + GET_PRICE_1a(p->choice2);
+  uint32_t i = 0;
+  for (i = 0; i < kLenNumLowSymbols; i++)
+  {
+    if (i >= numSymbols)
+      return;
+    prices[i] = a0 + RcTree_GetPrice(p->low + (posState << kLenNumLowBits), kLenNumLowBits, i, ProbPrices);
+  }
+  for (; i < kLenNumLowSymbols + kLenNumMidSymbols; i++)
+  {
+    if (i >= numSymbols)
+      return;
+    prices[i] = b0 + RcTree_GetPrice(p->mid + (posState << kLenNumMidBits), kLenNumMidBits, i - kLenNumLowSymbols, ProbPrices);
+  }
+  for (; i < numSymbols; i++)
+    prices[i] = b1 + RcTree_GetPrice(p->high, kLenNumHighBits, i - kLenNumLowSymbols - kLenNumMidSymbols, ProbPrices);
+}
+
+static void LenPriceEnc_UpdateTable(struct CLenPriceEnc *p, uint32_t posState, uint32_t *ProbPrices)
+{
+  LenEnc_SetPrices(&p->p, posState, p->tableSize, p->prices[posState], ProbPrices);
+  p->counters[posState] = p->tableSize;
+}
+
+static void LenPriceEnc_UpdateTables(struct CLenPriceEnc *p, uint32_t numPosStates, uint32_t *ProbPrices)
+{
+  uint32_t posState;
+  for (posState = 0; posState < numPosStates; posState++)
+    LenPriceEnc_UpdateTable(p, posState, ProbPrices);
+}
+
+static void LenEnc_Encode2(struct CLenPriceEnc *p, struct CRangeEnc *rc, uint32_t symbol, uint32_t posState, bool updatePrice, uint32_t *ProbPrices)
+{
+  LenEnc_Encode(&p->p, rc, symbol, posState);
+  if (updatePrice)
+    if (--p->counters[posState] == 0)
+      LenPriceEnc_UpdateTable(p, posState, ProbPrices);
+}
+
+
+
+
+static void MovePos(struct CLzmaEnc *p, uint32_t num)
+{
+  if (num != 0)
+  {
+    p->additionalOffset += num;
+    p->matchFinder.Skip(p->matchFinderObj, num);
+  }
+}
+
+static uint32_t ReadMatchDistances(struct CLzmaEnc *p, uint32_t *numDistancePairsRes)
+{
+  uint32_t lenRes = 0, numPairs;
+  p->numAvail = p->matchFinder.GetNumAvailableBytes(p->matchFinderObj);
+  numPairs = p->matchFinder.GetMatches(p->matchFinderObj, p->matches);
+  if (numPairs > 0)
+  {
+    lenRes = p->matches[numPairs - 2];
+    if (lenRes == p->numFastuint8_ts)
+    {
+      const uint8_t *pby = p->matchFinder.GetPointerToCurrentPos(p->matchFinderObj) - 1;
+      uint32_t distance = p->matches[numPairs - 1] + 1;
+      uint32_t numAvail = p->numAvail;
+      if (numAvail > LZMA_MATCH_LEN_MAX)
+        numAvail = LZMA_MATCH_LEN_MAX;
+      {
+        const uint8_t *pby2 = pby - distance;
+        for (; lenRes < numAvail && pby[lenRes] == pby2[lenRes]; lenRes++);
+      }
+    }
+  }
+  p->additionalOffset++;
+  *numDistancePairsRes = numPairs;
+  return lenRes;
+}
+
+
+#define MakeAsChar(p) (p)->backPrev = (uint32_t)(-1); (p)->prev1IsChar = false;
+#define MakeAsShortRep(p) (p)->backPrev = 0; (p)->prev1IsChar = false;
+#define IsShortRep(p) ((p)->backPrev == 0)
+
+static uint32_t GetRepLen1Price(struct CLzmaEnc *p, uint32_t state, uint32_t posState)
+{
+  return
+    GET_PRICE_0(p->isRepG0[state]) +
+    GET_PRICE_0(p->isRep0Long[state][posState]);
+}
+
+static uint32_t GetPureRepPrice(struct CLzmaEnc *p, uint32_t repIndex, uint32_t state, uint32_t posState)
+{
+  uint32_t price;
+  if (repIndex == 0)
+  {
+    price = GET_PRICE_0(p->isRepG0[state]);
+    price += GET_PRICE_1(p->isRep0Long[state][posState]);
+  }
+  else
+  {
+    price = GET_PRICE_1(p->isRepG0[state]);
+    if (repIndex == 1)
+      price += GET_PRICE_0(p->isRepG1[state]);
+    else
+    {
+      price += GET_PRICE_1(p->isRepG1[state]);
+      price += GET_PRICE(p->isRepG2[state], repIndex - 2);
+    }
+  }
+  return price;
+}
+
+static uint32_t GetRepPrice(struct CLzmaEnc *p, uint32_t repIndex, uint32_t len, uint32_t state, uint32_t posState)
+{
+  return p->repLenEnc.prices[posState][len - LZMA_MATCH_LEN_MIN] +
+    GetPureRepPrice(p, repIndex, state, posState);
+}
+
+static uint32_t Backward(struct CLzmaEnc *p, uint32_t *backRes, uint32_t cur)
+{
+  uint32_t posMem = p->opt[cur].posPrev;
+  uint32_t backMem = p->opt[cur].backPrev;
+  p->optimumEndIndex = cur;
+  do
+  {
+    if (p->opt[cur].prev1IsChar)
+    {
+      MakeAsChar(&p->opt[posMem])
+      p->opt[posMem].posPrev = posMem - 1;
+      if (p->opt[cur].prev2)
+      {
+        p->opt[posMem - 1].prev1IsChar = false;
+        p->opt[posMem - 1].posPrev = p->opt[cur].posPrev2;
+        p->opt[posMem - 1].backPrev = p->opt[cur].backPrev2;
+      }
+    }
+    {
+      uint32_t posPrev = posMem;
+      uint32_t backCur = backMem;
+
+      backMem = p->opt[posPrev].backPrev;
+      posMem = p->opt[posPrev].posPrev;
+
+      p->opt[posPrev].backPrev = backCur;
+      p->opt[posPrev].posPrev = cur;
+      cur = posPrev;
+    }
+  }
+  while (cur != 0);
+  *backRes = p->opt[0].backPrev;
+  p->optimumCurrentIndex  = p->opt[0].posPrev;
+  return p->optimumCurrentIndex;
+}
+
+#define LIT_PROBS(pos, prevuint8_t) (p->litProbs + ((((pos) & p->lpMask) << p->lc) + ((prevuint8_t) >> (8 - p->lc))) * 0x300)
+
+static uint32_t GetOptimum(struct CLzmaEnc *p, uint32_t position, uint32_t *backRes)
+{
+  uint32_t numAvail, mainLen, numPairs, repMaxIndex, i, posState, lenEnd, len, cur;
+  uint32_t matchPrice, repMatchPrice, normalMatchPrice;
+  uint32_t reps[LZMA_NUM_REPS], repLens[LZMA_NUM_REPS];
+  uint32_t *matches;
+  const uint8_t *data;
+  uint8_t curuint8_t, matchuint8_t;
+  if (p->optimumEndIndex != p->optimumCurrentIndex)
+  {
+    const struct COptimal *opt = &p->opt[p->optimumCurrentIndex];
+    uint32_t lenRes = opt->posPrev - p->optimumCurrentIndex;
+    *backRes = opt->backPrev;
+    p->optimumCurrentIndex = opt->posPrev;
+    return lenRes;
+  }
+  p->optimumCurrentIndex = p->optimumEndIndex = 0;
+
+  if (p->additionalOffset == 0)
+    mainLen = ReadMatchDistances(p, &numPairs);
+  else
+  {
+    mainLen = p->longestMatchLength;
+    numPairs = p->numPairs;
+  }
+
+  numAvail = p->numAvail;
+  if (numAvail < 2)
+  {
+    *backRes = (uint32_t)(-1);
+    return 1;
+  }
+  if (numAvail > LZMA_MATCH_LEN_MAX)
+    numAvail = LZMA_MATCH_LEN_MAX;
+
+  data = p->matchFinder.GetPointerToCurrentPos(p->matchFinderObj) - 1;
+  repMaxIndex = 0;
+  for (i = 0; i < LZMA_NUM_REPS; i++)
+  {
+    uint32_t lenTest;
+    const uint8_t *data2;
+    reps[i] = p->reps[i];
+    data2 = data - (reps[i] + 1);
+    if (data[0] != data2[0] || data[1] != data2[1])
+    {
+      repLens[i] = 0;
+      continue;
+    }
+    for (lenTest = 2; lenTest < numAvail && data[lenTest] == data2[lenTest]; lenTest++);
+    repLens[i] = lenTest;
+    if (lenTest > repLens[repMaxIndex])
+      repMaxIndex = i;
+  }
+  if (repLens[repMaxIndex] >= p->numFastuint8_ts)
+  {
+    uint32_t lenRes;
+    *backRes = repMaxIndex;
+    lenRes = repLens[repMaxIndex];
+    MovePos(p, lenRes - 1);
+    return lenRes;
+  }
+
+  matches = p->matches;
+  if (mainLen >= p->numFastuint8_ts)
+  {
+    *backRes = matches[numPairs - 1] + LZMA_NUM_REPS;
+    MovePos(p, mainLen - 1);
+    return mainLen;
+  }
+  curuint8_t = *data;
+  matchuint8_t = *(data - (reps[0] + 1));
+
+  if (mainLen < 2 && curuint8_t != matchuint8_t && repLens[repMaxIndex] < 2)
+  {
+    *backRes = (uint32_t)-1;
+    return 1;
+  }
+
+  p->opt[0].state = (CState)p->state;
+
+  posState = (position & p->pbMask);
+
+  {
+    const CLzmaProb *probs = LIT_PROBS(position, *(data - 1));
+    p->opt[1].price = GET_PRICE_0(p->isMatch[p->state][posState]) +
+        (!IsCharState(p->state) ?
+          LitEnc_GetPriceMatched(probs, curuint8_t, matchuint8_t, p->ProbPrices) :
+          LitEnc_GetPrice(probs, curuint8_t, p->ProbPrices));
+  }
+
+  MakeAsChar(&p->opt[1]);
+
+  matchPrice = GET_PRICE_1(p->isMatch[p->state][posState]);
+  repMatchPrice = matchPrice + GET_PRICE_1(p->isRep[p->state]);
+
+  if (matchuint8_t == curuint8_t)
+  {
+    uint32_t shortRepPrice = repMatchPrice + GetRepLen1Price(p, p->state, posState);
+    if (shortRepPrice < p->opt[1].price)
+    {
+      p->opt[1].price = shortRepPrice;
+      MakeAsShortRep(&p->opt[1]);
+    }
+  }
+  lenEnd = ((mainLen >= repLens[repMaxIndex]) ? mainLen : repLens[repMaxIndex]);
+
+  if (lenEnd < 2)
+  {
+    *backRes = p->opt[1].backPrev;
+    return 1;
+  }
+
+  p->opt[1].posPrev = 0;
+  for (i = 0; i < LZMA_NUM_REPS; i++)
+    p->opt[0].backs[i] = reps[i];
+
+  len = lenEnd;
+  do
+    p->opt[len--].price = kInfinityPrice;
+  while (len >= 2);
+
+  for (i = 0; i < LZMA_NUM_REPS; i++)
+  {
+    uint32_t repLen = repLens[i];
+    uint32_t price;
+    if (repLen < 2)
+      continue;
+    price = repMatchPrice + GetPureRepPrice(p, i, p->state, posState);
+    do
+    {
+      uint32_t curAndLenPrice = price + p->repLenEnc.prices[posState][repLen - 2];
+      struct COptimal *opt = &p->opt[repLen];
+      if (curAndLenPrice < opt->price)
+      {
+        opt->price = curAndLenPrice;
+        opt->posPrev = 0;
+        opt->backPrev = i;
+        opt->prev1IsChar = false;
+      }
+    }
+    while (--repLen >= 2);
+  }
+
+  normalMatchPrice = matchPrice + GET_PRICE_0(p->isRep[p->state]);
+
+  len = ((repLens[0] >= 2) ? repLens[0] + 1 : 2);
+  if (len <= mainLen)
+  {
+    uint32_t offs = 0;
+    while (len > matches[offs])
+      offs += 2;
+    for (; ; len++)
+    {
+      struct COptimal *opt;
+      uint32_t distance = matches[offs + 1];
+
+      uint32_t curAndLenPrice = normalMatchPrice + p->lenEnc.prices[posState][len - LZMA_MATCH_LEN_MIN];
+      uint32_t lenToPosState = GetLenToPosState(len);
+      if (distance < kNumFullDistances)
+        curAndLenPrice += p->distancesPrices[lenToPosState][distance];
+      else
+      {
+        uint32_t slot;
+        GetPosSlot2(distance, slot);
+        curAndLenPrice += p->alignPrices[distance & kAlignMask] + p->posSlotPrices[lenToPosState][slot];
+      }
+      opt = &p->opt[len];
+      if (curAndLenPrice < opt->price)
+      {
+        opt->price = curAndLenPrice;
+        opt->posPrev = 0;
+        opt->backPrev = distance + LZMA_NUM_REPS;
+        opt->prev1IsChar = false;
+      }
+      if (len == matches[offs])
+      {
+        offs += 2;
+        if (offs == numPairs)
+          break;
+      }
+    }
+  }
+
+  cur = 0;
+
+  for (;;)
+  {
+    uint32_t numAvailFull, newLen, posPrev, state, startLen;
+    uint32_t curPrice, curAnd1Price;
+    bool nextIsChar;
+    struct COptimal *curOpt;
+    struct COptimal *nextOpt;
+
+    cur++;
+    if (cur == lenEnd)
+      return Backward(p, backRes, cur);
+
+    newLen = ReadMatchDistances(p, &numPairs);
+    if (newLen >= p->numFastuint8_ts)
+    {
+      p->numPairs = numPairs;
+      p->longestMatchLength = newLen;
+      return Backward(p, backRes, cur);
+    }
+    position++;
+    curOpt = &p->opt[cur];
+    posPrev = curOpt->posPrev;
+    if (curOpt->prev1IsChar)
+    {
+      posPrev--;
+      if (curOpt->prev2)
+      {
+        state = p->opt[curOpt->posPrev2].state;
+        if (curOpt->backPrev2 < LZMA_NUM_REPS)
+          state = kRepNextStates[state];
+        else
+          state = kMatchNextStates[state];
+      }
+      else
+        state = p->opt[posPrev].state;
+      state = kLiteralNextStates[state];
+    }
+    else
+      state = p->opt[posPrev].state;
+    if (posPrev == cur - 1)
+    {
+      if (IsShortRep(curOpt))
+        state = kShortRepNextStates[state];
+      else
+        state = kLiteralNextStates[state];
+    }
+    else
+    {
+      uint32_t pos;
+      const struct COptimal *prevOpt;
+      if (curOpt->prev1IsChar && curOpt->prev2)
+      {
+        posPrev = curOpt->posPrev2;
+        pos = curOpt->backPrev2;
+        state = kRepNextStates[state];
+      }
+      else
+      {
+        pos = curOpt->backPrev;
+        if (pos < LZMA_NUM_REPS)
+          state = kRepNextStates[state];
+        else
+          state = kMatchNextStates[state];
+      }
+      prevOpt = &p->opt[posPrev];
+      if (pos < LZMA_NUM_REPS)
+      {
+        reps[0] = prevOpt->backs[pos];
+        for (i = 1; i <= pos; i++)
+          reps[i] = prevOpt->backs[i - 1];
+        for (; i < LZMA_NUM_REPS; i++)
+          reps[i] = prevOpt->backs[i];
+      }
+      else
+      {
+        reps[0] = (pos - LZMA_NUM_REPS);
+        for (i = 1; i < LZMA_NUM_REPS; i++)
+          reps[i] = prevOpt->backs[i - 1];
+      }
+    }
+    curOpt->state = (CState)state;
+
+    curOpt->backs[0] = reps[0];
+    curOpt->backs[1] = reps[1];
+    curOpt->backs[2] = reps[2];
+    curOpt->backs[3] = reps[3];
+
+    curPrice = curOpt->price;
+    nextIsChar = false;
+    data = p->matchFinder.GetPointerToCurrentPos(p->matchFinderObj) - 1;
+    curuint8_t = *data;
+    matchuint8_t = *(data - (reps[0] + 1));
+
+    posState = (position & p->pbMask);
+
+    curAnd1Price = curPrice + GET_PRICE_0(p->isMatch[state][posState]);
+    {
+      const CLzmaProb *probs = LIT_PROBS(position, *(data - 1));
+      curAnd1Price +=
+        (!IsCharState(state) ?
+          LitEnc_GetPriceMatched(probs, curuint8_t, matchuint8_t, p->ProbPrices) :
+          LitEnc_GetPrice(probs, curuint8_t, p->ProbPrices));
+    }
+
+    nextOpt = &p->opt[cur + 1];
+
+    if (curAnd1Price < nextOpt->price)
+    {
+      nextOpt->price = curAnd1Price;
+      nextOpt->posPrev = cur;
+      MakeAsChar(nextOpt);
+      nextIsChar = true;
+    }
+
+    matchPrice = curPrice + GET_PRICE_1(p->isMatch[state][posState]);
+    repMatchPrice = matchPrice + GET_PRICE_1(p->isRep[state]);
+
+    if (matchuint8_t == curuint8_t && !(nextOpt->posPrev < cur && nextOpt->backPrev == 0))
+    {
+      uint32_t shortRepPrice = repMatchPrice + GetRepLen1Price(p, state, posState);
+      if (shortRepPrice <= nextOpt->price)
+      {
+        nextOpt->price = shortRepPrice;
+        nextOpt->posPrev = cur;
+        MakeAsShortRep(nextOpt);
+        nextIsChar = true;
+      }
+    }
+    numAvailFull = p->numAvail;
+    {
+      uint32_t temp = kNumOpts - 1 - cur;
+      if (temp < numAvailFull)
+        numAvailFull = temp;
+    }
+
+    if (numAvailFull < 2)
+      continue;
+    numAvail = (numAvailFull <= p->numFastuint8_ts ? numAvailFull : p->numFastuint8_ts);
+
+    if (!nextIsChar && matchuint8_t != curuint8_t) /* speed optimization */
+    {
+      /* try Literal + rep0 */
+      uint32_t temp;
+      uint32_t lenTest2;
+      const uint8_t *data2 = data - (reps[0] + 1);
+      uint32_t limit = p->numFastuint8_ts + 1;
+      if (limit > numAvailFull)
+        limit = numAvailFull;
+
+      for (temp = 1; temp < limit && data[temp] == data2[temp]; temp++);
+      lenTest2 = temp - 1;
+      if (lenTest2 >= 2)
+      {
+        uint32_t state2 = kLiteralNextStates[state];
+        uint32_t posStateNext = (position + 1) & p->pbMask;
+        uint32_t nextRepMatchPrice = curAnd1Price +
+            GET_PRICE_1(p->isMatch[state2][posStateNext]) +
+            GET_PRICE_1(p->isRep[state2]);
+        /* for (; lenTest2 >= 2; lenTest2--) */
+        {
+          uint32_t curAndLenPrice;
+          struct COptimal *opt;
+          uint32_t offset = cur + 1 + lenTest2;
+          while (lenEnd < offset)
+            p->opt[++lenEnd].price = kInfinityPrice;
+          curAndLenPrice = nextRepMatchPrice + GetRepPrice(p, 0, lenTest2, state2, posStateNext);
+          opt = &p->opt[offset];
+          if (curAndLenPrice < opt->price)
+          {
+            opt->price = curAndLenPrice;
+            opt->posPrev = cur + 1;
+            opt->backPrev = 0;
+            opt->prev1IsChar = true;
+            opt->prev2 = false;
+          }
+        }
+      }
+    }
+
+    startLen = 2; /* speed optimization */
+    {
+    uint32_t repIndex;
+    for (repIndex = 0; repIndex < LZMA_NUM_REPS; repIndex++)
+    {
+      uint32_t lenTest;
+      uint32_t lenTestTemp;
+      uint32_t price;
+      const uint8_t *data2 = data - (reps[repIndex] + 1);
+      if (data[0] != data2[0] || data[1] != data2[1])
+        continue;
+      for (lenTest = 2; lenTest < numAvail && data[lenTest] == data2[lenTest]; lenTest++);
+      while (lenEnd < cur + lenTest)
+        p->opt[++lenEnd].price = kInfinityPrice;
+      lenTestTemp = lenTest;
+      price = repMatchPrice + GetPureRepPrice(p, repIndex, state, posState);
+      do
+      {
+        uint32_t curAndLenPrice = price + p->repLenEnc.prices[posState][lenTest - 2];
+        struct COptimal *opt = &p->opt[cur + lenTest];
+        if (curAndLenPrice < opt->price)
+        {
+          opt->price = curAndLenPrice;
+          opt->posPrev = cur;
+          opt->backPrev = repIndex;
+          opt->prev1IsChar = false;
+        }
+      }
+      while (--lenTest >= 2);
+      lenTest = lenTestTemp;
+
+      if (repIndex == 0)
+        startLen = lenTest + 1;
+
+      /* if (_maxMode) */
+        {
+          uint32_t lenTest2 = lenTest + 1;
+          uint32_t limit = lenTest2 + p->numFastuint8_ts;
+          uint32_t nextRepMatchPrice;
+          if (limit > numAvailFull)
+            limit = numAvailFull;
+          for (; lenTest2 < limit && data[lenTest2] == data2[lenTest2]; lenTest2++);
+          lenTest2 -= lenTest + 1;
+          if (lenTest2 >= 2)
+          {
+            uint32_t state2 = kRepNextStates[state];
+            uint32_t posStateNext = (position + lenTest) & p->pbMask;
+            uint32_t curAndLenCharPrice =
+                price + p->repLenEnc.prices[posState][lenTest - 2] +
+                GET_PRICE_0(p->isMatch[state2][posStateNext]) +
+                LitEnc_GetPriceMatched(LIT_PROBS(position + lenTest, data[lenTest - 1]),
+                    data[lenTest], data2[lenTest], p->ProbPrices);
+            state2 = kLiteralNextStates[state2];
+            posStateNext = (position + lenTest + 1) & p->pbMask;
+            nextRepMatchPrice = curAndLenCharPrice +
+                GET_PRICE_1(p->isMatch[state2][posStateNext]) +
+                GET_PRICE_1(p->isRep[state2]);
+
+            /* for (; lenTest2 >= 2; lenTest2--) */
+            {
+              uint32_t curAndLenPrice;
+              struct COptimal *opt;
+              uint32_t offset = cur + lenTest + 1 + lenTest2;
+              while (lenEnd < offset)
+                p->opt[++lenEnd].price = kInfinityPrice;
+              curAndLenPrice = nextRepMatchPrice + GetRepPrice(p, 0, lenTest2, state2, posStateNext);
+              opt = &p->opt[offset];
+              if (curAndLenPrice < opt->price)
+              {
+                opt->price = curAndLenPrice;
+                opt->posPrev = cur + lenTest + 1;
+                opt->backPrev = 0;
+                opt->prev1IsChar = true;
+                opt->prev2 = true;
+                opt->posPrev2 = cur;
+                opt->backPrev2 = repIndex;
+              }
+            }
+          }
+        }
+    }
+    }
+    /* for (uint32_t lenTest = 2; lenTest <= newLen; lenTest++) */
+    if (newLen > numAvail)
+    {
+      newLen = numAvail;
+      for (numPairs = 0; newLen > matches[numPairs]; numPairs += 2);
+      matches[numPairs] = newLen;
+      numPairs += 2;
+    }
+    if (newLen >= startLen)
+    {
+      uint32_t offs, curBack, posSlot;
+      uint32_t lenTest;
+
+      normalMatchPrice = matchPrice + GET_PRICE_0(p->isRep[state]);
+
+      while (lenEnd < cur + newLen)
+        p->opt[++lenEnd].price = kInfinityPrice;
+
+      offs = 0;
+      while (startLen > matches[offs])
+        offs += 2;
+      curBack = matches[offs + 1];
+      GetPosSlot2(curBack, posSlot);
+      for (lenTest = /*2*/ startLen; ; lenTest++)
+      {
+        uint32_t curAndLenPrice = normalMatchPrice + p->lenEnc.prices[posState][lenTest - LZMA_MATCH_LEN_MIN];
+        uint32_t lenToPosState = GetLenToPosState(lenTest);
+        struct COptimal *opt;
+        if (curBack < kNumFullDistances)
+          curAndLenPrice += p->distancesPrices[lenToPosState][curBack];
+        else
+          curAndLenPrice += p->posSlotPrices[lenToPosState][posSlot] + p->alignPrices[curBack & kAlignMask];
+
+        opt = &p->opt[cur + lenTest];
+        if (curAndLenPrice < opt->price)
+        {
+          opt->price = curAndLenPrice;
+          opt->posPrev = cur;
+          opt->backPrev = curBack + LZMA_NUM_REPS;
+          opt->prev1IsChar = false;
+        }
+
+        if (/*_maxMode && */lenTest == matches[offs])
+        {
+          /* Try Match + Literal + Rep0 */
+          const uint8_t *data2 = data - (curBack + 1);
+          uint32_t lenTest2 = lenTest + 1;
+          uint32_t limit = lenTest2 + p->numFastuint8_ts;
+          uint32_t nextRepMatchPrice;
+          if (limit > numAvailFull)
+            limit = numAvailFull;
+          for (; lenTest2 < limit && data[lenTest2] == data2[lenTest2]; lenTest2++);
+          lenTest2 -= lenTest + 1;
+          if (lenTest2 >= 2)
+          {
+            uint32_t state2 = kMatchNextStates[state];
+            uint32_t posStateNext = (position + lenTest) & p->pbMask;
+            uint32_t curAndLenCharPrice = curAndLenPrice +
+                GET_PRICE_0(p->isMatch[state2][posStateNext]) +
+                LitEnc_GetPriceMatched(LIT_PROBS(position + lenTest, data[lenTest - 1]),
+                    data[lenTest], data2[lenTest], p->ProbPrices);
+            state2 = kLiteralNextStates[state2];
+            posStateNext = (posStateNext + 1) & p->pbMask;
+            nextRepMatchPrice = curAndLenCharPrice +
+                GET_PRICE_1(p->isMatch[state2][posStateNext]) +
+                GET_PRICE_1(p->isRep[state2]);
+
+            /* for (; lenTest2 >= 2; lenTest2--) */
+            {
+              uint32_t offset = cur + lenTest + 1 + lenTest2;
+              while (lenEnd < offset)
+                p->opt[++lenEnd].price = kInfinityPrice;
+              curAndLenPrice = nextRepMatchPrice + GetRepPrice(p, 0, lenTest2, state2, posStateNext);
+              opt = &p->opt[offset];
+              if (curAndLenPrice < opt->price)
+              {
+                opt->price = curAndLenPrice;
+                opt->posPrev = cur + lenTest + 1;
+                opt->backPrev = 0;
+                opt->prev1IsChar = true;
+                opt->prev2 = true;
+                opt->posPrev2 = cur;
+                opt->backPrev2 = curBack + LZMA_NUM_REPS;
+              }
+            }
+          }
+          offs += 2;
+          if (offs == numPairs)
+            break;
+          curBack = matches[offs + 1];
+          if (curBack >= kNumFullDistances)
+            GetPosSlot2(curBack, posSlot);
+        }
+      }
+    }
+  }
+}
+
+#define ChangePair(smallDist, bigDist) (((bigDist) >> 7) > (smallDist))
+
+static uint32_t GetOptimumFast(struct CLzmaEnc *p, uint32_t *backRes)
+{
+  uint32_t numAvail, mainLen, mainDist, numPairs, repIndex, repLen, i;
+  const uint8_t *data;
+  const uint32_t *matches;
+
+  if (p->additionalOffset == 0)
+    mainLen = ReadMatchDistances(p, &numPairs);
+  else
+  {
+    mainLen = p->longestMatchLength;
+    numPairs = p->numPairs;
+  }
+
+  numAvail = p->numAvail;
+  *backRes = (uint32_t)-1;
+  if (numAvail < 2)
+    return 1;
+  if (numAvail > LZMA_MATCH_LEN_MAX)
+    numAvail = LZMA_MATCH_LEN_MAX;
+  data = p->matchFinder.GetPointerToCurrentPos(p->matchFinderObj) - 1;
+
+  repLen = repIndex = 0;
+  for (i = 0; i < LZMA_NUM_REPS; i++)
+  {
+    uint32_t len;
+    const uint8_t *data2 = data - (p->reps[i] + 1);
+    if (data[0] != data2[0] || data[1] != data2[1])
+      continue;
+    for (len = 2; len < numAvail && data[len] == data2[len]; len++);
+    if (len >= p->numFastuint8_ts)
+    {
+      *backRes = i;
+      MovePos(p, len - 1);
+      return len;
+    }
+    if (len > repLen)
+    {
+      repIndex = i;
+      repLen = len;
+    }
+  }
+
+  matches = p->matches;
+  if (mainLen >= p->numFastuint8_ts)
+  {
+    *backRes = matches[numPairs - 1] + LZMA_NUM_REPS;
+    MovePos(p, mainLen - 1);
+    return mainLen;
+  }
+
+  mainDist = 0; /* for GCC */
+  if (mainLen >= 2)
+  {
+    mainDist = matches[numPairs - 1];
+    while (numPairs > 2 && mainLen == matches[numPairs - 4] + 1)
+    {
+      if (!ChangePair(matches[numPairs - 3], mainDist))
+        break;
+      numPairs -= 2;
+      mainLen = matches[numPairs - 2];
+      mainDist = matches[numPairs - 1];
+    }
+    if (mainLen == 2 && mainDist >= 0x80)
+      mainLen = 1;
+  }
+
+  if (repLen >= 2 && (
+        (repLen + 1 >= mainLen) ||
+        (repLen + 2 >= mainLen && mainDist >= (1 << 9)) ||
+        (repLen + 3 >= mainLen && mainDist >= (1 << 15))))
+  {
+    *backRes = repIndex;
+    MovePos(p, repLen - 1);
+    return repLen;
+  }
+
+  if (mainLen < 2 || numAvail <= 2)
+    return 1;
+
+  p->longestMatchLength = ReadMatchDistances(p, &p->numPairs);
+  if (p->longestMatchLength >= 2)
+  {
+    uint32_t newDistance = matches[p->numPairs - 1];
+    if ((p->longestMatchLength >= mainLen && newDistance < mainDist) ||
+        (p->longestMatchLength == mainLen + 1 && !ChangePair(mainDist, newDistance)) ||
+        (p->longestMatchLength > mainLen + 1) ||
+        (p->longestMatchLength + 1 >= mainLen && mainLen >= 3 && ChangePair(newDistance, mainDist)))
+      return 1;
+  }
+
+  data = p->matchFinder.GetPointerToCurrentPos(p->matchFinderObj) - 1;
+  for (i = 0; i < LZMA_NUM_REPS; i++)
+  {
+    uint32_t len, limit;
+    const uint8_t *data2 = data - (p->reps[i] + 1);
+    if (data[0] != data2[0] || data[1] != data2[1])
+      continue;
+    limit = mainLen - 1;
+    for (len = 2; len < limit && data[len] == data2[len]; len++);
+    if (len >= limit)
+      return 1;
+  }
+  *backRes = mainDist + LZMA_NUM_REPS;
+  MovePos(p, mainLen - 2);
+  return mainLen;
+}
+
+static void WriteEndMarker(struct CLzmaEnc *p, uint32_t posState)
+{
+  uint32_t len;
+  RangeEnc_EncodeBit(&p->rc, &p->isMatch[p->state][posState], 1);
+  RangeEnc_EncodeBit(&p->rc, &p->isRep[p->state], 0);
+  p->state = kMatchNextStates[p->state];
+  len = LZMA_MATCH_LEN_MIN;
+  LenEnc_Encode2(&p->lenEnc, &p->rc, len - LZMA_MATCH_LEN_MIN, posState, !p->fastMode, p->ProbPrices);
+  RcTree_Encode(&p->rc, p->posSlotEncoder[GetLenToPosState(len)], kNumPosSlotBits, (1 << kNumPosSlotBits) - 1);
+  RangeEnc_EncodeDirectBits(&p->rc, (((uint32_t)1 << 30) - 1) >> kNumAlignBits, 30 - kNumAlignBits);
+  RcTree_ReverseEncode(&p->rc, p->posAlignEncoder, kNumAlignBits, kAlignMask);
+}
+
+static SRes CheckErrors(struct CLzmaEnc *p)
+{
+  if (p->result != SZ_OK)
+    return p->result;
+  if (p->rc.res != SZ_OK)
+    p->result = SZ_ERROR_WRITE;
+  if (p->matchFinderBase.result != SZ_OK)
+    p->result = SZ_ERROR_READ;
+  if (p->result != SZ_OK)
+    p->finished = true;
+  return p->result;
+}
+
+static SRes Flush(struct CLzmaEnc *p, uint32_t nowPos)
+{
+  /* ReleaseMFStream(); */
+  p->finished = true;
+  if (p->writeEndMark)
+    WriteEndMarker(p, nowPos & p->pbMask);
+  RangeEnc_FlushData(&p->rc);
+  RangeEnc_FlushStream(&p->rc);
+  return CheckErrors(p);
+}
+
+static void FillAlignPrices(struct CLzmaEnc *p)
+{
+  uint32_t i;
+  for (i = 0; i < kAlignTableSize; i++)
+    p->alignPrices[i] = RcTree_ReverseGetPrice(p->posAlignEncoder, kNumAlignBits, i, p->ProbPrices);
+  p->alignPriceCount = 0;
+}
+
+static void FillDistancesPrices(struct CLzmaEnc *p)
+{
+  uint32_t tempPrices[kNumFullDistances];
+  uint32_t i, lenToPosState;
+  for (i = kStartPosModelIndex; i < kNumFullDistances; i++)
+  {
+    uint32_t posSlot = GetPosSlot1(i);
+    uint32_t footerBits = ((posSlot >> 1) - 1);
+    uint32_t base = ((2 | (posSlot & 1)) << footerBits);
+    tempPrices[i] = RcTree_ReverseGetPrice(p->posEncoders + base - posSlot - 1, footerBits, i - base, p->ProbPrices);
+  }
+
+  for (lenToPosState = 0; lenToPosState < kNumLenToPosStates; lenToPosState++)
+  {
+    uint32_t posSlot;
+    const CLzmaProb *encoder = p->posSlotEncoder[lenToPosState];
+    uint32_t *posSlotPrices = p->posSlotPrices[lenToPosState];
+    for (posSlot = 0; posSlot < p->distTableSize; posSlot++)
+      posSlotPrices[posSlot] = RcTree_GetPrice(encoder, kNumPosSlotBits, posSlot, p->ProbPrices);
+    for (posSlot = kEndPosModelIndex; posSlot < p->distTableSize; posSlot++)
+      posSlotPrices[posSlot] += ((((posSlot >> 1) - 1) - kNumAlignBits) << kNumBitPriceShiftBits);
+
+    {
+      uint32_t *distancesPrices = p->distancesPrices[lenToPosState];
+      for (i = 0; i < kStartPosModelIndex; i++)
+        distancesPrices[i] = posSlotPrices[i];
+      for (; i < kNumFullDistances; i++)
+        distancesPrices[i] = posSlotPrices[GetPosSlot1(i)] + tempPrices[i];
+    }
+  }
+  p->matchPriceCount = 0;
+}
+
+static void LzmaEnc_Construct(struct CLzmaEnc *p)
+{
+  RangeEnc_Construct(&p->rc);
+  MatchFinder_Construct(&p->matchFinderBase);
+
+  {
+    struct CLzmaEncProps props;
+    LzmaEncProps_Init(&props);
+    LzmaEnc_SetProps(p, &props);
+  }
+
+  #ifndef LZMA_LOG_BSR
+  LzmaEnc_FastPosInit(p->g_FastPos);
+  #endif
+
+  LzmaEnc_InitPriceTables(p->ProbPrices);
+  p->litProbs = 0;
+  p->saveState.litProbs = 0;
+}
+
+CLzmaEncHandle LzmaEnc_Create(struct ISzAlloc *alloc)
+{
+  void *p;
+  p = alloc->Alloc(alloc, sizeof(struct CLzmaEnc));
+  if (p != 0)
+    LzmaEnc_Construct((struct CLzmaEnc *)p);
+  return p;
+}
+
+static void LzmaEnc_FreeLits(struct CLzmaEnc *p, struct ISzAlloc *alloc)
+{
+  alloc->Free(alloc, p->litProbs);
+  alloc->Free(alloc, p->saveState.litProbs);
+  p->litProbs = 0;
+  p->saveState.litProbs = 0;
+}
+
+static void LzmaEnc_Destruct(struct CLzmaEnc *p, struct ISzAlloc *alloc, struct ISzAlloc *allocBig)
+{
+  MatchFinder_Free(&p->matchFinderBase, allocBig);
+  LzmaEnc_FreeLits(p, alloc);
+  RangeEnc_Free(&p->rc, alloc);
+}
+
+void LzmaEnc_Destroy(CLzmaEncHandle p, struct ISzAlloc *alloc, struct ISzAlloc *allocBig)
+{
+  LzmaEnc_Destruct((struct CLzmaEnc *)p, alloc, allocBig);
+  alloc->Free(alloc, p);
+}
+
+static SRes LzmaEnc_CodeOneBlock(struct CLzmaEnc *p, bool useLimits, uint32_t maxPackSize, uint32_t maxUnpackSize)
+{
+  uint32_t nowPos32, startPos32;
+  if (p->needInit)
+  {
+    p->matchFinder.Init(p->matchFinderObj);
+    p->needInit = 0;
+  }
+
+  if (p->finished)
+    return p->result;
+  RINOK(CheckErrors(p));
+
+  nowPos32 = (uint32_t)p->nowPos64;
+  startPos32 = nowPos32;
+
+  if (p->nowPos64 == 0)
+  {
+    uint32_t numPairs;
+    uint8_t curuint8_t;
+    if (p->matchFinder.GetNumAvailableBytes(p->matchFinderObj) == 0)
+      return Flush(p, nowPos32);
+    ReadMatchDistances(p, &numPairs);
+    RangeEnc_EncodeBit(&p->rc, &p->isMatch[p->state][0], 0);
+    p->state = kLiteralNextStates[p->state];
+    curuint8_t = p->matchFinder.GetIndexByte(p->matchFinderObj, 0 - p->additionalOffset);
+    LitEnc_Encode(&p->rc, p->litProbs, curuint8_t);
+    p->additionalOffset--;
+    nowPos32++;
+  }
+
+  if (p->matchFinder.GetNumAvailableBytes(p->matchFinderObj) != 0)
+  for (;;)
+  {
+    uint32_t pos, len, posState;
+
+    if (p->fastMode)
+      len = GetOptimumFast(p, &pos);
+    else
+      len = GetOptimum(p, nowPos32, &pos);
+
+    posState = nowPos32 & p->pbMask;
+    if (len == 1 && pos == (uint32_t)-1)
+    {
+      uint8_t curuint8_t;
+      CLzmaProb *probs;
+      const uint8_t *data;
+
+      RangeEnc_EncodeBit(&p->rc, &p->isMatch[p->state][posState], 0);
+      data = p->matchFinder.GetPointerToCurrentPos(p->matchFinderObj) - p->additionalOffset;
+      curuint8_t = *data;
+      probs = LIT_PROBS(nowPos32, *(data - 1));
+      if (IsCharState(p->state))
+        LitEnc_Encode(&p->rc, probs, curuint8_t);
+      else
+        LitEnc_EncodeMatched(&p->rc, probs, curuint8_t, *(data - p->reps[0] - 1));
+      p->state = kLiteralNextStates[p->state];
+    }
+    else
+    {
+      RangeEnc_EncodeBit(&p->rc, &p->isMatch[p->state][posState], 1);
+      if (pos < LZMA_NUM_REPS)
+      {
+        RangeEnc_EncodeBit(&p->rc, &p->isRep[p->state], 1);
+        if (pos == 0)
+        {
+          RangeEnc_EncodeBit(&p->rc, &p->isRepG0[p->state], 0);
+          RangeEnc_EncodeBit(&p->rc, &p->isRep0Long[p->state][posState], ((len == 1) ? 0 : 1));
+        }
+        else
+        {
+          uint32_t distance = p->reps[pos];
+          RangeEnc_EncodeBit(&p->rc, &p->isRepG0[p->state], 1);
+          if (pos == 1)
+            RangeEnc_EncodeBit(&p->rc, &p->isRepG1[p->state], 0);
+          else
+          {
+            RangeEnc_EncodeBit(&p->rc, &p->isRepG1[p->state], 1);
+            RangeEnc_EncodeBit(&p->rc, &p->isRepG2[p->state], pos - 2);
+            if (pos == 3)
+              p->reps[3] = p->reps[2];
+            p->reps[2] = p->reps[1];
+          }
+          p->reps[1] = p->reps[0];
+          p->reps[0] = distance;
+        }
+        if (len == 1)
+          p->state = kShortRepNextStates[p->state];
+        else
+        {
+          LenEnc_Encode2(&p->repLenEnc, &p->rc, len - LZMA_MATCH_LEN_MIN, posState, !p->fastMode, p->ProbPrices);
+          p->state = kRepNextStates[p->state];
+        }
+      }
+      else
+      {
+        uint32_t posSlot;
+        RangeEnc_EncodeBit(&p->rc, &p->isRep[p->state], 0);
+        p->state = kMatchNextStates[p->state];
+        LenEnc_Encode2(&p->lenEnc, &p->rc, len - LZMA_MATCH_LEN_MIN, posState, !p->fastMode, p->ProbPrices);
+        pos -= LZMA_NUM_REPS;
+        GetPosSlot(pos, posSlot);
+        RcTree_Encode(&p->rc, p->posSlotEncoder[GetLenToPosState(len)], kNumPosSlotBits, posSlot);
+
+        if (posSlot >= kStartPosModelIndex)
+        {
+          uint32_t footerBits = ((posSlot >> 1) - 1);
+          uint32_t base = ((2 | (posSlot & 1)) << footerBits);
+          uint32_t posReduced = pos - base;
+
+          if (posSlot < kEndPosModelIndex)
+            RcTree_ReverseEncode(&p->rc, p->posEncoders + base - posSlot - 1, footerBits, posReduced);
+          else
+          {
+            RangeEnc_EncodeDirectBits(&p->rc, posReduced >> kNumAlignBits, footerBits - kNumAlignBits);
+            RcTree_ReverseEncode(&p->rc, p->posAlignEncoder, kNumAlignBits, posReduced & kAlignMask);
+            p->alignPriceCount++;
+          }
+        }
+        p->reps[3] = p->reps[2];
+        p->reps[2] = p->reps[1];
+        p->reps[1] = p->reps[0];
+        p->reps[0] = pos;
+        p->matchPriceCount++;
+      }
+    }
+    p->additionalOffset -= len;
+    nowPos32 += len;
+    if (p->additionalOffset == 0)
+    {
+      uint32_t processed;
+      if (!p->fastMode)
+      {
+        if (p->matchPriceCount >= (1 << 7))
+          FillDistancesPrices(p);
+        if (p->alignPriceCount >= kAlignTableSize)
+          FillAlignPrices(p);
+      }
+      if (p->matchFinder.GetNumAvailableBytes(p->matchFinderObj) == 0)
+        break;
+      processed = nowPos32 - startPos32;
+      if (useLimits)
+      {
+        if (processed + kNumOpts + 300 >= maxUnpackSize ||
+            RangeEnc_GetProcessed(&p->rc) + kNumOpts * 2 >= maxPackSize)
+          break;
+      }
+      else if (processed >= (1 << 15))
+      {
+        p->nowPos64 += nowPos32 - startPos32;
+        return CheckErrors(p);
+      }
+    }
+  }
+  p->nowPos64 += nowPos32 - startPos32;
+  return Flush(p, nowPos32);
+}
+
+#define kBigHashDicLimit ((uint32_t)1 << 24)
+
+static SRes LzmaEnc_Alloc(struct CLzmaEnc *p, uint32_t keepWindowSize, struct ISzAlloc *alloc, struct ISzAlloc *allocBig)
+{
+  uint32_t beforeSize = kNumOpts;
+  if (!RangeEnc_Alloc(&p->rc, alloc))
+    return SZ_ERROR_MEM;
+
+  {
+    unsigned lclp = p->lc + p->lp;
+    if (p->litProbs == 0 || p->saveState.litProbs == 0 || p->lclp != lclp)
+    {
+      LzmaEnc_FreeLits(p, alloc);
+      p->litProbs = (CLzmaProb *)alloc->Alloc(alloc, (0x300 << lclp) * sizeof(CLzmaProb));
+      p->saveState.litProbs = (CLzmaProb *)alloc->Alloc(alloc, (0x300 << lclp) * sizeof(CLzmaProb));
+      if (p->litProbs == 0 || p->saveState.litProbs == 0)
+      {
+        LzmaEnc_FreeLits(p, alloc);
+        return SZ_ERROR_MEM;
+      }
+      p->lclp = lclp;
+    }
+  }
+
+  p->matchFinderBase.bigHash = (p->dictSize > kBigHashDicLimit);
+
+  if (beforeSize + p->dictSize < keepWindowSize)
+    beforeSize = keepWindowSize - p->dictSize;
+
+  {
+    if (!MatchFinder_Create(&p->matchFinderBase, p->dictSize, beforeSize, p->numFastuint8_ts, LZMA_MATCH_LEN_MAX, allocBig))
+      return SZ_ERROR_MEM;
+    p->matchFinderObj = &p->matchFinderBase;
+    MatchFinder_CreateVTable(&p->matchFinderBase, &p->matchFinder);
+  }
+  return SZ_OK;
+}
+
+static void LzmaEnc_Init(struct CLzmaEnc *p)
+{
+  uint32_t i;
+  p->state = 0;
+  for (i = 0 ; i < LZMA_NUM_REPS; i++)
+    p->reps[i] = 0;
+
+  RangeEnc_Init(&p->rc);
+
+
+  for (i = 0; i < kNumStates; i++)
+  {
+    uint32_t j;
+    for (j = 0; j < LZMA_NUM_PB_STATES_MAX; j++)
+    {
+      p->isMatch[i][j] = kProbInitValue;
+      p->isRep0Long[i][j] = kProbInitValue;
+    }
+    p->isRep[i] = kProbInitValue;
+    p->isRepG0[i] = kProbInitValue;
+    p->isRepG1[i] = kProbInitValue;
+    p->isRepG2[i] = kProbInitValue;
+  }
+
+  {
+    uint32_t num = 0x300 << (p->lp + p->lc);
+    for (i = 0; i < num; i++)
+      p->litProbs[i] = kProbInitValue;
+  }
+
+  {
+    for (i = 0; i < kNumLenToPosStates; i++)
+    {
+      CLzmaProb *probs = p->posSlotEncoder[i];
+      uint32_t j;
+      for (j = 0; j < (1 << kNumPosSlotBits); j++)
+        probs[j] = kProbInitValue;
+    }
+  }
+  {
+    for (i = 0; i < kNumFullDistances - kEndPosModelIndex; i++)
+      p->posEncoders[i] = kProbInitValue;
+  }
+
+  LenEnc_Init(&p->lenEnc.p);
+  LenEnc_Init(&p->repLenEnc.p);
+
+  for (i = 0; i < (1 << kNumAlignBits); i++)
+    p->posAlignEncoder[i] = kProbInitValue;
+
+  p->optimumEndIndex = 0;
+  p->optimumCurrentIndex = 0;
+  p->additionalOffset = 0;
+
+  p->pbMask = (1 << p->pb) - 1;
+  p->lpMask = (1 << p->lp) - 1;
+}
+
+static void LzmaEnc_InitPrices(struct CLzmaEnc *p)
+{
+  if (!p->fastMode)
+  {
+    FillDistancesPrices(p);
+    FillAlignPrices(p);
+  }
+
+  p->lenEnc.tableSize =
+  p->repLenEnc.tableSize =
+      p->numFastuint8_ts + 1 - LZMA_MATCH_LEN_MIN;
+  LenPriceEnc_UpdateTables(&p->lenEnc, 1 << p->pb, p->ProbPrices);
+  LenPriceEnc_UpdateTables(&p->repLenEnc, 1 << p->pb, p->ProbPrices);
+}
+
+static SRes LzmaEnc_AllocAndInit(struct CLzmaEnc *p, uint32_t keepWindowSize, struct ISzAlloc *alloc, struct ISzAlloc *allocBig)
+{
+  uint32_t i;
+  for (i = 0; i < (uint32_t)kDicLogSizeMaxCompress; i++)
+    if (p->dictSize <= ((uint32_t)1 << i))
+      break;
+  p->distTableSize = i * 2;
+
+  p->finished = false;
+  p->result = SZ_OK;
+  RINOK(LzmaEnc_Alloc(p, keepWindowSize, alloc, allocBig));
+  LzmaEnc_Init(p);
+  LzmaEnc_InitPrices(p);
+  p->nowPos64 = 0;
+  return SZ_OK;
+}
+
+static SRes LzmaEnc_Prepare(CLzmaEncHandle pp, struct ISeqOutStream *outStream, struct ISeqInStream *inStream,
+    struct ISzAlloc *alloc, struct ISzAlloc *allocBig)
+{
+  struct CLzmaEnc *p = (struct CLzmaEnc *)pp;
+  p->matchFinderBase.stream = inStream;
+  p->needInit = 1;
+  p->rc.outStream = outStream;
+  return LzmaEnc_AllocAndInit(p, 0, alloc, allocBig);
+}
+
+/*static SRes LzmaEnc_PrepareForLzma2(CLzmaEncHandle pp,
+    ISeqInStream *inStream, uint32_t keepWindowSize,
+    ISzAlloc *alloc, ISzAlloc *allocBig)
+{
+  CLzmaEnc *p = (CLzmaEnc *)pp;
+  p->matchFinderBase.stream = inStream;
+  p->needInit = 1;
+  return LzmaEnc_AllocAndInit(p, keepWindowSize, alloc, allocBig);
+}*/
+
+static void LzmaEnc_SetInputBuf(struct CLzmaEnc *p, const uint8_t *src, size_t srcLen)
+{
+  p->matchFinderBase.directInput = 1;
+  p->matchFinderBase.bufferBase = (uint8_t *)src;
+  p->matchFinderBase.directInputRem = srcLen;
+}
+
+static SRes LzmaEnc_MemPrepare(CLzmaEncHandle pp, const uint8_t *src, size_t srcLen,
+    uint32_t keepWindowSize, struct ISzAlloc *alloc, struct ISzAlloc *allocBig)
+{
+  struct CLzmaEnc *p = (struct CLzmaEnc *)pp;
+  LzmaEnc_SetInputBuf(p, src, srcLen);
+  p->needInit = 1;
+
+  return LzmaEnc_AllocAndInit(p, keepWindowSize, alloc, allocBig);
+}
+
+static void LzmaEnc_Finish(CLzmaEncHandle pp)
+{
+  (void)pp;
+}
+
+struct CSeqOutStreamBuf
+{
+  struct ISeqOutStream funcTable;
+  uint8_t *data;
+  size_t rem;
+  bool overflow;
+};
+
+static size_t MyWrite(void *pp, const void *data, size_t size)
+{
+  struct CSeqOutStreamBuf *p = (struct CSeqOutStreamBuf *)pp;
+  if (p->rem < size)
+  {
+    size = p->rem;
+    p->overflow = true;
+  }
+  memcpy(p->data, data, size);
+  p->rem -= size;
+  p->data += size;
+  return size;
+}
+
+
+/*static uint32_t LzmaEnc_GetNumAvailableBytes(CLzmaEncHandle pp)
+{
+  const CLzmaEnc *p = (CLzmaEnc *)pp;
+  return p->matchFinder.GetNumAvailableBytes(p->matchFinderObj);
+}*/
+
+/*static const uint8_t *LzmaEnc_GetCurBuf(CLzmaEncHandle pp)
+{
+  const CLzmaEnc *p = (CLzmaEnc *)pp;
+  return p->matchFinder.GetPointerToCurrentPos(p->matchFinderObj) - p->additionalOffset;
+}*/
+
+/*static SRes LzmaEnc_CodeOneMemBlock(CLzmaEncHandle pp, bool reInit,
+    uint8_t *dest, size_t *destLen, uint32_t desiredPackSize, uint32_t *unpackSize)
+{
+  CLzmaEnc *p = (CLzmaEnc *)pp;
+  uint64_t nowPos64;
+  SRes res;
+  CSeqOutStreamBuf outStream;
+
+  outStream.funcTable.Write = MyWrite;
+  outStream.data = dest;
+  outStream.rem = *destLen;
+  outStream.overflow = false;
+
+  p->writeEndMark = false;
+  p->finished = false;
+  p->result = SZ_OK;
+
+  if (reInit)
+    LzmaEnc_Init(p);
+  LzmaEnc_InitPrices(p);
+  nowPos64 = p->nowPos64;
+  RangeEnc_Init(&p->rc);
+  p->rc.outStream = &outStream.funcTable;
+
+  res = LzmaEnc_CodeOneBlock(p, true, desiredPackSize, *unpackSize);
+
+  *unpackSize = (uint32_t)(p->nowPos64 - nowPos64);
+  *destLen -= outStream.rem;
+  if (outStream.overflow)
+    return SZ_ERROR_OUTPUT_EOF;
+
+  return res;
+}*/
+
+static SRes LzmaEnc_Encode2(struct CLzmaEnc *p, struct ICompressProgress *progress)
+{
+  SRes res = SZ_OK;
+
+  for (;;)
+  {
+    res = LzmaEnc_CodeOneBlock(p, false, 0, 0);
+    if (res != SZ_OK || p->finished != 0)
+      break;
+    if (progress != 0)
+    {
+      res = progress->Progress(progress, p->nowPos64, RangeEnc_GetProcessed(&p->rc));
+      if (res != SZ_OK)
+      {
+        res = SZ_ERROR_PROGRESS;
+        break;
+      }
+    }
+  }
+  LzmaEnc_Finish(p);
+  return res;
+}
+
+SRes LzmaEnc_Encode(CLzmaEncHandle pp, struct ISeqOutStream *outStream, struct ISeqInStream *inStream, struct ICompressProgress *progress,
+    struct ISzAlloc *alloc, struct ISzAlloc *allocBig)
+{
+  RINOK(LzmaEnc_Prepare(pp, outStream, inStream, alloc, allocBig));
+  return LzmaEnc_Encode2((struct CLzmaEnc *)pp, progress);
+}
+
+SRes LzmaEnc_WriteProperties(CLzmaEncHandle pp, uint8_t *props, size_t *size)
+{
+  struct CLzmaEnc *p = (struct CLzmaEnc *)pp;
+  int i;
+  uint32_t dictSize = p->dictSize;
+  if (*size < LZMA_PROPS_SIZE)
+    return SZ_ERROR_PARAM;
+  *size = LZMA_PROPS_SIZE;
+  props[0] = (uint8_t)((p->pb * 5 + p->lp) * 9 + p->lc);
+
+  for (i = 11; i <= 30; i++)
+  {
+    if (dictSize <= ((uint32_t)2 << i))
+    {
+      dictSize = (2 << i);
+      break;
+    }
+    if (dictSize <= ((uint32_t)3 << i))
+    {
+      dictSize = (3 << i);
+      break;
+    }
+  }
+
+  for (i = 0; i < 4; i++)
+    props[1 + i] = (uint8_t)(dictSize >> (8 * i));
+  return SZ_OK;
+}
+
+SRes LzmaEnc_MemEncode(CLzmaEncHandle pp, uint8_t *dest, size_t *destLen, const uint8_t *src, size_t srcLen,
+		       int writeEndMark, struct ICompressProgress *progress, struct ISzAlloc *alloc, struct ISzAlloc *allocBig)
+{
+  SRes res;
+  struct CLzmaEnc *p = (struct CLzmaEnc *)pp;
+
+  struct CSeqOutStreamBuf outStream;
+
+  LzmaEnc_SetInputBuf(p, src, srcLen);
+
+  outStream.funcTable.Write = MyWrite;
+  outStream.data = dest;
+  outStream.rem = *destLen;
+  outStream.overflow = false;
+
+  p->writeEndMark = writeEndMark;
+
+  p->rc.outStream = &outStream.funcTable;
+  res = LzmaEnc_MemPrepare(pp, src, srcLen, 0, alloc, allocBig);
+  if (res == SZ_OK)
+    res = LzmaEnc_Encode2(p, progress);
+
+  *destLen -= outStream.rem;
+  if (outStream.overflow)
+    return SZ_ERROR_OUTPUT_EOF;
+  return res;
+}
+
+SRes LzmaEncode(uint8_t *dest, size_t *destLen, const uint8_t *src, size_t srcLen,
+    const struct CLzmaEncProps *props, uint8_t *propsEncoded, size_t *propsSize, int writeEndMark,
+    struct ICompressProgress *progress, struct ISzAlloc *alloc, struct ISzAlloc *allocBig)
+{
+  struct CLzmaEnc *p = (struct CLzmaEnc *)LzmaEnc_Create(alloc);
+  SRes res;
+  if (p == 0)
+    return SZ_ERROR_MEM;
+
+  res = LzmaEnc_SetProps(p, props);
+  if (res == SZ_OK)
+  {
+    res = LzmaEnc_WriteProperties(p, propsEncoded, propsSize);
+    if (res == SZ_OK)
+      res = LzmaEnc_MemEncode(p, dest, destLen, src, srcLen,
+          writeEndMark, progress, alloc, allocBig);
+  }
+
+  LzmaEnc_Destroy(p, alloc, allocBig);
+  return res;
+}
diff --git a/tools/cbfstool/Makefile b/tools/cbfstool/Makefile
new file mode 100644
index 0000000000..8f1a750a78
--- /dev/null
+++ b/tools/cbfstool/Makefile
@@ -0,0 +1,80 @@
+hostprogs-y	:= cbfstool
+always		:= $(hostprogs-y)
+
+HOSTCFLAGS_CBFSTOOL := -I$(src) -I$(src)/flashmap -I$(src)/vboot -I$(src)/edk2 \
+		       -I$(src)/lzma
+
+HOSTCFLAGS_cbfstool.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_common.o := $(HOSTCFLAGS_CBFSTOOL)
+
+HOSTCFLAGS_cbfs_image.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_cbfs-mkstage.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_cbfs-mkpayload.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_elfheaders.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_rmodule.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_xdr.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_partitioned_file.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_cbfs.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_fsp_relocate.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_mem_pool.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_region.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_2sha_utility.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_2sha1.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_2sha256.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_2sha512.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_fmap.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_kv_pair.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_valstr.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_linux_trampoline.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_cbfs-payload-linux.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_compress.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_lz4.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_lz4hc.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_lz4frame.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_xxhash.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_lz4_wrapper.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_lzma.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_LzFind.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_LzmaDec.o := $(HOSTCFLAGS_CBFSTOOL)
+HOSTCFLAGS_LzmaEnc.o := $(HOSTCFLAGS_CBFSTOOL)
+
+cbfstool-objs :=
+cbfstool-objs += cbfstool.o
+cbfstool-objs += common.o
+cbfstool-objs += cbfs_image.o
+cbfstool-objs += cbfs-mkstage.o
+cbfstool-objs += cbfs-mkpayload.o
+cbfstool-objs += elfheaders.o
+cbfstool-objs += rmodule.o
+cbfstool-objs += xdr.o
+cbfstool-objs += partitioned_file.o
+# COMMONLIB
+cbfstool-objs += cbfs.o
+cbfstool-objs += fsp_relocate.o
+cbfstool-objs += mem_pool.o
+cbfstool-objs += region.o
+# CRYPTOLIB
+cbfstool-objs += 2sha_utility.o
+cbfstool-objs += 2sha1.o
+cbfstool-objs += 2sha256.o
+cbfstool-objs += 2sha512.o
+# FMAP
+cbfstool-objs += fmap.o
+cbfstool-objs += kv_pair.o
+cbfstool-objs += valstr.o
+# linux as payload
+cbfstool-objs += linux_trampoline.o
+cbfstool-objs += cbfs-payload-linux.o
+# compression
+cbfstool-objs += compress.o
+# LZ4
+cbfstool-objs += lz4.o
+cbfstool-objs += lz4hc.o
+cbfstool-objs += lz4frame.o
+cbfstool-objs += xxhash.o
+cbfstool-objs += lz4_wrapper.o
+# LZMA
+cbfstool-objs += lzma.o
+cbfstool-objs += LzFind.o
+cbfstool-objs += LzmaDec.o
+cbfstool-objs += LzmaEnc.o
diff --git a/tools/cbfstool/ProcessorBind.h b/tools/cbfstool/ProcessorBind.h
new file mode 100644
index 0000000000..c0f4df0ee5
--- /dev/null
+++ b/tools/cbfstool/ProcessorBind.h
@@ -0,0 +1,102 @@
+/** @file
+  Processor or Compiler specific defines and types for IA-32 architecture.
+
+Copyright 2015 Google Inc.
+Copyright (c) 2006 - 2013, Intel Corporation. All rights reserved.<BR>
+This program and the accompanying materials are licensed and made available under
+the terms and conditions of the BSD License that accompanies this distribution.
+The full text of the license may be found at
+http://opensource.org/licenses/bsd-license.php.
+
+THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+**/
+
+#ifndef __PROCESSOR_BIND_H__
+#define __PROCESSOR_BIND_H__
+
+
+/*
+ * This to mimic a processor binding for EDK. This is just to provide the
+ * processor types.
+ */
+#include <inttypes.h>
+
+///
+/// Define the processor type so other code can make processor based choices.
+///
+#define MDE_CPU_IA32
+
+///
+/// 8-byte unsigned value.
+///
+typedef uint64_t UINT64;
+///
+/// 8-byte signed value.
+///
+typedef int64_t INT64;
+///
+/// 4-byte unsigned value.
+///
+typedef uint32_t UINT32;
+///
+/// 4-byte signed value.
+///
+typedef int32_t INT32;
+///
+/// 2-byte unsigned value.
+///
+typedef uint16_t UINT16;
+///
+/// 2-byte Character.  Unless otherwise specified all strings are stored in the
+/// UTF-16 encoding format as defined by Unicode 2.1 and ISO/IEC 10646 standards.
+///
+typedef uint16_t CHAR16;
+///
+/// 2-byte signed value.
+///
+typedef int16_t INT16;
+///
+/// Logical Boolean.  1-byte value containing 0 for FALSE or a 1 for TRUE.  Other
+/// values are undefined.
+///
+typedef unsigned char BOOLEAN;
+///
+/// 1-byte unsigned value.
+///
+typedef unsigned char UINT8;
+///
+/// 1-byte Character
+///
+typedef char CHAR8;
+///
+/// 1-byte signed value
+///
+typedef signed char INT8;
+
+///
+/// Unsigned value of native width.  (4 bytes on supported 32-bit processor instructions;
+/// 8 bytes on supported 64-bit processor instructions.)
+///
+typedef uintptr_t UINTN;
+///
+/// Signed value of native width.  (4 bytes on supported 32-bit processor instructions;
+/// 8 bytes on supported 64-bit processor instructions.)
+///
+typedef intptr_t INTN;
+
+//
+// Processor specific defines
+//
+
+///
+/// A value of native width with the highest bit set.
+//  Not needed for non-runtime, but it shouldb
+///
+//#define MAX_BIT     0x80000000
+
+// No API requirements as this is not for runtime.
+#define EFIAPI
+
+#endif
diff --git a/tools/cbfstool/cbfs-mkpayload.c b/tools/cbfstool/cbfs-mkpayload.c
new file mode 100644
index 0000000000..d6c10adc7e
--- /dev/null
+++ b/tools/cbfstool/cbfs-mkpayload.c
@@ -0,0 +1,456 @@
+/*
+ * cbfs-mkpayload
+ *
+ * Copyright (C) 2008 Jordan Crouse <jordan@cosmicpenguin.net>
+ *               2009 coresystems GmbH
+ *                 written by Patrick Georgi <patrick.georgi@coresystems.de>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <commonlib/endian.h>
+
+#include "elfparsing.h"
+#include "common.h"
+#include "cbfs.h"
+#include "fv.h"
+#include "coff.h"
+#include "fdt.h"
+
+/* serialize the seg array into the buffer.
+ * The buffer is assumed to be large enough.
+ */
+void xdr_segs(struct buffer *output,
+	struct cbfs_payload_segment *segs, int nseg)
+{
+	struct buffer outheader;
+	int i;
+
+	outheader.data = output->data;
+	outheader.size = 0;
+
+	for(i = 0; i < nseg; i++){
+		xdr_be.put32(&outheader, segs[i].type);
+		xdr_be.put32(&outheader, segs[i].compression);
+		xdr_be.put32(&outheader, segs[i].offset);
+		xdr_be.put64(&outheader, segs[i].load_addr);
+		xdr_be.put32(&outheader, segs[i].len);
+		xdr_be.put32(&outheader, segs[i].mem_len);
+	}
+}
+
+void xdr_get_seg(struct cbfs_payload_segment *out,
+		struct cbfs_payload_segment *in)
+{
+	struct buffer inheader;
+
+	inheader.data = (void *)in;
+	inheader.size = sizeof(*in);
+
+	out->type = xdr_be.get32(&inheader);
+	out->compression = xdr_be.get32(&inheader);
+	out->offset = xdr_be.get32(&inheader);
+	out->load_addr = xdr_be.get64(&inheader);
+	out->len = xdr_be.get32(&inheader);
+	out->mem_len = xdr_be.get32(&inheader);
+}
+
+int parse_elf_to_payload(const struct buffer *input, struct buffer *output,
+			 enum comp_algo algo)
+{
+	Elf64_Phdr *phdr;
+	Elf64_Ehdr ehdr;
+	Elf64_Shdr *shdr;
+	char *header;
+	char *strtab;
+	int headers;
+	int segments = 1;
+	int isize = 0, osize = 0;
+	int doffset = 0;
+	struct cbfs_payload_segment *segs = NULL;
+	int i;
+	int ret = 0;
+
+	comp_func_ptr compress = compression_function(algo);
+	if (!compress)
+		return -1;
+
+	if (elf_headers(input, &ehdr, &phdr, &shdr) < 0)
+		return -1;
+
+	DEBUG("start: parse_elf_to_payload\n");
+	headers = ehdr.e_phnum;
+	header = input->data;
+
+	strtab = &header[shdr[ehdr.e_shstrndx].sh_offset];
+
+	/* Count the number of headers - look for the .notes.pinfo
+	 * section */
+
+	for (i = 0; i < ehdr.e_shnum; i++) {
+		char *name;
+
+		if (i == ehdr.e_shstrndx)
+			continue;
+
+		if (shdr[i].sh_size == 0)
+			continue;
+
+		name = (char *)(strtab + shdr[i].sh_name);
+
+		if (!strcmp(name, ".note.pinfo")) {
+			segments++;
+			isize += (unsigned int)shdr[i].sh_size;
+		}
+	}
+
+	/* Now, regular headers - we only care about PT_LOAD headers,
+	 * because thats what we're actually going to load
+	 */
+
+	for (i = 0; i < headers; i++) {
+		if (phdr[i].p_type != PT_LOAD)
+			continue;
+
+		/* Empty segments are never interesting */
+		if (phdr[i].p_memsz == 0)
+			continue;
+
+		isize += phdr[i].p_filesz;
+
+		segments++;
+	}
+	/* Allocate and initialize the segment header array */
+	segs = calloc(segments, sizeof(*segs));
+	if (segs == NULL) {
+		ret = -1;
+		goto out;
+	}
+	/* Allocate a block of memory to store the data in */
+	if (buffer_create(output, (segments * sizeof(*segs)) + isize,
+			  input->name) != 0) {
+		ret = -1;
+		goto out;
+	}
+	memset(output->data, 0, output->size);
+
+	doffset = (segments * sizeof(*segs));
+
+	/* set up for output marshaling. This is a bit
+	 * tricky as we are marshaling the headers at the front,
+	 * and the data starting after the headers. We need to convert
+	 * the headers to the right format but the data
+	 * passes through unchanged. Unlike most XDR code,
+	 * we are doing these two concurrently. The doffset is
+	 * used to compute the address for the raw data, and the
+	 * outheader is used to marshal the headers. To make it simpler
+	 * for The Reader, we set up the headers in a separate array,
+	 * then marshal them all at once to the output.
+	 */
+	segments = 0;
+
+	for (i = 0; i < ehdr.e_shnum; i++) {
+		char *name;
+		if (i == ehdr.e_shstrndx)
+			continue;
+
+		if (shdr[i].sh_size == 0)
+			continue;
+		name = (char *)(strtab + shdr[i].sh_name);
+		if (!strcmp(name, ".note.pinfo")) {
+			segs[segments].type = PAYLOAD_SEGMENT_PARAMS;
+			segs[segments].load_addr = 0;
+			segs[segments].len = (unsigned int)shdr[i].sh_size;
+			segs[segments].offset = doffset;
+
+			memcpy((unsigned long *)(output->data + doffset),
+			       &header[shdr[i].sh_offset], shdr[i].sh_size);
+
+			doffset += segs[segments].len;
+			osize += segs[segments].len;
+
+			segments++;
+		}
+	}
+
+	for (i = 0; i < headers; i++) {
+		if (phdr[i].p_type != PT_LOAD)
+			continue;
+		if (phdr[i].p_memsz == 0)
+			continue;
+		if (phdr[i].p_filesz == 0) {
+			segs[segments].type = PAYLOAD_SEGMENT_BSS;
+			segs[segments].load_addr = phdr[i].p_paddr;
+			segs[segments].mem_len = phdr[i].p_memsz;
+			segs[segments].offset = doffset;
+
+			segments++;
+			continue;
+		}
+
+		if (phdr[i].p_flags & PF_X)
+			segs[segments].type = PAYLOAD_SEGMENT_CODE;
+		else
+			segs[segments].type = PAYLOAD_SEGMENT_DATA;
+		segs[segments].load_addr = phdr[i].p_paddr;
+		segs[segments].mem_len = phdr[i].p_memsz;
+		segs[segments].offset = doffset;
+
+		/* If the compression failed or made the section is larger,
+		   use the original stuff */
+
+		int len;
+		if (compress((char *)&header[phdr[i].p_offset],
+			     phdr[i].p_filesz, output->data + doffset, &len) ||
+		    (unsigned int)len > phdr[i].p_filesz) {
+			WARN("Compression failed or would make the data bigger "
+			     "- disabled.\n");
+			segs[segments].compression = 0;
+			segs[segments].len = phdr[i].p_filesz;
+			memcpy(output->data + doffset,
+			       &header[phdr[i].p_offset], phdr[i].p_filesz);
+		} else {
+			segs[segments].compression = algo;
+			segs[segments].len = len;
+		}
+
+		doffset += segs[segments].len;
+		osize += segs[segments].len;
+
+		segments++;
+	}
+
+	segs[segments].type = PAYLOAD_SEGMENT_ENTRY;
+	segs[segments++].load_addr = ehdr.e_entry;
+
+	output->size = (segments * sizeof(*segs)) + osize;
+	xdr_segs(output, segs, segments);
+
+out:
+	if (segs) free(segs);
+	if (shdr) free(shdr);
+	if (phdr) free(phdr);
+	return ret;
+}
+
+int parse_flat_binary_to_payload(const struct buffer *input,
+				 struct buffer *output,
+				 uint32_t loadaddress,
+				 uint32_t entrypoint,
+				 enum comp_algo algo)
+{
+	comp_func_ptr compress;
+	struct cbfs_payload_segment segs[2] = { {0} };
+	int doffset, len = 0;
+
+	compress = compression_function(algo);
+	if (!compress)
+		return -1;
+
+	DEBUG("start: parse_flat_binary_to_payload\n");
+	if (buffer_create(output, (sizeof(segs) + input->size),
+			  input->name) != 0)
+		return -1;
+	memset(output->data, 0, output->size);
+
+	doffset = (2 * sizeof(*segs));
+
+	/* Prepare code segment */
+	segs[0].type = PAYLOAD_SEGMENT_CODE;
+	segs[0].load_addr = loadaddress;
+	segs[0].mem_len = input->size;
+	segs[0].offset = doffset;
+
+	if (!compress(input->data, input->size, output->data + doffset, &len) &&
+	    (unsigned int)len < input->size) {
+		segs[0].compression = algo;
+		segs[0].len = len;
+	} else {
+		WARN("Compression failed or would make the data bigger "
+		     "- disabled.\n");
+		segs[0].compression = 0;
+		segs[0].len = input->size;
+		memcpy(output->data + doffset, input->data, input->size);
+	}
+
+	/* prepare entry point segment */
+	segs[1].type = PAYLOAD_SEGMENT_ENTRY;
+	segs[1].load_addr = entrypoint;
+	output->size = doffset + segs[0].len;
+	xdr_segs(output, segs, 2);
+	return 0;
+}
+
+int parse_fv_to_payload(const struct buffer *input, struct buffer *output,
+			enum comp_algo algo)
+{
+	comp_func_ptr compress;
+	struct cbfs_payload_segment segs[2] = { {0} };
+	int doffset, len = 0;
+	firmware_volume_header_t *fv;
+	ffs_file_header_t *fh;
+	common_section_header_t *cs;
+	dos_header_t *dh;
+	coff_header_t *ch;
+	int dh_offset;
+
+	uint32_t loadaddress = 0;
+	uint32_t entrypoint = 0;
+
+	compress = compression_function(algo);
+	if (!compress)
+		return -1;
+
+	DEBUG("start: parse_fv_to_payload\n");
+
+	fv = (firmware_volume_header_t *)input->data;
+	if (fv->signature != FV_SIGNATURE) {
+		INFO("Not a UEFI firmware volume.\n");
+		return -1;
+	}
+
+	fh = (ffs_file_header_t *)(input->data + fv->header_length);
+	while (fh->file_type == FILETYPE_PAD) {
+		unsigned long offset = (fh->size[2] << 16) | (fh->size[1] << 8) | fh->size[0];
+		DEBUG("skipping %lu bytes of FV padding\n", offset);
+		fh = (ffs_file_header_t *)(((uintptr_t)fh) + offset);
+	}
+	if (fh->file_type != FILETYPE_SEC) {
+		ERROR("Not a usable UEFI firmware volume.\n");
+		INFO("First file in first FV not a SEC core.\n");
+		return -1;
+	}
+
+	cs = (common_section_header_t *)&fh[1];
+	while (cs->section_type == SECTION_RAW) {
+		unsigned long offset = (cs->size[2] << 16) | (cs->size[1] << 8) | cs->size[0];
+		DEBUG("skipping %lu bytes of section padding\n", offset);
+		cs = (common_section_header_t *)(((uintptr_t)cs) + offset);
+	}
+	if (cs->section_type != SECTION_PE32) {
+		ERROR("Not a usable UEFI firmware volume.\n");
+		INFO("Section type not PE32.\n");
+		return -1;
+	}
+
+	dh = (dos_header_t *)&cs[1];
+	if (dh->signature != DOS_MAGIC) {
+		ERROR("Not a usable UEFI firmware volume.\n");
+		INFO("DOS header signature wrong.\n");
+		return -1;
+	}
+
+	dh_offset = (unsigned long)dh - (unsigned long)input->data;
+	DEBUG("dos header offset = %x\n", dh_offset);
+
+	ch = (coff_header_t *)(((uintptr_t)dh)+dh->e_lfanew);
+
+	if (ch->machine == MACHINE_TYPE_X86) {
+		pe_opt_header_32_t *ph;
+		ph = (pe_opt_header_32_t *)&ch[1];
+		if (ph->signature != PE_HDR_32_MAGIC) {
+			WARN("PE header signature incorrect.\n");
+			return -1;
+		}
+		DEBUG("image base %x\n", ph->image_addr);
+		DEBUG("entry point %x\n", ph->entry_point);
+
+		loadaddress = ph->image_addr - dh_offset;
+		entrypoint = ph->image_addr + ph->entry_point;
+	} else if (ch->machine == MACHINE_TYPE_X64) {
+		pe_opt_header_64_t *ph;
+		ph = (pe_opt_header_64_t *)&ch[1];
+		if (ph->signature != PE_HDR_64_MAGIC) {
+			WARN("PE header signature incorrect.\n");
+			return -1;
+		}
+		DEBUG("image base %lx\n", (unsigned long)ph->image_addr);
+		DEBUG("entry point %x\n", ph->entry_point);
+
+		loadaddress = ph->image_addr - dh_offset;
+		entrypoint = ph->image_addr + ph->entry_point;
+	} else {
+		ERROR("Machine type not x86 or x64.\n");
+		return -1;
+	}
+
+	if (buffer_create(output, (sizeof(segs) + input->size),
+			  input->name) != 0)
+		return -1;
+
+	memset(output->data, 0, output->size);
+
+	doffset = (sizeof(segs));
+
+	/* Prepare code segment */
+	segs[0].type = PAYLOAD_SEGMENT_CODE;
+	segs[0].load_addr = loadaddress;
+	segs[0].mem_len = input->size;
+	segs[0].offset = doffset;
+
+	if (!compress(input->data, input->size, output->data + doffset, &len) &&
+	    (unsigned int)len < input->size) {
+		segs[0].compression = algo;
+		segs[0].len = len;
+	} else {
+		WARN("Compression failed or would make the data bigger "
+		     "- disabled.\n");
+		segs[0].compression = 0;
+		segs[0].len = input->size;
+		memcpy(output->data + doffset, input->data, input->size);
+	}
+
+	/* prepare entry point segment */
+	segs[1].type = PAYLOAD_SEGMENT_ENTRY;
+	segs[1].load_addr = entrypoint;
+	output->size = doffset + segs[0].len;
+	xdr_segs(output, segs, 2);
+	return 0;
+
+}
+
+int parse_fit_to_payload(const struct buffer *input, struct buffer *output,
+			 enum comp_algo algo)
+{
+	struct fdt_header *fdt_h;
+
+	DEBUG("start: parse_fit_to_payload\n");
+
+	fdt_h = buffer_get(input);
+	if (read_be32(&fdt_h->magic) != FDT_HEADER_MAGIC) {
+		INFO("Not a FIT payload.\n");
+		return -1;
+	}
+
+	/**
+	 * For developers:
+	 * Compress the kernel binary you're sourcing in your its-script
+	 * manually with LZ4 or LZMA and add 'compression = "lz4"' or "lzma" to
+	 * the kernel@1 node in the its-script before assembling the image with
+	 * mkimage.
+	 */
+	if (algo != CBFS_COMPRESS_NONE) {
+		ERROR("FIT images don't support whole-image compression,"
+		      " compress the kernel component instead!\n")
+		return -1;
+	}
+
+	if (buffer_create(output, buffer_size(input), input->name) != 0)
+		return -1;
+
+	memcpy(buffer_get(output), buffer_get(input), buffer_size(input));
+
+	DEBUG("done\n");
+
+	return 0;
+}
diff --git a/tools/cbfstool/cbfs-mkstage.c b/tools/cbfstool/cbfs-mkstage.c
new file mode 100644
index 0000000000..6071437d05
--- /dev/null
+++ b/tools/cbfstool/cbfs-mkstage.c
@@ -0,0 +1,474 @@
+/*
+ * cbfs-mkstage
+ *
+ * Copyright (C) 2008 Jordan Crouse <jordan@cosmicpenguin.net>
+ *               2009 coresystems GmbH
+ *                 written by Patrick Georgi <patrick.georgi@coresystems.de>
+ * Copyright (C) 2012 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <inttypes.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#include "elfparsing.h"
+#include "common.h"
+#include "cbfs.h"
+#include "rmodule.h"
+
+#include <commonlib/compression.h>
+
+/* Checks if program segment contains the ignored section */
+static int is_phdr_ignored(Elf64_Phdr *phdr, Elf64_Shdr *shdr)
+{
+	/* If no ignored section, return false. */
+	if (shdr == NULL)
+		return 0;
+
+	Elf64_Addr sh_start = shdr->sh_addr;
+	Elf64_Addr sh_end = shdr->sh_addr + shdr->sh_size;
+	Elf64_Addr ph_start = phdr->p_vaddr;
+	Elf64_Addr ph_end = phdr->p_vaddr + phdr->p_memsz;
+
+	/* Return true only if section occupies whole of segment. */
+	if ((sh_start == ph_start) && (sh_end == ph_end)) {
+		DEBUG("Ignoring program segment at 0x%" PRIx64 "\n", ph_start);
+		return 1;
+	}
+
+	/* If shdr intersects phdr at all, its a conflict */
+	if (((sh_start >= ph_start) && (sh_start <= ph_end)) ||
+	    ((sh_end >= ph_start) && (sh_end <= ph_end))) {
+		ERROR("Conflicting sections in segment\n");
+		exit(1);
+	}
+
+	/* Program header doesn't need to be ignored. */
+	return 0;
+}
+
+/* Find section header based on ignored section name */
+static Elf64_Shdr *find_ignored_section_header(struct parsed_elf *pelf,
+					       const char *ignore_section)
+{
+	int i;
+	const char *shstrtab;
+
+	/* No section needs to be ignored */
+	if (ignore_section == NULL)
+		return NULL;
+
+	DEBUG("Section to be ignored: %s\n", ignore_section);
+
+	/* Get pointer to string table */
+	shstrtab = buffer_get(pelf->strtabs[pelf->ehdr.e_shstrndx]);
+
+	for (i = 0; i < pelf->ehdr.e_shnum; i++) {
+		Elf64_Shdr *shdr;
+		const char *section_name;
+
+		shdr = &pelf->shdr[i];
+		section_name = &shstrtab[shdr->sh_name];
+
+		/* If section name matches ignored string, return shdr */
+		if (strcmp(section_name, ignore_section) == 0)
+			return shdr;
+	}
+
+	/* No section matches ignore string */
+	return NULL;
+}
+
+static void fill_cbfs_stage(struct buffer *outheader, enum comp_algo algo,
+				uint64_t entry, uint64_t loadaddr,
+				uint32_t filesize, uint32_t memsize)
+{
+	/* N.B. The original plan was that SELF data was B.E.
+	 * but: this is all L.E.
+	 * Maybe we should just change the spec.
+	 */
+	xdr_le.put32(outheader, algo);
+	xdr_le.put64(outheader, entry);
+	xdr_le.put64(outheader, loadaddr);
+	xdr_le.put32(outheader, filesize);
+	xdr_le.put32(outheader, memsize);
+}
+
+/* returns size of result, or -1 if error.
+ * Note that, with the new code, this function
+ * works for all elf files, not just the restricted set.
+ */
+int parse_elf_to_stage(const struct buffer *input, struct buffer *output,
+		       enum comp_algo algo, uint32_t *location,
+		       const char *ignore_section)
+{
+	struct parsed_elf pelf;
+	Elf64_Phdr *phdr;
+	Elf64_Ehdr *ehdr;
+	Elf64_Shdr *shdr_ignored;
+	Elf64_Addr virt_to_phys;
+	char *buffer;
+	struct buffer outheader;
+	int ret = -1;
+
+	int headers;
+	int i, outlen;
+	uint64_t data_start, data_end, mem_end;
+
+	comp_func_ptr compress = compression_function(algo);
+	if (!compress)
+		return -1;
+
+	DEBUG("start: parse_elf_to_stage(location=0x%x)\n", *location);
+
+	int flags = ELF_PARSE_PHDR | ELF_PARSE_SHDR | ELF_PARSE_STRTAB;
+
+	if (parse_elf(input, &pelf, flags)) {
+		ERROR("Couldn't parse ELF\n");
+		return -1;
+	}
+
+	ehdr = &pelf.ehdr;
+	phdr = &pelf.phdr[0];
+
+	/* Find the section header corresponding to ignored-section */
+	shdr_ignored = find_ignored_section_header(&pelf, ignore_section);
+
+	if (ignore_section && (shdr_ignored == NULL))
+		WARN("Ignore section not found\n");
+
+	headers = ehdr->e_phnum;
+
+	/* Ignore the program header containing ignored section */
+	for (i = 0; i < headers; i++) {
+		if (is_phdr_ignored(&phdr[i], shdr_ignored))
+			phdr[i].p_type = PT_NULL;
+	}
+
+	data_start = ~0;
+	data_end = 0;
+	mem_end = 0;
+	virt_to_phys = 0;
+
+	for (i = 0; i < headers; i++) {
+		uint64_t start, mend, rend;
+
+		if (phdr[i].p_type != PT_LOAD)
+			continue;
+
+		/* Empty segments are never interesting */
+		if (phdr[i].p_memsz == 0)
+			continue;
+
+		/* BSS */
+
+		start = phdr[i].p_paddr;
+
+		mend = start + phdr[i].p_memsz;
+		rend = start + phdr[i].p_filesz;
+
+		if (start < data_start)
+			data_start = start;
+
+		if (rend > data_end)
+			data_end = rend;
+
+		if (mend > mem_end)
+			mem_end = mend;
+
+		if (virt_to_phys == 0)
+			virt_to_phys = phdr[i].p_paddr - phdr[i].p_vaddr;
+	}
+
+	if (data_start < *location) {
+		data_start = *location;
+	}
+
+	if (data_end <= data_start) {
+		ERROR("data ends (%08lx) before it starts (%08lx). Make sure "
+		      "the ELF file is correct and resides in ROM space.\n",
+		      (unsigned long)data_end, (unsigned long)data_start);
+		exit(1);
+	}
+
+	/* allocate an intermediate buffer for the data */
+	buffer = calloc(data_end - data_start, 1);
+
+	if (buffer == NULL) {
+		ERROR("Unable to allocate memory: %m\n");
+		goto err;
+	}
+
+	/* Copy the file data into the buffer */
+
+	for (i = 0; i < headers; i++) {
+		uint64_t l_start, l_offset = 0;
+
+		if (phdr[i].p_type != PT_LOAD)
+			continue;
+
+		if (phdr[i].p_memsz == 0)
+			continue;
+
+		l_start = phdr[i].p_paddr;
+		if (l_start < *location) {
+			l_offset = *location - l_start;
+			l_start = *location;
+		}
+
+		/* A legal ELF file can have a program header with
+		 * non-zero length but zero-length file size and a
+		 * non-zero offset which, added together, are > than
+		 * input->size (i.e. the total file size).  So we need
+		 * to not even test in the case that p_filesz is zero.
+		 */
+		if (! phdr[i].p_filesz)
+			continue;
+		if (input->size < (phdr[i].p_offset + phdr[i].p_filesz)){
+			ERROR("Underflow copying out the segment."
+			      "File has %zu bytes left, segment end is %zu\n",
+			      input->size, (size_t)(phdr[i].p_offset + phdr[i].p_filesz));
+			free(buffer);
+			goto err;
+		}
+		memcpy(buffer + (l_start - data_start),
+		       &input->data[phdr[i].p_offset + l_offset],
+		       phdr[i].p_filesz - l_offset);
+	}
+
+	/* Now make the output buffer */
+	if (buffer_create(output, sizeof(struct cbfs_stage) + data_end - data_start,
+			  input->name) != 0) {
+		ERROR("Unable to allocate memory: %m\n");
+		free(buffer);
+		goto err;
+	}
+	memset(output->data, 0, output->size);
+
+	/* Compress the data, at which point we'll know information
+	 * to fill out the header. This seems backward but it works because
+	 * - the output header is a known size (not always true in many xdr's)
+	 * - we do need to know the compressed output size first
+	 * If compression fails or makes the data bigger, we'll warn about it
+	 * and use the original data.
+	 */
+	if (compress(buffer, data_end - data_start,
+		     (output->data + sizeof(struct cbfs_stage)),
+		     &outlen) < 0 || (unsigned)outlen > data_end - data_start) {
+		WARN("Compression failed or would make the data bigger "
+		     "- disabled.\n");
+		memcpy(output->data + sizeof(struct cbfs_stage),
+		       buffer, data_end - data_start);
+		outlen = data_end - data_start;
+		algo = CBFS_COMPRESS_NONE;
+	}
+
+	/* Check for enough BSS scratch space to decompress LZ4 in-place. */
+	if (algo == CBFS_COMPRESS_LZ4) {
+		size_t result;
+		size_t memlen = mem_end - data_start;
+		size_t compressed_size = outlen;
+		char *compare_buffer = malloc(memlen);
+		char *start = compare_buffer + memlen - compressed_size;
+
+		if (compare_buffer == NULL) {
+			ERROR("Can't allocate memory!\n");
+			free(buffer);
+			goto err;
+		}
+
+		memcpy(start, output->data + sizeof(struct cbfs_stage),
+		       compressed_size);
+		result = ulz4fn(start, compressed_size, compare_buffer, memlen);
+
+		if (result == 0) {
+			ERROR("Not enough scratch space to decompress LZ4 in-place -- increase BSS size or disable compression!\n");
+			free(compare_buffer);
+			free(buffer);
+			goto err;
+		}
+		if (result != data_end - data_start ||
+		    memcmp(compare_buffer, buffer, data_end - data_start)) {
+			ERROR("LZ4 compression BUG! Report to mailing list.\n");
+			free(compare_buffer);
+			free(buffer);
+			goto err;
+		}
+		free(compare_buffer);
+	}
+
+	free(buffer);
+
+	/* Set up for output marshaling. */
+	outheader.data = output->data;
+	outheader.size = 0;
+
+	/* coreboot expects entry point to be physical address. Thus, adjust the
+	 * entry point accordingly.
+	 */
+	fill_cbfs_stage(&outheader, algo, ehdr->e_entry + virt_to_phys,
+			data_start, outlen, mem_end - data_start);
+
+	if (*location)
+		*location -= sizeof(struct cbfs_stage);
+	output->size = sizeof(struct cbfs_stage) + outlen;
+	ret = 0;
+
+err:
+	parsed_elf_destroy(&pelf);
+	return ret;
+}
+
+struct xip_context {
+	struct rmod_context rmodctx;
+	size_t ignored_section_idx;
+	Elf64_Shdr *ignored_section;
+};
+
+static int rmod_filter(struct reloc_filter *f, const Elf64_Rela *r)
+{
+	size_t symbol_index;
+	int reloc_type;
+	struct parsed_elf *pelf;
+	Elf64_Sym *sym;
+	struct xip_context *xipctx;
+
+	xipctx = f->context;
+	pelf = &xipctx->rmodctx.pelf;
+
+	/* Allow everything through if there isn't an ignored section. */
+	if (xipctx->ignored_section == NULL)
+		return 1;
+
+	reloc_type = ELF64_R_TYPE(r->r_info);
+	symbol_index = ELF64_R_SYM(r->r_info);
+	sym = &pelf->syms[symbol_index];
+
+	/* Nothing to filter. Relocation is not being applied to the
+	 * ignored section. */
+	if (sym->st_shndx != xipctx->ignored_section_idx)
+		return 1;
+
+	/* If there is any relocation to the ignored section that isn't
+	 * absolute fail as current assumptions are that all relocations
+	 * are absolute. */
+	if ((reloc_type != R_386_32) &&
+	    (reloc_type != R_AMD64_64) &&
+	    (reloc_type != R_AMD64_32)) {
+		ERROR("Invalid reloc to ignored section: %x\n", reloc_type);
+		return -1;
+	}
+
+	/* Relocation referencing ignored section. Don't emit it. */
+	return 0;
+}
+
+int parse_elf_to_xip_stage(const struct buffer *input, struct buffer *output,
+				uint32_t *location, const char *ignore_section)
+{
+	struct xip_context xipctx;
+	struct rmod_context *rmodctx;
+	struct reloc_filter filter;
+	struct parsed_elf *pelf;
+	size_t output_sz;
+	uint32_t adjustment;
+	struct buffer binput;
+	struct buffer boutput;
+	Elf64_Xword i;
+	int ret = -1;
+
+	xipctx.ignored_section_idx = 0;
+	rmodctx = &xipctx.rmodctx;
+	pelf = &rmodctx->pelf;
+
+	if (rmodule_init(rmodctx, input))
+		return -1;
+
+	/* Only support x86 / x86_64 XIP currently. */
+	if ((rmodctx->pelf.ehdr.e_machine != EM_386) &&
+	    (rmodctx->pelf.ehdr.e_machine != EM_X86_64)) {
+		ERROR("Only support XIP stages for x86/x86_64\n");
+		goto out;
+	}
+
+	xipctx.ignored_section =
+		find_ignored_section_header(pelf, ignore_section);
+
+	if (xipctx.ignored_section != NULL)
+		xipctx.ignored_section_idx =
+			xipctx.ignored_section - pelf->shdr;
+
+	filter.filter = rmod_filter;
+	filter.context = &xipctx;
+
+	if (rmodule_collect_relocations(rmodctx, &filter))
+		goto out;
+
+	output_sz = sizeof(struct cbfs_stage) + pelf->phdr->p_filesz;
+	if (buffer_create(output, output_sz, input->name) != 0) {
+		ERROR("Unable to allocate memory: %m\n");
+		goto out;
+	}
+	buffer_clone(&boutput, output);
+	memset(buffer_get(&boutput), 0, output_sz);
+	buffer_set_size(&boutput, 0);
+
+	/* Single loadable segment. The entire segment moves to final
+	 * location from based on virtual address of loadable segment. */
+	adjustment = *location - pelf->phdr->p_vaddr;
+	DEBUG("Relocation adjustment: %08x\n", adjustment);
+
+	fill_cbfs_stage(&boutput, CBFS_COMPRESS_NONE,
+			(uint32_t)pelf->ehdr.e_entry + adjustment,
+			(uint32_t)pelf->phdr->p_vaddr + adjustment,
+			pelf->phdr->p_filesz, pelf->phdr->p_memsz);
+	/* Need an adjustable buffer. */
+	buffer_clone(&binput, input);
+	buffer_seek(&binput, pelf->phdr->p_offset);
+	bputs(&boutput, buffer_get(&binput), pelf->phdr->p_filesz);
+
+	buffer_clone(&boutput, output);
+	buffer_seek(&boutput, sizeof(struct cbfs_stage));
+
+	/* Make adjustments to all the relocations within the program. */
+	for (i = 0; i < rmodctx->nrelocs; i++) {
+		size_t reloc_offset;
+		uint32_t val;
+		struct buffer in, out;
+
+		/* The relocations represent in-program addresses of the
+		 * linked program. Obtain the offset into the program to do
+		 * the adjustment. */
+		reloc_offset = rmodctx->emitted_relocs[i] - pelf->phdr->p_vaddr;
+
+		buffer_clone(&out, &boutput);
+		buffer_seek(&out, reloc_offset);
+		buffer_clone(&in, &out);
+		/* Appease around xdr semantics: xdr decrements buffer
+		 * size when get()ing and appends to size when put()ing. */
+		buffer_set_size(&out, 0);
+
+		val = xdr_le.get32(&in);
+		DEBUG("reloc %zx %08x -> %08x\n", reloc_offset, val,
+			val + adjustment);
+		xdr_le.put32(&out, val + adjustment);
+	}
+
+	/* Need to back up the location to include cbfs stage metadata. */
+	*location -= sizeof(struct cbfs_stage);
+	ret = 0;
+
+out:
+	rmodule_cleanup(rmodctx);
+	return ret;
+}
diff --git a/tools/cbfstool/cbfs-payload-linux.c b/tools/cbfstool/cbfs-payload-linux.c
new file mode 100644
index 0000000000..6b4bf27b85
--- /dev/null
+++ b/tools/cbfstool/cbfs-payload-linux.c
@@ -0,0 +1,334 @@
+/*
+ * cbfs-payload-linux
+ *
+ * Copyright (C) 2013 Patrick Georgi <patrick@georgi-clan.de>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#include "common.h"
+#include "cbfs.h"
+#include "linux.h"
+
+/* trampoline */
+extern unsigned char trampoline[];
+extern unsigned int trampoline_len;
+
+/*
+ * Current max number of segments include:
+ *
+ * 1. parameters
+ * 2. kernel
+ * 3. trampoline
+ * 4. optional cmdline
+ * 5. optional initrd
+ * 6. terminating entry segment
+ */
+#define MAX_NUM_SEGMENTS 6
+
+struct bzpayload {
+	/* Input variables. */
+	int num_segments;
+	struct cbfs_payload_segment segs[MAX_NUM_SEGMENTS];
+	struct buffer parameters;
+	struct buffer kernel;
+	struct buffer trampoline;
+	struct buffer cmdline;
+	struct buffer initrd;
+	/* Output variables. */
+	enum comp_algo algo;
+	comp_func_ptr compress;
+	struct buffer output;
+	size_t offset;
+	struct cbfs_payload_segment *out_seg;
+};
+
+static int bzp_init(struct bzpayload *bzp, enum comp_algo algo)
+{
+	memset(bzp, 0, sizeof(*bzp));
+
+	/*
+	 * Need at least the terminating entry segment.
+	 */
+	bzp->num_segments = 1;
+
+	bzp->algo = algo;
+	bzp->compress = compression_function(algo);
+	if (bzp->compress == NULL) {
+		ERROR("Invalid compression algorithm specified.\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+static int bzp_add_initrd(struct bzpayload *bzp, const char *fname)
+{
+	if (fname == NULL)
+		return 0;
+
+	if (buffer_from_file(&bzp->initrd, fname)) {
+		ERROR("could not open initrd.\n");
+		return -1;
+	}
+
+	bzp->num_segments++;
+
+	return 0;
+}
+
+static void bzp_add_segment(struct bzpayload *bzp, struct buffer *b, void *data,
+                            size_t size)
+{
+	buffer_init(b, NULL, data, size);
+	bzp->num_segments++;
+}
+
+static int bzp_add_trampoline(struct bzpayload *bzp)
+{
+	bzp_add_segment(bzp, &bzp->trampoline, trampoline,
+			trampoline_len);
+	return 0;
+}
+
+static int bzp_add_cmdline(struct bzpayload *bzp, char *cmdline)
+{
+	if (cmdline == NULL)
+		return 0;
+
+	bzp_add_segment(bzp, &bzp->cmdline, cmdline, strlen(cmdline) + 1);
+
+	return 0;
+}
+
+static int bzp_add_params(struct bzpayload *bzp, struct linux_params *params)
+{
+	bzp_add_segment(bzp, &bzp->parameters, params, sizeof(*params));
+
+	return 0;
+}
+
+static int bzp_add_kernel(struct bzpayload *bzp, const struct buffer *in,
+                          size_t setup_size)
+{
+	char *input = buffer_get(in);
+	size_t kern_sz = buffer_size(in) - setup_size;
+
+	bzp_add_segment(bzp, &bzp->kernel, &input[setup_size], kern_sz);
+
+	return 0;
+}
+
+static int bzp_init_output(struct bzpayload *bzp, const char *name)
+{
+	size_t sz = 0;
+
+	sz += buffer_size(&bzp->parameters);
+	sz += buffer_size(&bzp->kernel);
+	sz += buffer_size(&bzp->trampoline);
+	sz += buffer_size(&bzp->cmdline);
+	sz += buffer_size(&bzp->initrd);
+
+	bzp->offset = bzp->num_segments * sizeof(struct cbfs_payload_segment);
+	sz += bzp->offset;
+
+	if (buffer_create(&bzp->output, sz, name) != 0)
+		return -1;
+
+	bzp->out_seg = &bzp->segs[0];
+
+	return 0;
+}
+
+static void bzp_output_segment(struct bzpayload *bzp, struct buffer *b,
+                               uint32_t type, uint64_t load_addr)
+{
+	struct buffer out;
+	struct cbfs_payload_segment *seg;
+	int len = 0;
+
+	/* Don't process empty buffers. */
+	if (b != NULL && buffer_size(b) == 0)
+		return;
+
+	seg = bzp->out_seg;
+	seg->type = type;
+	seg->load_addr = load_addr;
+	bzp->out_seg++;
+
+	/* No buffer associated with segment. */
+	if (b == NULL)
+		return;
+
+	/* Use a temp buffer for easier management. */
+	buffer_splice(&out, &bzp->output, bzp->offset, buffer_size(b));
+
+	seg->mem_len = buffer_size(b);
+	seg->offset = bzp->offset;
+	bzp->compress(buffer_get(b), buffer_size(b), buffer_get(&out), &len);
+	seg->compression = bzp->algo;
+	seg->len = len;
+
+	/* Update output offset. */
+	bzp->offset += len;
+}
+
+/* TODO:
+ *   handle special arguments
+ *     mem= argument - only affects loading decisions (kernel + initrd), not e820 -> build time
+ *     vga= argument (FILO ignores this)
+ *   add support for more parameters to trampoline:
+ *     alt_mem_k, ext_mem_k (not strictly necessary since e820 takes precedence)
+ *     framebuffer/console values
+ *
+ *  larger work:
+ *     is compress() safe to use in a size constrained buffer? ie. do(es) the
+ *     compression algorithm(s) stop once the compression result reaches input
+ *     size (ie. incompressible data)?
+ */
+int parse_bzImage_to_payload(const struct buffer *input,
+			     struct buffer *output, const char *initrd_name,
+			     char *cmdline, enum comp_algo algo)
+{
+	struct bzpayload bzp;
+	unsigned int initrd_base = 64*1024*1024;
+	struct linux_header *hdr = (struct linux_header *)input->data;
+	unsigned int setup_size = 4 * 512;
+
+	if (bzp_init(&bzp, algo) != 0)
+		return -1;
+
+	if (bzp_add_trampoline(&bzp) != 0)
+		return -1;
+
+	if (bzp_add_initrd(&bzp, initrd_name) != 0)
+		return -1;
+
+	if (bzp_add_cmdline(&bzp, cmdline) != 0)
+		return -1;
+
+	if (hdr->setup_sects != 0) {
+		setup_size = (hdr->setup_sects + 1) * 512;
+	} else {
+		WARN("hdr->setup_sects is 0, which could cause boot problems.\n");
+	}
+
+	/* Setup parameter block. Imitate FILO. */
+	struct linux_params params;
+
+	memset(&params, 0, sizeof(struct linux_params));
+
+	params.mount_root_rdonly = hdr->root_flags;
+	params.orig_root_dev = hdr->root_dev;
+	params.init_size = hdr->init_size;
+
+	/* Sensible video defaults. Might be overridden on runtime by coreboot tables. */
+	params.orig_video_mode = 3;
+	params.orig_video_cols = 80;
+	params.orig_video_lines = 25;
+	params.orig_video_isVGA = 1;
+	params.orig_video_points = 16;
+
+	params.loader_type = 0xff; /* Unregistered Linux loader */
+
+	if (cmdline != NULL) {
+		if (hdr->protocol_version < 0x202) {
+			params.cl_magic = CL_MAGIC_VALUE;
+			params.cl_offset = COMMAND_LINE_LOC - LINUX_PARAM_LOC;
+		} else {
+			params.cmd_line_ptr = COMMAND_LINE_LOC;
+		}
+	}
+
+	unsigned long kernel_base = 0x100000;
+	if ((hdr->protocol_version < 0x200) || !(hdr->loadflags & 1)) {
+		kernel_base = 0x1000; /* zImage kernel */
+	}
+	/* kernel prefers an address, so listen */
+	if ((hdr->protocol_version >= 0x20a) && (!(hdr->pref_address >> 32))) {
+		kernel_base = hdr->pref_address;
+	}
+	if (hdr->protocol_version >= 0x205) {
+		params.relocatable_kernel = hdr->relocatable_kernel;
+		params.kernel_alignment = hdr->kernel_alignment;
+		if (hdr->relocatable_kernel != 0) {
+			/* 16 MB should be way outside coreboot's playground,
+			 * so if possible (relocatable kernel) use that to
+			 * avoid a trampoline copy. */
+			kernel_base = ALIGN(16*1024*1024, params.kernel_alignment);
+			if (hdr->init_size == 0) {
+				ERROR("init_size 0 for relocatable kernel\n");
+				return -1;
+			}
+		}
+	}
+
+	/* We have a trampoline and use that, but it can simply use
+	 * this information for its jump to real Linux. */
+	params.kernel_start = kernel_base;
+
+	if (bzp_add_kernel(&bzp, input, setup_size) != 0)
+		return -1;
+
+	if (buffer_size(&bzp.initrd) != 0) {
+		/* TODO: this is a bit of a hack. Linux recommends to store
+		 * initrd near to end-of-mem, but that's hard to do on build
+		 * time. It definitely fails to read the image if it's too
+		 * close to the kernel, so give it some room.
+		 */
+		initrd_base = kernel_base + buffer_size(&bzp.kernel);
+		initrd_base = ALIGN(initrd_base, 64*1024*1024);
+
+		params.initrd_start = initrd_base;
+		params.initrd_size = buffer_size(&bzp.initrd);
+	}
+
+	if (bzp_add_params(&bzp, &params) != 0)
+		return -1;
+
+	if (bzp_init_output(&bzp, input->name) != 0)
+		return -1;
+
+	/* parameter block */
+	bzp_output_segment(&bzp, &bzp.parameters,
+	                   PAYLOAD_SEGMENT_DATA, LINUX_PARAM_LOC);
+
+	/* code block */
+	bzp_output_segment(&bzp, &bzp.kernel,
+	                   PAYLOAD_SEGMENT_CODE, kernel_base);
+
+	/* trampoline */
+	bzp_output_segment(&bzp, &bzp.trampoline,
+	                   PAYLOAD_SEGMENT_CODE, TRAMPOLINE_ENTRY_LOC);
+
+	/* cmdline */
+	bzp_output_segment(&bzp, &bzp.cmdline,
+	                   PAYLOAD_SEGMENT_DATA, COMMAND_LINE_LOC);
+
+	/* initrd */
+	bzp_output_segment(&bzp, &bzp.initrd,
+	                   PAYLOAD_SEGMENT_DATA, initrd_base);
+
+	/* Terminating entry segment. */
+	bzp_output_segment(&bzp, NULL, PAYLOAD_SEGMENT_ENTRY, TRAMPOLINE_ENTRY_LOC);
+
+	/* Set size of buffer taking into account potential compression. */
+	buffer_set_size(&bzp.output, bzp.offset);
+	/* Make passed-in output buffer be valid. */
+	buffer_clone(output, &bzp.output);
+
+	/* Serialize the segments with the correct encoding. */
+	xdr_segs(output, bzp.segs, bzp.num_segments);
+	return 0;
+}
diff --git a/tools/cbfstool/cbfs.c b/tools/cbfstool/cbfs.c
new file mode 100644
index 0000000000..5c9aacba20
--- /dev/null
+++ b/tools/cbfstool/cbfs.c
@@ -0,0 +1,377 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <console/console.h>
+#include <commonlib/cbfs.h>
+#include <commonlib/endian.h>
+#include <commonlib/helpers.h>
+#include <string.h>
+#include <vb2_sha.h>
+
+#if !defined(ERROR)
+#define ERROR(x...) printk(BIOS_ERR, "CBFS: " x)
+#endif
+#if !defined(LOG)
+#define LOG(x...) printk(BIOS_INFO, "CBFS: " x)
+#endif
+#if defined(CONFIG)
+
+#if CONFIG(DEBUG_CBFS)
+#define DEBUG(x...) printk(BIOS_SPEW, "CBFS: " x)
+#else
+#define DEBUG(x...)
+#endif
+
+#elif !defined(DEBUG)
+#define DEBUG(x...)
+#endif
+
+static size_t cbfs_next_offset(const struct region_device *cbfs,
+				const struct cbfsf *f)
+{
+	size_t offset;
+
+	if (f == NULL)
+		return 0;
+
+	/* The region_device objects store absolute offets over the whole
+	 * region. Therefore a relative offset needs to be calculated. */
+	offset = rdev_relative_offset(cbfs, &f->data);
+	offset += region_device_sz(&f->data);
+
+	return ALIGN_UP(offset, CBFS_ALIGNMENT);
+}
+
+static int cbfs_end(const struct region_device *cbfs, size_t offset)
+{
+	if (offset >= region_device_sz(cbfs))
+		return 1;
+
+	return 0;
+}
+
+int cbfs_for_each_file(const struct region_device *cbfs,
+			const struct cbfsf *prev, struct cbfsf *fh)
+{
+	size_t offset;
+
+	offset = cbfs_next_offset(cbfs, prev);
+
+	/* Try to scan the entire cbfs region looking for file name. */
+	while (1) {
+		struct cbfs_file file;
+		const size_t fsz = sizeof(file);
+
+		 DEBUG("Checking offset %zx\n", offset);
+
+		/* End of region. */
+		if (cbfs_end(cbfs, offset))
+			return 1;
+
+		/* Can't read file. Nothing else to do but bail out. */
+		if (rdev_readat(cbfs, &file, offset, fsz) != fsz)
+			break;
+
+		if (memcmp(file.magic, CBFS_FILE_MAGIC, sizeof(file.magic))) {
+			offset++;
+			offset = ALIGN_UP(offset, CBFS_ALIGNMENT);
+			continue;
+		}
+
+		file.len = read_be32(&file.len);
+		file.offset = read_be32(&file.offset);
+
+		DEBUG("File @ offset %zx size %x\n", offset, file.len);
+
+		/* Keep track of both the metadata and the data for the file. */
+		if (rdev_chain(&fh->metadata, cbfs, offset, file.offset))
+			break;
+
+		if (rdev_chain(&fh->data, cbfs, offset + file.offset, file.len))
+			break;
+
+		/* Success. */
+		return 0;
+	}
+
+	return -1;
+}
+
+size_t cbfs_for_each_attr(void *metadata, size_t metadata_size,
+			  size_t last_offset)
+{
+	struct cbfs_file_attribute *attr;
+
+	if (!last_offset) {
+		struct cbfs_file *file = metadata;
+		size_t start_offset = read_be32(&file->attributes_offset);
+		if (start_offset <= sizeof(struct cbfs_file) ||
+		    start_offset + sizeof(*attr) > metadata_size)
+			return 0;
+		return start_offset;
+	}
+
+	attr = metadata + last_offset;
+	size_t next_offset = last_offset + read_be32(&attr->len);
+
+	if (next_offset + sizeof(*attr) > metadata_size)
+		return 0;
+	return next_offset;
+}
+
+int cbfsf_decompression_info(struct cbfsf *fh, uint32_t *algo, size_t *size)
+{
+	size_t metadata_size = region_device_sz(&fh->metadata);
+	void *metadata = rdev_mmap_full(&fh->metadata);
+	size_t offs = 0;
+
+	if (!metadata)
+		return -1;
+
+	while ((offs = cbfs_for_each_attr(metadata, metadata_size, offs))) {
+		struct cbfs_file_attr_compression *attr = metadata + offs;
+		if (read_be32(&attr->tag) != CBFS_FILE_ATTR_TAG_COMPRESSION)
+			continue;
+
+		*algo = read_be32(&attr->compression);
+		*size = read_be32(&attr->decompressed_size);
+		rdev_munmap(&fh->metadata, metadata);
+		return 0;
+	}
+
+	*algo = CBFS_COMPRESS_NONE;
+	*size = region_device_sz(&fh->data);
+	rdev_munmap(&fh->metadata, metadata);
+	return 0;
+}
+
+int cbfsf_file_type(struct cbfsf *fh, uint32_t *ftype)
+{
+	const size_t sz = sizeof(*ftype);
+
+	if (rdev_readat(&fh->metadata, ftype,
+			offsetof(struct cbfs_file, type), sz) != sz)
+		return -1;
+
+	*ftype = read_be32(ftype);
+
+	return 0;
+}
+
+int cbfs_locate(struct cbfsf *fh, const struct region_device *cbfs,
+		const char *name, uint32_t *type)
+{
+	struct cbfsf *prev;
+
+	LOG("Locating '%s'\n", name);
+
+	prev = NULL;
+
+	while (1) {
+		int ret;
+		char *fname;
+		int name_match;
+		const size_t fsz = sizeof(struct cbfs_file);
+
+		ret = cbfs_for_each_file(cbfs, prev, fh);
+		prev = fh;
+
+		/* Either failed to read or hit the end of the region. */
+		if (ret < 0 || ret > 0)
+			break;
+
+		fname = rdev_mmap(&fh->metadata, fsz,
+				region_device_sz(&fh->metadata) - fsz);
+
+		if (fname == NULL)
+			break;
+
+		name_match = !strcmp(fname, name);
+		rdev_munmap(&fh->metadata, fname);
+
+		if (!name_match) {
+			DEBUG(" Unmatched '%s' at %zx\n", fname,
+				rdev_relative_offset(cbfs, &fh->metadata));
+			continue;
+		}
+
+		if (type != NULL) {
+			uint32_t ftype;
+
+			if (cbfsf_file_type(fh, &ftype))
+				break;
+
+			if (*type != 0 && *type != ftype) {
+				DEBUG(" Unmatched type %x at %zx\n", ftype,
+					rdev_relative_offset(cbfs,
+							&fh->metadata));
+				continue;
+			}
+			// *type being 0 means we want to know ftype.
+			// We could just do a blind assignment but
+			// if type is pointing to read-only memory
+			// that might be bad.
+			if (*type == 0)
+				*type = ftype;
+		}
+
+		LOG("Found @ offset %zx size %zx\n",
+			rdev_relative_offset(cbfs, &fh->metadata),
+			region_device_sz(&fh->data));
+
+		/* Success. */
+		return 0;
+	}
+
+	LOG("'%s' not found.\n", name);
+	return -1;
+}
+
+static int cbfs_extend_hash_buffer(struct vb2_digest_context *ctx,
+					void *buf, size_t sz)
+{
+	return vb2_digest_extend(ctx, buf, sz);
+}
+
+static int cbfs_extend_hash(struct vb2_digest_context *ctx,
+				const struct region_device *rdev)
+{
+	uint8_t buffer[1024];
+	size_t sz_left;
+	size_t offset;
+
+	sz_left = region_device_sz(rdev);
+	offset = 0;
+
+	while (sz_left) {
+		int rv;
+		size_t block_sz = MIN(sz_left, sizeof(buffer));
+
+		if (rdev_readat(rdev, buffer, offset, block_sz) != block_sz)
+			return VB2_ERROR_UNKNOWN;
+
+		rv = cbfs_extend_hash_buffer(ctx, buffer, block_sz);
+
+		if (rv)
+			return rv;
+
+		sz_left -= block_sz;
+		offset += block_sz;
+	}
+
+	return VB2_SUCCESS;
+}
+
+/* Include offsets of child regions within the parent into the hash. */
+static int cbfs_extend_hash_with_offset(struct vb2_digest_context *ctx,
+					const struct region_device *p,
+					const struct region_device *c)
+{
+	int32_t soffset;
+	int rv;
+
+	soffset = rdev_relative_offset(p, c);
+
+	if (soffset < 0)
+		return VB2_ERROR_UNKNOWN;
+
+	/* All offsets in big endian format. */
+	write_be32(&soffset, soffset);
+
+	rv = cbfs_extend_hash_buffer(ctx, &soffset, sizeof(soffset));
+
+	if (rv)
+		return rv;
+
+	return cbfs_extend_hash(ctx, c);
+}
+
+/* Hash in the potential CBFS header sitting at the beginning of the CBFS
+ * region as well as relative offset at the end. */
+static int cbfs_extend_hash_master_header(struct vb2_digest_context *ctx,
+					const struct region_device *cbfs)
+{
+	struct region_device rdev;
+	int rv;
+
+	if (rdev_chain(&rdev, cbfs, 0, sizeof(struct cbfs_header)))
+		return VB2_ERROR_UNKNOWN;
+
+	rv = cbfs_extend_hash_with_offset(ctx, cbfs, &rdev);
+
+	if (rv)
+		return rv;
+
+	/* Include potential relative offset at end of region. */
+	if (rdev_chain(&rdev, cbfs, region_device_sz(cbfs) - sizeof(int32_t),
+			sizeof(int32_t)))
+		return VB2_ERROR_UNKNOWN;
+
+	return cbfs_extend_hash_with_offset(ctx, cbfs, &rdev);
+}
+
+int cbfs_vb2_hash_contents(const struct region_device *cbfs,
+				enum vb2_hash_algorithm hash_alg, void *digest,
+				size_t digest_sz)
+{
+	struct vb2_digest_context ctx;
+	int rv;
+	struct cbfsf f;
+	struct cbfsf *prev;
+	struct cbfsf *fh;
+
+	rv = vb2_digest_init(&ctx, hash_alg);
+
+	if (rv)
+		return rv;
+
+	rv = cbfs_extend_hash_master_header(&ctx, cbfs);
+	if (rv)
+		return rv;
+
+	prev = NULL;
+	fh = &f;
+
+	while (1) {
+		uint32_t ftype;
+
+		rv = cbfs_for_each_file(cbfs, prev, fh);
+		prev = fh;
+
+		if (rv < 0)
+			return VB2_ERROR_UNKNOWN;
+
+		/* End of CBFS. */
+		if (rv > 0)
+			break;
+
+		rv = cbfs_extend_hash_with_offset(&ctx, cbfs, &fh->metadata);
+
+		if (rv)
+			return rv;
+
+		/* Include data contents in hash if file is non-empty. */
+		if (cbfsf_file_type(fh, &ftype))
+			return VB2_ERROR_UNKNOWN;
+
+		if (ftype == CBFS_TYPE_DELETED || ftype == CBFS_TYPE_DELETED2)
+			continue;
+
+		rv = cbfs_extend_hash_with_offset(&ctx, cbfs, &fh->data);
+
+		if (rv)
+			return rv;
+	}
+
+	return vb2_digest_finalize(&ctx, digest, digest_sz);
+}
diff --git a/tools/cbfstool/cbfs.h b/tools/cbfstool/cbfs.h
new file mode 100644
index 0000000000..b082d8c783
--- /dev/null
+++ b/tools/cbfstool/cbfs.h
@@ -0,0 +1,257 @@
+/*
+ * Copyright (C) 2009 coresystems GmbH
+ *                 written by Patrick Georgi <patrick.georgi@coresystems.de>
+ * Copyright (C) 2016 Siemens AG
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __CBFS_H
+#define __CBFS_H
+
+#include "common.h"
+#include <stdint.h>
+
+#include <vb2_api.h>
+
+/* cbfstool will fail when trying to build a cbfs_file header that's larger
+ * than MAX_CBFS_FILE_HEADER_BUFFER. 1K should give plenty of room. */
+#define MAX_CBFS_FILE_HEADER_BUFFER 1024
+
+/* create a magic number in host-byte order.
+ * b3 is the high order byte.
+ * in the coreboot tools, we go with the 32-bit
+ * magic number convention.
+ * This was an inline func but that breaks anything
+ * that uses it in a case statement.
+ */
+
+#define makemagic(b3, b2, b1, b0)\
+	(((b3)<<24) | ((b2) << 16) | ((b1) << 8) | (b0))
+
+/* To make CBFS more friendly to ROM, fill -1 (0xFF) instead of zero. */
+#define CBFS_CONTENT_DEFAULT_VALUE	(-1)
+
+// Alignment (in bytes) to be used when no master header is present
+#define CBFS_ENTRY_ALIGNMENT 64
+
+#define CBFS_HEADER_MAGIC  0x4F524243
+#define CBFS_HEADPTR_ADDR_X86 0xFFFFFFFC
+#define CBFS_HEADER_VERSION1 0x31313131
+#define CBFS_HEADER_VERSION2 0x31313132
+#define CBFS_HEADER_VERSION  CBFS_HEADER_VERSION2
+
+#define CBFS_ALIGNMENT 64
+
+struct cbfs_header {
+	uint32_t magic;
+	uint32_t version;
+	uint32_t romsize;
+	uint32_t bootblocksize;
+	uint32_t align; /* hard coded to 64 byte */
+	uint32_t offset;
+	uint32_t architecture;	/* Version 2 */
+	uint32_t pad[1];
+} __packed;
+
+#define CBFS_ARCHITECTURE_UNKNOWN  0xFFFFFFFF
+#define CBFS_ARCHITECTURE_X86      0x00000001
+#define CBFS_ARCHITECTURE_ARM      0x00000010
+#define CBFS_ARCHITECTURE_AARCH64  0x0000aa64
+#define CBFS_ARCHITECTURE_MIPS     0x00000100
+#define CBFS_ARCHITECTURE_RISCV    0xc001d0de
+#define CBFS_ARCHITECTURE_PPC64    0x407570ff
+
+#define CBFS_FILE_MAGIC "LARCHIVE"
+
+struct cbfs_file {
+	uint8_t magic[8];
+	/* length of file data */
+	uint32_t len;
+	uint32_t type;
+	/* offset to struct cbfs_file_attribute or 0 */
+	uint32_t attributes_offset;
+	/* length of header incl. variable data */
+	uint32_t offset;
+	char filename[];
+} __packed;
+
+#if defined __GNUC__ && (__GNUC__ * 100 + __GNUC_MINOR__) >= 406
+_Static_assert(sizeof(struct cbfs_file) == 24, "cbfs_file size mismatch");
+#endif
+
+/* The common fields of extended cbfs file attributes.
+   Attributes are expected to start with tag/len, then append their
+   specific fields. */
+struct cbfs_file_attribute {
+	uint32_t tag;
+	/* len covers the whole structure, incl. tag and len */
+	uint32_t len;
+	uint8_t data[0];
+} __packed;
+
+/* Depending on how the header was initialized, it may be backed with 0x00 or
+ * 0xff. Support both. */
+#define CBFS_FILE_ATTR_TAG_UNUSED 0
+#define CBFS_FILE_ATTR_TAG_UNUSED2 0xffffffff
+#define CBFS_FILE_ATTR_TAG_COMPRESSION 0x42435a4c
+#define CBFS_FILE_ATTR_TAG_HASH 0x68736148
+#define CBFS_FILE_ATTR_TAG_POSITION 0x42435350 /* PSCB */
+#define CBFS_FILE_ATTR_TAG_ALIGNMENT 0x42434c41 /* ALCB */
+#define CBFS_FILE_ATTR_TAG_PADDING 0x47444150 /* PDNG */
+
+struct cbfs_file_attr_compression {
+	uint32_t tag;
+	uint32_t len;
+	/* whole file compression format. 0 if no compression. */
+	uint32_t compression;
+	uint32_t decompressed_size;
+} __packed;
+
+struct cbfs_file_attr_hash {
+	uint32_t tag;
+	uint32_t len;
+	uint32_t hash_type;
+	/* hash_data is len - sizeof(struct) bytes */
+	uint8_t  hash_data[];
+} __packed;
+
+struct cbfs_file_attr_position {
+	uint32_t tag;
+	uint32_t len;
+	uint32_t position;
+} __packed;
+
+struct cbfs_file_attr_align {
+	uint32_t tag;
+	uint32_t len;
+	uint32_t alignment;
+} __packed;
+
+struct cbfs_stage {
+	uint32_t compression;
+	uint64_t entry;
+	uint64_t load;
+	uint32_t len;
+	uint32_t memlen;
+} __packed;
+
+#define PAYLOAD_SEGMENT_CODE	makemagic('C', 'O', 'D', 'E')
+#define PAYLOAD_SEGMENT_DATA	makemagic('D', 'A', 'T', 'A')
+#define PAYLOAD_SEGMENT_BSS	makemagic('B', 'S', 'S', ' ')
+#define PAYLOAD_SEGMENT_PARAMS	makemagic('P', 'A', 'R', 'A')
+#define PAYLOAD_SEGMENT_ENTRY	makemagic('E', 'N', 'T', 'R')
+
+struct cbfs_payload_segment {
+	uint32_t type;
+	uint32_t compression;
+	uint32_t offset;
+	uint64_t load_addr;
+	uint32_t len;
+	uint32_t mem_len;
+} __packed;
+
+struct cbfs_payload {
+	struct cbfs_payload_segment segments;
+} __packed;
+
+/** These are standard component types for well known
+    components (i.e - those that coreboot needs to consume.
+    Users are welcome to use any other value for their
+    components */
+
+#define CBFS_COMPONENT_BOOTBLOCK  0x01
+#define CBFS_COMPONENT_CBFSHEADER 0x02
+#define CBFS_COMPONENT_STAGE      0x10
+#define CBFS_COMPONENT_SELF       0x20
+#define CBFS_COMPONENT_FIT        0x21
+#define CBFS_COMPONENT_OPTIONROM  0x30
+#define CBFS_COMPONENT_BOOTSPLASH 0x40
+#define CBFS_COMPONENT_RAW        0x50
+#define CBFS_COMPONENT_VSA        0x51
+#define CBFS_COMPONENT_MBI        0x52
+#define CBFS_COMPONENT_MICROCODE  0x53
+#define CBFS_COMPONENT_FSP        0x60
+#define CBFS_COMPONENT_MRC        0x61
+#define CBFS_COMPONENT_MMA	  0x62
+#define CBFS_COMPONENT_EFI	  0x63
+#define CBFS_COMPONENT_STRUCT	  0x70
+#define CBFS_COMPONENT_CMOS_DEFAULT 0xaa
+#define CBFS_COMPONENT_SPD          0xab
+#define CBFS_COMPONENT_MRC_CACHE    0xac
+#define CBFS_COMPONENT_CMOS_LAYOUT 0x01aa
+
+/* The deleted type is chosen to be a value
+ * that can be written in a FLASH from all other
+ * values.
+ */
+#define CBFS_COMPONENT_DELETED 0
+
+/* for all known FLASH, this value can be changed
+ * to all other values. This allows NULL files to be
+ * changed without a block erase
+ */
+#define CBFS_COMPONENT_NULL 0xFFFFFFFF
+
+static struct typedesc_t filetypes[] unused = {
+	{CBFS_COMPONENT_BOOTBLOCK, "bootblock"},
+	{CBFS_COMPONENT_CBFSHEADER, "cbfs header"},
+	{CBFS_COMPONENT_STAGE, "stage"},
+	{CBFS_COMPONENT_SELF, "simple elf"},
+	{CBFS_COMPONENT_FIT, "fit"},
+	{CBFS_COMPONENT_OPTIONROM, "optionrom"},
+	{CBFS_COMPONENT_BOOTSPLASH, "bootsplash"},
+	{CBFS_COMPONENT_RAW, "raw"},
+	{CBFS_COMPONENT_VSA, "vsa"},
+	{CBFS_COMPONENT_MBI, "mbi"},
+	{CBFS_COMPONENT_MICROCODE, "microcode"},
+	{CBFS_COMPONENT_FSP, "fsp"},
+	{CBFS_COMPONENT_MRC, "mrc"},
+	{CBFS_COMPONENT_CMOS_DEFAULT, "cmos_default"},
+	{CBFS_COMPONENT_CMOS_LAYOUT, "cmos_layout"},
+	{CBFS_COMPONENT_SPD, "spd"},
+	{CBFS_COMPONENT_MRC_CACHE, "mrc_cache"},
+	{CBFS_COMPONENT_MMA, "mma"},
+	{CBFS_COMPONENT_EFI, "efi"},
+	{CBFS_COMPONENT_STRUCT, "struct"},
+	{CBFS_COMPONENT_DELETED, "deleted"},
+	{CBFS_COMPONENT_NULL, "null"}
+};
+
+static const struct typedesc_t types_cbfs_hash[] unused = {
+	{VB2_HASH_INVALID, "none"},
+	{VB2_HASH_SHA1, "sha1"},
+	{VB2_HASH_SHA256, "sha256"},
+	{VB2_HASH_SHA512, "sha512"},
+	{0, NULL}
+};
+
+static size_t widths_cbfs_hash[] unused = {
+	[VB2_HASH_INVALID] = 0,
+	[VB2_HASH_SHA1] = 20,
+	[VB2_HASH_SHA256] = 32,
+	[VB2_HASH_SHA512] = 64,
+};
+
+#define CBFS_NUM_SUPPORTED_HASHES ARRAY_SIZE(widths_cbfs_hash)
+
+#define CBFS_SUBHEADER(_p) ( (void *) ((((uint8_t *) (_p)) + ntohl((_p)->offset))) )
+
+/* cbfs_image.c */
+uint32_t get_cbfs_entry_type(const char *name, uint32_t default_value);
+uint32_t get_cbfs_compression(const char *name, uint32_t unknown);
+
+/* cbfs-mkpayload.c */
+void xdr_segs(struct buffer *output,
+	      struct cbfs_payload_segment *segs, int nseg);
+void xdr_get_seg(struct cbfs_payload_segment *out,
+		struct cbfs_payload_segment *in);
+
+#endif
diff --git a/tools/cbfstool/cbfs_image.c b/tools/cbfstool/cbfs_image.c
new file mode 100644
index 0000000000..5cbe1f185a
--- /dev/null
+++ b/tools/cbfstool/cbfs_image.c
@@ -0,0 +1,2046 @@
+/*
+ * CBFS Image Manipulation
+ *
+ * Copyright (C) 2013 The Chromium OS Authors. All rights reserved.
+ * Copyright (C) 2016 Siemens AG. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <inttypes.h>
+#include <libgen.h>
+#include <stddef.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <strings.h>
+#include <commonlib/endian.h>
+#include <vb2_sha.h>
+
+#include "common.h"
+#include "cbfs_image.h"
+#include "elfparsing.h"
+#include "rmodule.h"
+
+/* Even though the file-adding functions---cbfs_add_entry() and
+ * cbfs_add_entry_at()---perform their sizing checks against the beginning of
+ * the subsequent section rather than a stable recorded value such as an empty
+ * file header's len field, it's possible to prove two interesting properties
+ * about their behavior:
+ *  - Placing a new file within an empty entry located below an existing file
+ *    entry will never leave an aligned flash address containing neither the
+ *    beginning of a file header nor part of a file.
+ *  - Placing a new file in an empty entry at the very end of the image such
+ *    that it fits, but leaves no room for a final header, is guaranteed not to
+ *    change the total amount of space for entries, even if that new file is
+ *    later removed from the CBFS.
+ * These properties are somewhat nonobvious from the implementation, so the
+ * reader is encouraged to blame this comment and examine the full proofs
+ * in the commit message before making significant changes that would risk
+ * removing said guarantees.
+ */
+
+/* The file name align is not defined in CBFS spec -- only a preference by
+ * (old) cbfstool. */
+#define CBFS_FILENAME_ALIGN	(16)
+
+static const char *lookup_name_by_type(const struct typedesc_t *desc, uint32_t type,
+				const char *default_value)
+{
+	int i;
+	for (i = 0; desc[i].name; i++)
+		if (desc[i].type == type)
+			return desc[i].name;
+	return default_value;
+}
+
+static int lookup_type_by_name(const struct typedesc_t *desc, const char *name)
+{
+	int i;
+	for (i = 0; desc[i].name && strcasecmp(name, desc[i].name); ++i);
+	return desc[i].name ? (int)desc[i].type : -1;
+}
+
+static const char *get_cbfs_entry_type_name(uint32_t type)
+{
+	return lookup_name_by_type(filetypes, type, "(unknown)");
+}
+
+int cbfs_parse_comp_algo(const char *name)
+{
+	return lookup_type_by_name(types_cbfs_compression, name);
+}
+
+static const char *get_hash_attr_name(uint16_t hash_type)
+{
+	return lookup_name_by_type(types_cbfs_hash, hash_type, "(invalid)");
+}
+
+int cbfs_parse_hash_algo(const char *name)
+{
+	return lookup_type_by_name(types_cbfs_hash, name);
+}
+
+/* CBFS image */
+
+size_t cbfs_calculate_file_header_size(const char *name)
+{
+	return (sizeof(struct cbfs_file) +
+		align_up(strlen(name) + 1, CBFS_FILENAME_ALIGN));
+}
+
+/* Only call on legacy CBFSes possessing a master header. */
+static int cbfs_fix_legacy_size(struct cbfs_image *image, char *hdr_loc)
+{
+	assert(image);
+	assert(cbfs_is_legacy_cbfs(image));
+	// A bug in old cbfstool may produce extra few bytes (by alignment) and
+	// cause cbfstool to overwrite things after free space -- which is
+	// usually CBFS header on x86. We need to workaround that.
+	// Except when we run across a file that contains the actual header,
+	// in which case this image is a safe, new-style
+	// `cbfstool add-master-header` based image.
+
+	struct cbfs_file *entry, *first = NULL, *last = NULL;
+	for (first = entry = cbfs_find_first_entry(image);
+	     entry && cbfs_is_valid_entry(image, entry);
+	     entry = cbfs_find_next_entry(image, entry)) {
+		/* Is the header guarded by a CBFS file entry? Then exit */
+		if (((char *)entry) + ntohl(entry->offset) == hdr_loc) {
+			return 0;
+		}
+		last = entry;
+	}
+	if ((char *)first < (char *)hdr_loc &&
+	    (char *)entry > (char *)hdr_loc) {
+		WARN("CBFS image was created with old cbfstool with size bug. "
+		     "Fixing size in last entry...\n");
+		last->len = htonl(ntohl(last->len) - image->header.align);
+		DEBUG("Last entry has been changed from 0x%x to 0x%x.\n",
+		      cbfs_get_entry_addr(image, entry),
+		      cbfs_get_entry_addr(image,
+					  cbfs_find_next_entry(image, last)));
+	}
+	return 0;
+}
+
+void cbfs_put_header(void *dest, const struct cbfs_header *header)
+{
+	struct buffer outheader;
+
+	outheader.data = dest;
+	outheader.size = 0;
+
+	xdr_be.put32(&outheader, header->magic);
+	xdr_be.put32(&outheader, header->version);
+	xdr_be.put32(&outheader, header->romsize);
+	xdr_be.put32(&outheader, header->bootblocksize);
+	xdr_be.put32(&outheader, header->align);
+	xdr_be.put32(&outheader, header->offset);
+	xdr_be.put32(&outheader, header->architecture);
+}
+
+static void cbfs_decode_payload_segment(struct cbfs_payload_segment *output,
+					struct cbfs_payload_segment *input)
+{
+	struct buffer seg = {
+		.data = (void *)input,
+		.size = sizeof(*input),
+	};
+	output->type = xdr_be.get32(&seg);
+	output->compression = xdr_be.get32(&seg);
+	output->offset = xdr_be.get32(&seg);
+	output->load_addr = xdr_be.get64(&seg);
+	output->len = xdr_be.get32(&seg);
+	output->mem_len = xdr_be.get32(&seg);
+	assert(seg.size == 0);
+}
+
+static int cbfs_file_get_compression_info(struct cbfs_file *entry,
+	uint32_t *decompressed_size)
+{
+	unsigned int compression = CBFS_COMPRESS_NONE;
+	if (decompressed_size)
+		*decompressed_size = ntohl(entry->len);
+	for (struct cbfs_file_attribute *attr = cbfs_file_first_attr(entry);
+	     attr != NULL;
+	     attr = cbfs_file_next_attr(entry, attr)) {
+		if (ntohl(attr->tag) == CBFS_FILE_ATTR_TAG_COMPRESSION) {
+			struct cbfs_file_attr_compression *ac =
+				(struct cbfs_file_attr_compression *)attr;
+			compression = ntohl(ac->compression);
+			if (decompressed_size)
+				*decompressed_size =
+					ntohl(ac->decompressed_size);
+		}
+	}
+	return compression;
+}
+
+static struct cbfs_file_attr_hash *cbfs_file_get_next_hash(
+	struct cbfs_file *entry, struct cbfs_file_attr_hash *cur)
+{
+	struct cbfs_file_attribute *attr = (struct cbfs_file_attribute *)cur;
+	if (attr == NULL) {
+		attr = cbfs_file_first_attr(entry);
+		if (attr == NULL)
+			return NULL;
+		if (ntohl(attr->tag) == CBFS_FILE_ATTR_TAG_HASH)
+			return (struct cbfs_file_attr_hash *)attr;
+	}
+	while ((attr = cbfs_file_next_attr(entry, attr)) != NULL) {
+		if (ntohl(attr->tag) == CBFS_FILE_ATTR_TAG_HASH)
+			return (struct cbfs_file_attr_hash *)attr;
+	};
+	return NULL;
+}
+
+void cbfs_get_header(struct cbfs_header *header, void *src)
+{
+	struct buffer outheader;
+
+	outheader.data = src;	/* We're not modifying the data */
+	outheader.size = 0;
+
+	header->magic = xdr_be.get32(&outheader);
+	header->version = xdr_be.get32(&outheader);
+	header->romsize = xdr_be.get32(&outheader);
+	header->bootblocksize = xdr_be.get32(&outheader);
+	header->align = xdr_be.get32(&outheader);
+	header->offset = xdr_be.get32(&outheader);
+	header->architecture = xdr_be.get32(&outheader);
+}
+
+int cbfs_image_create(struct cbfs_image *image, size_t entries_size)
+{
+	assert(image);
+	assert(image->buffer.data);
+
+	size_t empty_header_len = cbfs_calculate_file_header_size("");
+	uint32_t entries_offset = 0;
+	uint32_t align = CBFS_ENTRY_ALIGNMENT;
+	if (image->has_header) {
+		entries_offset = image->header.offset;
+
+		if (entries_offset > image->buffer.size) {
+			ERROR("CBFS file entries are located outside CBFS itself\n");
+			return -1;
+		}
+
+		align = image->header.align;
+	}
+
+	// This attribute must be given in order to prove that this module
+	// correctly preserves certain CBFS properties. See the block comment
+	// near the top of this file (and the associated commit message).
+	if (align < empty_header_len) {
+		ERROR("CBFS must be aligned to at least %zu bytes\n",
+							empty_header_len);
+		return -1;
+	}
+
+	if (entries_size > image->buffer.size - entries_offset) {
+		ERROR("CBFS doesn't have enough space to fit its file entries\n");
+		return -1;
+	}
+
+	if (empty_header_len > entries_size) {
+		ERROR("CBFS is too small to fit any header\n");
+		return -1;
+	}
+	struct cbfs_file *entry_header =
+		(struct cbfs_file *)(image->buffer.data + entries_offset);
+	// This alignment is necessary in order to prove that this module
+	// correctly preserves certain CBFS properties. See the block comment
+	// near the top of this file (and the associated commit message).
+	entries_size -= entries_size % align;
+
+	size_t capacity = entries_size - empty_header_len;
+	LOG("Created CBFS (capacity = %zu bytes)\n", capacity);
+	return cbfs_create_empty_entry(entry_header, CBFS_COMPONENT_NULL,
+		capacity, "");
+}
+
+int cbfs_legacy_image_create(struct cbfs_image *image,
+			     uint32_t architecture,
+			     uint32_t align,
+			     struct buffer *bootblock,
+			     uint32_t bootblock_offset,
+			     uint32_t header_offset,
+			     uint32_t entries_offset)
+{
+	assert(image);
+	assert(image->buffer.data);
+	assert(bootblock);
+
+	int32_t *rel_offset;
+	uint32_t cbfs_len;
+	void *header_loc;
+	size_t size = image->buffer.size;
+
+	DEBUG("cbfs_image_create: bootblock=0x%x+0x%zx, "
+	      "header=0x%x+0x%zx, entries_offset=0x%x\n",
+	      bootblock_offset, bootblock->size, header_offset,
+	      sizeof(image->header), entries_offset);
+
+	// Adjust legacy top-aligned address to ROM offset.
+	if (IS_TOP_ALIGNED_ADDRESS(entries_offset))
+		entries_offset = size + (int32_t)entries_offset;
+	if (IS_TOP_ALIGNED_ADDRESS(bootblock_offset))
+		bootblock_offset = size + (int32_t)bootblock_offset;
+	if (IS_TOP_ALIGNED_ADDRESS(header_offset))
+		header_offset = size + (int32_t)header_offset;
+
+	DEBUG("cbfs_create_image: (real offset) bootblock=0x%x, "
+	      "header=0x%x, entries_offset=0x%x\n",
+	      bootblock_offset, header_offset, entries_offset);
+
+	// Prepare bootblock
+	if (bootblock_offset + bootblock->size > size) {
+		ERROR("Bootblock (0x%x+0x%zx) exceed ROM size (0x%zx)\n",
+		      bootblock_offset, bootblock->size, size);
+		return -1;
+	}
+	if (entries_offset > bootblock_offset &&
+	    entries_offset < bootblock->size) {
+		ERROR("Bootblock (0x%x+0x%zx) overlap CBFS data (0x%x)\n",
+		      bootblock_offset, bootblock->size, entries_offset);
+		return -1;
+	}
+	memcpy(image->buffer.data + bootblock_offset, bootblock->data,
+	       bootblock->size);
+
+	// Prepare header
+	if (header_offset + sizeof(image->header) > size - sizeof(int32_t)) {
+		ERROR("Header (0x%x+0x%zx) exceed ROM size (0x%zx)\n",
+		      header_offset, sizeof(image->header), size);
+		return -1;
+	}
+	image->header.magic = CBFS_HEADER_MAGIC;
+	image->header.version = CBFS_HEADER_VERSION;
+	image->header.romsize = size;
+	image->header.bootblocksize = bootblock->size;
+	image->header.align = align;
+	image->header.offset = entries_offset;
+	image->header.architecture = architecture;
+
+	header_loc = (image->buffer.data + header_offset);
+	cbfs_put_header(header_loc, &image->header);
+	image->has_header = true;
+
+	// The last 4 byte of the image contain the relative offset from the end
+	// of the image to the master header as a 32-bit signed integer. x86
+	// relies on this also being its (memory-mapped, top-aligned) absolute
+	// 32-bit address by virtue of how two's complement numbers work.
+	assert(size % sizeof(int32_t) == 0);
+	rel_offset = (int32_t *)(image->buffer.data + size - sizeof(int32_t));
+	*rel_offset = header_offset - size;
+
+	// Prepare entries
+	if (align_up(entries_offset, align) != entries_offset) {
+		ERROR("Offset (0x%x) must be aligned to 0x%x.\n",
+		      entries_offset, align);
+		return -1;
+	}
+	// To calculate available length, find
+	//   e = min(bootblock, header, rel_offset) where e > entries_offset.
+	cbfs_len = size - sizeof(int32_t);
+	if (bootblock_offset > entries_offset && bootblock_offset < cbfs_len)
+		cbfs_len = bootblock_offset;
+	if (header_offset > entries_offset && header_offset < cbfs_len)
+		cbfs_len = header_offset;
+
+	if (cbfs_image_create(image, cbfs_len - entries_offset))
+		return -1;
+	return 0;
+}
+
+int cbfs_image_from_buffer(struct cbfs_image *out, struct buffer *in,
+			   uint32_t offset)
+{
+	assert(out);
+	assert(in);
+	assert(in->data);
+
+	buffer_clone(&out->buffer, in);
+	out->has_header = false;
+
+	if (cbfs_is_valid_cbfs(out)) {
+		return 0;
+	}
+
+	void *header_loc = cbfs_find_header(in->data, in->size, offset);
+	if (header_loc) {
+		cbfs_get_header(&out->header, header_loc);
+		out->has_header = true;
+		cbfs_fix_legacy_size(out, header_loc);
+		return 0;
+	} else if (offset != ~0u) {
+		ERROR("The -H switch is only valid on legacy images having CBFS master headers.\n");
+		return 1;
+	}
+	ERROR("Selected image region is not a valid CBFS.\n");
+	return 1;
+}
+
+int cbfs_copy_instance(struct cbfs_image *image, struct buffer *dst)
+{
+	assert(image);
+
+	struct cbfs_file *src_entry, *dst_entry;
+	size_t align;
+	ssize_t last_entry_size;
+
+	size_t copy_end = buffer_size(dst);
+
+	align = CBFS_ENTRY_ALIGNMENT;
+
+	dst_entry = (struct cbfs_file *)buffer_get(dst);
+
+	/* Copy non-empty files */
+	for (src_entry = cbfs_find_first_entry(image);
+	     src_entry && cbfs_is_valid_entry(image, src_entry);
+	     src_entry = cbfs_find_next_entry(image, src_entry)) {
+		size_t entry_size;
+
+		if ((src_entry->type == htonl(CBFS_COMPONENT_NULL)) ||
+		    (src_entry->type == htonl(CBFS_COMPONENT_CBFSHEADER)) ||
+		    (src_entry->type == htonl(CBFS_COMPONENT_DELETED)))
+			continue;
+
+		entry_size = htonl(src_entry->len) + htonl(src_entry->offset);
+		memcpy(dst_entry, src_entry, entry_size);
+		dst_entry = (struct cbfs_file *)(
+			(uintptr_t)dst_entry + align_up(entry_size, align));
+
+		if ((size_t)((uint8_t *)dst_entry - (uint8_t *)buffer_get(dst))
+					>= copy_end) {
+			ERROR("Ran out of room in copy region.\n");
+			return 1;
+		}
+	}
+
+	/* Last entry size is all the room above it, except for top 4 bytes
+	 * which may be used by the master header pointer. This messes with
+	 * the ability to stash something "top-aligned" into the region, but
+	 * keeps things simpler. */
+	last_entry_size = copy_end -
+		((uint8_t *)dst_entry - (uint8_t *)buffer_get(dst)) -
+		cbfs_calculate_file_header_size("") - sizeof(int32_t);
+
+	if (last_entry_size < 0)
+		WARN("No room to create the last entry!\n")
+	else
+		cbfs_create_empty_entry(dst_entry, CBFS_COMPONENT_NULL,
+			last_entry_size, "");
+
+	return 0;
+}
+
+int cbfs_expand_to_region(struct buffer *region)
+{
+	if (buffer_get(region) == NULL)
+		return 1;
+
+	struct cbfs_image image;
+	memset(&image, 0, sizeof(image));
+	if (cbfs_image_from_buffer(&image, region, 0)) {
+		ERROR("reading CBFS failed!\n");
+		return 1;
+	}
+
+	uint32_t region_sz = buffer_size(region);
+
+	struct cbfs_file *entry;
+	for (entry = buffer_get(region);
+	     cbfs_is_valid_entry(&image, entry);
+	     entry = cbfs_find_next_entry(&image, entry)) {
+	     /* just iterate through */
+	}
+
+	/* entry now points to the first aligned address after the last valid
+	 * file header. That's either outside the image or exactly the place
+	 * where we need to create a new file.
+	 */
+	int last_entry_size = region_sz -
+		((uint8_t *)entry - (uint8_t *)buffer_get(region)) -
+		cbfs_calculate_file_header_size("") - sizeof(int32_t);
+
+	if (last_entry_size > 0) {
+		cbfs_create_empty_entry(entry, CBFS_COMPONENT_NULL,
+			last_entry_size, "");
+		/* If the last entry was an empty file, merge them. */
+		cbfs_walk(&image, cbfs_merge_empty_entry, NULL);
+	}
+
+	return 0;
+}
+
+int cbfs_truncate_space(struct buffer *region, uint32_t *size)
+{
+	if (buffer_get(region) == NULL)
+		return 1;
+
+	struct cbfs_image image;
+	memset(&image, 0, sizeof(image));
+	if (cbfs_image_from_buffer(&image, region, 0)) {
+		ERROR("reading CBFS failed!\n");
+		return 1;
+	}
+
+	struct cbfs_file *entry, *trailer;
+	for (trailer = entry = buffer_get(region);
+	     cbfs_is_valid_entry(&image, entry);
+	     trailer = entry,
+	     entry = cbfs_find_next_entry(&image, entry)) {
+	     /* just iterate through */
+	}
+
+	/* trailer now points to the last valid CBFS entry's header.
+	 * If that file is empty, remove it and report its header's offset as
+	 * maximum size.
+	 */
+	if ((strlen(trailer->filename) != 0) &&
+	    (trailer->type != htonl(CBFS_COMPONENT_NULL)) &&
+	    (trailer->type != htonl(CBFS_COMPONENT_DELETED))) {
+		/* nothing to truncate. Return de-facto CBFS size in case it
+		 * was already truncated. */
+		*size = (uint8_t *)entry - (uint8_t *)buffer_get(region);
+		return 0;
+	}
+	*size = (uint8_t *)trailer - (uint8_t *)buffer_get(region);
+	memset(trailer, 0xff, buffer_size(region) - *size);
+
+	return 0;
+}
+
+static size_t cbfs_file_entry_metadata_size(const struct cbfs_file *f)
+{
+	return ntohl(f->offset);
+}
+
+static size_t cbfs_file_entry_data_size(const struct cbfs_file *f)
+{
+	return ntohl(f->len);
+}
+
+static size_t cbfs_file_entry_size(const struct cbfs_file *f)
+{
+	return cbfs_file_entry_metadata_size(f) + cbfs_file_entry_data_size(f);
+}
+
+int cbfs_compact_instance(struct cbfs_image *image)
+{
+	assert(image);
+
+	struct cbfs_file *prev;
+	struct cbfs_file *cur;
+
+	/* The prev entry will always be an empty entry. */
+	prev = NULL;
+
+	/*
+	 * Note: this function does not honor alignment or fixed location files.
+	 * It's behavior is akin to cbfs_copy_instance() in that it expects
+	 * the caller to understand the ramifications of compacting a
+	 * fragmented CBFS image.
+	 */
+
+	for (cur = cbfs_find_first_entry(image);
+	     cur && cbfs_is_valid_entry(image, cur);
+	     cur = cbfs_find_next_entry(image, cur)) {
+		size_t prev_size;
+		size_t cur_size;
+		size_t empty_metadata_size;
+		size_t spill_size;
+		uint32_t type = htonl(cur->type);
+
+		/* Current entry is empty. Kepp track of it. */
+		if ((type == htonl(CBFS_COMPONENT_NULL)) ||
+		    (type == htonl(CBFS_COMPONENT_DELETED))) {
+			prev = cur;
+			continue;
+		}
+
+		/* Need to ensure the previous entry is an empty one. */
+		if (prev == NULL)
+			continue;
+
+		/* At this point prev is an empty entry. Put the non-empty
+		 * file in prev's location. Then add a new emptry entry. This
+		 * essentialy bubbles empty entries towards the end. */
+
+		prev_size = cbfs_file_entry_size(prev);
+		cur_size = cbfs_file_entry_size(cur);
+
+		/*
+		 * Adjust the empty file size by the actual space occupied
+		 * bewtween the beginning of the empty file and the non-empty
+		 * file.
+		 */
+		prev_size += (cbfs_get_entry_addr(image, cur) -
+				cbfs_get_entry_addr(image, prev)) - prev_size;
+
+		/* Move the non-empty file over the empty file. */
+		memmove(prev, cur, cur_size);
+
+		/*
+		 * Get location of the empty file. Note that since prev was
+		 * overwritten with the non-empty file the previously moved
+		 * file needs to be used to calculate the empty file's location.
+		 */
+		cur = cbfs_find_next_entry(image, prev);
+
+		/*
+		 * The total space to work with for swapping the 2 entries
+		 * consists of the 2 files' sizes combined. However, the
+		 * cbfs_file entries start on CBFS_ALIGNMENT boundaries.
+		 * Because of this the empty file size may end up smaller
+		 * because of the non-empty file's metadata and data length.
+		 *
+		 * Calculate the spill size which is the amount of data lost
+		 * due to the alignment constraints after moving the non-empty
+		 * file.
+		 */
+		spill_size = (cbfs_get_entry_addr(image, cur) -
+				cbfs_get_entry_addr(image, prev)) - cur_size;
+
+		empty_metadata_size = cbfs_calculate_file_header_size("");
+
+		/* Check if new empty size can contain the metadata. */
+		if (empty_metadata_size + spill_size > prev_size) {
+			ERROR("Unable to swap '%s' with prev empty entry.\n",
+				prev->filename);
+			return 1;
+		}
+
+		/* Update the empty file's size. */
+		prev_size -= spill_size + empty_metadata_size;
+
+		/* Create new empty file. */
+		cbfs_create_empty_entry(cur, CBFS_COMPONENT_NULL,
+					prev_size, "");
+
+		/* Merge any potential empty entries together. */
+		cbfs_walk(image, cbfs_merge_empty_entry, NULL);
+
+		/*
+		 * Since current switched to an empty file keep track of it.
+		 * Even if any empty files were merged the empty entry still
+		 * starts at previously calculated location.
+		 */
+		prev = cur;
+	}
+
+	return 0;
+}
+
+int cbfs_image_delete(struct cbfs_image *image)
+{
+	if (image == NULL)
+		return 0;
+
+	buffer_delete(&image->buffer);
+	return 0;
+}
+
+/* Tries to add an entry with its data (CBFS_SUBHEADER) at given offset. */
+static int cbfs_add_entry_at(struct cbfs_image *image,
+			     struct cbfs_file *entry,
+			     const void *data,
+			     uint32_t content_offset,
+			     const struct cbfs_file *header)
+{
+	struct cbfs_file *next = cbfs_find_next_entry(image, entry);
+	uint32_t addr = cbfs_get_entry_addr(image, entry),
+		 addr_next = cbfs_get_entry_addr(image, next);
+	uint32_t min_entry_size = cbfs_calculate_file_header_size("");
+	uint32_t len, header_offset;
+	uint32_t align = image->has_header ? image->header.align :
+							CBFS_ENTRY_ALIGNMENT;
+	uint32_t header_size = ntohl(header->offset);
+
+	header_offset = content_offset - header_size;
+	if (header_offset % align)
+		header_offset -= header_offset % align;
+	if (header_offset < addr) {
+		ERROR("No space to hold cbfs_file header.");
+		return -1;
+	}
+
+	// Process buffer BEFORE content_offset.
+	if (header_offset - addr > min_entry_size) {
+		DEBUG("|min|...|header|content|... <create new entry>\n");
+		len = header_offset - addr - min_entry_size;
+		cbfs_create_empty_entry(entry, CBFS_COMPONENT_NULL, len, "");
+		if (verbose > 1) cbfs_print_entry_info(image, entry, stderr);
+		entry = cbfs_find_next_entry(image, entry);
+		addr = cbfs_get_entry_addr(image, entry);
+	}
+
+	len = content_offset - addr - header_size;
+	memcpy(entry, header, header_size);
+	if (len != 0) {
+		/* the header moved backwards a bit to accommodate cbfs_file
+		 * alignment requirements, so patch up ->offset to still point
+		 * to file data.
+		 */
+		DEBUG("|..|header|content|... <use offset to create entry>\n");
+		DEBUG("before: offset=0x%x\n", ntohl(entry->offset));
+		// TODO reset expanded name buffer to 0xFF.
+		entry->offset = htonl(ntohl(entry->offset) + len);
+		DEBUG("after: offset=0x%x\n", ntohl(entry->len));
+	}
+
+	// Ready to fill data into entry.
+	DEBUG("content_offset: 0x%x, entry location: %x\n",
+	      content_offset, (int)((char*)CBFS_SUBHEADER(entry) -
+				    image->buffer.data));
+	assert((char*)CBFS_SUBHEADER(entry) - image->buffer.data ==
+	       (ptrdiff_t)content_offset);
+	memcpy(CBFS_SUBHEADER(entry), data, ntohl(entry->len));
+	if (verbose > 1) cbfs_print_entry_info(image, entry, stderr);
+
+	// Process buffer AFTER entry.
+	entry = cbfs_find_next_entry(image, entry);
+	addr = cbfs_get_entry_addr(image, entry);
+	if (addr == addr_next)
+		return 0;
+
+	assert(addr < addr_next);
+	if (addr_next - addr < min_entry_size) {
+		DEBUG("No need for new \"empty\" entry\n");
+		/* No need to increase the size of the just
+		 * stored file to extend to next file. Alignment
+		 * of next file takes care of this.
+		 */
+		return 0;
+	}
+
+	len = addr_next - addr - min_entry_size;
+	/* keep space for master header pointer */
+	if ((uint8_t *)entry + min_entry_size + len >
+			(uint8_t *)buffer_get(&image->buffer) +
+			buffer_size(&image->buffer) - sizeof(int32_t)) {
+		len -= sizeof(int32_t);
+	}
+	cbfs_create_empty_entry(entry, CBFS_COMPONENT_NULL, len, "");
+	if (verbose > 1) cbfs_print_entry_info(image, entry, stderr);
+	return 0;
+}
+
+int cbfs_add_entry(struct cbfs_image *image, struct buffer *buffer,
+		   uint32_t content_offset,
+		   struct cbfs_file *header)
+{
+	assert(image);
+	assert(buffer);
+	assert(buffer->data);
+	assert(!IS_TOP_ALIGNED_ADDRESS(content_offset));
+
+	const char *name = header->filename;
+
+	uint32_t entry_type;
+	uint32_t addr, addr_next;
+	struct cbfs_file *entry, *next;
+	uint32_t need_size;
+	uint32_t header_size = ntohl(header->offset);
+
+	need_size = header_size + buffer->size;
+	DEBUG("cbfs_add_entry('%s'@0x%x) => need_size = %u+%zu=%u\n",
+	      name, content_offset, header_size, buffer->size, need_size);
+
+	// Merge empty entries.
+	DEBUG("(trying to merge empty entries...)\n");
+	cbfs_walk(image, cbfs_merge_empty_entry, NULL);
+
+	for (entry = cbfs_find_first_entry(image);
+	     entry && cbfs_is_valid_entry(image, entry);
+	     entry = cbfs_find_next_entry(image, entry)) {
+
+		entry_type = ntohl(entry->type);
+		if (entry_type != CBFS_COMPONENT_NULL)
+			continue;
+
+		addr = cbfs_get_entry_addr(image, entry);
+		next = cbfs_find_next_entry(image, entry);
+		addr_next = cbfs_get_entry_addr(image, next);
+
+		DEBUG("cbfs_add_entry: space at 0x%x+0x%x(%d) bytes\n",
+		      addr, addr_next - addr, addr_next - addr);
+
+		/* Will the file fit? Don't yet worry if we have space for a new
+		 * "empty" entry. We take care of that later.
+		 */
+		if (addr + need_size > addr_next)
+			continue;
+
+		// Test for complicated cases
+		if (content_offset > 0) {
+			if (addr_next < content_offset) {
+				DEBUG("Not for specified offset yet");
+				continue;
+			} else if (addr > content_offset) {
+				DEBUG("Exceed specified content_offset.");
+				break;
+			} else if (addr + header_size > content_offset) {
+				ERROR("Not enough space for header.\n");
+				break;
+			} else if (content_offset + buffer->size > addr_next) {
+				ERROR("Not enough space for content.\n");
+				break;
+			}
+		}
+
+		// TODO there are more few tricky cases that we may
+		// want to fit by altering offset.
+
+		if (content_offset == 0) {
+			// we tested every condition earlier under which
+			// placing the file there might fail
+			content_offset = addr + header_size;
+		}
+
+		DEBUG("section 0x%x+0x%x for content_offset 0x%x.\n",
+		      addr, addr_next - addr, content_offset);
+
+		if (cbfs_add_entry_at(image, entry, buffer->data,
+				      content_offset, header) == 0) {
+			return 0;
+		}
+		break;
+	}
+
+	ERROR("Could not add [%s, %zd bytes (%zd KB)@0x%x]; too big?\n",
+	      buffer->name, buffer->size, buffer->size / 1024, content_offset);
+	return -1;
+}
+
+struct cbfs_file *cbfs_get_entry(struct cbfs_image *image, const char *name)
+{
+	struct cbfs_file *entry;
+	for (entry = cbfs_find_first_entry(image);
+	     entry && cbfs_is_valid_entry(image, entry);
+	     entry = cbfs_find_next_entry(image, entry)) {
+		if (strcasecmp(entry->filename, name) == 0) {
+			DEBUG("cbfs_get_entry: found %s\n", name);
+			return entry;
+		}
+	}
+	return NULL;
+}
+
+static int cbfs_stage_decompress(struct cbfs_stage *stage, struct buffer *buff)
+{
+	struct buffer reader;
+	char *orig_buffer;
+	char *new_buffer;
+	size_t new_buff_sz;
+	decomp_func_ptr decompress;
+
+	buffer_clone(&reader, buff);
+
+	/* The stage metadata is in little endian. */
+	stage->compression = xdr_le.get32(&reader);
+	stage->entry = xdr_le.get64(&reader);
+	stage->load = xdr_le.get64(&reader);
+	stage->len = xdr_le.get32(&reader);
+	stage->memlen = xdr_le.get32(&reader);
+
+	/* Create a buffer just with the uncompressed program now that the
+	 * struct cbfs_stage has been peeled off. */
+	if (stage->compression == CBFS_COMPRESS_NONE) {
+		new_buff_sz = buffer_size(buff) - sizeof(struct cbfs_stage);
+
+		orig_buffer = buffer_get(buff);
+		new_buffer = calloc(1, new_buff_sz);
+		memcpy(new_buffer, orig_buffer + sizeof(struct cbfs_stage),
+			new_buff_sz);
+		buffer_init(buff, buff->name, new_buffer, new_buff_sz);
+		free(orig_buffer);
+		return 0;
+	}
+
+	decompress = decompression_function(stage->compression);
+	if (decompress == NULL)
+		return -1;
+
+	orig_buffer = buffer_get(buff);
+
+	/* This can be too big of a buffer needed, but there's no current
+	 * field indicating decompressed size of data. */
+	new_buff_sz = stage->memlen;
+	new_buffer = calloc(1, new_buff_sz);
+
+	if (decompress(orig_buffer + sizeof(struct cbfs_stage),
+			(int)(buffer_size(buff) - sizeof(struct cbfs_stage)),
+			new_buffer, (int)new_buff_sz, &new_buff_sz)) {
+		ERROR("Couldn't decompress stage.\n");
+		free(new_buffer);
+		return -1;
+	}
+
+	/* Include correct size for full stage info. */
+	buffer_init(buff, buff->name, new_buffer, new_buff_sz);
+
+	/* True decompressed size is just the data size -- no metadata. */
+	stage->len = new_buff_sz;
+	/* Stage is not compressed. */
+	stage->compression = CBFS_COMPRESS_NONE;
+
+	free(orig_buffer);
+
+	return 0;
+}
+
+static int cbfs_payload_decompress(struct cbfs_payload_segment *segments,
+		struct buffer *buff, int num_seg)
+{
+	struct buffer new_buffer;
+	struct buffer seg_buffer;
+	size_t new_buff_sz;
+	char *in_ptr;
+	char *out_ptr;
+	size_t new_offset;
+	decomp_func_ptr decompress;
+
+	new_offset = num_seg * sizeof(*segments);
+	new_buff_sz = num_seg * sizeof(*segments);
+
+	/* Find out and allocate the amount of memory occupied
+	 * by the binary data */
+	for (int i = 0; i < num_seg; i++)
+		new_buff_sz += segments[i].mem_len;
+
+	if (buffer_create(&new_buffer, new_buff_sz, "decompressed_buff"))
+		return -1;
+
+	in_ptr = buffer_get(buff) + new_offset;
+	out_ptr = buffer_get(&new_buffer) + new_offset;
+
+	for (int i = 0; i < num_seg; i++) {
+		struct buffer tbuff;
+		size_t decomp_size;
+
+		/* Segments BSS and ENTRY do not have binary data. */
+		if (segments[i].type == PAYLOAD_SEGMENT_BSS ||
+				segments[i].type == PAYLOAD_SEGMENT_ENTRY) {
+			continue;
+		} else if (segments[i].type == PAYLOAD_SEGMENT_PARAMS) {
+			memcpy(out_ptr, in_ptr, segments[i].len);
+			segments[i].offset = new_offset;
+			new_offset += segments[i].len;
+			in_ptr += segments[i].len;
+			out_ptr += segments[i].len;
+			segments[i].compression = CBFS_COMPRESS_NONE;
+			continue;
+		}
+
+		/* The payload uses an unknown compression algorithm. */
+		decompress = decompression_function(segments[i].compression);
+		if (decompress == NULL) {
+			ERROR("Unknown decompression algorithm: %u\n",
+					segments[i].compression);
+			return -1;
+		}
+
+		if (buffer_create(&tbuff, segments[i].mem_len, "segment")) {
+			buffer_delete(&new_buffer);
+			return -1;
+		}
+
+		if (decompress(in_ptr, segments[i].len, buffer_get(&tbuff),
+					(int) buffer_size(&tbuff),
+					&decomp_size)) {
+			ERROR("Couldn't decompress payload segment %u\n", i);
+			buffer_delete(&new_buffer);
+			buffer_delete(&tbuff);
+			return -1;
+		}
+
+		memcpy(out_ptr, buffer_get(&tbuff), decomp_size);
+
+		in_ptr += segments[i].len;
+
+		/* Update the offset of the segment. */
+		segments[i].offset = new_offset;
+		/* True decompressed size is just the data size. No metadata */
+		segments[i].len = decomp_size;
+		/* Segment is not compressed. */
+		segments[i].compression = CBFS_COMPRESS_NONE;
+
+		/* Update the offset and output buffer pointer. */
+		new_offset += decomp_size;
+		out_ptr += decomp_size;
+
+		buffer_delete(&tbuff);
+	}
+
+	buffer_splice(&seg_buffer, &new_buffer, 0, 0);
+	xdr_segs(&seg_buffer, segments, num_seg);
+
+	buffer_delete(buff);
+	*buff = new_buffer;
+
+	return 0;
+}
+
+static int init_elf_from_arch(Elf64_Ehdr *ehdr, uint32_t cbfs_arch)
+{
+	int endian;
+	int nbits;
+	int machine;
+
+	switch (cbfs_arch) {
+	case CBFS_ARCHITECTURE_X86:
+		endian = ELFDATA2LSB;
+		nbits = ELFCLASS32;
+		machine = EM_386;
+		break;
+	case CBFS_ARCHITECTURE_ARM:
+		endian = ELFDATA2LSB;
+		nbits = ELFCLASS32;
+		machine = EM_ARM;
+		break;
+	case CBFS_ARCHITECTURE_AARCH64:
+		endian = ELFDATA2LSB;
+		nbits = ELFCLASS64;
+		machine = EM_AARCH64;
+		break;
+	case CBFS_ARCHITECTURE_MIPS:
+		endian = ELFDATA2LSB;
+		nbits = ELFCLASS32;
+		machine = EM_MIPS;
+		break;
+	case CBFS_ARCHITECTURE_RISCV:
+		endian = ELFDATA2LSB;
+		nbits = ELFCLASS32;
+		machine = EM_RISCV;
+		break;
+	default:
+		ERROR("Unsupported arch: %x\n", cbfs_arch);
+		return -1;
+	}
+
+	elf_init_eheader(ehdr, machine, nbits, endian);
+	return 0;
+}
+
+static int cbfs_stage_make_elf(struct buffer *buff, uint32_t arch)
+{
+	Elf64_Ehdr ehdr;
+	Elf64_Shdr shdr;
+	struct cbfs_stage stage;
+	struct elf_writer *ew;
+	struct buffer elf_out;
+	size_t empty_sz;
+	int rmod_ret;
+
+	if (arch == CBFS_ARCHITECTURE_UNKNOWN) {
+		ERROR("You need to specify -m ARCH.\n");
+		return -1;
+	}
+
+	if (cbfs_stage_decompress(&stage, buff)) {
+		ERROR("Failed to decompress stage.\n");
+		return -1;
+	}
+
+	if (init_elf_from_arch(&ehdr, arch))
+		return -1;
+
+	ehdr.e_entry = stage.entry;
+
+	/* Attempt rmodule translation first. */
+	rmod_ret = rmodule_stage_to_elf(&ehdr, buff);
+
+	if (rmod_ret < 0) {
+		ERROR("rmodule parsing failed\n");
+		return -1;
+	} else if (rmod_ret == 0)
+		return 0;
+
+	/* Rmodule couldn't do anything with the data. Continue on with SELF. */
+
+	ew = elf_writer_init(&ehdr);
+	if (ew == NULL) {
+		ERROR("Unable to init ELF writer.\n");
+		return -1;
+	}
+
+	memset(&shdr, 0, sizeof(shdr));
+	shdr.sh_type = SHT_PROGBITS;
+	shdr.sh_flags = SHF_WRITE | SHF_ALLOC | SHF_EXECINSTR;
+	shdr.sh_addr = stage.load;
+	shdr.sh_size = stage.len;
+	empty_sz = stage.memlen - stage.len;
+
+	if (elf_writer_add_section(ew, &shdr, buff, ".program")) {
+		ERROR("Unable to add ELF section: .program\n");
+		elf_writer_destroy(ew);
+		return -1;
+	}
+
+	if (empty_sz != 0) {
+		struct buffer b;
+
+		buffer_init(&b, NULL, NULL, 0);
+		memset(&shdr, 0, sizeof(shdr));
+		shdr.sh_type = SHT_NOBITS;
+		shdr.sh_flags = SHF_WRITE | SHF_ALLOC;
+		shdr.sh_addr = stage.load + stage.len;
+		shdr.sh_size = empty_sz;
+		if (elf_writer_add_section(ew, &shdr, &b, ".empty")) {
+			ERROR("Unable to add ELF section: .empty\n");
+			elf_writer_destroy(ew);
+			return -1;
+		}
+	}
+
+	if (elf_writer_serialize(ew, &elf_out)) {
+		ERROR("Unable to create ELF file from stage.\n");
+		elf_writer_destroy(ew);
+		return -1;
+	}
+
+	/* Flip buffer with the created ELF one. */
+	buffer_delete(buff);
+	*buff = elf_out;
+
+	elf_writer_destroy(ew);
+
+	return 0;
+}
+
+static int cbfs_payload_make_elf(struct buffer *buff, uint32_t arch)
+{
+	Elf64_Ehdr ehdr;
+	Elf64_Shdr shdr;
+	struct cbfs_payload_segment *segs = NULL;
+	struct elf_writer *ew = NULL;
+	struct buffer elf_out;
+	int segments = 0;
+	int retval = -1;
+
+	if (arch == CBFS_ARCHITECTURE_UNKNOWN) {
+		ERROR("You need to specify -m ARCH.\n");
+		goto out;
+	}
+
+	/* Count the number of segments inside buffer */
+	while (true) {
+		uint32_t payload_type = 0;
+
+		struct cbfs_payload_segment *seg;
+
+		seg = buffer_get(buff);
+		payload_type = read_be32(&seg[segments].type);
+
+		if (payload_type == PAYLOAD_SEGMENT_CODE) {
+			segments++;
+		} else if (payload_type == PAYLOAD_SEGMENT_DATA) {
+			segments++;
+		} else if (payload_type == PAYLOAD_SEGMENT_BSS) {
+			segments++;
+		} else if (payload_type == PAYLOAD_SEGMENT_PARAMS) {
+			segments++;
+		} else if (payload_type == PAYLOAD_SEGMENT_ENTRY) {
+			/* The last segment in a payload is always ENTRY as
+			 * specified by the  parse_elf_to_payload() function.
+			 * Therefore there is no need to continue looking for
+			 * segments.*/
+			segments++;
+			break;
+		} else {
+			ERROR("Unknown payload segment type: %x\n",
+					payload_type);
+			goto out;
+		}
+	}
+
+	segs = malloc(segments * sizeof(*segs));
+
+	/* Decode xdr segments */
+	for (int i = 0; i < segments; i++) {
+		struct cbfs_payload_segment *serialized_seg = buffer_get(buff);
+		xdr_get_seg(&segs[i], &serialized_seg[i]);
+	}
+
+	if (cbfs_payload_decompress(segs, buff, segments)) {
+		ERROR("Failed to decompress payload.\n");
+		goto out;
+	}
+
+	if (init_elf_from_arch(&ehdr, arch))
+		goto out;
+
+	ehdr.e_entry = segs[segments-1].load_addr;
+
+	ew = elf_writer_init(&ehdr);
+	if (ew == NULL) {
+		ERROR("Unable to init ELF writer.\n");
+		goto out;
+	}
+
+	for (int i = 0; i < segments; i++) {
+		struct buffer tbuff;
+		size_t empty_sz = 0;
+
+		memset(&shdr, 0, sizeof(shdr));
+		char *name = NULL;
+
+		if (segs[i].type == PAYLOAD_SEGMENT_CODE) {
+			shdr.sh_type = SHT_PROGBITS;
+			shdr.sh_flags = SHF_WRITE | SHF_ALLOC | SHF_EXECINSTR;
+			shdr.sh_addr = segs[i].load_addr;
+			shdr.sh_size = segs[i].len;
+			empty_sz = segs[i].mem_len - segs[i].len;
+			name = strdup(".text");
+			buffer_splice(&tbuff, buff, segs[i].offset,
+				       segs[i].len);
+		} else if (segs[i].type == PAYLOAD_SEGMENT_DATA) {
+			shdr.sh_type = SHT_PROGBITS;
+			shdr.sh_flags = SHF_ALLOC | SHF_WRITE;
+			shdr.sh_addr = segs[i].load_addr;
+			shdr.sh_size = segs[i].len;
+			empty_sz = segs[i].mem_len - segs[i].len;
+			name = strdup(".data");
+			buffer_splice(&tbuff, buff, segs[i].offset,
+				       segs[i].len);
+		} else if (segs[i].type == PAYLOAD_SEGMENT_BSS) {
+			shdr.sh_type = SHT_NOBITS;
+			shdr.sh_flags = SHF_ALLOC | SHF_WRITE;
+			shdr.sh_addr = segs[i].load_addr;
+			shdr.sh_size = segs[i].len;
+			name = strdup(".bss");
+			buffer_splice(&tbuff, buff, 0, 0);
+		} else if (segs[i].type == PAYLOAD_SEGMENT_PARAMS) {
+			shdr.sh_type = SHT_NOTE;
+			shdr.sh_flags = 0;
+			shdr.sh_size = segs[i].len;
+			name = strdup(".note.pinfo");
+			buffer_splice(&tbuff, buff, segs[i].offset,
+				       segs[i].len);
+		} else if (segs[i].type == PAYLOAD_SEGMENT_ENTRY) {
+			break;
+		} else {
+			ERROR("unknown ELF segment type\n");
+			goto out;
+		}
+
+		if (!name) {
+			ERROR("out of memory\n");
+			goto out;
+		}
+
+		if (elf_writer_add_section(ew, &shdr, &tbuff, name)) {
+			ERROR("Unable to add ELF section: %s\n", name);
+			free(name);
+			goto out;
+		}
+		free(name);
+
+		if (empty_sz != 0) {
+			struct buffer b;
+
+			buffer_init(&b, NULL, NULL, 0);
+			memset(&shdr, 0, sizeof(shdr));
+			shdr.sh_type = SHT_NOBITS;
+			shdr.sh_flags = SHF_WRITE | SHF_ALLOC;
+			shdr.sh_addr = segs[i].load_addr + segs[i].len;
+			shdr.sh_size = empty_sz;
+			name = strdup(".empty");
+			if (!name) {
+				ERROR("out of memory\n");
+				goto out;
+			}
+			if (elf_writer_add_section(ew, &shdr, &b, name)) {
+				ERROR("Unable to add ELF section: %s\n", name);
+				free(name);
+				goto out;
+			}
+			free(name);
+		}
+	}
+
+	if (elf_writer_serialize(ew, &elf_out)) {
+		ERROR("Unable to create ELF file from stage.\n");
+		goto out;
+	}
+
+	/* Flip buffer with the created ELF one. */
+	buffer_delete(buff);
+	*buff = elf_out;
+	retval = 0;
+
+out:
+	free(segs);
+	elf_writer_destroy(ew);
+	return retval;
+}
+
+int cbfs_export_entry(struct cbfs_image *image, const char *entry_name,
+		      const char *filename, uint32_t arch, bool do_processing)
+{
+	struct cbfs_file *entry = cbfs_get_entry(image, entry_name);
+	struct buffer buffer;
+	if (!entry) {
+		ERROR("File not found: %s\n", entry_name);
+		return -1;
+	}
+
+	unsigned int compressed_size = ntohl(entry->len);
+	unsigned int decompressed_size = 0;
+	unsigned int compression = cbfs_file_get_compression_info(entry,
+		&decompressed_size);
+	unsigned int buffer_len;
+	decomp_func_ptr decompress;
+
+	if (do_processing) {
+		decompress = decompression_function(compression);
+		if (!decompress) {
+			ERROR("looking up decompression routine failed\n");
+			return -1;
+		}
+		buffer_len = decompressed_size;
+	} else {
+		/* Force nop decompression */
+		decompress = decompression_function(CBFS_COMPRESS_NONE);
+		buffer_len = compressed_size;
+	}
+
+	LOG("Found file %.30s at 0x%x, type %.12s, compressed %d, size %d\n",
+	    entry_name, cbfs_get_entry_addr(image, entry),
+	    get_cbfs_entry_type_name(ntohl(entry->type)), compressed_size,
+	    decompressed_size);
+
+	buffer_init(&buffer, strdup("(cbfs_export_entry)"), NULL, 0);
+	buffer.data = malloc(buffer_len);
+	buffer.size = buffer_len;
+
+	if (decompress(CBFS_SUBHEADER(entry), compressed_size,
+		       buffer.data, buffer.size, NULL)) {
+		ERROR("decompression failed for %s\n", entry_name);
+		buffer_delete(&buffer);
+		return -1;
+	}
+
+	/*
+	 * The stage metadata is never compressed proper for cbfs_stage
+	 * files. The contents of the stage data can be though. Therefore
+	 * one has to do a second pass for stages to potentially decompress
+	 * the stage data to make it more meaningful.
+	 */
+	if (do_processing) {
+		int (*make_elf)(struct buffer *, uint32_t) = NULL;
+		switch (ntohl(entry->type)) {
+		case CBFS_COMPONENT_STAGE:
+			make_elf = cbfs_stage_make_elf;
+			break;
+		case CBFS_COMPONENT_SELF:
+			make_elf = cbfs_payload_make_elf;
+			break;
+		}
+		if (make_elf && make_elf(&buffer, arch)) {
+			ERROR("Failed to write %s into %s.\n",
+			      entry_name, filename);
+			buffer_delete(&buffer);
+			return -1;
+		}
+	}
+
+	if (buffer_write_file(&buffer, filename) != 0) {
+		ERROR("Failed to write %s into %s.\n",
+		      entry_name, filename);
+		buffer_delete(&buffer);
+		return -1;
+	}
+
+	buffer_delete(&buffer);
+	INFO("Successfully dumped the file to: %s\n", filename);
+	return 0;
+}
+
+int cbfs_remove_entry(struct cbfs_image *image, const char *name)
+{
+	struct cbfs_file *entry;
+	entry = cbfs_get_entry(image, name);
+	if (!entry) {
+		ERROR("CBFS file %s not found.\n", name);
+		return -1;
+	}
+	DEBUG("cbfs_remove_entry: Removed %s @ 0x%x\n",
+	      entry->filename, cbfs_get_entry_addr(image, entry));
+	entry->type = htonl(CBFS_COMPONENT_DELETED);
+	cbfs_walk(image, cbfs_merge_empty_entry, NULL);
+	return 0;
+}
+
+int cbfs_print_header_info(struct cbfs_image *image)
+{
+	char *name = strdup(image->buffer.name);
+	assert(image);
+	printf("%s: %zd kB, bootblocksize %d, romsize %d, offset 0x%x\n"
+	       "alignment: %d bytes, architecture: %s\n\n",
+	       basename(name),
+	       image->buffer.size / 1024,
+	       image->header.bootblocksize,
+	       image->header.romsize,
+	       image->header.offset,
+	       image->header.align,
+	       arch_to_string(image->header.architecture));
+	free(name);
+	return 0;
+}
+
+static int cbfs_print_stage_info(struct cbfs_stage *stage, FILE* fp)
+{
+	fprintf(fp,
+		"    %s compression, entry: 0x%" PRIx64 ", load: 0x%" PRIx64 ", "
+		"length: %d/%d\n",
+		lookup_name_by_type(types_cbfs_compression,
+				    stage->compression, "(unknown)"),
+		stage->entry,
+		stage->load,
+		stage->len,
+		stage->memlen);
+	return 0;
+}
+
+static int cbfs_print_decoded_payload_segment_info(
+		struct cbfs_payload_segment *seg, FILE *fp)
+{
+	/* The input (seg) must be already decoded by
+	 * cbfs_decode_payload_segment.
+	 */
+	switch (seg->type) {
+		case PAYLOAD_SEGMENT_CODE:
+		case PAYLOAD_SEGMENT_DATA:
+			fprintf(fp, "    %s (%s compression, offset: 0x%x, "
+				"load: 0x%" PRIx64 ", length: %d/%d)\n",
+				(seg->type == PAYLOAD_SEGMENT_CODE ?
+				 "code " : "data"),
+				lookup_name_by_type(types_cbfs_compression,
+						    seg->compression,
+						    "(unknown)"),
+				seg->offset, seg->load_addr, seg->len,
+				seg->mem_len);
+			break;
+
+		case PAYLOAD_SEGMENT_ENTRY:
+			fprintf(fp, "    entry (0x%" PRIx64 ")\n",
+				seg->load_addr);
+			break;
+
+		case PAYLOAD_SEGMENT_BSS:
+			fprintf(fp, "    BSS (address 0x%016" PRIx64 ", "
+				"length 0x%x)\n",
+				seg->load_addr, seg->len);
+			break;
+
+		case PAYLOAD_SEGMENT_PARAMS:
+			fprintf(fp, "    parameters\n");
+			break;
+
+		default:
+			fprintf(fp, "   0x%x (%s compression, offset: 0x%x, "
+				"load: 0x%" PRIx64 ", length: %d/%d\n",
+				seg->type,
+				lookup_name_by_type(types_cbfs_compression,
+						    seg->compression,
+						    "(unknown)"),
+				seg->offset, seg->load_addr, seg->len,
+				seg->mem_len);
+			break;
+	}
+	return 0;
+}
+
+int cbfs_print_entry_info(struct cbfs_image *image, struct cbfs_file *entry,
+			  void *arg)
+{
+	const char *name = entry->filename;
+	struct cbfs_payload_segment *payload;
+	FILE *fp = (FILE *)arg;
+
+	if (!cbfs_is_valid_entry(image, entry)) {
+		ERROR("cbfs_print_entry_info: Invalid entry at 0x%x\n",
+		      cbfs_get_entry_addr(image, entry));
+		return -1;
+	}
+	if (!fp)
+		fp = stdout;
+
+	unsigned int decompressed_size = 0;
+	unsigned int compression = cbfs_file_get_compression_info(entry,
+		&decompressed_size);
+	const char *compression_name = lookup_name_by_type(
+			types_cbfs_compression, compression, "????");
+
+	if (compression == CBFS_COMPRESS_NONE)
+		fprintf(fp, "%-30s 0x%-8x %-12s %8d %-4s\n",
+			*name ? name : "(empty)",
+			cbfs_get_entry_addr(image, entry),
+			get_cbfs_entry_type_name(ntohl(entry->type)),
+			ntohl(entry->len),
+			compression_name
+			);
+	else
+		fprintf(fp, "%-30s 0x%-8x %-12s %8d %-4s (%d decompressed)\n",
+			*name ? name : "(empty)",
+			cbfs_get_entry_addr(image, entry),
+			get_cbfs_entry_type_name(ntohl(entry->type)),
+			ntohl(entry->len),
+			compression_name,
+			decompressed_size
+			);
+
+	struct cbfs_file_attr_hash *hash = NULL;
+	while ((hash = cbfs_file_get_next_hash(entry, hash)) != NULL) {
+		unsigned int hash_type = ntohl(hash->hash_type);
+		if (hash_type >= CBFS_NUM_SUPPORTED_HASHES) {
+			fprintf(fp, "invalid hash type %d\n", hash_type);
+			break;
+		}
+		size_t hash_len = widths_cbfs_hash[hash_type];
+		char *hash_str = bintohex(hash->hash_data, hash_len);
+		uint8_t local_hash[hash_len];
+		if (vb2_digest_buffer(CBFS_SUBHEADER(entry),
+			ntohl(entry->len), hash_type, local_hash,
+			hash_len) != VB2_SUCCESS) {
+			fprintf(fp, "failed to hash '%s'\n", name);
+			free(hash_str);
+			break;
+		}
+		int valid = memcmp(local_hash, hash->hash_data, hash_len) == 0;
+		const char *valid_str = valid ? "valid" : "invalid";
+
+		fprintf(fp, "    hash %s:%s %s\n",
+			get_hash_attr_name(hash_type),
+			hash_str, valid_str);
+		free(hash_str);
+	}
+
+	if (!verbose)
+		return 0;
+
+	DEBUG(" cbfs_file=0x%x, offset=0x%x, content_address=0x%x+0x%x\n",
+	      cbfs_get_entry_addr(image, entry), ntohl(entry->offset),
+	      cbfs_get_entry_addr(image, entry) + ntohl(entry->offset),
+	      ntohl(entry->len));
+
+	/* note the components of the subheader may be in host order ... */
+	switch (ntohl(entry->type)) {
+		case CBFS_COMPONENT_STAGE:
+			cbfs_print_stage_info((struct cbfs_stage *)
+					      CBFS_SUBHEADER(entry), fp);
+			break;
+
+		case CBFS_COMPONENT_SELF:
+			payload = (struct cbfs_payload_segment *)
+					CBFS_SUBHEADER(entry);
+			while (payload) {
+				struct cbfs_payload_segment seg;
+				cbfs_decode_payload_segment(&seg, payload);
+				cbfs_print_decoded_payload_segment_info(
+						&seg, fp);
+				if (seg.type == PAYLOAD_SEGMENT_ENTRY)
+					break;
+				else
+				payload ++;
+			}
+			break;
+		default:
+			break;
+	}
+	return 0;
+}
+
+static int cbfs_print_parseable_entry_info(struct cbfs_image *image,
+					struct cbfs_file *entry, void *arg)
+{
+	FILE *fp = (FILE *)arg;
+	const char *name;
+	const char *type;
+	size_t offset;
+	size_t metadata_size;
+	size_t data_size;
+	const char *sep = "\t";
+
+	if (!cbfs_is_valid_entry(image, entry)) {
+		ERROR("cbfs_print_entry_info: Invalid entry at 0x%x\n",
+		      cbfs_get_entry_addr(image, entry));
+		return -1;
+	}
+
+	name = entry->filename;
+	if (*name == '\0')
+		name = "(empty)";
+	type = get_cbfs_entry_type_name(ntohl(entry->type)),
+	metadata_size = ntohl(entry->offset);
+	data_size = ntohl(entry->len);
+	offset = cbfs_get_entry_addr(image, entry);
+
+	fprintf(fp, "%s%s", name, sep);
+	fprintf(fp, "0x%zx%s", offset, sep);
+	fprintf(fp, "%s%s", type, sep);
+	fprintf(fp, "0x%zx%s", metadata_size, sep);
+	fprintf(fp, "0x%zx%s", data_size, sep);
+	fprintf(fp, "0x%zx\n", metadata_size + data_size);
+
+	return 0;
+}
+
+int cbfs_print_directory(struct cbfs_image *image)
+{
+	if (cbfs_is_legacy_cbfs(image))
+		cbfs_print_header_info(image);
+	printf("%-30s %-10s %-12s   Size   Comp\n", "Name", "Offset", "Type");
+	cbfs_walk(image, cbfs_print_entry_info, NULL);
+	return 0;
+}
+
+int cbfs_print_parseable_directory(struct cbfs_image *image)
+{
+	size_t i;
+	const char *header[] = {
+		"Name",
+		"Offset",
+		"Type",
+		"Metadata Size",
+		"Data Size",
+		"Total Size",
+	};
+	const char *sep = "\t";
+
+	for (i = 0; i < ARRAY_SIZE(header) - 1; i++)
+		fprintf(stdout, "%s%s", header[i], sep);
+	fprintf(stdout, "%s\n", header[i]);
+	cbfs_walk(image, cbfs_print_parseable_entry_info, stdout);
+	return 0;
+}
+
+int cbfs_merge_empty_entry(struct cbfs_image *image, struct cbfs_file *entry,
+			   unused void *arg)
+{
+	struct cbfs_file *next;
+	uint32_t next_addr = 0;
+
+	/* We don't return here even if this entry is already empty because we
+	   want to merge the empty entries following after it. */
+
+	/* Loop until non-empty entry is found, starting from the current entry.
+	   After the loop, next_addr points to the next non-empty entry. */
+	next = entry;
+	while (ntohl(next->type) == CBFS_COMPONENT_DELETED ||
+			ntohl(next->type) == CBFS_COMPONENT_NULL) {
+		next = cbfs_find_next_entry(image, next);
+		if (!next)
+			break;
+		next_addr = cbfs_get_entry_addr(image, next);
+		if (!cbfs_is_valid_entry(image, next))
+			/* 'next' could be the end of cbfs */
+			break;
+	}
+
+	if (!next_addr)
+		/* Nothing to empty */
+		return 0;
+
+	/* We can return here if we find only a single empty entry.
+	   For simplicity, we just proceed (and make it empty again). */
+
+	/* We're creating one empty entry for combined empty spaces */
+	uint32_t addr = cbfs_get_entry_addr(image, entry);
+	size_t len = next_addr - addr - cbfs_calculate_file_header_size("");
+	DEBUG("join_empty_entry: [0x%x, 0x%x) len=%zu\n", addr, next_addr, len);
+	cbfs_create_empty_entry(entry, CBFS_COMPONENT_NULL, len, "");
+
+	return 0;
+}
+
+int cbfs_walk(struct cbfs_image *image, cbfs_entry_callback callback,
+	      void *arg)
+{
+	int count = 0;
+	struct cbfs_file *entry;
+	for (entry = cbfs_find_first_entry(image);
+	     entry && cbfs_is_valid_entry(image, entry);
+	     entry = cbfs_find_next_entry(image, entry)) {
+		count ++;
+		if (callback(image, entry, arg) != 0)
+			break;
+	}
+	return count;
+}
+
+static int cbfs_header_valid(struct cbfs_header *header)
+{
+	if ((ntohl(header->magic) == CBFS_HEADER_MAGIC) &&
+	    ((ntohl(header->version) == CBFS_HEADER_VERSION1) ||
+	     (ntohl(header->version) == CBFS_HEADER_VERSION2)) &&
+	    (ntohl(header->offset) < ntohl(header->romsize)))
+		return 1;
+	return 0;
+}
+
+struct cbfs_header *cbfs_find_header(char *data, size_t size,
+				     uint32_t forced_offset)
+{
+	size_t offset;
+	int found = 0;
+	int32_t rel_offset;
+	struct cbfs_header *header, *result = NULL;
+
+	if (forced_offset < (size - sizeof(struct cbfs_header))) {
+		/* Check if the forced header is valid. */
+		header = (struct cbfs_header *)(data + forced_offset);
+		if (cbfs_header_valid(header))
+			return header;
+		return NULL;
+	}
+
+	// Try finding relative offset of master header at end of file first.
+	rel_offset = *(int32_t *)(data + size - sizeof(int32_t));
+	offset = size + rel_offset;
+	DEBUG("relative offset: %#zx(-%#zx), offset: %#zx\n",
+	      (size_t)rel_offset, (size_t)-rel_offset, offset);
+
+	if (offset >= size - sizeof(*header) ||
+	    !cbfs_header_valid((struct cbfs_header *)(data + offset))) {
+		// Some use cases append non-CBFS data to the end of the ROM.
+		DEBUG("relative offset seems wrong, scanning whole image...\n");
+		offset = 0;
+	}
+
+	for (; offset + sizeof(*header) < size; offset++) {
+		header = (struct cbfs_header *)(data + offset);
+		if (!cbfs_header_valid(header))
+			continue;
+		if (!found++)
+			result = header;
+	}
+	if (found > 1)
+		// Top-aligned images usually have a working relative offset
+		// field, so this is more likely to happen on bottom-aligned
+		// ones (where the first header is the "outermost" one)
+		WARN("Multiple (%d) CBFS headers found, using the first one.\n",
+		       found);
+	return result;
+}
+
+
+struct cbfs_file *cbfs_find_first_entry(struct cbfs_image *image)
+{
+	assert(image);
+	if (image->has_header)
+		/* header.offset is relative to start of flash, not
+		 * start of region, so use it with the full image.
+		 */
+		return (struct cbfs_file *)
+			(buffer_get_original_backing(&image->buffer) +
+			image->header.offset);
+	else
+		return (struct cbfs_file *)buffer_get(&image->buffer);
+}
+
+struct cbfs_file *cbfs_find_next_entry(struct cbfs_image *image,
+				       struct cbfs_file *entry)
+{
+	uint32_t addr = cbfs_get_entry_addr(image, entry);
+	int align = image->has_header ? image->header.align :
+							CBFS_ENTRY_ALIGNMENT;
+	assert(entry && cbfs_is_valid_entry(image, entry));
+	addr += ntohl(entry->offset) + ntohl(entry->len);
+	addr = align_up(addr, align);
+	return (struct cbfs_file *)(image->buffer.data + addr);
+}
+
+uint32_t cbfs_get_entry_addr(struct cbfs_image *image, struct cbfs_file *entry)
+{
+	assert(image && image->buffer.data && entry);
+	return (int32_t)((char *)entry - image->buffer.data);
+}
+
+int cbfs_is_valid_cbfs(struct cbfs_image *image)
+{
+	return buffer_check_magic(&image->buffer, CBFS_FILE_MAGIC,
+						strlen(CBFS_FILE_MAGIC));
+}
+
+int cbfs_is_legacy_cbfs(struct cbfs_image *image)
+{
+	return image->has_header;
+}
+
+int cbfs_is_valid_entry(struct cbfs_image *image, struct cbfs_file *entry)
+{
+	uint32_t offset = cbfs_get_entry_addr(image, entry);
+
+	if (offset >= image->buffer.size)
+		return 0;
+
+	struct buffer entry_data;
+	buffer_clone(&entry_data, &image->buffer);
+	buffer_seek(&entry_data, offset);
+	return buffer_check_magic(&entry_data, CBFS_FILE_MAGIC,
+						strlen(CBFS_FILE_MAGIC));
+}
+
+struct cbfs_file *cbfs_create_file_header(int type,
+			    size_t len, const char *name)
+{
+	struct cbfs_file *entry = malloc(MAX_CBFS_FILE_HEADER_BUFFER);
+	memset(entry, CBFS_CONTENT_DEFAULT_VALUE, MAX_CBFS_FILE_HEADER_BUFFER);
+	memcpy(entry->magic, CBFS_FILE_MAGIC, sizeof(entry->magic));
+	entry->type = htonl(type);
+	entry->len = htonl(len);
+	entry->attributes_offset = 0;
+	entry->offset = htonl(cbfs_calculate_file_header_size(name));
+	memset(entry->filename, 0, ntohl(entry->offset) - sizeof(*entry));
+	strcpy(entry->filename, name);
+	return entry;
+}
+
+int cbfs_create_empty_entry(struct cbfs_file *entry, int type,
+			    size_t len, const char *name)
+{
+	struct cbfs_file *tmp = cbfs_create_file_header(type, len, name);
+	memcpy(entry, tmp, ntohl(tmp->offset));
+	free(tmp);
+	memset(CBFS_SUBHEADER(entry), CBFS_CONTENT_DEFAULT_VALUE, len);
+	return 0;
+}
+
+struct cbfs_file_attribute *cbfs_file_first_attr(struct cbfs_file *file)
+{
+	/* attributes_offset should be 0 when there is no attribute, but all
+	 * values that point into the cbfs_file header are invalid, too. */
+	if (ntohl(file->attributes_offset) <= sizeof(*file))
+		return NULL;
+
+	/* There needs to be enough space for the file header and one
+	 * attribute header for this to make sense. */
+	if (ntohl(file->offset) <=
+		sizeof(*file) + sizeof(struct cbfs_file_attribute))
+		return NULL;
+
+	return (struct cbfs_file_attribute *)
+		(((uint8_t *)file) + ntohl(file->attributes_offset));
+}
+
+struct cbfs_file_attribute *cbfs_file_next_attr(struct cbfs_file *file,
+	struct cbfs_file_attribute *attr)
+{
+	/* ex falso sequitur quodlibet */
+	if (attr == NULL)
+		return NULL;
+
+	/* Is there enough space for another attribute? */
+	if ((uint8_t *)attr + ntohl(attr->len) +
+		sizeof(struct cbfs_file_attribute) >
+		(uint8_t *)file + ntohl(file->offset))
+		return NULL;
+
+	struct cbfs_file_attribute *next = (struct cbfs_file_attribute *)
+		(((uint8_t *)attr) + ntohl(attr->len));
+	/* If any, "unused" attributes must come last. */
+	if (ntohl(next->tag) == CBFS_FILE_ATTR_TAG_UNUSED)
+		return NULL;
+	if (ntohl(next->tag) == CBFS_FILE_ATTR_TAG_UNUSED2)
+		return NULL;
+
+	return next;
+}
+
+struct cbfs_file_attribute *cbfs_add_file_attr(struct cbfs_file *header,
+					       uint32_t tag,
+					       uint32_t size)
+{
+	struct cbfs_file_attribute *attr, *next;
+	next = cbfs_file_first_attr(header);
+	do {
+		attr = next;
+		next = cbfs_file_next_attr(header, attr);
+	} while (next != NULL);
+	uint32_t header_size = ntohl(header->offset) + size;
+	if (header_size > MAX_CBFS_FILE_HEADER_BUFFER) {
+		DEBUG("exceeding allocated space for cbfs_file headers");
+		return NULL;
+	}
+	/* attr points to the last valid attribute now.
+	 * If NULL, we have to create the first one. */
+	if (attr == NULL) {
+		/* New attributes start where the header ends.
+		 * header->offset is later set to accommodate the
+		 * additional structure.
+		 * No endianness translation necessary here, because both
+		 * fields are encoded the same way. */
+		header->attributes_offset = header->offset;
+		attr = (struct cbfs_file_attribute *)
+			(((uint8_t *)header) +
+			ntohl(header->attributes_offset));
+	} else {
+		attr = (struct cbfs_file_attribute *)
+			(((uint8_t *)attr) +
+			ntohl(attr->len));
+	}
+	header->offset = htonl(header_size);
+	memset(attr, CBFS_CONTENT_DEFAULT_VALUE, size);
+	attr->tag = htonl(tag);
+	attr->len = htonl(size);
+	return attr;
+}
+
+int cbfs_add_file_hash(struct cbfs_file *header, struct buffer *buffer,
+	enum vb2_hash_algorithm hash_type)
+{
+	uint32_t hash_index = hash_type;
+
+	if (hash_index >= CBFS_NUM_SUPPORTED_HASHES)
+		return -1;
+
+	unsigned hash_size = widths_cbfs_hash[hash_type];
+	if (hash_size == 0)
+		return -1;
+
+	struct cbfs_file_attr_hash *attrs =
+		(struct cbfs_file_attr_hash *)cbfs_add_file_attr(header,
+			CBFS_FILE_ATTR_TAG_HASH,
+			sizeof(struct cbfs_file_attr_hash) + hash_size);
+
+	if (attrs == NULL)
+		return -1;
+
+	attrs->hash_type = htonl(hash_type);
+	if (vb2_digest_buffer(buffer_get(buffer), buffer_size(buffer),
+		hash_type, attrs->hash_data, hash_size) != VB2_SUCCESS)
+		return -1;
+
+	return 0;
+}
+
+/* Finds a place to hold whole data in same memory page. */
+static int is_in_same_page(uint32_t start, uint32_t size, uint32_t page)
+{
+	if (!page)
+		return 1;
+	return (start / page) == (start + size - 1) / page;
+}
+
+/* Tests if data can fit in a range by given offset:
+ *  start ->| metadata_size | offset (+ size) |<- end
+ */
+static int is_in_range(size_t start, size_t end, size_t metadata_size,
+		       size_t offset, size_t size)
+{
+	return (offset >= start + metadata_size && offset + size <= end);
+}
+
+static size_t absolute_align(const struct cbfs_image *image, size_t val,
+				size_t align)
+{
+	const size_t region_offset = buffer_offset(&image->buffer);
+	/* To perform alignment on absolute address, take the region offset */
+	/* of the image into account.					    */
+	return align_up(val + region_offset, align) - region_offset;
+
+}
+
+int32_t cbfs_locate_entry(struct cbfs_image *image, size_t size,
+			  size_t page_size, size_t align, size_t metadata_size)
+{
+	struct cbfs_file *entry;
+	size_t need_len;
+	size_t addr, addr_next, addr2, addr3, offset;
+
+	/* Default values: allow fitting anywhere in ROM. */
+	if (!page_size)
+		page_size = image->has_header ? image->header.romsize :
+							image->buffer.size;
+	if (!align)
+		align = 1;
+
+	if (size > page_size)
+		ERROR("Input file size (%zd) greater than page size (%zd).\n",
+		      size, page_size);
+
+	size_t image_align = image->has_header ? image->header.align :
+							CBFS_ENTRY_ALIGNMENT;
+	if (page_size % image_align)
+		WARN("%s: Page size (%#zx) not aligned with CBFS image (%#zx).\n",
+		     __func__, page_size, image_align);
+
+	need_len = metadata_size + size;
+
+	// Merge empty entries to build get max available space.
+	cbfs_walk(image, cbfs_merge_empty_entry, NULL);
+
+	/* Three cases of content location on memory page:
+	 * case 1.
+	 *          |  PAGE 1  |   PAGE 2  |
+	 *          |     <header><content>| Fit. Return start of content.
+	 *
+	 * case 2.
+	 *          |  PAGE 1  |   PAGE 2  |
+	 *          | <header><content>    | Fits when we shift content to align
+	 *  shift-> |  <header>|<content>  | at starting of PAGE 2.
+	 *
+	 * case 3. (large content filling whole page)
+	 *  | PAGE 1 |  PAGE 2  | PAGE 3 |
+	 *  |  <header>< content >       | Can't fit. If we shift content to
+	 *  |trial-> <header>< content > | PAGE 2, header can't fit in free
+	 *  |  shift->  <header><content> space, so we must use PAGE 3.
+	 *
+	 * The returned address can be then used as "base-address" (-b) in add-*
+	 * commands (will be re-calculated and positioned by cbfs_add_entry_at).
+	 * For stage targets, the address is also used to re-link stage before
+	 * being added into CBFS.
+	 */
+	for (entry = cbfs_find_first_entry(image);
+	     entry && cbfs_is_valid_entry(image, entry);
+	     entry = cbfs_find_next_entry(image, entry)) {
+
+		uint32_t type = ntohl(entry->type);
+		if (type != CBFS_COMPONENT_NULL)
+			continue;
+
+		addr = cbfs_get_entry_addr(image, entry);
+		addr_next = cbfs_get_entry_addr(image, cbfs_find_next_entry(
+				image, entry));
+		if (addr_next - addr < need_len)
+			continue;
+
+		offset = absolute_align(image, addr + metadata_size, align);
+		if (is_in_same_page(offset, size, page_size) &&
+		    is_in_range(addr, addr_next, metadata_size, offset, size)) {
+			DEBUG("cbfs_locate_entry: FIT (PAGE1).");
+			return offset;
+		}
+
+		addr2 = align_up(addr, page_size);
+		offset = absolute_align(image, addr2, align);
+		if (is_in_range(addr, addr_next, metadata_size, offset, size)) {
+			DEBUG("cbfs_locate_entry: OVERLAP (PAGE2).");
+			return offset;
+		}
+
+		/* Assume page_size >= metadata_size so adding one page will
+		 * definitely provide the space for header. */
+		assert(page_size >= metadata_size);
+		addr3 = addr2 + page_size;
+		offset = absolute_align(image, addr3, align);
+		if (is_in_range(addr, addr_next, metadata_size, offset, size)) {
+			DEBUG("cbfs_locate_entry: OVERLAP+ (PAGE3).");
+			return offset;
+		}
+	}
+	return -1;
+}
diff --git a/tools/cbfstool/cbfs_image.h b/tools/cbfstool/cbfs_image.h
new file mode 100644
index 0000000000..1f8b162d7c
--- /dev/null
+++ b/tools/cbfstool/cbfs_image.h
@@ -0,0 +1,207 @@
+/*
+ * CBFS Image Manipulation
+ *
+ * Copyright (C) 2013 The Chromium OS Authors. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __CBFS_IMAGE_H
+#define __CBFS_IMAGE_H
+#include "common.h"
+#include "cbfs.h"
+
+/* CBFS image processing */
+
+struct cbfs_image {
+	struct buffer buffer;
+	/* An image has a header iff it's a legacy CBFS. */
+	bool has_header;
+	/* Only meaningful if has_header is selected. */
+	struct cbfs_header header;
+};
+
+/* Given the string name of a compression algorithm, return the corresponding
+ * enum comp_algo if it's supported, or a number < 0 otherwise. */
+int cbfs_parse_comp_algo(const char *name);
+
+/* Given the string name of a hash algorithm, return the corresponding
+ * id if it's supported, or a number < 0 otherwise. */
+int cbfs_parse_hash_algo(const char *name);
+
+/* Given a pointer, serialize the header from host-native byte format
+ * to cbfs format, i.e. big-endian. */
+void cbfs_put_header(void *dest, const struct cbfs_header *header);
+/* Or deserialize into host-native format */
+void cbfs_get_header(struct cbfs_header *header, void *src);
+
+/* Populates a CBFS with a single empty entry filling all available space
+ * (entries_size bytes). If image's header field is already present, its
+ * contents will be used to place an empty entry of the requested length at the
+ * appropriate position in the existing buffer; otherwise, if not has_header,
+ * the first entries_size bytes of buffer will be filled exclusively with the
+ * single empty entry (and no CBFS master header).
+ * Returns 0 on success, otherwise nonzero. */
+int cbfs_image_create(struct cbfs_image *image, size_t entries_size);
+
+/* Creates an empty CBFS image by given size, and description to its content
+ * (bootblock, align, header location, starting offset of CBFS entries).
+ * The output image will contain a valid cbfs_header, with one cbfs_file
+ * entry with type CBFS_COMPONENT_NULL, with max available size.
+ * Only call this if you want a legacy CBFS with a master header.
+ * Returns 0 on success, otherwise nonzero. */
+int cbfs_legacy_image_create(struct cbfs_image *image,
+			      uint32_t arch,
+			      uint32_t align,
+			      struct buffer *bootblock,
+			      uint32_t bootblock_offset,
+			      uint32_t header_offset,
+			      uint32_t entries_offset);
+
+/* Constructs a cbfs_image from a buffer. The resulting image contains a shallow
+ * copy of the buffer; releasing either one is the legal way to clean up after
+ * both of them at once. Always produces a cbfs_image, but...
+ * Returns 0 if it contains a valid CBFS, non-zero if it's unrecognized data. */
+int cbfs_image_from_buffer(struct cbfs_image *out, struct buffer *in,
+			   uint32_t offset);
+
+/* Create a duplicate CBFS image. Returns 0 on success, otherwise non-zero.
+ * Will not succeed on new-style images without a master header. */
+int cbfs_copy_instance(struct cbfs_image *image, struct buffer *dst);
+
+/* Compact a fragmented CBFS image by placing all the non-empty files at the
+ * beginning of the image. Returns 0 on success, otherwise non-zero.  */
+int cbfs_compact_instance(struct cbfs_image *image);
+
+/* Expand a CBFS image inside an fmap region to the entire region's space.
+   Returns 0 on success, otherwise non-zero. */
+int cbfs_expand_to_region(struct buffer *region);
+
+/* Truncate a CBFS by removing a trailing "empty" file if it exists.
+   Returns 0 on success, otherwise non-zero and passes the CBFS' remaining
+   size in the size argument. */
+int cbfs_truncate_space(struct buffer *region, uint32_t *size);
+
+/* Releases the CBFS image. Returns 0 on success, otherwise non-zero. */
+int cbfs_image_delete(struct cbfs_image *image);
+
+/* Returns a pointer to entry by name, or NULL if name is not found. */
+struct cbfs_file *cbfs_get_entry(struct cbfs_image *image, const char *name);
+
+/* Exports an entry to external file. If do_processing is true, file contents
+ * will be decompressed, and also turned into an ELF if appropriate.
+ * Returns 0 on success, otherwise (ex, not found) non-zero. */
+int cbfs_export_entry(struct cbfs_image *image, const char *entry_name,
+		      const char *filename, uint32_t arch, bool do_processing);
+
+/* Adds an entry to CBFS image by given name and type. If content_offset is
+ * non-zero, try to align "content" (CBFS_SUBHEADER(p)) at content_offset.
+ * Never pass this function a top-aligned address: convert it to an offset.
+ * Returns 0 on success, otherwise non-zero. */
+int cbfs_add_entry(struct cbfs_image *image, struct buffer *buffer,
+		   uint32_t content_offset, struct cbfs_file *header);
+
+/* Removes an entry from CBFS image. Returns 0 on success, otherwise non-zero. */
+int cbfs_remove_entry(struct cbfs_image *image, const char *name);
+
+/* Create a new cbfs file header structure to work with.
+   Returns newly allocated memory that the caller needs to free after use. */
+struct cbfs_file *cbfs_create_file_header(int type, size_t len,
+	const char *name);
+
+/* Initializes a new empty (type = NULL) entry with size and name in CBFS image.
+ * Returns 0 on success, otherwise (ex, not found) non-zero. */
+int cbfs_create_empty_entry(struct cbfs_file *entry, int type,
+			    size_t len, const char *name);
+
+/* Finds a location to put given content by specified criteria:
+ *  "page_size" limits the content to fit on same memory page, and
+ *  "align" specifies starting address alignment.
+ * Returns a valid offset, or -1 on failure. */
+int32_t cbfs_locate_entry(struct cbfs_image *image, size_t size,
+			  size_t page_size, size_t align, size_t metadata_size);
+
+/* Callback function used by cbfs_walk.
+ * Returns 0 on success, or non-zero to stop further iteration. */
+typedef int (*cbfs_entry_callback)(struct cbfs_image *image,
+				   struct cbfs_file *file,
+				   void *arg);
+
+/* Iterates through all entries in CBFS image, and invoke with callback.
+ * Stops if callback returns non-zero values.
+ * Returns number of entries invoked. */
+int cbfs_walk(struct cbfs_image *image, cbfs_entry_callback callback, void *arg);
+
+/* Primitive CBFS utilities */
+
+/* Returns a pointer to the only valid CBFS header in give buffer, otherwise
+ * NULL (including when multiple headers were found). If there is a X86 ROM
+ * style signature (pointer at 0xfffffffc) found in ROM, it will be selected as
+ * the only header.*/
+struct cbfs_header *cbfs_find_header(char *data, size_t size,
+				     uint32_t forced_offset);
+
+/* Returns the first cbfs_file entry in CBFS image by CBFS header (no matter if
+ * the entry has valid content or not), otherwise NULL. */
+struct cbfs_file *cbfs_find_first_entry(struct cbfs_image *image);
+
+/* Returns next cbfs_file entry (no matter if its content is valid or not), or
+ * NULL on failure. */
+struct cbfs_file *cbfs_find_next_entry(struct cbfs_image *image,
+				       struct cbfs_file *entry);
+
+/* Returns ROM address (offset) of entry.
+ * This is different from entry->offset (pointer to content). */
+uint32_t cbfs_get_entry_addr(struct cbfs_image *image, struct cbfs_file *entry);
+
+/* Returns 1 if valid new-format CBFS (without a master header), otherwise 0. */
+int cbfs_is_valid_cbfs(struct cbfs_image *image);
+
+/* Returns 1 if valid legacy CBFS (with a master header), otherwise 0. */
+int cbfs_is_legacy_cbfs(struct cbfs_image *image);
+
+/* Returns 1 if entry has valid data (by checking magic number), otherwise 0. */
+int cbfs_is_valid_entry(struct cbfs_image *image, struct cbfs_file *entry);
+
+/* Print CBFS component information. */
+int cbfs_print_directory(struct cbfs_image *image);
+int cbfs_print_parseable_directory(struct cbfs_image *image);
+int cbfs_print_header_info(struct cbfs_image *image);
+int cbfs_print_entry_info(struct cbfs_image *image, struct cbfs_file *entry,
+			  void *arg);
+
+/* Merge empty entries starting from given entry.
+ * Returns 0 on success, otherwise non-zero. */
+int cbfs_merge_empty_entry(struct cbfs_image *image, struct cbfs_file *entry,
+			   void *arg);
+
+/* Returns the size of a cbfs file header with no extensions */
+size_t cbfs_calculate_file_header_size(const char *name);
+
+/* Given a cbfs_file, return the first file attribute, or NULL. */
+struct cbfs_file_attribute *cbfs_file_first_attr(struct cbfs_file *file);
+
+/* Given a cbfs_file and a cbfs_file_attribute, return the attribute that
+ * follows it, or NULL. */
+struct cbfs_file_attribute *cbfs_file_next_attr(struct cbfs_file *file,
+	struct cbfs_file_attribute *attr);
+
+/* Adds to header a new extended attribute tagged 'tag', sized 'size'.
+ * Returns pointer to the new attribute, or NULL on error. */
+struct cbfs_file_attribute *cbfs_add_file_attr(struct cbfs_file *header,
+					       uint32_t tag,
+					       uint32_t size);
+
+/* Adds an extended attribute to header, containing a hash of buffer's data of
+ * the type specified by hash_type.
+ * Returns 0 on success, -1 on error. */
+int cbfs_add_file_hash(struct cbfs_file *header, struct buffer *buffer,
+	enum vb2_hash_algorithm hash_type);
+#endif
diff --git a/tools/cbfstool/cbfs_sections.h b/tools/cbfstool/cbfs_sections.h
new file mode 100644
index 0000000000..3526f8d94c
--- /dev/null
+++ b/tools/cbfstool/cbfs_sections.h
@@ -0,0 +1,55 @@
+/*
+ * fmap_sections.h, track which sections of the image will contain CBFSes
+ *
+ * Copyright (C) 2015 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef CBFS_SECTIONS_H_
+#define CBFS_SECTIONS_H_
+
+#include "fmd.h"
+
+#include <stdbool.h>
+
+#define SECTION_NAME_FMAP		"FMAP"
+#define SECTION_NAME_PRIMARY_CBFS	"COREBOOT"
+
+#define SECTION_ANNOTATION_CBFS		"CBFS"
+
+typedef const struct descriptor_node *cbfs_section_iterator_t;
+
+/** @return Iterator pointing to first CBFS section, or NULL if none exist */
+cbfs_section_iterator_t cbfs_sections_iterator(void);
+
+/**
+ * Advance iterator to point to the next CBFS section.
+ * If it was already pointing to the last such section, it will be set to NULL.
+ *
+ * @param it (Non-NULL) pointer to (possibly NULL) iterator to be updated
+ * @return   Whether it was successfully advanced (wasn't already NULL)
+ */
+bool cbfs_sections_iterator_advance(cbfs_section_iterator_t *it);
+
+/**
+ * @param it Iterator, which must currently be non-NULL
+ * @return   Section to which it points
+ */
+const struct flashmap_descriptor *cbfs_sections_iterator_deref(
+						cbfs_section_iterator_t it);
+
+/** @return Whether a section named SECTION_NAME_PRIMARY_CBFS is in the list. */
+bool cbfs_sections_primary_cbfs_accounted_for(void);
+
+/** Reclaim the space used to store knowledge of which sections are CBFSes. */
+void cbfs_sections_cleanup(void);
+
+#endif
diff --git a/tools/cbfstool/cbfstool.c b/tools/cbfstool/cbfstool.c
new file mode 100644
index 0000000000..54b5f6549c
--- /dev/null
+++ b/tools/cbfstool/cbfstool.c
@@ -0,0 +1,1817 @@
+/*
+ * cbfstool, CLI utility for CBFS file manipulation
+ *
+ * Copyright (C) 2009 coresystems GmbH
+ *                 written by Patrick Georgi <patrick.georgi@coresystems.de>
+ * Copyright (C) 2012 Google, Inc.
+ * Copyright (C) 2016 Siemens AG
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <strings.h>
+#include <ctype.h>
+#include <unistd.h>
+#include <getopt.h>
+#include "common.h"
+#include "cbfs.h"
+#include "cbfs_image.h"
+#include "cbfs_sections.h"
+#include "elfparsing.h"
+#include "partitioned_file.h"
+#include <commonlib/fsp.h>
+#include <commonlib/endian.h>
+#include <commonlib/helpers.h>
+
+#define SECTION_WITH_FIT_TABLE	"BOOTBLOCK"
+
+struct command {
+	const char *name;
+	const char *optstring;
+	int (*function) (void);
+	// Whether to populate param.image_region before invoking function
+	bool accesses_region;
+	// This set to true means two things:
+	// - in case of a command operating on a region, the region's contents
+	//   will be written back to image_file at the end
+	// - write access to the file is required
+	bool modifies_region;
+};
+
+static struct param {
+	partitioned_file_t *image_file;
+	struct buffer *image_region;
+	const char *name;
+	const char *filename;
+	const char *fmap;
+	const char *region_name;
+	const char *source_region;
+	const char *bootblock;
+	const char *ignore_section;
+	const char *ucode_region;
+	uint64_t u64val;
+	uint32_t type;
+	uint32_t baseaddress;
+	uint32_t baseaddress_assigned;
+	uint32_t loadaddress;
+	uint32_t headeroffset;
+	uint32_t headeroffset_assigned;
+	uint32_t entrypoint;
+	uint32_t size;
+	uint32_t alignment;
+	uint32_t pagesize;
+	uint32_t cbfsoffset;
+	uint32_t cbfsoffset_assigned;
+	uint32_t arch;
+	uint32_t padding;
+	uint32_t topswap_size;
+	bool u64val_assigned;
+	bool fill_partial_upward;
+	bool fill_partial_downward;
+	bool show_immutable;
+	bool stage_xip;
+	bool autogen_attr;
+	bool machine_parseable;
+	bool unprocessed;
+	enum comp_algo compression;
+	int precompression;
+	enum vb2_hash_algorithm hash;
+	/* For linux payloads */
+	char *initrd;
+	char *cmdline;
+	int force;
+} param = {
+	/* All variables not listed are initialized as zero. */
+	.arch = CBFS_ARCHITECTURE_UNKNOWN,
+	.compression = CBFS_COMPRESS_NONE,
+	.hash = VB2_HASH_INVALID,
+	.headeroffset = ~0,
+	.region_name = SECTION_NAME_PRIMARY_CBFS,
+	.u64val = -1,
+};
+
+static bool region_is_flashmap(const char *region)
+{
+	return partitioned_file_region_check_magic(param.image_file, region,
+					FMAP_SIGNATURE, strlen(FMAP_SIGNATURE));
+}
+
+/* @return Same as cbfs_is_valid_cbfs(), but for a named region. */
+static bool region_is_modern_cbfs(const char *region)
+{
+	return partitioned_file_region_check_magic(param.image_file, region,
+				CBFS_FILE_MAGIC, strlen(CBFS_FILE_MAGIC));
+}
+
+/*
+ * Converts between offsets from the start of the specified image region and
+ * "top-aligned" offsets from the top of the entire boot media. See comment
+ * below for convert_to_from_top_aligned() about forming addresses.
+ */
+static unsigned convert_to_from_absolute_top_aligned(
+		const struct buffer *region, unsigned offset)
+{
+	assert(region);
+
+	size_t image_size = partitioned_file_total_size(param.image_file);
+
+	return image_size - region->offset - offset;
+}
+
+/*
+ * Converts between offsets from the start of the specified image region and
+ * "top-aligned" offsets from the top of the image region. Works in either
+ * direction: pass in one type of offset and receive the other type.
+ * N.B. A top-aligned offset is always a positive number, and should not be
+ * confused with a top-aligned *address*, which is its arithmetic inverse. */
+static unsigned convert_to_from_top_aligned(const struct buffer *region,
+								unsigned offset)
+{
+	assert(region);
+
+	/* Cover the situation where a negative base address is given by the
+	 * user. Callers of this function negate it, so it'll be a positive
+	 * number smaller than the region.
+	 */
+	if ((offset > 0) && (offset < region->size)) {
+		return region->size - offset;
+	}
+
+	return convert_to_from_absolute_top_aligned(region, offset);
+}
+
+static int do_cbfs_locate(int32_t *cbfs_addr, size_t metadata_size,
+			size_t data_size)
+{
+	if (!param.filename) {
+		ERROR("You need to specify -f/--filename.\n");
+		return 1;
+	}
+
+	if (!param.name) {
+		ERROR("You need to specify -n/--name.\n");
+		return 1;
+	}
+
+	struct cbfs_image image;
+	if (cbfs_image_from_buffer(&image, param.image_region,
+							param.headeroffset))
+		return 1;
+
+	if (cbfs_get_entry(&image, param.name))
+		WARN("'%s' already in CBFS.\n", param.name);
+
+	if (!data_size) {
+		struct buffer buffer;
+		if (buffer_from_file(&buffer, param.filename) != 0) {
+			ERROR("Cannot load %s.\n", param.filename);
+			return 1;
+		}
+		data_size = buffer.size;
+		buffer_delete(&buffer);
+	}
+
+	DEBUG("File size is %zd (0x%zx)\n", data_size, data_size);
+
+	/* Include cbfs_file size along with space for with name. */
+	metadata_size += cbfs_calculate_file_header_size(param.name);
+	/* Adjust metadata_size if additional attributes were added */
+	if (param.autogen_attr) {
+		if (param.alignment)
+			metadata_size += sizeof(struct cbfs_file_attr_align);
+		if (param.baseaddress_assigned || param.stage_xip)
+			metadata_size += sizeof(struct cbfs_file_attr_position);
+	}
+
+	/* Take care of the hash attribute if it is used */
+	if (param.hash != VB2_HASH_INVALID)
+		metadata_size += sizeof(struct cbfs_file_attr_hash);
+
+	int32_t address = cbfs_locate_entry(&image, data_size, param.pagesize,
+						param.alignment, metadata_size);
+
+	if (address == -1) {
+		ERROR("'%s' can't fit in CBFS for page-size %#x, align %#x.\n",
+		      param.name, param.pagesize, param.alignment);
+		return 1;
+	}
+
+	*cbfs_addr = address;
+	return 0;
+}
+
+typedef int (*convert_buffer_t)(struct buffer *buffer, uint32_t *offset,
+	struct cbfs_file *header);
+
+static int cbfs_add_integer_component(const char *name,
+			      uint64_t u64val,
+			      uint32_t offset,
+			      uint32_t headeroffset) {
+	struct cbfs_image image;
+	struct cbfs_file *header = NULL;
+	struct buffer buffer;
+	int i, ret = 1;
+
+	if (!name) {
+		ERROR("You need to specify -n/--name.\n");
+		return 1;
+	}
+
+	if (buffer_create(&buffer, 8, name) != 0)
+		return 1;
+
+	for (i = 0; i < 8; i++)
+		buffer.data[i] = (u64val >> i*8) & 0xff;
+
+	if (cbfs_image_from_buffer(&image, param.image_region, headeroffset)) {
+		ERROR("Selected image region is not a CBFS.\n");
+		goto done;
+	}
+
+	if (cbfs_get_entry(&image, name)) {
+		ERROR("'%s' already in ROM image.\n", name);
+		goto done;
+	}
+
+	if (IS_TOP_ALIGNED_ADDRESS(offset))
+		offset = convert_to_from_top_aligned(param.image_region,
+								-offset);
+
+	header = cbfs_create_file_header(CBFS_COMPONENT_RAW,
+		buffer.size, name);
+	if (cbfs_add_entry(&image, &buffer, offset, header) != 0) {
+		ERROR("Failed to add %llu into ROM image as '%s'.\n",
+					(long long unsigned)u64val, name);
+		goto done;
+	}
+
+	ret = 0;
+
+done:
+	free(header);
+	buffer_delete(&buffer);
+	return ret;
+}
+
+static int is_valid_topswap(void)
+{
+	switch (param.topswap_size) {
+	case (64 * KiB):
+	case (128 * KiB):
+	case (256 * KiB):
+	case (512 * KiB):
+	case (1 * MiB):
+		break;
+	default:
+		ERROR("Invalid topswap_size %d, topswap can be 64K|128K|256K|512K|1M\n",
+							param.topswap_size);
+		return 0;
+	}
+	return 1;
+}
+
+static void fill_header_offset(void *location, uint32_t offset)
+{
+	// TODO: When we have a BE target, we'll need to store this as BE
+	write_le32(location, offset);
+}
+
+static int update_master_header_loc_topswap(struct cbfs_image *image,
+				void *h_loc, uint32_t header_offset)
+{
+	struct cbfs_file *entry;
+	void *ts_h_loc = h_loc;
+
+	entry = cbfs_get_entry(image, "bootblock");
+	if (entry == NULL) {
+		ERROR("Bootblock not in ROM image?!?\n");
+		return 1;
+	}
+
+	/*
+	 * Check if the existing topswap boundary matches with
+	 * the one provided.
+	 */
+	if (param.topswap_size != ntohl(entry->len)/2) {
+		ERROR("Top swap boundary does not match\n");
+		return 1;
+	}
+
+	ts_h_loc -= param.topswap_size;
+	fill_header_offset(ts_h_loc, header_offset);
+
+	return 0;
+}
+
+static int cbfs_add_master_header(void)
+{
+	const char * const name = "cbfs master header";
+	struct cbfs_image image;
+	struct cbfs_file *header = NULL;
+	struct buffer buffer;
+	int ret = 1;
+	size_t offset;
+	size_t size;
+	void *h_loc;
+
+	if (cbfs_image_from_buffer(&image, param.image_region,
+		param.headeroffset)) {
+		ERROR("Selected image region is not a CBFS.\n");
+		return 1;
+	}
+
+	if (cbfs_get_entry(&image, name)) {
+		ERROR("'%s' already in ROM image.\n", name);
+		return 1;
+	}
+
+	if (buffer_create(&buffer, sizeof(struct cbfs_header), name) != 0)
+		return 1;
+
+	struct cbfs_header *h = (struct cbfs_header *)buffer.data;
+	h->magic = htonl(CBFS_HEADER_MAGIC);
+	h->version = htonl(CBFS_HEADER_VERSION);
+	/* The 4 bytes are left out for two reasons:
+	 * 1. the cbfs master header pointer resides there
+	 * 2. some cbfs implementations assume that an image that resides
+	 *    below 4GB has a bootblock and get confused when the end of the
+	 *    image is at 4GB == 0.
+	 */
+	h->bootblocksize = htonl(4);
+	h->align = htonl(CBFS_ENTRY_ALIGNMENT);
+	/* The offset and romsize fields within the master header are absolute
+	 * values within the boot media. As such, romsize needs to relfect
+	 * the end 'offset' for a CBFS. To achieve that the current buffer
+	 * representing the CBFS region's size is added to the offset of
+	 * the region within a larger image.
+	 */
+	offset = buffer_get(param.image_region) -
+		buffer_get_original_backing(param.image_region);
+	size = buffer_size(param.image_region);
+	h->romsize = htonl(size + offset);
+	h->offset = htonl(offset);
+	h->architecture = htonl(CBFS_ARCHITECTURE_UNKNOWN);
+
+	header = cbfs_create_file_header(CBFS_COMPONENT_CBFSHEADER,
+		buffer_size(&buffer), name);
+	if (cbfs_add_entry(&image, &buffer, 0, header) != 0) {
+		ERROR("Failed to add cbfs master header into ROM image.\n");
+		goto done;
+	}
+
+	struct cbfs_file *entry;
+	if ((entry = cbfs_get_entry(&image, name)) == NULL) {
+		ERROR("'%s' not in ROM image?!?\n", name);
+		goto done;
+	}
+
+	uint32_t header_offset = CBFS_SUBHEADER(entry) -
+		buffer_get(&image.buffer);
+	header_offset = -(buffer_size(&image.buffer) - header_offset);
+
+	h_loc = (void *)(buffer_get(&image.buffer) +
+				buffer_size(&image.buffer) - 4);
+	fill_header_offset(h_loc, header_offset);
+	/*
+	 * If top swap present, update the header
+	 * location in secondary bootblock
+	 */
+	if (param.topswap_size) {
+		if (update_master_header_loc_topswap(&image, h_loc,
+							header_offset))
+			return 1;
+	}
+
+	ret = 0;
+
+done:
+	free(header);
+	buffer_delete(&buffer);
+	return ret;
+}
+
+static int add_topswap_bootblock(struct buffer *buffer, uint32_t *offset)
+{
+	size_t bb_buf_size = buffer_size(buffer);
+
+	if (bb_buf_size > param.topswap_size) {
+		ERROR("Bootblock bigger than the topswap boundary\n");
+		ERROR("size = %zd, ts = %d\n", bb_buf_size,
+							param.topswap_size);
+		return 1;
+	}
+
+	/*
+	 * Allocate topswap_size*2 bytes for bootblock to
+	 * accommodate the second bootblock.
+	 */
+	struct buffer new_bootblock, bb1, bb2;
+	if (buffer_create(&new_bootblock, 2 * param.topswap_size,
+							buffer->name))
+		return 1;
+
+	buffer_splice(&bb1, &new_bootblock, param.topswap_size - bb_buf_size,
+							bb_buf_size);
+	buffer_splice(&bb2, &new_bootblock,
+				buffer_size(&new_bootblock) - bb_buf_size,
+							bb_buf_size);
+
+	/* Copy to first bootblock */
+	memcpy(buffer_get(&bb1), buffer_get(buffer), bb_buf_size);
+	/* Copy to second bootblock */
+	memcpy(buffer_get(&bb2), buffer_get(buffer), bb_buf_size);
+
+	buffer_delete(buffer);
+	buffer_clone(buffer, &new_bootblock);
+
+	 /* Update the location (offset) of bootblock in the region */
+	*offset = convert_to_from_top_aligned(param.image_region,
+							buffer_size(buffer));
+
+	return 0;
+}
+
+static int cbfs_add_component(const char *filename,
+			      const char *name,
+			      uint32_t type,
+			      uint32_t offset,
+			      uint32_t headeroffset,
+			      convert_buffer_t convert)
+{
+	if (!filename) {
+		ERROR("You need to specify -f/--filename.\n");
+		return 1;
+	}
+
+	if (!name) {
+		ERROR("You need to specify -n/--name.\n");
+		return 1;
+	}
+
+	if (type == 0) {
+		ERROR("You need to specify a valid -t/--type.\n");
+		return 1;
+	}
+
+	struct cbfs_image image;
+	if (cbfs_image_from_buffer(&image, param.image_region, headeroffset))
+		return 1;
+
+	if (cbfs_get_entry(&image, name)) {
+		ERROR("'%s' already in ROM image.\n", name);
+		return 1;
+	}
+
+	struct buffer buffer;
+	if (buffer_from_file(&buffer, filename) != 0) {
+		ERROR("Could not load file '%s'.\n", filename);
+		return 1;
+	}
+
+	/*
+	 * Check if Intel CPU topswap is specified this will require a
+	 * second bootblock to be added.
+	 */
+	if (type == CBFS_COMPONENT_BOOTBLOCK && param.topswap_size)
+		if (add_topswap_bootblock(&buffer, &offset))
+			return 1;
+
+	struct cbfs_file *header =
+		cbfs_create_file_header(type, buffer.size, name);
+
+	if (convert && convert(&buffer, &offset, header) != 0) {
+		ERROR("Failed to parse file '%s'.\n", filename);
+		buffer_delete(&buffer);
+		return 1;
+	}
+
+	if (param.hash != VB2_HASH_INVALID)
+		if (cbfs_add_file_hash(header, &buffer, param.hash) == -1) {
+			ERROR("couldn't add hash for '%s'\n", name);
+			free(header);
+			buffer_delete(&buffer);
+			return 1;
+		}
+
+	if (param.autogen_attr) {
+		/* Add position attribute if assigned */
+		if (param.baseaddress_assigned || param.stage_xip) {
+			struct cbfs_file_attr_position *attrs =
+				(struct cbfs_file_attr_position *)
+				cbfs_add_file_attr(header,
+					CBFS_FILE_ATTR_TAG_POSITION,
+					sizeof(struct cbfs_file_attr_position));
+			if (attrs == NULL)
+				return -1;
+			/* If we add a stage or a payload, we need to take  */
+			/* care about the additional metadata that is added */
+			/* to the cbfs file and therefore set the position  */
+			/* the real beginning of the data. */
+			if (type == CBFS_COMPONENT_STAGE)
+				attrs->position = htonl(offset +
+					sizeof(struct cbfs_stage));
+			else if (type == CBFS_COMPONENT_SELF)
+				attrs->position = htonl(offset +
+					sizeof(struct cbfs_payload));
+			else
+				attrs->position = htonl(offset);
+		}
+		/* Add alignment attribute if used */
+		if (param.alignment) {
+			struct cbfs_file_attr_align *attrs =
+				(struct cbfs_file_attr_align *)
+				cbfs_add_file_attr(header,
+					CBFS_FILE_ATTR_TAG_ALIGNMENT,
+					sizeof(struct cbfs_file_attr_align));
+			if (attrs == NULL)
+				return -1;
+			attrs->alignment = htonl(param.alignment);
+		}
+	}
+
+	if (param.padding) {
+		const uint32_t hs = sizeof(struct cbfs_file_attribute);
+		uint32_t size = MAX(hs, param.padding);
+		INFO("Padding %d bytes\n", size);
+		struct cbfs_file_attribute *attr =
+			(struct cbfs_file_attribute *)cbfs_add_file_attr(
+					header, CBFS_FILE_ATTR_TAG_PADDING,
+					size);
+		if (attr == NULL)
+			return -1;
+	}
+
+	if (IS_TOP_ALIGNED_ADDRESS(offset))
+		offset = convert_to_from_top_aligned(param.image_region,
+								-offset);
+	if (cbfs_add_entry(&image, &buffer, offset, header) != 0) {
+		ERROR("Failed to add '%s' into ROM image.\n", filename);
+		free(header);
+		buffer_delete(&buffer);
+		return 1;
+	}
+
+	free(header);
+	buffer_delete(&buffer);
+	return 0;
+}
+
+static int cbfstool_convert_raw(struct buffer *buffer,
+	unused uint32_t *offset, struct cbfs_file *header)
+{
+	char *compressed;
+	int decompressed_size, compressed_size;
+	comp_func_ptr compress;
+
+	decompressed_size = buffer->size;
+	if (param.precompression) {
+		param.compression = read_le32(buffer->data);
+		decompressed_size = read_le32(buffer->data + sizeof(uint32_t));
+		compressed_size = buffer->size - 8;
+		compressed = malloc(compressed_size);
+		if (!compressed)
+			return -1;
+		memcpy(compressed, buffer->data + 8, compressed_size);
+	} else {
+		compress = compression_function(param.compression);
+		if (!compress)
+			return -1;
+		compressed = calloc(buffer->size, 1);
+		if (!compressed)
+			return -1;
+
+		if (compress(buffer->data, buffer->size,
+			     compressed, &compressed_size)) {
+			WARN("Compression failed - disabled\n");
+			free(compressed);
+			return 0;
+		}
+	}
+
+	struct cbfs_file_attr_compression *attrs =
+		(struct cbfs_file_attr_compression *)
+		cbfs_add_file_attr(header,
+			CBFS_FILE_ATTR_TAG_COMPRESSION,
+			sizeof(struct cbfs_file_attr_compression));
+	if (attrs == NULL) {
+		free(compressed);
+		return -1;
+	}
+	attrs->compression = htonl(param.compression);
+	attrs->decompressed_size = htonl(decompressed_size);
+
+	free(buffer->data);
+	buffer->data = compressed;
+	buffer->size = compressed_size;
+
+	header->len = htonl(buffer->size);
+	return 0;
+}
+
+static int cbfstool_convert_fsp(struct buffer *buffer,
+				uint32_t *offset, struct cbfs_file *header)
+{
+	uint32_t address;
+	struct buffer fsp;
+	int do_relocation = 1;
+
+	address = *offset;
+
+	/*
+	 * If the FSP component is xip, then ensure that the address is a memory
+	 * mapped one.
+	 * If the FSP component is not xip, then use param.baseaddress that is
+	 * passed in by the caller.
+	 */
+	if (param.stage_xip) {
+		if (!IS_TOP_ALIGNED_ADDRESS(address))
+			address = -convert_to_from_absolute_top_aligned(
+					param.image_region, address);
+	} else {
+		if (param.baseaddress_assigned == 0) {
+			INFO("Honoring pre-linked FSP module.\n");
+			do_relocation = 0;
+		} else {
+			address = param.baseaddress;
+		}
+
+		/*
+		 * *offset should either be 0 or the value returned by
+		 * do_cbfs_locate. do_cbfs_locate should not ever return a value
+		 * that is TOP_ALIGNED_ADDRESS. Thus, if *offset contains a top
+		 * aligned address, set it to 0.
+		 *
+		 * The only requirement in this case is that the binary should
+		 * be relocated to the base address that is requested. There is
+		 * no requirement on where the file ends up in the cbfs.
+		 */
+		if (IS_TOP_ALIGNED_ADDRESS(*offset))
+			*offset = 0;
+	}
+
+	/*
+	 * Nothing left to do if relocation is not being attempted. Just add
+	 * the file.
+	 */
+	if (!do_relocation)
+		return cbfstool_convert_raw(buffer, offset, header);
+
+	/* Create a copy of the buffer to attempt relocation. */
+	if (buffer_create(&fsp, buffer_size(buffer), "fsp"))
+		return -1;
+
+	memcpy(buffer_get(&fsp), buffer_get(buffer), buffer_size(buffer));
+
+	/* Replace the buffer contents w/ the relocated ones on success. */
+	if (fsp_component_relocate(address, buffer_get(&fsp), buffer_size(&fsp))
+	    > 0) {
+		buffer_delete(buffer);
+		buffer_clone(buffer, &fsp);
+	} else {
+		buffer_delete(&fsp);
+		WARN("Invalid FSP variant.\n");
+	}
+
+	/* Let the raw path handle all the cbfs metadata logic. */
+	return cbfstool_convert_raw(buffer, offset, header);
+}
+
+static int cbfstool_convert_mkstage(struct buffer *buffer, uint32_t *offset,
+	struct cbfs_file *header)
+{
+	struct buffer output;
+	int ret;
+
+	if (param.stage_xip) {
+		int32_t address;
+		size_t data_size;
+
+		if (elf_program_file_size(buffer, &data_size) < 0) {
+			ERROR("Could not obtain ELF size\n");
+			return 1;
+		}
+
+		if (do_cbfs_locate(&address, sizeof(struct cbfs_stage),
+			data_size))  {
+			ERROR("Could not find location for XIP stage.\n");
+			return 1;
+		}
+
+		/*
+		 * Ensure the address is a memory mapped one. This assumes
+		 * x86 semantics about the boot media being directly mapped
+		 * below 4GiB in the CPU address space.
+		 **/
+		address = -convert_to_from_absolute_top_aligned(
+				param.image_region, address);
+		*offset = address;
+
+		ret = parse_elf_to_xip_stage(buffer, &output, offset,
+						param.ignore_section);
+	} else
+		ret = parse_elf_to_stage(buffer, &output, param.compression,
+					 offset, param.ignore_section);
+
+	if (ret != 0)
+		return -1;
+	buffer_delete(buffer);
+	// Direct assign, no dupe.
+	memcpy(buffer, &output, sizeof(*buffer));
+	header->len = htonl(output.size);
+	return 0;
+}
+
+static int cbfstool_convert_mkpayload(struct buffer *buffer,
+	unused uint32_t *offset, struct cbfs_file *header)
+{
+	struct buffer output;
+	int ret;
+	/* Per default, try and see if payload is an ELF binary */
+	ret = parse_elf_to_payload(buffer, &output, param.compression);
+
+	/* If it's not an ELF, see if it's a FIT */
+	if (ret != 0) {
+		ret = parse_fit_to_payload(buffer, &output, param.compression);
+		if (ret == 0)
+			header->type = htonl(CBFS_COMPONENT_FIT);
+	}
+
+	/* If it's not an FIT, see if it's a UEFI FV */
+	if (ret != 0)
+		ret = parse_fv_to_payload(buffer, &output, param.compression);
+
+	/* If it's neither ELF nor UEFI Fv, try bzImage */
+	if (ret != 0)
+		ret = parse_bzImage_to_payload(buffer, &output,
+				param.initrd, param.cmdline, param.compression);
+
+	/* Not a supported payload type */
+	if (ret != 0) {
+		ERROR("Not a supported payload type (ELF / FV).\n");
+		buffer_delete(buffer);
+		return -1;
+	}
+
+	buffer_delete(buffer);
+	// Direct assign, no dupe.
+	memcpy(buffer, &output, sizeof(*buffer));
+	header->len = htonl(output.size);
+	return 0;
+}
+
+static int cbfstool_convert_mkflatpayload(struct buffer *buffer,
+	unused uint32_t *offset, struct cbfs_file *header)
+{
+	struct buffer output;
+	if (parse_flat_binary_to_payload(buffer, &output,
+					 param.loadaddress,
+					 param.entrypoint,
+					 param.compression) != 0) {
+		return -1;
+	}
+	buffer_delete(buffer);
+	// Direct assign, no dupe.
+	memcpy(buffer, &output, sizeof(*buffer));
+	header->len = htonl(output.size);
+	return 0;
+}
+
+static int cbfs_add(void)
+{
+	int32_t address;
+	convert_buffer_t convert;
+	uint32_t local_baseaddress = param.baseaddress;
+
+	if (param.alignment && param.baseaddress) {
+		ERROR("Cannot specify both alignment and base address\n");
+		return 1;
+	}
+
+	convert = cbfstool_convert_raw;
+
+	/* Set the alignment to 4KiB minimum for FSP blobs when no base address
+	 * is provided so that relocation can occur. */
+	if (param.type == CBFS_COMPONENT_FSP) {
+		if (!param.baseaddress_assigned)
+			param.alignment = 4*1024;
+		convert = cbfstool_convert_fsp;
+	} else if (param.stage_xip) {
+		ERROR("cbfs add supports xip only for FSP component type\n");
+		return 1;
+	}
+
+	if (param.alignment) {
+		/* CBFS compression file attribute is unconditionally added. */
+		size_t metadata_sz = sizeof(struct cbfs_file_attr_compression);
+		if (do_cbfs_locate(&address, metadata_sz, 0))
+			return 1;
+		local_baseaddress = address;
+	}
+
+	return cbfs_add_component(param.filename,
+				  param.name,
+				  param.type,
+				  local_baseaddress,
+				  param.headeroffset,
+				  convert);
+}
+
+static int cbfs_add_stage(void)
+{
+	if (param.stage_xip) {
+		if (param.baseaddress_assigned) {
+			ERROR("Cannot specify base address for XIP.\n");
+			return 1;
+		}
+
+		if (param.compression != CBFS_COMPRESS_NONE) {
+			ERROR("Cannot specify compression for XIP.\n");
+			return 1;
+		}
+	}
+
+	return cbfs_add_component(param.filename,
+				  param.name,
+				  CBFS_COMPONENT_STAGE,
+				  param.baseaddress,
+				  param.headeroffset,
+				  cbfstool_convert_mkstage);
+}
+
+static int cbfs_add_payload(void)
+{
+	return cbfs_add_component(param.filename,
+				  param.name,
+				  CBFS_COMPONENT_SELF,
+				  param.baseaddress,
+				  param.headeroffset,
+				  cbfstool_convert_mkpayload);
+}
+
+static int cbfs_add_flat_binary(void)
+{
+	if (param.loadaddress == 0) {
+		ERROR("You need to specify a valid "
+			"-l/--load-address.\n");
+		return 1;
+	}
+	if (param.entrypoint == 0) {
+		ERROR("You need to specify a valid "
+			"-e/--entry-point.\n");
+		return 1;
+	}
+	return cbfs_add_component(param.filename,
+				  param.name,
+				  CBFS_COMPONENT_SELF,
+				  param.baseaddress,
+				  param.headeroffset,
+				  cbfstool_convert_mkflatpayload);
+}
+
+static int cbfs_add_integer(void)
+{
+	if (!param.u64val_assigned) {
+		ERROR("You need to specify a value to write.\n");
+		return 1;
+	}
+	return cbfs_add_integer_component(param.name,
+				  param.u64val,
+				  param.baseaddress,
+				  param.headeroffset);
+}
+
+static int cbfs_remove(void)
+{
+	if (!param.name) {
+		ERROR("You need to specify -n/--name.\n");
+		return 1;
+	}
+
+	struct cbfs_image image;
+	if (cbfs_image_from_buffer(&image, param.image_region,
+							param.headeroffset))
+		return 1;
+
+	if (cbfs_remove_entry(&image, param.name) != 0) {
+		ERROR("Removing file '%s' failed.\n",
+		      param.name);
+		return 1;
+	}
+
+	return 0;
+}
+
+static int cbfs_create(void)
+{
+	struct cbfs_image image;
+	memset(&image, 0, sizeof(image));
+	buffer_clone(&image.buffer, param.image_region);
+
+	if (param.fmap) {
+		if (param.arch != CBFS_ARCHITECTURE_UNKNOWN || param.size ||
+						param.baseaddress_assigned ||
+						param.headeroffset_assigned ||
+						param.cbfsoffset_assigned ||
+							param.bootblock) {
+			ERROR("Since -M was provided, -m, -s, -b, -o, -H, and -B should be omitted\n");
+			return 1;
+		}
+
+		return cbfs_image_create(&image, image.buffer.size);
+	}
+
+	if (param.arch == CBFS_ARCHITECTURE_UNKNOWN) {
+		ERROR("You need to specify -m/--machine arch.\n");
+		return 1;
+	}
+
+	struct buffer bootblock;
+	if (!param.bootblock) {
+		DEBUG("-B not given, creating image without bootblock.\n");
+		if (buffer_create(&bootblock, 0, "(dummy)") != 0)
+			return 1;
+	} else if (buffer_from_file(&bootblock, param.bootblock)) {
+		return 1;
+	}
+
+	if (!param.alignment)
+		param.alignment = CBFS_ALIGNMENT;
+
+	// Set default offsets. x86, as usual, needs to be a special snowflake.
+	if (!param.baseaddress_assigned) {
+		if (param.arch == CBFS_ARCHITECTURE_X86) {
+			// Make sure there's at least enough room for rel_offset
+			param.baseaddress = param.size -
+					MAX(bootblock.size, sizeof(int32_t));
+			DEBUG("x86 -> bootblock lies at end of ROM (%#x).\n",
+			      param.baseaddress);
+		} else {
+			param.baseaddress = 0;
+			DEBUG("bootblock starts at address 0x0.\n");
+		}
+	}
+	if (!param.headeroffset_assigned) {
+		if (param.arch == CBFS_ARCHITECTURE_X86) {
+			param.headeroffset = param.baseaddress -
+					     sizeof(struct cbfs_header);
+			DEBUG("x86 -> CBFS header before bootblock (%#x).\n",
+				param.headeroffset);
+		} else {
+			param.headeroffset = align_up(param.baseaddress +
+				bootblock.size, sizeof(uint32_t));
+			DEBUG("CBFS header placed behind bootblock (%#x).\n",
+				param.headeroffset);
+		}
+	}
+	if (!param.cbfsoffset_assigned) {
+		if (param.arch == CBFS_ARCHITECTURE_X86) {
+			param.cbfsoffset = 0;
+			DEBUG("x86 -> CBFS entries start at address 0x0.\n");
+		} else {
+			param.cbfsoffset = align_up(param.headeroffset +
+						    sizeof(struct cbfs_header),
+						    CBFS_ALIGNMENT);
+			DEBUG("CBFS entries start beind master header (%#x).\n",
+			      param.cbfsoffset);
+		}
+	}
+
+	int ret = cbfs_legacy_image_create(&image,
+					   param.arch,
+					   CBFS_ALIGNMENT,
+					   &bootblock,
+					   param.baseaddress,
+					   param.headeroffset,
+					   param.cbfsoffset);
+	buffer_delete(&bootblock);
+	return ret;
+}
+
+static int cbfs_layout(void)
+{
+	const struct fmap *fmap = partitioned_file_get_fmap(param.image_file);
+	if (!fmap) {
+		LOG("This is a legacy image composed entirely of a single CBFS.\n");
+		return 1;
+	}
+
+	printf("This image contains the following sections that can be %s with this tool:\n",
+			param.show_immutable ? "accessed" : "manipulated");
+	puts("");
+	for (unsigned i = 0; i < fmap->nareas; ++i) {
+		const struct fmap_area *current = fmap->areas + i;
+
+		bool readonly = partitioned_file_fmap_count(param.image_file,
+			partitioned_file_fmap_select_children_of, current) ||
+				region_is_flashmap((const char *)current->name);
+		if (!param.show_immutable && readonly)
+			continue;
+
+		printf("'%s'", current->name);
+
+		// Detect consecutive sections that describe the same region and
+		// show them as aliases. This cannot find equivalent entries
+		// that aren't adjacent; however, fmaptool doesn't generate
+		// FMAPs with such sections, so this convenience feature works
+		// for all but the strangest manually created FMAP binaries.
+		// TODO: This could be done by parsing the FMAP into some kind
+		// of tree that had duplicate lists in addition to child lists,
+		// which would allow covering that weird, unlikely case as well.
+		unsigned lookahead;
+		for (lookahead = 1; i + lookahead < fmap->nareas;
+								++lookahead) {
+			const struct fmap_area *consecutive =
+					fmap->areas + i + lookahead;
+			if (consecutive->offset != current->offset ||
+					consecutive->size != current->size)
+				break;
+			printf(", '%s'", consecutive->name);
+		}
+		if (lookahead > 1)
+			fputs(" are aliases for the same region", stdout);
+
+		const char *qualifier = "";
+		if (readonly)
+			qualifier = "read-only, ";
+		else if (region_is_modern_cbfs((const char *)current->name))
+			qualifier = "CBFS, ";
+		else if (current->flags & FMAP_AREA_PRESERVE)
+			qualifier = "preserve, ";
+		printf(" (%ssize %u, offset %u)\n", qualifier, current->size,
+				current->offset);
+
+		i += lookahead - 1;
+	}
+	puts("");
+
+	if (param.show_immutable) {
+		puts("It is at least possible to perform the read action on every section listed above.");
+	} else {
+		puts("It is possible to perform either the write action or the CBFS add/remove actions on every section listed above.");
+		puts("To see the image's read-only sections as well, rerun with the -w option.");
+	}
+
+	return 0;
+}
+
+static int cbfs_print(void)
+{
+	struct cbfs_image image;
+	if (cbfs_image_from_buffer(&image, param.image_region,
+							param.headeroffset))
+		return 1;
+	if (param.machine_parseable)
+		return cbfs_print_parseable_directory(&image);
+	else {
+		printf("FMAP REGION: %s\n", param.region_name);
+		return cbfs_print_directory(&image);
+	}
+}
+
+static int cbfs_extract(void)
+{
+	if (!param.filename) {
+		ERROR("You need to specify -f/--filename.\n");
+		return 1;
+	}
+
+	if (!param.name) {
+		ERROR("You need to specify -n/--name.\n");
+		return 1;
+	}
+
+	struct cbfs_image image;
+	if (cbfs_image_from_buffer(&image, param.image_region,
+							param.headeroffset))
+		return 1;
+
+	return cbfs_export_entry(&image, param.name, param.filename,
+				param.arch, !param.unprocessed);
+}
+
+static int cbfs_write(void)
+{
+	if (!param.filename) {
+		ERROR("You need to specify a valid input -f/--file.\n");
+		return 1;
+	}
+	if (!partitioned_file_is_partitioned(param.image_file)) {
+		ERROR("This operation isn't valid on legacy images having CBFS master headers\n");
+		return 1;
+	}
+
+	if (!param.force && region_is_modern_cbfs(param.region_name)) {
+		ERROR("Target image region '%s' is a CBFS and must be manipulated using add and remove\n",
+							param.region_name);
+		return 1;
+	}
+
+	struct buffer new_content;
+	if (buffer_from_file(&new_content, param.filename))
+		return 1;
+
+	if (buffer_check_magic(&new_content, FMAP_SIGNATURE,
+						strlen(FMAP_SIGNATURE))) {
+		ERROR("File '%s' appears to be an FMAP and cannot be added to an existing image\n",
+								param.filename);
+		buffer_delete(&new_content);
+		return 1;
+	}
+	if (!param.force && buffer_check_magic(&new_content, CBFS_FILE_MAGIC,
+						strlen(CBFS_FILE_MAGIC))) {
+		ERROR("File '%s' appears to be a CBFS and cannot be inserted into a raw region\n",
+								param.filename);
+		buffer_delete(&new_content);
+		return 1;
+	}
+
+	unsigned offset = 0;
+	if (param.fill_partial_upward && param.fill_partial_downward) {
+		ERROR("You may only specify one of -u and -d.\n");
+		buffer_delete(&new_content);
+		return 1;
+	} else if (!param.fill_partial_upward && !param.fill_partial_downward) {
+		if (new_content.size != param.image_region->size) {
+			ERROR("File to add is %zu bytes and would not fill %zu-byte target region (did you mean to pass either -u or -d?)\n",
+				new_content.size, param.image_region->size);
+			buffer_delete(&new_content);
+			return 1;
+		}
+	} else {
+		if (new_content.size > param.image_region->size) {
+			ERROR("File to add is %zu bytes and would overflow %zu-byte target region\n",
+				new_content.size, param.image_region->size);
+			buffer_delete(&new_content);
+			return 1;
+		}
+		if (param.u64val == (uint64_t)-1) {
+			WARN("Written area will abut %s of target region: any unused space will keep its current contents\n",
+					param.fill_partial_upward ? "bottom" : "top");
+		} else if (param.u64val > 0xff) {
+			ERROR("given fill value (%x) is larger than a byte\n", (unsigned)(param.u64val & 0xff));
+			buffer_delete(&new_content);
+			return 1;
+		} else {
+			memset(buffer_get(param.image_region),
+				param.u64val & 0xff,
+				buffer_size(param.image_region));
+		}
+		if (param.fill_partial_downward)
+			offset = param.image_region->size - new_content.size;
+	}
+
+	memcpy(param.image_region->data + offset, new_content.data,
+							new_content.size);
+	buffer_delete(&new_content);
+	return 0;
+}
+
+static int cbfs_read(void)
+{
+	if (!param.filename) {
+		ERROR("You need to specify a valid output -f/--file.\n");
+		return 1;
+	}
+	if (!partitioned_file_is_partitioned(param.image_file)) {
+		ERROR("This operation isn't valid on legacy images having CBFS master headers\n");
+		return 1;
+	}
+
+	return buffer_write_file(param.image_region, param.filename);
+}
+
+static int cbfs_copy(void)
+{
+	struct cbfs_image src_image;
+	struct buffer src_buf;
+
+	if (!param.source_region) {
+		ERROR("You need to specify -R/--source-region.\n");
+		return 1;
+	}
+
+	/* Obtain the source region and convert it to a cbfs_image. */
+	if (!partitioned_file_read_region(&src_buf, param.image_file,
+						param.source_region)) {
+		ERROR("Region not found in image: %s\n", param.source_region);
+		return 1;
+	}
+
+	if (cbfs_image_from_buffer(&src_image, &src_buf, param.headeroffset))
+		return 1;
+
+	return cbfs_copy_instance(&src_image, param.image_region);
+}
+
+static int cbfs_compact(void)
+{
+	struct cbfs_image image;
+	if (cbfs_image_from_buffer(&image, param.image_region,
+							param.headeroffset))
+		return 1;
+	WARN("Compacting a CBFS doesn't honor alignment or fixed addresses!\n");
+	return cbfs_compact_instance(&image);
+}
+
+static int cbfs_expand(void)
+{
+	struct buffer src_buf;
+
+	/* Obtain the source region. */
+	if (!partitioned_file_read_region(&src_buf, param.image_file,
+						param.region_name)) {
+		ERROR("Region not found in image: %s\n", param.source_region);
+		return 1;
+	}
+
+	return cbfs_expand_to_region(param.image_region);
+}
+
+static int cbfs_truncate(void)
+{
+	struct buffer src_buf;
+
+	/* Obtain the source region. */
+	if (!partitioned_file_read_region(&src_buf, param.image_file,
+						param.region_name)) {
+		ERROR("Region not found in image: %s\n", param.source_region);
+		return 1;
+	}
+
+	uint32_t size;
+	int result = cbfs_truncate_space(param.image_region, &size);
+	printf("0x%x\n", size);
+	return result;
+}
+
+static const struct command commands[] = {
+	{"add", "H:r:f:n:t:c:b:a:p:yvA:j:gh?", cbfs_add, true, true},
+	{"add-flat-binary", "H:r:f:n:l:e:c:b:p:vA:gh?", cbfs_add_flat_binary,
+				true, true},
+	{"add-payload", "H:r:f:n:c:b:C:I:p:vA:gh?", cbfs_add_payload,
+				true, true},
+	{"add-stage", "a:H:r:f:n:t:c:b:P:S:p:yvA:gh?", cbfs_add_stage,
+				true, true},
+	{"add-int", "H:r:i:n:b:vgh?", cbfs_add_integer, true, true},
+	{"add-master-header", "H:r:vh?j:", cbfs_add_master_header, true, true},
+	{"compact", "r:h?", cbfs_compact, true, true},
+	{"copy", "r:R:h?", cbfs_copy, true, true},
+	{"create", "M:r:s:B:b:H:o:m:vh?", cbfs_create, true, true},
+	{"extract", "H:r:m:n:f:Uvh?", cbfs_extract, true, false},
+	{"layout", "wvh?", cbfs_layout, false, false},
+	{"print", "H:r:vkh?", cbfs_print, true, false},
+	{"read", "r:f:vh?", cbfs_read, true, false},
+	{"remove", "H:r:n:vh?", cbfs_remove, true, true},
+	{"write", "r:f:i:Fudvh?", cbfs_write, true, true},
+	{"expand", "r:h?", cbfs_expand, true, true},
+	{"truncate", "r:h?", cbfs_truncate, true, true},
+};
+
+static struct option long_options[] = {
+	{"alignment",     required_argument, 0, 'a' },
+	{"base-address",  required_argument, 0, 'b' },
+	{"bootblock",     required_argument, 0, 'B' },
+	{"cmdline",       required_argument, 0, 'C' },
+	{"compression",   required_argument, 0, 'c' },
+	{"topswap-size",  required_argument, 0, 'j' },
+	{"empty-fits",    required_argument, 0, 'x' },
+	{"entry-point",   required_argument, 0, 'e' },
+	{"file",          required_argument, 0, 'f' },
+	{"fill-downward", no_argument,       0, 'd' },
+	{"fill-upward",   no_argument,       0, 'u' },
+	{"flashmap",      required_argument, 0, 'M' },
+	{"fmap-regions",  required_argument, 0, 'r' },
+	{"force",         no_argument,       0, 'F' },
+	{"source-region", required_argument, 0, 'R' },
+	{"hash-algorithm",required_argument, 0, 'A' },
+	{"header-offset", required_argument, 0, 'H' },
+	{"help",          no_argument,       0, 'h' },
+	{"ignore-sec",    required_argument, 0, 'S' },
+	{"initrd",        required_argument, 0, 'I' },
+	{"int",           required_argument, 0, 'i' },
+	{"load-address",  required_argument, 0, 'l' },
+	{"machine",       required_argument, 0, 'm' },
+	{"name",          required_argument, 0, 'n' },
+	{"offset",        required_argument, 0, 'o' },
+	{"padding",       required_argument, 0, 'p' },
+	{"page-size",     required_argument, 0, 'P' },
+	{"ucode-region",  required_argument, 0, 'q' },
+	{"size",          required_argument, 0, 's' },
+	{"top-aligned",   required_argument, 0, 'T' },
+	{"type",          required_argument, 0, 't' },
+	{"verbose",       no_argument,       0, 'v' },
+	{"with-readonly", no_argument,       0, 'w' },
+	{"xip",           no_argument,       0, 'y' },
+	{"gen-attribute", no_argument,       0, 'g' },
+	{"mach-parseable",no_argument,       0, 'k' },
+	{"unprocessed",   no_argument,       0, 'U' },
+	{NULL,            0,                 0,  0  }
+};
+
+static int dispatch_command(struct command command)
+{
+	if (command.accesses_region) {
+		assert(param.image_file);
+
+		if (partitioned_file_is_partitioned(param.image_file)) {
+			INFO("Performing operation on '%s' region...\n",
+					param.region_name);
+		}
+		if (!partitioned_file_read_region(param.image_region,
+					param.image_file, param.region_name)) {
+			ERROR("The image will be left unmodified.\n");
+			return 1;
+		}
+
+		if (command.modifies_region) {
+			// We (intentionally) don't support overwriting the FMAP
+			// section. If you find yourself wanting to do this,
+			// consider creating a new image rather than performing
+			// whatever hacky transformation you were planning.
+			if (region_is_flashmap(param.region_name)) {
+				ERROR("Image region '%s' is read-only because it contains the FMAP.\n",
+							param.region_name);
+				ERROR("The image will be left unmodified.\n");
+				return 1;
+			}
+			// We don't allow writing raw data to regions that
+			// contain nested regions, since doing so would
+			// overwrite all such subregions.
+			if (partitioned_file_region_contains_nested(
+					param.image_file, param.region_name)) {
+				ERROR("Image region '%s' is read-only because it contains nested regions.\n",
+							param.region_name);
+				ERROR("The image will be left unmodified.\n");
+				return 1;
+			}
+		}
+	}
+
+	if (command.function()) {
+		if (partitioned_file_is_partitioned(param.image_file)) {
+			ERROR("Failed while operating on '%s' region!\n",
+							param.region_name);
+			ERROR("The image will be left unmodified.\n");
+		}
+		return 1;
+	}
+
+	return 0;
+}
+
+static void usage(char *name)
+{
+	printf
+	    ("cbfstool: Management utility for CBFS formatted ROM images\n\n"
+	     "USAGE:\n" " %s [-h]\n"
+	     " %s FILE COMMAND [-v] [PARAMETERS]...\n\n" "OPTIONs:\n"
+	     "  -H header_offset Do not search for header; use this offset*\n"
+	     "  -T               Output top-aligned memory address\n"
+	     "  -u               Accept short data; fill upward/from bottom\n"
+	     "  -d               Accept short data; fill downward/from top\n"
+	     "  -F               Force action\n"
+	     "  -g               Generate position and alignment arguments\n"
+	     "  -U               Unprocessed; don't decompress or make ELF\n"
+	     "  -v               Provide verbose output\n"
+	     "  -h               Display this help message\n\n"
+	     "COMMANDs:\n"
+	     " add [-r image,regions] -f FILE -n NAME -t TYPE [-A hash] \\\n"
+	     "        [-c compression] [-b base-address | -a alignment] \\\n"
+	     "        [-p padding size] [-y|--xip if TYPE is FSP]       \\\n"
+	     "        [-j topswap-size] (Intel CPUs only)                   "
+			"Add a component\n"
+	     "                                                         "
+	     "    -j valid size: 0x10000 0x20000 0x40000 0x80000 0x100000 \n"
+	     " add-payload [-r image,regions] -f FILE -n NAME [-A hash] \\\n"
+	     "        [-c compression] [-b base-address] \\\n"
+	     "        (linux specific: [-C cmdline] [-I initrd])           "
+			"Add a payload to the ROM\n"
+	     " add-stage [-r image,regions] -f FILE -n NAME [-A hash] \\\n"
+	     "        [-c compression] [-b base] [-S section-to-ignore] \\\n"
+	     "        [-a alignment] [-y|--xip] [-P page-size]             "
+			"Add a stage to the ROM\n"
+	     " add-flat-binary [-r image,regions] -f FILE -n NAME \\\n"
+	     "        [-A hash] -l load-address -e entry-point \\\n"
+	     "        [-c compression] [-b base]                           "
+			"Add a 32bit flat mode binary\n"
+	     " add-int [-r image,regions] -i INTEGER -n NAME [-b base]     "
+			"Add a raw 64-bit integer value\n"
+	     " add-master-header [-r image,regions] \\                   \n"
+	     "        [-j topswap-size] (Intel CPUs only)                  "
+			"Add a legacy CBFS master header\n"
+	     " remove [-r image,regions] -n NAME                           "
+			"Remove a component\n"
+	     " compact -r image,regions                                    "
+			"Defragment CBFS image.\n"
+	     " copy -r image,regions -R source-region                      "
+			"Create a copy (duplicate) cbfs instance in fmap\n"
+	     " create -m ARCH -s size [-b bootblock offset] \\\n"
+	     "        [-o CBFS offset] [-H header offset] [-B bootblock]   "
+			"Create a legacy ROM file with CBFS master header*\n"
+	     " create -M flashmap [-r list,of,regions,containing,cbfses]   "
+			"Create a new-style partitioned firmware image\n"
+	     " locate [-r image,regions] -f FILE -n NAME [-P page-size] \\\n"
+	     "        [-a align] [-T]                                      "
+			"Find a place for a file of that size\n"
+	     " layout [-w]                                                 "
+			"List mutable (or, with -w, readable) image regions\n"
+	     " print [-r image,regions]                                    "
+			"Show the contents of the ROM\n"
+	     " extract [-r image,regions] [-m ARCH] -n NAME -f FILE [-U]   "
+			"Extracts a file from ROM\n"
+	     " write [-F] -r image,regions -f file [-u | -d] [-i int]      "
+			"Write file into same-size [or larger] raw region\n"
+	     " read [-r fmap-region] -f file                               "
+			"Extract raw region contents into binary file\n"
+	     " truncate [-r fmap-region]                                   "
+			"Truncate CBFS and print new size on stdout\n"
+	     " expand [-r fmap-region]                                     "
+			"Expand CBFS to span entire region\n"
+	     "OFFSETs:\n"
+	     "  Numbers accompanying -b, -H, and -o switches* may be provided\n"
+	     "  in two possible formats: if their value is greater than\n"
+	     "  0x80000000, they are interpreted as a top-aligned x86 memory\n"
+	     "  address; otherwise, they are treated as an offset into flash.\n"
+	     "ARCHes:\n", name, name
+	    );
+	print_supported_architectures();
+
+	printf("TYPEs:\n");
+	print_supported_filetypes();
+	printf(
+	     "\n* Note that these actions and switches are only valid when\n"
+	     "  working with legacy images whose structure is described\n"
+	     "  primarily by a CBFS master header. New-style images, in\n"
+	     "  contrast, exclusively make use of an FMAP to describe their\n"
+	     "  layout: this must minimally contain an '%s' section\n"
+	     "  specifying the location of this FMAP itself and a '%s'\n"
+	     "  section describing the primary CBFS. It should also be noted\n"
+	     "  that, when working with such images, the -F and -r switches\n"
+	     "  default to '%s' for convenience, and both the -b switch to\n"
+	     "  CBFS operations and the output of the locate action become\n"
+	     "  relative to the selected CBFS region's lowest address.\n"
+	     "  The one exception to this rule is the top-aligned address,\n"
+	     "  which is always relative to the end of the entire image\n"
+	     "  rather than relative to the local region; this is true for\n"
+	     "  for both input (sufficiently large) and output (-T) data.\n",
+	     SECTION_NAME_FMAP, SECTION_NAME_PRIMARY_CBFS,
+	     SECTION_NAME_PRIMARY_CBFS
+	     );
+}
+
+int main(int argc, char **argv)
+{
+	size_t i;
+	int c;
+
+	if (argc < 3) {
+		usage(argv[0]);
+		return 1;
+	}
+
+	char *image_name = argv[1];
+	char *cmd = argv[2];
+	optind += 2;
+
+	for (i = 0; i < ARRAY_SIZE(commands); i++) {
+		if (strcmp(cmd, commands[i].name) != 0)
+			continue;
+
+		while (1) {
+			char *suffix = NULL;
+			int option_index = 0;
+
+			c = getopt_long(argc, argv, commands[i].optstring,
+						long_options, &option_index);
+			if (c == -1) {
+				if (optind < argc) {
+					ERROR("%s: excessive argument -- '%s'"
+						"\n", argv[0], argv[optind]);
+					return 1;
+				}
+				break;
+			}
+
+			/* Filter out illegal long options */
+			if (strchr(commands[i].optstring, c) == NULL) {
+				/* TODO maybe print actual long option instead */
+				ERROR("%s: invalid option -- '%c'\n",
+				      argv[0], c);
+				c = '?';
+			}
+
+			switch(c) {
+			case 'n':
+				param.name = optarg;
+				break;
+			case 't':
+				if (intfiletype(optarg) != ((uint64_t) - 1))
+					param.type = intfiletype(optarg);
+				else
+					param.type = strtoul(optarg, NULL, 0);
+				if (param.type == 0)
+					WARN("Unknown type '%s' ignored\n",
+							optarg);
+				break;
+			case 'c': {
+				if (strcmp(optarg, "precompression") == 0) {
+					param.precompression = 1;
+					break;
+				}
+				int algo = cbfs_parse_comp_algo(optarg);
+				if (algo >= 0)
+					param.compression = algo;
+				else
+					WARN("Unknown compression '%s' ignored.\n",
+									optarg);
+				break;
+			}
+			case 'A': {
+				int algo = cbfs_parse_hash_algo(optarg);
+				if (algo >= 0)
+					param.hash = algo;
+				else {
+					ERROR("Unknown hash algorithm '%s'.\n",
+						optarg);
+					return 1;
+				}
+				break;
+			}
+			case 'M':
+				param.fmap = optarg;
+				break;
+			case 'r':
+				param.region_name = optarg;
+				break;
+			case 'R':
+				param.source_region = optarg;
+				break;
+			case 'b':
+				param.baseaddress = strtoul(optarg, &suffix, 0);
+				if (!*optarg || (suffix && *suffix)) {
+					ERROR("Invalid base address '%s'.\n",
+						optarg);
+					return 1;
+				}
+				// baseaddress may be zero on non-x86, so we
+				// need an explicit "baseaddress_assigned".
+				param.baseaddress_assigned = 1;
+				break;
+			case 'l':
+				param.loadaddress = strtoul(optarg, &suffix, 0);
+				if (!*optarg || (suffix && *suffix)) {
+					ERROR("Invalid load address '%s'.\n",
+						optarg);
+					return 1;
+				}
+				break;
+			case 'e':
+				param.entrypoint = strtoul(optarg, &suffix, 0);
+				if (!*optarg || (suffix && *suffix)) {
+					ERROR("Invalid entry point '%s'.\n",
+						optarg);
+					return 1;
+				}
+				break;
+			case 's':
+				param.size = strtoul(optarg, &suffix, 0);
+				if (!*optarg) {
+					ERROR("Empty size specified.\n");
+					return 1;
+				}
+				switch (tolower((int)suffix[0])) {
+				case 'k':
+					param.size *= 1024;
+					break;
+				case 'm':
+					param.size *= 1024 * 1024;
+					break;
+				case '\0':
+					break;
+				default:
+					ERROR("Invalid suffix for size '%s'.\n",
+						optarg);
+					return 1;
+				}
+				break;
+			case 'B':
+				param.bootblock = optarg;
+				break;
+			case 'H':
+				param.headeroffset = strtoul(
+						optarg, &suffix, 0);
+				if (!*optarg || (suffix && *suffix)) {
+					ERROR("Invalid header offset '%s'.\n",
+						optarg);
+					return 1;
+				}
+				param.headeroffset_assigned = 1;
+				break;
+			case 'a':
+				param.alignment = strtoul(optarg, &suffix, 0);
+				if (!*optarg || (suffix && *suffix)) {
+					ERROR("Invalid alignment '%s'.\n",
+						optarg);
+					return 1;
+				}
+				break;
+			case 'p':
+				param.padding = strtoul(optarg, &suffix, 0);
+				if (!*optarg || (suffix && *suffix)) {
+					ERROR("Invalid pad size '%s'.\n",
+						optarg);
+					return 1;
+				}
+				break;
+			case 'P':
+				param.pagesize = strtoul(optarg, &suffix, 0);
+				if (!*optarg || (suffix && *suffix)) {
+					ERROR("Invalid page size '%s'.\n",
+						optarg);
+					return 1;
+				}
+				break;
+			case 'o':
+				param.cbfsoffset = strtoul(optarg, &suffix, 0);
+				if (!*optarg || (suffix && *suffix)) {
+					ERROR("Invalid cbfs offset '%s'.\n",
+						optarg);
+					return 1;
+				}
+				param.cbfsoffset_assigned = 1;
+				break;
+			case 'f':
+				param.filename = optarg;
+				break;
+			case 'F':
+				param.force = 1;
+				break;
+			case 'i':
+				param.u64val = strtoull(optarg, &suffix, 0);
+				param.u64val_assigned = 1;
+				if (!*optarg || (suffix && *suffix)) {
+					ERROR("Invalid int parameter '%s'.\n",
+						optarg);
+					return 1;
+				}
+				break;
+			case 'u':
+				param.fill_partial_upward = true;
+				break;
+			case 'd':
+				param.fill_partial_downward = true;
+				break;
+			case 'w':
+				param.show_immutable = true;
+				break;
+			case 'j':
+				param.topswap_size = strtol(optarg, NULL, 0);
+				if (!is_valid_topswap())
+					return 1;
+				break;
+			case 'q':
+				param.ucode_region = optarg;
+				break;
+			case 'v':
+				verbose++;
+				break;
+			case 'm':
+				param.arch = string_to_arch(optarg);
+				break;
+			case 'I':
+				param.initrd = optarg;
+				break;
+			case 'C':
+				param.cmdline = optarg;
+				break;
+			case 'S':
+				param.ignore_section = optarg;
+				break;
+			case 'y':
+				param.stage_xip = true;
+				break;
+			case 'g':
+				param.autogen_attr = true;
+				break;
+			case 'k':
+				param.machine_parseable = true;
+				break;
+			case 'U':
+				param.unprocessed = true;
+				break;
+			case 'h':
+			case '?':
+				usage(argv[0]);
+				return 1;
+			default:
+				break;
+			}
+		}
+
+		if (commands[i].function == cbfs_create) {
+			if (param.fmap) {
+				struct buffer flashmap;
+				if (buffer_from_file(&flashmap, param.fmap))
+					return 1;
+				param.image_file = partitioned_file_create(
+							image_name, &flashmap);
+				buffer_delete(&flashmap);
+			} else if (param.size) {
+				param.image_file = partitioned_file_create_flat(
+							image_name, param.size);
+			} else {
+				ERROR("You need to specify a valid -M/--flashmap or -s/--size.\n");
+				return 1;
+			}
+		} else {
+			bool write_access = commands[i].modifies_region;
+
+			param.image_file =
+				partitioned_file_reopen(image_name,
+							write_access);
+		}
+		if (!param.image_file)
+			return 1;
+
+		unsigned num_regions = 1;
+		for (const char *list = strchr(param.region_name, ','); list;
+						list = strchr(list + 1, ','))
+			++num_regions;
+
+		// If the action needs to read an image region, as indicated by
+		// having accesses_region set in its command struct, that
+		// region's buffer struct will be stored here and the client
+		// will receive a pointer to it via param.image_region. It
+		// need not write the buffer back to the image file itself,
+		// since this behavior can be requested via its modifies_region
+		// field. Additionally, it should never free the region buffer,
+		// as that is performed automatically once it completes.
+		struct buffer image_regions[num_regions];
+		memset(image_regions, 0, sizeof(image_regions));
+
+		bool seen_primary_cbfs = false;
+		char region_name_scratch[strlen(param.region_name) + 1];
+		strcpy(region_name_scratch, param.region_name);
+		param.region_name = strtok(region_name_scratch, ",");
+		for (unsigned region = 0; region < num_regions; ++region) {
+			if (!param.region_name) {
+				ERROR("Encountered illegal degenerate region name in -r list\n");
+				ERROR("The image will be left unmodified.\n");
+				partitioned_file_close(param.image_file);
+				return 1;
+			}
+
+			if (strcmp(param.region_name, SECTION_NAME_PRIMARY_CBFS)
+									== 0)
+				seen_primary_cbfs = true;
+
+			param.image_region = image_regions + region;
+			if (dispatch_command(commands[i])) {
+				partitioned_file_close(param.image_file);
+				return 1;
+			}
+
+			param.region_name = strtok(NULL, ",");
+		}
+
+		if (commands[i].function == cbfs_create && !seen_primary_cbfs) {
+			ERROR("The creation -r list must include the mandatory '%s' section.\n",
+						SECTION_NAME_PRIMARY_CBFS);
+			ERROR("The image will be left unmodified.\n");
+			partitioned_file_close(param.image_file);
+			return 1;
+		}
+
+		if (commands[i].modifies_region) {
+			assert(param.image_file);
+			for (unsigned region = 0; region < num_regions;
+								++region) {
+
+				if (!partitioned_file_write_region(
+							param.image_file,
+						image_regions + region)) {
+					partitioned_file_close(
+							param.image_file);
+					return 1;
+				}
+			}
+		}
+
+		partitioned_file_close(param.image_file);
+		return 0;
+	}
+
+	ERROR("Unknown command '%s'.\n", cmd);
+	usage(argv[0]);
+	return 1;
+}
diff --git a/tools/cbfstool/coff.h b/tools/cbfstool/coff.h
new file mode 100644
index 0000000000..e814379c1b
--- /dev/null
+++ b/tools/cbfstool/coff.h
@@ -0,0 +1,119 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * Copyright (C) 2013 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define DOS_MAGIC 0x5a4d
+typedef struct {
+	 uint16_t signature;
+	 uint16_t lastsize;
+	 uint16_t nblocks;
+	 uint16_t nreloc;
+	 uint16_t hdrsize;
+	 uint16_t minalloc;
+	 uint16_t maxalloc;
+	 uint16_t ss;
+	 uint16_t sp;
+	 uint16_t checksum;
+	 uint16_t ip;
+	 uint16_t cs;
+	 uint16_t relocpos;
+	 uint16_t noverlay;
+	 uint16_t reserved1[4];
+	 uint16_t oem_id;
+	 uint16_t oem_info;
+	 uint16_t reserved2[10];
+	 uint32_t e_lfanew;
+} dos_header_t;
+
+#define MACHINE_TYPE_X86 0x014c
+#define MACHINE_TYPE_X64 0x8664
+typedef struct {
+	uint8_t  signature[4];
+	uint16_t machine;
+	uint16_t num_sections;
+	uint32_t timestamp;
+	uint32_t symboltable;
+	uint32_t num_symbols;
+	uint16_t opt_header_size;
+	uint16_t characteristics;
+} coff_header_t;
+
+#define PE_HDR_32_MAGIC 0x10b
+typedef struct {
+	uint16_t signature;
+	uint8_t  major_linker_version;
+	uint8_t  minor_linker_version;
+	uint32_t code_size;
+	uint32_t data_size;
+	uint32_t bss_size;
+	uint32_t entry_point;
+	uint32_t code_offset;
+	uint32_t data_offset;
+	uint32_t image_addr;
+	uint32_t section_alignment;
+	uint32_t file_alignment;
+	uint16_t major_os_version;
+	uint16_t minor_os_version;
+	uint16_t major_image_version;
+	uint16_t minor_image_version;
+	uint16_t major_subsystem_version;
+	uint16_t minor_subsystem_version;
+	uint32_t reserved;
+	uint32_t image_size;
+	uint32_t header_size;
+	uint32_t checksum;
+	uint16_t subsystem;
+	uint16_t characteristics;
+	uint32_t stack_reserve_size;
+	uint32_t stack_commit_size;
+	uint32_t heap_reserve_size;
+	uint32_t heap_commit_size;
+	uint32_t loader_flags;
+	uint32_t number_of_va_and_sizes;
+	/* data directory not needed */
+} pe_opt_header_32_t;
+
+#define PE_HDR_64_MAGIC 0x20b
+typedef struct {
+	uint16_t signature;
+	uint8_t  major_linker_version;
+	uint8_t  minor_linker_version;
+	uint32_t code_size;
+	uint32_t data_size;
+	uint32_t bss_size;
+	uint32_t entry_point;
+	uint32_t code_offset;
+	uint64_t image_addr;
+	uint32_t section_alignment;
+	uint32_t file_alignment;
+	uint16_t major_os_version;
+	uint16_t minor_os_version;
+	uint16_t major_image_version;
+	uint16_t minor_image_version;
+	uint16_t major_subsystem_version;
+	uint16_t minor_subsystem_version;
+	uint32_t reserved;
+	uint32_t image_size;
+	uint32_t header_size;
+	uint32_t checksum;
+	uint16_t subsystem;
+	uint16_t characteristics;
+	uint64_t stack_reserve_size;
+	uint64_t stack_commit_size;
+	uint64_t heap_reserve_size;
+	uint64_t heap_commit_size;
+	uint32_t loader_flags;
+	uint32_t number_of_va_and_sizes;
+	/* data directory not needed */
+} pe_opt_header_64_t;
diff --git a/tools/cbfstool/common.c b/tools/cbfstool/common.c
new file mode 100644
index 0000000000..c1725dc903
--- /dev/null
+++ b/tools/cbfstool/common.c
@@ -0,0 +1,218 @@
+/*
+ * common utility functions for cbfstool
+ *
+ * Copyright (C) 2009 coresystems GmbH
+ *                 written by Patrick Georgi <patrick.georgi@coresystems.de>
+ * Copyright (C) 2012 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <strings.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <unistd.h>
+#include <libgen.h>
+#include "common.h"
+#include "cbfs.h"
+
+/* Utilities */
+int verbose = 0;
+
+/* Small, OS/libc independent runtime check for endianness */
+int is_big_endian(void)
+{
+	static const uint32_t inttest = 0x12345678;
+	const uint8_t inttest_lsb = *(const uint8_t *)&inttest;
+	if (inttest_lsb == 0x12) {
+		return 1;
+	}
+	return 0;
+}
+
+static off_t get_file_size(FILE *f)
+{
+	off_t fsize;
+	fseek(f, 0, SEEK_END);
+	fsize = ftell(f);
+	fseek(f, 0, SEEK_SET);
+	return fsize;
+}
+
+/* Buffer and file I/O */
+int buffer_create(struct buffer *buffer, size_t size, const char *name)
+{
+	buffer->name = strdup(name);
+	buffer->offset = 0;
+	buffer->size = size;
+	buffer->data = (char *)malloc(buffer->size);
+	if (!buffer->data) {
+		fprintf(stderr, "buffer_create: Insufficient memory (0x%zx).\n",
+			size);
+	}
+	return (buffer->data == NULL);
+}
+
+int buffer_from_file(struct buffer *buffer, const char *filename)
+{
+	FILE *fp = fopen(filename, "rb");
+	if (!fp) {
+		perror(filename);
+		return -1;
+	}
+	buffer->offset = 0;
+	off_t file_size = get_file_size(fp);
+	if (file_size < 0) {
+		fprintf(stderr, "could not determine size of %s\n", filename);
+		fclose(fp);
+		return -1;
+	}
+	buffer->size = file_size;
+	buffer->name = strdup(filename);
+	buffer->data = (char *)malloc(buffer->size);
+	assert(buffer->data);
+	if (fread(buffer->data, 1, buffer->size, fp) != buffer->size) {
+		fprintf(stderr, "incomplete read: %s\n", filename);
+		fclose(fp);
+		buffer_delete(buffer);
+		return -1;
+	}
+	fclose(fp);
+	return 0;
+}
+
+int buffer_write_file(struct buffer *buffer, const char *filename)
+{
+	FILE *fp = fopen(filename, "wb");
+	if (!fp) {
+		perror(filename);
+		return -1;
+	}
+	assert(buffer && buffer->data);
+	if (fwrite(buffer->data, 1, buffer->size, fp) != buffer->size) {
+		fprintf(stderr, "incomplete write: %s\n", filename);
+		fclose(fp);
+		return -1;
+	}
+	fclose(fp);
+	return 0;
+}
+
+void buffer_delete(struct buffer *buffer)
+{
+	assert(buffer);
+	if (buffer->name) {
+		free(buffer->name);
+		buffer->name = NULL;
+	}
+	if (buffer->data) {
+		free(buffer_get_original_backing(buffer));
+		buffer->data = NULL;
+	}
+	buffer->offset = 0;
+	buffer->size = 0;
+}
+
+static struct {
+	uint32_t arch;
+	const char *name;
+} arch_names[] = {
+	{ CBFS_ARCHITECTURE_AARCH64, "arm64" },
+	{ CBFS_ARCHITECTURE_ARM, "arm" },
+	{ CBFS_ARCHITECTURE_MIPS, "mips" },
+	{ CBFS_ARCHITECTURE_PPC64, "ppc64" },
+	/* power8 is a reasonable alias */
+	{ CBFS_ARCHITECTURE_PPC64, "power8" },
+	{ CBFS_ARCHITECTURE_RISCV, "riscv" },
+	{ CBFS_ARCHITECTURE_X86, "x86" },
+	{ CBFS_ARCHITECTURE_UNKNOWN, "unknown" }
+};
+
+uint32_t string_to_arch(const char *arch_string)
+{
+	size_t i;
+	uint32_t ret = CBFS_ARCHITECTURE_UNKNOWN;
+
+	for (i = 0; i < ARRAY_SIZE(arch_names); i++) {
+		if (!strcasecmp(arch_string, arch_names[i].name)) {
+			ret = arch_names[i].arch;
+			break;
+		}
+	}
+
+	return ret;
+}
+
+const char *arch_to_string(uint32_t a)
+{
+        size_t i;
+	const char *ret = NULL;
+
+	for (i = 0; i < ARRAY_SIZE(arch_names); i++) {
+		if (a == arch_names[i].arch) {
+			ret = arch_names[i].name;
+			break;
+		}
+	}
+
+	return ret;
+}
+
+void print_supported_architectures(void)
+{
+	size_t i;
+
+	for (i = 0; i < ARRAY_SIZE(arch_names); i++) {
+		printf(i == 0? "  ":", ");
+		printf("%s", arch_names[i].name);
+	}
+
+	printf("\n");
+}
+
+void print_supported_filetypes(void)
+{
+	int i, number = ARRAY_SIZE(filetypes);
+
+	for (i=0; i<number; i++) {
+		printf(" %s%c", filetypes[i].name, (i==(number-1))?'\n':',');
+		if ((i%8) == 7)
+			printf("\n");
+	}
+}
+
+uint64_t intfiletype(const char *name)
+{
+	size_t i;
+	for (i = 0; i < (sizeof(filetypes) / sizeof(struct typedesc_t)); i++)
+		if (strcmp(filetypes[i].name, name) == 0)
+			return filetypes[i].type;
+	return -1;
+}
+
+char *bintohex(uint8_t *data, size_t len)
+{
+	static const char translate[16] = "0123456789abcdef";
+
+	char *result = malloc(len * 2 + 1);
+	if (result == NULL)
+		return NULL;
+
+	result[len*2] = '\0';
+	unsigned int i;
+	for (i = 0; i < len; i++) {
+		result[i*2] = translate[(data[i] >> 4) & 0xf];
+		result[i*2+1] = translate[data[i] & 0xf];
+	}
+	return result;
+}
diff --git a/tools/cbfstool/common.h b/tools/cbfstool/common.h
new file mode 100644
index 0000000000..f1521043e9
--- /dev/null
+++ b/tools/cbfstool/common.h
@@ -0,0 +1,240 @@
+/*
+ * Copyright (C) 2009 coresystems GmbH
+ *                 written by Patrick Georgi <patrick.georgi@coresystems.de>
+ * Copyright (C) 2012 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __CBFSTOOL_COMMON_H
+#define __CBFSTOOL_COMMON_H
+
+#include <stdbool.h>
+#include <stddef.h>
+#include <stdint.h>
+#include <string.h>
+#include <assert.h>
+
+#include <commonlib/helpers.h>
+#include <console/console.h>
+
+/* Endianness */
+#include "swab.h"
+
+#define IS_TOP_ALIGNED_ADDRESS(x)	((uint32_t)(x) > 0x80000000)
+
+#define unused __attribute__((unused))
+
+static inline uint32_t align_up(uint32_t value, uint32_t align)
+{
+	if (value % align)
+		value += align - (value % align);
+	return value;
+}
+
+/* Buffer and file I/O */
+struct buffer {
+	char *name;
+	char *data;
+	size_t offset;
+	size_t size;
+};
+
+static inline void *buffer_get(const struct buffer *b)
+{
+	return b->data;
+}
+
+static inline size_t buffer_size(const struct buffer *b)
+{
+	return b->size;
+}
+
+static inline size_t buffer_offset(const struct buffer *b)
+{
+	return b->offset;
+}
+
+/*
+ * Shrink a buffer toward the beginning of its previous space.
+ * Afterward, buffer_delete() remains the means of cleaning it up. */
+static inline void buffer_set_size(struct buffer *b, size_t size)
+{
+	b->size = size;
+}
+
+/* Initialize a buffer with the given constraints. */
+static inline void buffer_init(struct buffer *b, char *name, void *data,
+                               size_t size)
+{
+	b->name = name;
+	b->data = data;
+	b->size = size;
+	b->offset = 0;
+}
+
+/* Splice a buffer into another buffer. Note that it's up to the caller to
+ * bounds check the offset and size. The resulting buffer is backed by the same
+ * storage as the original, so although it is valid to buffer_delete() either
+ * one of them, doing so releases both simultaneously. */
+static inline void buffer_splice(struct buffer *dest, const struct buffer *src,
+                                 size_t offset, size_t size)
+{
+	dest->name = src->name;
+	dest->data = src->data + offset;
+	dest->offset = src->offset + offset;
+	dest->size = size;
+}
+
+/*
+ * Shallow copy a buffer. To clean up the resources, buffer_delete()
+ * either one, but not both. */
+static inline void buffer_clone(struct buffer *dest, const struct buffer *src)
+{
+	buffer_splice(dest, src, 0, src->size);
+}
+
+/*
+ * Shrink a buffer toward the end of its previous space.
+ * Afterward, buffer_delete() remains the means of cleaning it up. */
+static inline void buffer_seek(struct buffer *b, size_t size)
+{
+	b->offset += size;
+	b->size -= size;
+	b->data += size;
+}
+
+/* Returns whether the buffer begins with the specified magic bytes. */
+static inline bool buffer_check_magic(const struct buffer *b, const char *magic,
+							size_t magic_len)
+{
+	assert(magic);
+	return b && b->size >= magic_len &&
+					memcmp(b->data, magic, magic_len) == 0;
+}
+
+/* Returns the start of the underlying buffer, with the offset undone */
+static inline void *buffer_get_original_backing(const struct buffer *b)
+{
+	if (!b)
+		return NULL;
+	return buffer_get(b) - buffer_offset(b);
+}
+
+/* Creates an empty memory buffer with given size.
+ * Returns 0 on success, otherwise non-zero. */
+int buffer_create(struct buffer *buffer, size_t size, const char *name);
+
+/* Loads a file into memory buffer. Returns 0 on success, otherwise non-zero. */
+int buffer_from_file(struct buffer *buffer, const char *filename);
+
+/* Writes memory buffer content into file.
+ * Returns 0 on success, otherwise non-zero. */
+int buffer_write_file(struct buffer *buffer, const char *filename);
+
+/* Destroys a memory buffer. */
+void buffer_delete(struct buffer *buffer);
+
+const char *arch_to_string(uint32_t a);
+uint32_t string_to_arch(const char *arch_string);
+
+/* Compress in_len bytes from in, storing the result at out, returning the
+ * resulting length in out_len.
+ * Returns 0 on error,
+ *         != 0 otherwise, depending on the compressing function.
+ */
+typedef int (*comp_func_ptr) (char *in, int in_len, char *out, int *out_len);
+
+/* Decompress in_len bytes from in, storing the result at out, up to out_len
+ * bytes.
+ * Returns 0 on error,
+ *         != 0 otherwise, depending on the decompressing function.
+ */
+typedef int (*decomp_func_ptr) (char *in, int in_len, char *out, int out_len,
+				size_t *actual_size);
+
+enum comp_algo {
+	CBFS_COMPRESS_NONE = 0,
+	CBFS_COMPRESS_LZMA = 1,
+	CBFS_COMPRESS_LZ4 = 2,
+};
+
+struct typedesc_t {
+	uint32_t type;
+	const char *name;
+};
+
+static const struct typedesc_t types_cbfs_compression[] = {
+	{CBFS_COMPRESS_NONE, "none"},
+	{CBFS_COMPRESS_LZMA, "LZMA"},
+	{CBFS_COMPRESS_LZ4, "LZ4"},
+	{0, NULL},
+};
+
+comp_func_ptr compression_function(enum comp_algo algo);
+decomp_func_ptr decompression_function(enum comp_algo algo);
+
+uint64_t intfiletype(const char *name);
+
+/* cbfs-mkpayload.c */
+int parse_elf_to_payload(const struct buffer *input, struct buffer *output,
+			 enum comp_algo algo);
+int parse_fv_to_payload(const struct buffer *input, struct buffer *output,
+			enum comp_algo algo);
+int parse_fit_to_payload(const struct buffer *input, struct buffer *output,
+			 enum comp_algo algo);
+int parse_bzImage_to_payload(const struct buffer *input,
+			     struct buffer *output, const char *initrd,
+			     char *cmdline, enum comp_algo algo);
+int parse_flat_binary_to_payload(const struct buffer *input,
+				 struct buffer *output,
+				 uint32_t loadaddress,
+				 uint32_t entrypoint,
+				 enum comp_algo algo);
+/* cbfs-mkstage.c */
+int parse_elf_to_stage(const struct buffer *input, struct buffer *output,
+		       enum comp_algo algo, uint32_t *location,
+		       const char *ignore_section);
+/* location is TOP aligned. */
+int parse_elf_to_xip_stage(const struct buffer *input, struct buffer *output,
+				uint32_t *location, const char *ignore_section);
+
+void print_supported_architectures(void);
+void print_supported_filetypes(void);
+
+/* lzma/lzma.c */
+int do_lzma_compress(char *in, int in_len, char *out, int *out_len);
+int do_lzma_uncompress(char *dst, int dst_len, char *src, int src_len,
+			size_t *actual_size);
+
+/* xdr.c */
+struct xdr {
+	uint8_t (*get8)(struct buffer *input);
+	uint16_t (*get16)(struct buffer *input);
+	uint32_t (*get32)(struct buffer *input);
+	uint64_t (*get64)(struct buffer *input);
+	void (*put8)(struct buffer *input, uint8_t val);
+	void (*put16)(struct buffer *input, uint16_t val);
+	void (*put32)(struct buffer *input, uint32_t val);
+	void (*put64)(struct buffer *input, uint64_t val);
+};
+
+extern struct xdr xdr_le, xdr_be;
+size_t bgets(struct buffer *input, void *output, size_t len);
+size_t bputs(struct buffer *b, const void *data, size_t len);
+
+/* Returns a 0-terminated string containing a hex representation of
+ * len bytes starting at data.
+ * The string is malloc'd and it's the caller's responsibility to free
+ * the memory.
+ * On error, bintohex returns NULL.
+ */
+char *bintohex(uint8_t *data, size_t len);
+#endif
diff --git a/tools/cbfstool/commonlib/cbfs.h b/tools/cbfstool/commonlib/cbfs.h
new file mode 100644
index 0000000000..cadc8c92cc
--- /dev/null
+++ b/tools/cbfstool/commonlib/cbfs.h
@@ -0,0 +1,86 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _COMMONLIB_CBFS_H_
+#define _COMMONLIB_CBFS_H_
+
+#include <commonlib/cbfs_serialized.h>
+#include <commonlib/region.h>
+#include <vb2_api.h>
+
+/* Object representing cbfs files. */
+struct cbfsf {
+	struct region_device metadata;
+	struct region_device data;
+};
+
+/* Locate file by name and optional type. Returns 0 on succcess else < 0 on
+ * error.*/
+int cbfs_locate(struct cbfsf *fh, const struct region_device *cbfs,
+		const char *name, uint32_t *type);
+
+static inline void cbfs_file_data(struct region_device *data,
+					const struct cbfsf *file)
+{
+	rdev_chain(data, &file->data, 0, region_device_sz(&file->data));
+}
+
+static inline void cbfs_file_metadata(struct region_device *metadata,
+					const struct cbfsf *file)
+{
+	rdev_chain(metadata, &file->metadata, 0,
+			region_device_sz(&file->metadata));
+}
+
+/*
+ * Provide a handle to each cbfs file within a cbfs. The prev pointer represents
+ * the previous file (NULL on first invocation). The next object gets filled
+ * out with the next file. This returns < 0 on error, 0 on finding the next
+ * file, and > 0 at end of cbfs.
+ */
+int cbfs_for_each_file(const struct region_device *cbfs,
+			const struct cbfsf *prev, struct cbfsf *fh);
+
+/*
+ * Return the offset for each CBFS attribute in a CBFS file metadata region.
+ * The metadata must already be fully mapped by the caller. Will return the
+ * offset (relative to the start of the metadata) or 0 when there are no
+ * further attributes. Should be called with 0 to begin, then always with
+ * the previously returned value until it returns 0.
+ */
+size_t cbfs_for_each_attr(void *metadata, size_t metadata_size,
+			  size_t last_offset);
+
+/*
+ * Find out the decompression algorithm and decompressed size of a non-stage
+ * CBFS file (by parsing its metadata attributes), and return them with
+ * out-parameters. Returns 0 on success and < 0 on error.
+ */
+int cbfsf_decompression_info(struct cbfsf *fh, uint32_t *algo, size_t *size);
+
+/*
+ * Return the CBFS file type as out-parameter.
+ * Returns 0 on success and < 0 on error.
+ */
+int cbfsf_file_type(struct cbfsf *fh, uint32_t *ftype);
+
+/*
+ * Perform the vb2 hash over the CBFS region skipping empty file contents.
+ * Caller is responsible for providing the hash algorithm as well as storage
+ * for the final digest. Return 0 on success or non-zero on error.
+ */
+int cbfs_vb2_hash_contents(const struct region_device *cbfs,
+				enum vb2_hash_algorithm hash_alg, void *digest,
+				size_t digest_sz);
+
+#endif
diff --git a/tools/cbfstool/commonlib/cbfs_serialized.h b/tools/cbfstool/commonlib/cbfs_serialized.h
new file mode 100644
index 0000000000..b8c1b7f8fb
--- /dev/null
+++ b/tools/cbfstool/commonlib/cbfs_serialized.h
@@ -0,0 +1,241 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * Copyright (C) 2008 Jordan Crouse <jordan@cosmicpenguin.net>
+ * Copyright (C) 2012 Google, Inc.
+ * Copyright (C) 2013 The Chromium OS Authors. All rights reserved.
+ *
+ * This file is dual-licensed. You can choose between:
+ *   - The GNU GPL, version 2, as published by the Free Software Foundation
+ *   - The revised BSD license (without advertising clause)
+ *
+ * ---------------------------------------------------------------------------
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * ---------------------------------------------------------------------------
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. The name of the author may not be used to endorse or promote products
+ *    derived from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ * ---------------------------------------------------------------------------
+ */
+
+#ifndef _CBFS_SERIALIZED_H_
+#define _CBFS_SERIALIZED_H_
+
+#include <commonlib/compiler.h>
+#include <stdint.h>
+
+/** These are standard values for the known compression
+    algorithms that coreboot knows about for stages and
+    payloads.  Of course, other CBFS users can use whatever
+    values they want, as long as they understand them. */
+
+#define CBFS_COMPRESS_NONE  0
+#define CBFS_COMPRESS_LZMA  1
+#define CBFS_COMPRESS_LZ4   2
+
+/** These are standard component types for well known
+    components (i.e - those that coreboot needs to consume.
+    Users are welcome to use any other value for their
+    components */
+
+#define CBFS_TYPE_DELETED    0x00000000
+#define CBFS_TYPE_DELETED2   0xffffffff
+#define CBFS_TYPE_STAGE      0x10
+#define CBFS_TYPE_SELF       0x20
+#define CBFS_TYPE_FIT        0x21
+#define CBFS_TYPE_OPTIONROM  0x30
+#define CBFS_TYPE_BOOTSPLASH 0x40
+#define CBFS_TYPE_RAW        0x50
+#define CBFS_TYPE_VSA        0x51
+#define CBFS_TYPE_MBI        0x52
+#define CBFS_TYPE_MICROCODE  0x53
+#define CBFS_TYPE_FSP        0x60
+#define CBFS_TYPE_MRC        0x61
+#define CBFS_TYPE_MMA        0x62
+#define CBFS_TYPE_EFI        0x63
+#define CBFS_TYPE_STRUCT     0x70
+#define CBFS_COMPONENT_CMOS_DEFAULT 0xaa
+#define CBFS_TYPE_SPD          0xab
+#define CBFS_TYPE_MRC_CACHE    0xac
+#define CBFS_COMPONENT_CMOS_LAYOUT 0x01aa
+
+#define CBFS_HEADER_MAGIC  0x4F524243
+#define CBFS_HEADER_VERSION1 0x31313131
+#define CBFS_HEADER_VERSION2 0x31313132
+#define CBFS_HEADER_VERSION  CBFS_HEADER_VERSION2
+
+/* this is the master cbfs header - it must be located somewhere available
+ * to bootblock (to load romstage). The last 4 bytes in the image contain its
+ * relative offset from the end of the image (as a 32-bit signed integer). */
+
+struct cbfs_header {
+	uint32_t magic;
+	uint32_t version;
+	uint32_t romsize;
+	uint32_t bootblocksize;
+	uint32_t align; /* fixed to 64 bytes */
+	uint32_t offset;
+	uint32_t architecture;
+	uint32_t pad[1];
+} __packed;
+
+/* this used to be flexible, but wasn't ever set to something different. */
+#define CBFS_ALIGNMENT 64
+
+/* "Unknown" refers to CBFS headers version 1,
+ * before the architecture was defined (i.e., x86 only).
+ */
+#define CBFS_ARCHITECTURE_UNKNOWN  0xFFFFFFFF
+#define CBFS_ARCHITECTURE_X86      0x00000001
+#define CBFS_ARCHITECTURE_ARM      0x00000010
+
+/** This is a component header - every entry in the CBFS
+    will have this header.
+
+    This is how the component is arranged in the ROM:
+
+    --------------   <- 0
+    component header
+    --------------   <- sizeof(struct component)
+    component name
+    --------------   <- offset
+    data
+    ...
+    --------------   <- offset + len
+*/
+
+#define CBFS_FILE_MAGIC "LARCHIVE"
+
+struct cbfs_file {
+	char magic[8];
+	uint32_t len;
+	uint32_t type;
+	uint32_t attributes_offset;
+	uint32_t offset;
+} __packed;
+
+/* The common fields of extended cbfs file attributes.
+   Attributes are expected to start with tag/len, then append their
+   specific fields. */
+struct cbfs_file_attribute {
+	uint32_t tag;
+	/* len covers the whole structure, incl. tag and len */
+	uint32_t len;
+	uint8_t data[0];
+} __packed;
+
+/* Depending on how the header was initialized, it may be backed with 0x00 or
+ * 0xff. Support both. */
+#define CBFS_FILE_ATTR_TAG_UNUSED 0
+#define CBFS_FILE_ATTR_TAG_UNUSED2 0xffffffff
+#define CBFS_FILE_ATTR_TAG_COMPRESSION 0x42435a4c
+#define CBFS_FILE_ATTR_TAG_HASH 0x68736148
+#define CBFS_FILE_ATTR_TAG_POSITION 0x42435350  /* PSCB */
+#define CBFS_FILE_ATTR_TAG_ALIGNMENT 0x42434c41 /* ALCB */
+
+struct cbfs_file_attr_compression {
+	uint32_t tag;
+	uint32_t len;
+	/* whole file compression format. 0 if no compression. */
+	uint32_t compression;
+	uint32_t decompressed_size;
+} __packed;
+
+struct cbfs_file_attr_hash {
+	uint32_t tag;
+	uint32_t len;
+	uint32_t hash_type;
+	/* hash_data is len - sizeof(struct) bytes */
+	uint8_t  hash_data[];
+} __packed;
+
+struct cbfs_file_attr_position {
+	uint32_t tag;
+	uint32_t len;
+	uint32_t position;
+} __packed;
+
+struct cbfs_file_attr_align {
+	uint32_t tag;
+	uint32_t len;
+	uint32_t alignment;
+} __packed;
+
+/*
+ * ROMCC does not understand uint64_t, so we hide future definitions as they are
+ * unlikely to be ever needed from ROMCC
+ */
+#ifndef __ROMCC__
+
+/*** Component sub-headers ***/
+
+/* Following are component sub-headers for the "standard"
+   component types */
+
+/** This is the sub-header for stage components.  Stages are
+    loaded by coreboot during the normal boot process */
+
+struct cbfs_stage {
+	uint32_t compression;  /** Compression type */
+	uint64_t entry;  /** entry point */
+	uint64_t load;   /** Where to load in memory */
+	uint32_t len;          /** length of data to load */
+	uint32_t memlen;	   /** total length of object in memory */
+} __packed;
+
+/** this is the sub-header for payload components.  Payloads
+    are loaded by coreboot at the end of the boot process */
+
+struct cbfs_payload_segment {
+	uint32_t type;
+	uint32_t compression;
+	uint32_t offset;
+	uint64_t load_addr;
+	uint32_t len;
+	uint32_t mem_len;
+} __packed;
+
+struct cbfs_payload {
+	struct cbfs_payload_segment segments;
+};
+
+#define PAYLOAD_SEGMENT_CODE   0x434F4445
+#define PAYLOAD_SEGMENT_DATA   0x44415441
+#define PAYLOAD_SEGMENT_BSS    0x42535320
+#define PAYLOAD_SEGMENT_PARAMS 0x50415241
+#define PAYLOAD_SEGMENT_ENTRY  0x454E5452
+
+struct cbfs_optionrom {
+	uint32_t compression;
+	uint32_t len;
+} __packed;
+
+#endif /* __ROMCC__ */
+
+#endif /* _CBFS_SERIALIZED_H_ */
diff --git a/tools/cbfstool/commonlib/compiler.h b/tools/cbfstool/commonlib/compiler.h
new file mode 100644
index 0000000000..972a2293a2
--- /dev/null
+++ b/tools/cbfstool/commonlib/compiler.h
@@ -0,0 +1,64 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _COMMONLIB_COMPILER_H_
+#define _COMMONLIB_COMPILER_H_
+
+#ifndef __packed
+#if defined(__WIN32) || defined(__WIN64)
+#define __packed __attribute__((gcc_struct, packed))
+#else
+#define __packed __attribute__((packed))
+#endif
+#endif
+
+#ifndef __aligned
+#define __aligned(x) __attribute__((aligned(x)))
+#endif
+
+#ifndef __always_unused
+#define __always_unused __attribute__((unused))
+#endif
+
+#ifndef __must_check
+#define __must_check __attribute__((warn_unused_result))
+#endif
+
+#ifndef __weak
+#define __weak __attribute__((weak))
+#endif
+
+#ifndef __noreturn
+#define __noreturn __attribute__((noreturn))
+#endif
+
+#ifndef __always_inline
+#define __always_inline inline __attribute__((always_inline))
+#endif
+
+/* This evaluates to the type of the first expression, unless that is constant
+   in which case it evalutates to the type of the second. This is useful when
+   assigning macro parameters to temporary variables, because that would
+   normally circumvent the special loosened type promotion rules for integer
+   literals. By using this macro, the promotion can happen at the time the
+   literal is assigned to the temporary variable. If the literal doesn't fit in
+   the chosen type, -Werror=overflow will catch it, so this should be safe. */
+#define __TYPEOF_UNLESS_CONST(expr, fallback_expr) __typeof__( \
+	__builtin_choose_expr(__builtin_constant_p(expr), fallback_expr, expr))
+
+/* This creates a unique local variable name for use in macros. */
+#define __TMPNAME_3(i) __tmpname_##i
+#define __TMPNAME_2(i) __TMPNAME_3(i)
+#define __TMPNAME __TMPNAME_2(__COUNTER__)
+
+#endif
diff --git a/tools/cbfstool/commonlib/compression.h b/tools/cbfstool/commonlib/compression.h
new file mode 100644
index 0000000000..3988ef8ade
--- /dev/null
+++ b/tools/cbfstool/commonlib/compression.h
@@ -0,0 +1,32 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _COMMONLIB_COMPRESSION_H_
+#define _COMMONLIB_COMPRESSION_H_
+
+#include <stddef.h>
+
+/* Decompresses an LZ4F image (multiple LZ4 blocks with frame header) from src
+ * to dst, ensuring that it doesn't read more than srcn bytes and doesn't write
+ * more than dstn. Buffer sizes must stay below 2GB. Can decompress files loaded
+ * to the end of a buffer in-place, as long as buffer is larger than the final
+ * output size. (Usually just a few bytes, but may be up to (8 + dstn/255) in
+ * worst case. Will reliably return an error if buffer was too small.)
+ * Returns amount of decompressed bytes, or 0 on error.
+ */
+size_t ulz4fn(const void *src, size_t srcn, void *dst, size_t dstn);
+
+/* Same as ulz4fn() but does not perform any bounds checks. */
+size_t ulz4f(const void *src, void *dst);
+
+#endif	/* _COMMONLIB_COMPRESSION_H_ */
diff --git a/tools/cbfstool/commonlib/endian.h b/tools/cbfstool/commonlib/endian.h
new file mode 100644
index 0000000000..3d7ccb112b
--- /dev/null
+++ b/tools/cbfstool/commonlib/endian.h
@@ -0,0 +1,261 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _COMMONLIB_ENDIAN_H_
+#define _COMMONLIB_ENDIAN_H_
+
+#include <stddef.h>
+#include <stdint.h>
+#include <string.h>
+
+/* Endian agnostic functions working on single byte. */
+
+static inline uint8_t read_ble8(const void *src)
+{
+	const uint8_t *s = src;
+	return *s;
+}
+
+static inline uint8_t read_at_ble8(const void *src, size_t offset)
+{
+	const uint8_t *s = src;
+	s += offset;
+	return read_ble8(s);
+}
+
+static inline void write_ble8(void *dest, uint8_t val)
+{
+	*(uint8_t *)dest = val;
+}
+
+static inline void write_at_ble8(void *dest, uint8_t val, size_t offset)
+{
+	uint8_t *d = dest;
+	d += offset;
+	write_ble8(d, val);
+}
+
+/* Big Endian functions. */
+
+static inline uint8_t read_be8(const void *src)
+{
+	return read_ble8(src);
+}
+
+static inline uint8_t read_at_be8(const void *src, size_t offset)
+{
+	return read_at_ble8(src, offset);
+}
+
+static inline void write_be8(void *dest, uint8_t val)
+{
+	write_ble8(dest, val);
+}
+
+static inline void write_at_be8(void *dest, uint8_t val, size_t offset)
+{
+	write_at_ble8(dest, val, offset);
+}
+
+static inline uint16_t read_be16(const void *src)
+{
+	const uint8_t *s = src;
+	return (((uint16_t)s[0]) << 8) | (((uint16_t)s[1]) << 0);
+}
+
+static inline uint16_t read_at_be16(const void *src, size_t offset)
+{
+	const uint8_t *s = src;
+	s += offset;
+	return read_be16(s);
+}
+
+static inline void write_be16(void *dest, uint16_t val)
+{
+	write_be8(dest, val >> 8);
+	write_at_be8(dest, val >> 0, sizeof(uint8_t));
+}
+
+static inline void write_at_be16(void *dest, uint16_t val, size_t offset)
+{
+	uint8_t *d = dest;
+	d += offset;
+	write_be16(d, val);
+}
+
+static inline uint32_t read_be32(const void *src)
+{
+	const uint8_t *s = src;
+	return (((uint32_t)s[0]) << 24) | (((uint32_t)s[1]) << 16) |
+		(((uint32_t)s[2]) << 8) | (((uint32_t)s[3]) << 0);
+}
+
+static inline uint32_t read_at_be32(const void *src, size_t offset)
+{
+	const uint8_t *s = src;
+	s += offset;
+	return read_be32(s);
+}
+
+static inline void write_be32(void *dest, uint32_t val)
+{
+	write_be16(dest, val >> 16);
+	write_at_be16(dest, val >> 0, sizeof(uint16_t));
+}
+
+static inline void write_at_be32(void *dest, uint32_t val, size_t offset)
+{
+	uint8_t *d = dest;
+	d += offset;
+	write_be32(d, val);
+}
+
+static inline uint64_t read_be64(const void *src)
+{
+	uint64_t val;
+	val = read_be32(src);
+	val <<= 32;
+	val |= read_at_be32(src, sizeof(uint32_t));
+	return val;
+}
+
+static inline uint64_t read_at_be64(const void *src, size_t offset)
+{
+	const uint8_t *s = src;
+	s += offset;
+	return read_be64(s);
+}
+
+static inline void write_be64(void *dest, uint64_t val)
+{
+	write_be32(dest, val >> 32);
+	write_at_be32(dest, val >> 0, sizeof(uint32_t));
+}
+
+static inline void write_at_be64(void *dest, uint64_t val, size_t offset)
+{
+	uint8_t *d = dest;
+	d += offset;
+	write_be64(d, val);
+}
+
+/* Little Endian functions. */
+
+static inline uint8_t read_le8(const void *src)
+{
+	return read_ble8(src);
+}
+
+static inline uint8_t read_at_le8(const void *src, size_t offset)
+{
+	return read_at_ble8(src, offset);
+}
+
+static inline void write_le8(void *dest, uint8_t val)
+{
+	write_ble8(dest, val);
+}
+
+static inline void write_at_le8(void *dest, uint8_t val, size_t offset)
+{
+	write_at_ble8(dest, val, offset);
+}
+
+static inline uint16_t read_le16(const void *src)
+{
+	const uint8_t *s = src;
+	return (((uint16_t)s[1]) << 8) | (((uint16_t)s[0]) << 0);
+}
+
+static inline uint16_t read_at_le16(const void *src, size_t offset)
+{
+	const uint8_t *s = src;
+	s += offset;
+	return read_le16(s);
+}
+
+static inline void write_le16(void *dest, uint16_t val)
+{
+	write_le8(dest, val >> 0);
+	write_at_le8(dest, val >> 8, sizeof(uint8_t));
+}
+
+static inline void write_at_le16(void *dest, uint16_t val, size_t offset)
+{
+	uint8_t *d = dest;
+	d += offset;
+	write_le16(d, val);
+}
+
+static inline uint32_t read_le32(const void *src)
+{
+	const uint8_t *s = src;
+	return (((uint32_t)s[3]) << 24) | (((uint32_t)s[2]) << 16) |
+		(((uint32_t)s[1]) << 8) | (((uint32_t)s[0]) << 0);
+}
+
+static inline uint32_t read_at_le32(const void *src, size_t offset)
+{
+	const uint8_t *s = src;
+	s += offset;
+	return read_le32(s);
+}
+
+static inline void write_le32(void *dest, uint32_t val)
+{
+	write_le16(dest, val >> 0);
+	write_at_le16(dest, val >> 16, sizeof(uint16_t));
+}
+
+static inline void write_at_le32(void *dest, uint32_t val, size_t offset)
+{
+	uint8_t *d = dest;
+	d += offset;
+	write_le32(d, val);
+}
+
+static inline uint64_t read_le64(const void *src)
+{
+	uint64_t val;
+	val = read_at_le32(src, sizeof(uint32_t));
+	val <<= 32;
+	val |= read_le32(src);
+	return val;
+}
+
+static inline uint64_t read_at_le64(const void *src, size_t offset)
+{
+	const uint8_t *s = src;
+	s += offset;
+	return read_le64(s);
+}
+
+static inline void write_le64(void *dest, uint64_t val)
+{
+	write_le32(dest, val >> 0);
+	write_at_le32(dest, val >> 32, sizeof(uint32_t));
+}
+
+static inline void write_at_le64(void *dest, uint64_t val, size_t offset)
+{
+	uint8_t *d = dest;
+	d += offset;
+	write_le64(d, val);
+}
+
+static inline void zero_n(void *dest, size_t n)
+{
+	memset(dest, 0, n);
+}
+
+#endif
diff --git a/tools/cbfstool/commonlib/fsp.h b/tools/cbfstool/commonlib/fsp.h
new file mode 100644
index 0000000000..2ae7949c8e
--- /dev/null
+++ b/tools/cbfstool/commonlib/fsp.h
@@ -0,0 +1,30 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _COMMONLIB_FSP_H_
+#define _COMMONLIB_FSP_H_
+
+#include <stddef.h>
+#include <stdint.h>
+#include <sys/types.h>
+
+/*
+ * Relocate FSP held within buffer defined by size to new_addr. Returns < 0
+ * on error, offset to FSP_INFO_HEADER on success.
+ */
+ssize_t fsp_component_relocate(uintptr_t new_addr, void *fsp, size_t size);
+
+/* API to relocate fsp 1.1 component. */
+ssize_t fsp1_1_relocate(uintptr_t new_addr, void *fsp, size_t size);
+
+#endif
diff --git a/tools/cbfstool/commonlib/helpers.h b/tools/cbfstool/commonlib/helpers.h
new file mode 100644
index 0000000000..4429ea41c3
--- /dev/null
+++ b/tools/cbfstool/commonlib/helpers.h
@@ -0,0 +1,140 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef COMMONLIB_HELPERS_H
+#define COMMONLIB_HELPERS_H
+/* This file is for helpers for both coreboot firmware and its utilities. */
+
+#ifndef __ASSEMBLER__
+#include <commonlib/compiler.h>
+#include <stddef.h>
+#endif
+
+#ifndef ARRAY_SIZE
+#define ARRAY_SIZE(a) (sizeof(a) / sizeof((a)[0]))
+#endif
+
+#define ALIGN(x, a)             __ALIGN_MASK(x, (__typeof__(x))(a)-1UL)
+#define __ALIGN_MASK(x, mask)   (((x)+(mask))&~(mask))
+#define ALIGN_UP(x, a)          ALIGN((x), (a))
+#define ALIGN_DOWN(x, a)        ((x) & ~((__typeof__(x))(a)-1UL))
+#define IS_ALIGNED(x, a)        (((x) & ((__typeof__(x))(a)-1UL)) == 0)
+
+/* Double-evaluation unsafe min/max, for bitfields and outside of functions */
+#define __CMP_UNSAFE(a, b, op) ((a) op (b) ? (a) : (b))
+#define MIN_UNSAFE(a, b) __CMP_UNSAFE(a, b, <)
+#define MAX_UNSAFE(a, b) __CMP_UNSAFE(a, b, >)
+
+#define __CMP_SAFE(a, b, op, var_a, var_b) ({ \
+	__TYPEOF_UNLESS_CONST(a, b) var_a = (a); \
+	__TYPEOF_UNLESS_CONST(b, a) var_b = (b); \
+	var_a op var_b ? var_a : var_b; \
+})
+
+#ifdef __ROMCC__	/* romcc doesn't support __builtin_choose_expr() */
+#define __CMP(a, b, op) __CMP_UNSAFE(a, b, op)
+#else
+#define __CMP(a, b, op) __builtin_choose_expr( \
+	__builtin_constant_p(a) && __builtin_constant_p(b), \
+	__CMP_UNSAFE(a, b, op), __CMP_SAFE(a, b, op, __TMPNAME, __TMPNAME))
+#endif
+
+#ifndef MIN
+#define MIN(a, b) __CMP(a, b, <)
+#endif
+#ifndef MAX
+#define MAX(a, b) __CMP(a, b, >)
+#endif
+
+#ifndef ABS
+#define ABS(a) ({ \
+	__typeof__(a) _abs_local_a = (a); \
+	(_abs_local_a < 0) ? (-_abs_local_a) : _abs_local_a; \
+})
+#endif
+
+#define IS_POWER_OF_2(x) ({ \
+	__typeof__(x) _power_local_x = (x); \
+	(_power_local_x & (_power_local_x - 1)) == 0; \
+})
+
+#define DIV_ROUND_UP(x, y) ({ \
+	__typeof__(x) _div_local_x = (x); \
+	__typeof__(y) _div_local_y = (y); \
+	(_div_local_x + _div_local_y - 1) / _div_local_y; \
+})
+
+#define SWAP(a, b) do { \
+	__typeof__(&(a)) _swap_local_a = &(a); \
+	__typeof__(&(b)) _swap_local_b = &(b); \
+	__typeof__(a) _swap_local_tmp = *_swap_local_a; \
+	*_swap_local_a = *_swap_local_b; \
+	*_swap_local_b = _swap_local_tmp; \
+} while (0)
+
+/*
+ * Divide positive or negative dividend by positive divisor and round
+ * to closest integer. Result is undefined for negative divisors and
+ * for negative dividends if the divisor variable type is unsigned.
+ */
+#define DIV_ROUND_CLOSEST(x, divisor)({					\
+	__typeof__(x) _div_local_x = (x);				\
+	__typeof__(divisor) _div_local_d = (divisor);			\
+	(((__typeof__(x))-1) > 0 ||					\
+	 ((__typeof__(divisor))-1) > 0 || (_div_local_x) > 0) ?		\
+		((_div_local_x + (_div_local_d / 2)) / _div_local_d) :	\
+		((_div_local_x - (_div_local_d / 2)) / _div_local_d);	\
+})
+
+/* Standard units. */
+#define KiB (1<<10)
+#define MiB (1<<20)
+#define GiB (1<<30)
+/* Could we ever run into this one? I hope we get this much memory! */
+#define TiB (1<<40)
+
+#define KHz (1000)
+#define MHz (1000 * KHz)
+#define GHz (1000 * MHz)
+
+#ifndef offsetof
+#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
+#endif
+
+#if !defined(__clang__)
+#define check_member(structure, member, offset) _Static_assert( \
+	offsetof(struct structure, member) == offset, \
+	"`struct " #structure "` offset for `" #member "` is not " #offset)
+#else
+#define check_member(structure, member, offset)
+#endif
+
+/**
+ * container_of - cast a member of a structure out to the containing structure
+ * @param ptr:    the pointer to the member.
+ * @param type:   the type of the container struct this is embedded in.
+ * @param member: the name of the member within the struct.
+ *
+ */
+#define container_of(ptr, type, member) ({			\
+	const __typeof__(((type *)0)->member) *__mptr = (ptr);	\
+	(type *)((char *)__mptr - offsetof(type, member)); })
+
+/* Calculate size of structure member. */
+#define member_size(type, member)	(sizeof(((type *)0)->member))
+
+#ifndef __unused
+#define __unused __attribute__((unused))
+#endif
+
+#endif /* COMMONLIB_HELPERS_H */
diff --git a/tools/cbfstool/commonlib/loglevel.h b/tools/cbfstool/commonlib/loglevel.h
new file mode 100644
index 0000000000..7a1654179d
--- /dev/null
+++ b/tools/cbfstool/commonlib/loglevel.h
@@ -0,0 +1,172 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef LOGLEVEL_H
+#define LOGLEVEL_H
+
+/**
+ * @file loglevel.h
+ *
+ * \brief Definitions of the log levels to be used in printk calls.
+ *
+ * Safe for inclusion in assembly.
+ *
+ */
+
+/**
+ * \brief BIOS_EMERG - Emergency / Fatal
+ *
+ * Log level for when the system is entirely unusable. To be used when execution
+ * is halting as a result of the failure. No further instructions should run.
+ *
+ * Example - End of all debug output / death notice.
+ *
+ * @{
+ */
+#define BIOS_EMERG      0
+/** @} */
+
+/**
+ * \brief BIOS_ALERT - Dying / Unrecoverable
+ *
+ * Log level for when the system is certainly in the process of dying.
+ * To be used when execution will eventually halt as a result of the
+ * failure, but the system can still output valuable debugging
+ * information.
+ *
+ * Example - Ram initialization fails, dumping relevant POST codes and
+ * information
+ *
+ * @{
+ */
+#define BIOS_ALERT      1
+/** @} */
+
+/**
+ * \brief BIOS_CRIT - Recovery unlikely
+ *
+ * Log level for when the system has experienced a dire issue in essential
+ * components. To be used when boot will probably be unsuccessful as a
+ * result of the failure, but recovery/retry can be attempted.
+ *
+ * Example - MSR failures, SMM/SMI failures.
+ * or
+ *
+ * @{
+ */
+#define BIOS_CRIT       2
+/** @} */
+
+/**
+ * \brief BIOS_ERR - System in incomplete state.
+ *
+ * Log level for when the system has experienced an issue that may not preclude
+ * a successful boot. To be used when coreboot execution may still succeed,
+ * but the error places some non-essential portion of the machine in a broken
+ * state that will be noticed downstream.
+ *
+ * Example - Payload could still load, but will be missing access to integral
+ * components such as drives.
+ *
+ * @{
+ */
+#define BIOS_ERR        3
+/** @} */
+
+/**
+ * \brief BIOS_WARNING - Bad configuration
+ *
+ * Log level for when the system has noticed an issue that most likely will
+ * not preclude a successful boot. To be used when something is wrong, and
+ * would likely be noticed by an end user.
+ *
+ * Example - Bad ME firmware, bad microcode, mis-clocked CPU
+ *
+ * @{
+ */
+#define BIOS_WARNING    4
+/** @} */
+
+/**
+ * \brief BIOS_NOTICE - Unexpected but relatively insignificant
+ *
+ * Log level for when the system has noticed an issue that is an edge case,
+ * but is handled and is recoverable. To be used when an end-user would likely
+ * not notice.
+ *
+ * Example - Hardware was misconfigured, but is promptly fixed.
+ *
+ * @{
+ */
+#define BIOS_NOTICE     5
+/** @} */
+
+/**
+ * \brief BIOS_INFO - Expected events.
+ *
+ * Log level for when the system has experienced some typical event.
+ * Messages should be superficial in nature.
+ *
+ * Example - Success messages. Status messages.
+ *
+ * @{
+ */
+#define BIOS_INFO       6
+/** @} */
+
+/**
+ * \brief BIOS_DEBUG - Verbose output
+ *
+ * Log level for details of a method. Messages may be dense,
+ * but should not be excessive. Messages should be detailed enough
+ * that this level provides sufficient details to diagnose a problem,
+ * but not necessarily enough to fix it.
+ *
+ * Example - Printing of important variables.
+ *
+ * @{
+ */
+#define BIOS_DEBUG      7
+/** @} */
+
+/**
+ * \brief BIOS_SPEW - Excessively verbose output
+ *
+ * Log level for intricacies of a method. Messages might contain raw
+ * data and will produce large logs. Developers should try to make sure
+ * that this level is not useful to anyone besides developers.
+ *
+ * Example - Data dumps.
+ *
+ * @{
+ */
+#define BIOS_SPEW       8
+/** @} */
+
+/**
+ * \brief BIOS_NEVER - Muted log level.
+ *
+ * Roughly equal to commenting out a printk statement. Because a user
+ * should not set their log level higher than 8, these statements
+ * are never printed.
+ *
+ * Example - A developer might locally define MY_LOGLEVEL to BIOS_SPEW,
+ * and later replace it with BIOS_NEVER as to mute their debug output.
+ *
+ * @{
+ */
+#define BIOS_NEVER	9
+/** @} */
+
+#endif /* LOGLEVEL_H */
diff --git a/tools/cbfstool/commonlib/mem_pool.h b/tools/cbfstool/commonlib/mem_pool.h
new file mode 100644
index 0000000000..ed473ebdf2
--- /dev/null
+++ b/tools/cbfstool/commonlib/mem_pool.h
@@ -0,0 +1,67 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _MEM_POOL_H_
+#define _MEM_POOL_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+/*
+ * The memory pool allows one to allocate memory from a fixed size buffer
+ * that also allows freeing semantics for reuse. However, the current
+ * limitation is that the most recent allocation is the only one that
+ * can be freed. If one tries to free any allocation that isn't the
+ * most recently allocated it will result in a leak within the memory pool.
+ *
+ * The memory returned by allocations are at least 8 byte aligned. Note
+ * that this requires the backing buffer to start on at least an 8 byte
+ * alignment.
+ */
+
+struct mem_pool {
+	uint8_t *buf;
+	size_t size;
+	uint8_t *last_alloc;
+	size_t free_offset;
+};
+
+#define MEM_POOL_INIT(buf_, size_)	\
+	{				\
+		.buf = (buf_),		\
+		.size = (size_),	\
+		.last_alloc = NULL,	\
+		.free_offset = 0,	\
+	}
+
+static inline void mem_pool_reset(struct mem_pool *mp)
+{
+	mp->last_alloc = NULL;
+	mp->free_offset = 0;
+}
+
+/* Initialize a memory pool. */
+static inline void mem_pool_init(struct mem_pool *mp, void *buf, size_t sz)
+{
+	mp->buf = buf;
+	mp->size = sz;
+	mem_pool_reset(mp);
+}
+
+/* Allocate requested size from the memory pool. NULL returned on error. */
+void *mem_pool_alloc(struct mem_pool *mp, size_t sz);
+
+/* Free allocation from memory pool. */
+void mem_pool_free(struct mem_pool *mp, void *alloc);
+
+#endif /* _MEM_POOL_H_ */
diff --git a/tools/cbfstool/commonlib/region.h b/tools/cbfstool/commonlib/region.h
new file mode 100644
index 0000000000..dca12dc741
--- /dev/null
+++ b/tools/cbfstool/commonlib/region.h
@@ -0,0 +1,272 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _REGION_H_
+#define _REGION_H_
+
+#include <sys/types.h>
+#include <stdint.h>
+#include <stddef.h>
+#include <commonlib/mem_pool.h>
+
+/*
+ * Region support.
+ *
+ * Regions are intended to abstract away the access mechanisms for blocks of
+ * data. This could be SPI, eMMC, or a memory region as the backing store.
+ * They are accessed through a region_device.  Subregions can be made by
+ * chaining together multiple region_devices.
+ */
+
+struct region_device;
+
+/*
+ * Returns NULL on error otherwise a buffer is returned with the conents of
+ * the requested data at offset of size.
+ */
+void *rdev_mmap(const struct region_device *rd, size_t offset, size_t size);
+
+/* Unmap a previously mapped area. Returns 0 on success, < 0 on error. */
+int rdev_munmap(const struct region_device *rd, void *mapping);
+
+/*
+ * Returns < 0 on error otherwise returns size of data read at provided
+ * offset filling in the buffer passed.
+ */
+ssize_t rdev_readat(const struct region_device *rd, void *b, size_t offset,
+			size_t size);
+
+/*
+ * Returns < 0 on error otherwise returns size of data wrote at provided
+ * offset from the buffer passed.
+ */
+ssize_t rdev_writeat(const struct region_device *rd, const void *b,
+			size_t offset, size_t size);
+
+/*
+ * Returns < 0 on error otherwise returns size of data erased.
+ * If eraseat ops is not defined it returns size which indicates
+ * that operation was successful.
+ */
+ssize_t rdev_eraseat(const struct region_device *rd, size_t offset,
+			size_t size);
+
+/****************************************
+ *  Implementation of a region device   *
+ ****************************************/
+
+/*
+ * Create a child region of the parent provided the sub-region is within
+ * the parent's region. Returns < 0 on error otherwise 0 on success. Note
+ * that the child device only calls through the parent's operations.
+ */
+int rdev_chain(struct region_device *child, const struct region_device *parent,
+		size_t offset, size_t size);
+
+
+/* A region_device operations. */
+struct region_device_ops {
+	void *(*mmap)(const struct region_device *, size_t, size_t);
+	int (*munmap)(const struct region_device *, void *);
+	ssize_t (*readat)(const struct region_device *, void *, size_t, size_t);
+	ssize_t (*writeat)(const struct region_device *, const void *, size_t,
+		size_t);
+	ssize_t (*eraseat)(const struct region_device *, size_t, size_t);
+};
+
+struct region {
+	size_t offset;
+	size_t size;
+};
+
+struct region_device {
+	const struct region_device *root;
+	const struct region_device_ops *ops;
+	struct region region;
+};
+
+#define REGION_DEV_INIT(ops_, offset_, size_)		\
+	{						\
+		.root = NULL,				\
+		.ops = (ops_),				\
+		.region = {				\
+			.offset = (offset_),		\
+			.size = (size_),		\
+		},					\
+	}
+
+/* Helper to dynamically initialize region device. */
+void region_device_init(struct region_device *rdev,
+			const struct region_device_ops *ops, size_t offset,
+			size_t size);
+
+/* Return 1 if child is subregion of parent, else 0. */
+int region_is_subregion(const struct region *p, const struct region *c);
+
+static inline size_t region_offset(const struct region *r)
+{
+	return r->offset;
+}
+
+static inline size_t region_sz(const struct region *r)
+{
+	return r->size;
+}
+
+static inline const struct region *region_device_region(
+					const struct region_device *rdev)
+{
+	return &rdev->region;
+}
+
+static inline size_t region_device_sz(const struct region_device *rdev)
+{
+	return region_sz(region_device_region(rdev));
+}
+
+static inline size_t region_device_offset(const struct region_device *rdev)
+{
+	return region_offset(region_device_region(rdev));
+}
+
+/* Memory map entire region device. Same semantics as rdev_mmap() above. */
+static inline void *rdev_mmap_full(const struct region_device *rd)
+{
+	return rdev_mmap(rd, 0, region_device_sz(rd));
+}
+
+/*
+ * Compute relative offset of the child (c) w.r.t. the parent (p). Returns < 0
+ * when child is not within the parent's region.
+ */
+ssize_t rdev_relative_offset(const struct region_device *p,
+				const struct region_device *c);
+
+struct mem_region_device {
+	char *base;
+	struct region_device rdev;
+};
+
+/* Inititalize at runtime a mem_region_device. This would be used when
+ * the base and size are dynamic or can't be known during linking.
+ * There are two variants: read-only and read-write. */
+void mem_region_device_ro_init(struct mem_region_device *mdev, void *base,
+				size_t size);
+
+void mem_region_device_rw_init(struct mem_region_device *mdev, void *base,
+				size_t size);
+
+extern const struct region_device_ops mem_rdev_ro_ops;
+
+extern const struct region_device_ops mem_rdev_rw_ops;
+
+/* Statically initialize mem_region_device. */
+#define MEM_REGION_DEV_INIT(base_, size_, ops_)				\
+	{								\
+		.base = (void *)(base_),				\
+		.rdev = REGION_DEV_INIT((ops_), 0, (size_)),		\
+	}
+
+#define MEM_REGION_DEV_RO_INIT(base_, size_)				\
+		MEM_REGION_DEV_INIT(base_, size_, &mem_rdev_ro_ops)	\
+
+#define MEM_REGION_DEV_RW_INIT(base_, size_)				\
+		MEM_REGION_DEV_INIT(base_, size_, &mem_rdev_rw_ops)	\
+
+struct mmap_helper_region_device {
+	struct mem_pool pool;
+	struct region_device rdev;
+};
+
+#define MMAP_HELPER_REGION_INIT(ops_, offset_, size_)			\
+	{								\
+		.rdev = REGION_DEV_INIT((ops_), (offset_), (size_)),	\
+	}
+
+void mmap_helper_device_init(struct mmap_helper_region_device *mdev,
+				void *cache, size_t cache_size);
+
+void *mmap_helper_rdev_mmap(const struct region_device *, size_t, size_t);
+int mmap_helper_rdev_munmap(const struct region_device *, void *);
+
+/* A translated region device provides the ability to publish a region device
+ * in one address space and use an access mechanism within another address
+ * space. The sub region is the window within the 1st address space and
+ * the request is modified prior to accessing the second address space
+ * provided by access_dev. */
+struct xlate_region_device {
+	const struct region_device *access_dev;
+	struct region sub_region;
+	struct region_device rdev;
+};
+
+extern const struct region_device_ops xlate_rdev_ro_ops;
+
+extern const struct region_device_ops xlate_rdev_rw_ops;
+
+#define XLATE_REGION_DEV_INIT(access_dev_, sub_offset_, sub_size_,	\
+		parent_sz_, ops_)					\
+	{								\
+		.access_dev = access_dev_,				\
+		.sub_region = {						\
+			.offset = (sub_offset_),			\
+			.size = (sub_size_),				\
+		},							\
+		.rdev = REGION_DEV_INIT((ops_), 0,  (parent_sz_)),	\
+	}
+
+#define XLATE_REGION_DEV_RO_INIT(access_dev_, sub_offset_, sub_size_,	\
+		parent_sz_)						\
+		XLATE_REGION_DEV_INIT(access_dev_, sub_offset_,		\
+			sub_size_, parent_sz_, &xlate_rdev_ro_ops),	\
+
+#define XLATE_REGION_DEV_RW_INIT(access_dev_, sub_offset_, sub_size_,	\
+		parent_sz_)						\
+		XLATE_REGION_DEV_INIT(access_dev_, sub_offset_,		\
+			sub_size_, parent_sz_, &xlate_rdev_rw_ops),	\
+
+/* Helper to dynamically initialize xlate region device. */
+void xlate_region_device_ro_init(struct xlate_region_device *xdev,
+			      const struct region_device *access_dev,
+			      size_t sub_offset, size_t sub_size,
+			      size_t parent_size);
+
+void xlate_region_device_rw_init(struct xlate_region_device *xdev,
+			      const struct region_device *access_dev,
+			      size_t sub_offset, size_t sub_size,
+			      size_t parent_size);
+
+/* This type can be used for incoherent access where the read and write
+ * operations are backed by separate drivers. An example is x86 systems
+ * with memory mapped media for reading but use a spi flash driver for
+ * writing. One needs to ensure using this object is appropriate in context. */
+struct incoherent_rdev {
+	struct region_device rdev;
+	const struct region_device *read;
+	const struct region_device *write;
+};
+
+/* Initialize an incoherent_rdev based on the region as well as the read and
+ * write rdevs. The read and write rdevs should match in size to the passed
+ * in region. If not the initialization will fail returning NULL. Otherwise
+ * the function will return a pointer to the containing region_device to
+ * be used for region operations. Therefore, the lifetime of the returned
+ * pointer matches the lifetime of the incoherent_rdev object. Likewise,
+ * the lifetime of the read and write rdev need to match the lifetime of
+ * the incoherent_rdev object. */
+const struct region_device *incoherent_rdev_init(struct incoherent_rdev *irdev,
+				const struct region *r,
+				const struct region_device *read,
+				const struct region_device *write);
+
+#endif /* _REGION_H_ */
diff --git a/tools/cbfstool/commonlib/rmodule-defs.h b/tools/cbfstool/commonlib/rmodule-defs.h
new file mode 100644
index 0000000000..de06941fa2
--- /dev/null
+++ b/tools/cbfstool/commonlib/rmodule-defs.h
@@ -0,0 +1,57 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+#ifndef RMODULE_DEFS_H
+#define RMODULE_DEFS_H
+
+#include <stdint.h>
+#include <stddef.h>
+
+#define RMODULE_MAGIC 0xf8fe
+#define RMODULE_VERSION_1 1
+
+/* All fields with '_offset' in the name are byte offsets into the flat blob.
+ * The linker and the linker script takes are of assigning the values.  */
+struct rmodule_header {
+	uint16_t magic;
+	uint8_t  version;
+	uint8_t  type;
+	/* The payload represents the program's loadable code and data. */
+	uint32_t payload_begin_offset;
+	uint32_t payload_end_offset;
+	/* Begin and of relocation information about the program module. */
+	uint32_t relocations_begin_offset;
+	uint32_t relocations_end_offset;
+	/* The starting address of the linked program. This address is vital
+	 * for determining relocation offsets as the relocation info and other
+	 * symbols (bss, entry point) need this value as a basis to calculate
+	 * the offsets.
+	 */
+	uint32_t module_link_start_address;
+	/* The module_program_size is the size of memory used while running
+	 * the program. The program is assumed to consume a contiguous amount
+	 * of memory. */
+	uint32_t module_program_size;
+	/* This is program's execution entry point. */
+	uint32_t module_entry_point;
+	/* Optional parameter structure that can be used to pass data into
+	 * the module. */
+	uint32_t parameters_begin;
+	uint32_t parameters_end;
+	/* BSS section information so the loader can clear the bss. */
+	uint32_t bss_begin;
+	uint32_t bss_end;
+	/* Add some room for growth. */
+	uint32_t padding[4];
+} __packed;
+
+#endif /* RMODULE_DEFS_H */
diff --git a/tools/cbfstool/compress.c b/tools/cbfstool/compress.c
new file mode 100644
index 0000000000..a6a0df4dd1
--- /dev/null
+++ b/tools/cbfstool/compress.c
@@ -0,0 +1,124 @@
+/*
+ * compression handling for cbfstool
+ *
+ * Copyright (C) 2009 coresystems GmbH
+ *                 written by Patrick Georgi <patrick.georgi@coresystems.de>
+ *
+ * Adapted from code
+ * Copyright (C) 2008 Jordan Crouse <jordan@cosmicpenguin.net>, released
+ * under identical license terms
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <string.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include "common.h"
+#include "lz4/lib/lz4frame.h"
+#include <commonlib/compression.h>
+
+static int lz4_compress(char *in, int in_len, char *out, int *out_len)
+{
+	LZ4F_preferences_t prefs = {
+		.compressionLevel = 20,
+		.frameInfo = {
+			.blockSizeID = max4MB,
+			.blockMode = blockIndependent,
+			.contentChecksumFlag = noContentChecksum,
+		},
+	};
+	size_t worst_size = LZ4F_compressFrameBound(in_len, &prefs);
+	void *bounce = malloc(worst_size);
+	if (!bounce)
+		return -1;
+	*out_len = LZ4F_compressFrame(bounce, worst_size, in, in_len, &prefs);
+	if (LZ4F_isError(*out_len) || *out_len >= in_len)
+		return -1;
+	memcpy(out, bounce, *out_len);
+	return 0;
+}
+
+static int lz4_decompress(char *in, int in_len, char *out, int out_len,
+			  size_t *actual_size)
+{
+	size_t result = ulz4fn(in, in_len, out, out_len);
+	if (result == 0)
+		return -1;
+	if (actual_size != NULL)
+		*actual_size = result;
+	return 0;
+}
+
+static int lzma_compress(char *in, int in_len, char *out, int *out_len)
+{
+	return do_lzma_compress(in, in_len, out, out_len);
+}
+
+static int lzma_decompress(char *in, int in_len, char *out, unused int out_len,
+				size_t *actual_size)
+{
+	return do_lzma_uncompress(out, out_len, in, in_len, actual_size);
+}
+static int none_compress(char *in, int in_len, char *out, int *out_len)
+{
+	memcpy(out, in, in_len);
+	*out_len = in_len;
+	return 0;
+}
+
+static int none_decompress(char *in, int in_len, char *out, unused int out_len,
+				size_t *actual_size)
+{
+	memcpy(out, in, in_len);
+	if (actual_size != NULL)
+		*actual_size = in_len;
+	return 0;
+}
+
+comp_func_ptr compression_function(enum comp_algo algo)
+{
+	comp_func_ptr compress;
+	switch (algo) {
+	case CBFS_COMPRESS_NONE:
+		compress = none_compress;
+		break;
+	case CBFS_COMPRESS_LZMA:
+		compress = lzma_compress;
+		break;
+	case CBFS_COMPRESS_LZ4:
+		compress = lz4_compress;
+		break;
+	default:
+		ERROR("Unknown compression algorithm %d!\n", algo);
+		return NULL;
+	}
+	return compress;
+}
+
+decomp_func_ptr decompression_function(enum comp_algo algo)
+{
+	decomp_func_ptr decompress;
+	switch (algo) {
+	case CBFS_COMPRESS_NONE:
+		decompress = none_decompress;
+		break;
+	case CBFS_COMPRESS_LZMA:
+		decompress = lzma_decompress;
+		break;
+	case CBFS_COMPRESS_LZ4:
+		decompress = lz4_decompress;
+		break;
+	default:
+		ERROR("Unknown compression algorithm %d!\n", algo);
+		return NULL;
+	}
+	return decompress;
+}
diff --git a/tools/cbfstool/console/console.h b/tools/cbfstool/console/console.h
new file mode 100644
index 0000000000..40c1436ace
--- /dev/null
+++ b/tools/cbfstool/console/console.h
@@ -0,0 +1,44 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * Copyright 2015 Google Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _CBFSTOOL_CONSOLE_H_
+#define _CBFSTOOL_CONSOLE_H_
+
+#include <stdio.h>
+#include <commonlib/loglevel.h>
+
+/* Message output */
+extern int verbose;
+#define ERROR(...) { fprintf(stderr, "E: " __VA_ARGS__); }
+#define WARN(...) { fprintf(stderr, "W: " __VA_ARGS__); }
+#define LOG(...) { fprintf(stderr, __VA_ARGS__); }
+#define INFO(...) { if (verbose > 0) fprintf(stderr, "INFO: " __VA_ARGS__); }
+#define DEBUG(...) { if (verbose > 1) fprintf(stderr, "DEBUG: " __VA_ARGS__); }
+
+
+#define printk(lvl, ...) \
+	{						\
+		if ((lvl) <= BIOS_ERR) {		\
+			ERROR(__VA_ARGS__);		\
+		} else if ((lvl) <= BIOS_NOTICE) {	\
+			WARN(__VA_ARGS__);		\
+		} else if ((lvl) <= BIOS_INFO) {	\
+			INFO(__VA_ARGS__);		\
+		} else if ((lvl) <= BIOS_DEBUG) {	\
+			DEBUG(__VA_ARGS__);		\
+		}					\
+	}
+
+#endif
diff --git a/tools/cbfstool/edk2/Base.h b/tools/cbfstool/edk2/Base.h
new file mode 100644
index 0000000000..c0ea9c1db8
--- /dev/null
+++ b/tools/cbfstool/edk2/Base.h
@@ -0,0 +1,1018 @@
+/** @file
+  Root include file for Mde Package Base type modules
+
+  This is the include file for any module of type base. Base modules only use
+  types defined via this include file and can be ported easily to any
+  environment. There are a set of base libraries in the Mde Package that can
+  be used to implement base modules.
+
+Copyright (c) 2006 - 2013, Intel Corporation. All rights reserved.<BR>
+Portions copyright (c) 2008 - 2009, Apple Inc. All rights reserved.<BR>
+This program and the accompanying materials
+are licensed and made available under the terms and conditions of the BSD License
+which accompanies this distribution.  The full text of the license may be found at
+http://opensource.org/licenses/bsd-license.php.
+
+THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+**/
+
+
+#ifndef __BASE_H__
+#define __BASE_H__
+
+//
+// Include processor specific binding
+//
+#include <ProcessorBind.h>
+
+
+/**
+  Verifies the storage size of a given data type.
+
+  This macro generates a divide by zero error or a zero size array declaration in
+  the preprocessor if the size is incorrect.  These are declared as "extern" so
+  the space for these arrays will not be in the modules.
+
+  @param  TYPE  The date type to determine the size of.
+  @param  Size  The expected size for the TYPE.
+
+**/
+#define VERIFY_SIZE_OF(TYPE, Size) extern UINT8 _VerifySizeof##TYPE[(sizeof(TYPE) == (Size)) / (sizeof(TYPE) == (Size))]
+
+//
+// Verify that ProcessorBind.h produced UEFI Data Types that are compliant with
+// Section 2.3.1 of the UEFI 2.3 Specification.
+//
+VERIFY_SIZE_OF (BOOLEAN, 1);
+VERIFY_SIZE_OF (INT8, 1);
+VERIFY_SIZE_OF (UINT8, 1);
+VERIFY_SIZE_OF (INT16, 2);
+VERIFY_SIZE_OF (UINT16, 2);
+VERIFY_SIZE_OF (INT32, 4);
+VERIFY_SIZE_OF (UINT32, 4);
+VERIFY_SIZE_OF (INT64, 8);
+VERIFY_SIZE_OF (UINT64, 8);
+VERIFY_SIZE_OF (CHAR8, 1);
+VERIFY_SIZE_OF (CHAR16, 2);
+
+//
+// The Microsoft* C compiler can removed references to unreferenced data items
+//  if the /OPT:REF linker option is used. We defined a macro as this is a
+//  a non standard extension
+//
+#if defined(_MSC_EXTENSIONS) && !defined (MDE_CPU_EBC)
+  ///
+  /// Remove global variable from the linked image if there are no references to
+  /// it after all compiler and linker optimizations have been performed.
+  ///
+  ///
+  #define GLOBAL_REMOVE_IF_UNREFERENCED __declspec(selectany)
+#else
+  ///
+  /// Remove the global variable from the linked image if there are no references
+  ///  to it after all compiler and linker optimizations have been performed.
+  ///
+  ///
+  #define GLOBAL_REMOVE_IF_UNREFERENCED
+#endif
+
+//
+// For symbol name in assembly code, an extra "_" is sometimes necessary
+//
+
+///
+/// Private worker functions for ASM_PFX()
+///
+#define _CONCATENATE(a, b)  __CONCATENATE(a, b)
+#define __CONCATENATE(a, b) a ## b
+
+///
+/// The __USER_LABEL_PREFIX__ macro predefined by GNUC represents the prefix
+/// on symbols in assembly language.
+///
+#define ASM_PFX(name) _CONCATENATE (__USER_LABEL_PREFIX__, name)
+
+#ifdef __CC_ARM
+  //
+  // Older RVCT ARM compilers don't fully support #pragma pack and require __packed
+  // as a prefix for the structure.
+  //
+  #define PACKED  __packed
+#else
+  #define PACKED
+#endif
+
+///
+/// 128 bit buffer containing a unique identifier value.
+/// Unless otherwise specified, aligned on a 64 bit boundary.
+///
+typedef struct {
+  UINT32  Data1;
+  UINT16  Data2;
+  UINT16  Data3;
+  UINT8   Data4[8];
+} GUID;
+
+//
+// 8-bytes unsigned value that represents a physical system address.
+//
+typedef UINT64 PHYSICAL_ADDRESS;
+
+///
+/// LIST_ENTRY structure definition.
+///
+typedef struct _LIST_ENTRY LIST_ENTRY;
+
+///
+/// _LIST_ENTRY structure definition.
+///
+struct _LIST_ENTRY {
+  LIST_ENTRY  *ForwardLink;
+  LIST_ENTRY  *BackLink;
+};
+
+//
+// Modifiers to abstract standard types to aid in debug of problems
+//
+
+///
+/// Datum is read-only.
+///
+#define CONST     const
+
+///
+/// Datum is scoped to the current file or function.
+///
+#define STATIC    static
+
+///
+/// Undeclared type.
+///
+#define VOID      void
+
+//
+// Modifiers for Data Types used to self document code.
+// This concept is borrowed for UEFI specification.
+//
+
+///
+/// Datum is passed to the function.
+///
+#define IN
+
+///
+/// Datum is returned from the function.
+///
+#define OUT
+
+///
+/// Passing the datum to the function is optional, and a NULL
+/// is passed if the value is not supplied.
+///
+#define OPTIONAL
+
+//
+//  UEFI specification claims 1 and 0. We are concerned about the
+//  complier portability so we did it this way.
+//
+
+///
+/// Boolean true value.  UEFI Specification defines this value to be 1,
+/// but this form is more portable.
+///
+#define TRUE  ((BOOLEAN)(1==1))
+
+///
+/// Boolean false value.  UEFI Specification defines this value to be 0,
+/// but this form is more portable.
+///
+#define FALSE ((BOOLEAN)(0==1))
+
+///
+/// NULL pointer (VOID *)
+///
+#ifndef NULL
+#define NULL  ((VOID *) 0)
+#endif
+
+///
+/// Maximum values for common UEFI Data Types
+///
+#define MAX_INT8    ((INT8)0x7F)
+#define MAX_UINT8   ((UINT8)0xFF)
+#define MAX_INT16   ((INT16)0x7FFF)
+#define MAX_UINT16  ((UINT16)0xFFFF)
+#define MAX_INT32   ((INT32)0x7FFFFFFF)
+#define MAX_UINT32  ((UINT32)0xFFFFFFFF)
+#define MAX_INT64   ((INT64)0x7FFFFFFFFFFFFFFFULL)
+#define MAX_UINT64  ((UINT64)0xFFFFFFFFFFFFFFFFULL)
+
+#define  BIT0     0x00000001
+#define  BIT1     0x00000002
+#define  BIT2     0x00000004
+#define  BIT3     0x00000008
+#define  BIT4     0x00000010
+#define  BIT5     0x00000020
+#define  BIT6     0x00000040
+#define  BIT7     0x00000080
+#define  BIT8     0x00000100
+#define  BIT9     0x00000200
+#define  BIT10    0x00000400
+#define  BIT11    0x00000800
+#define  BIT12    0x00001000
+#define  BIT13    0x00002000
+#define  BIT14    0x00004000
+#define  BIT15    0x00008000
+#define  BIT16    0x00010000
+#define  BIT17    0x00020000
+#define  BIT18    0x00040000
+#define  BIT19    0x00080000
+#define  BIT20    0x00100000
+#define  BIT21    0x00200000
+#define  BIT22    0x00400000
+#define  BIT23    0x00800000
+#define  BIT24    0x01000000
+#define  BIT25    0x02000000
+#define  BIT26    0x04000000
+#define  BIT27    0x08000000
+#define  BIT28    0x10000000
+#define  BIT29    0x20000000
+#define  BIT30    0x40000000
+#define  BIT31    0x80000000
+#define  BIT32    0x0000000100000000ULL
+#define  BIT33    0x0000000200000000ULL
+#define  BIT34    0x0000000400000000ULL
+#define  BIT35    0x0000000800000000ULL
+#define  BIT36    0x0000001000000000ULL
+#define  BIT37    0x0000002000000000ULL
+#define  BIT38    0x0000004000000000ULL
+#define  BIT39    0x0000008000000000ULL
+#define  BIT40    0x0000010000000000ULL
+#define  BIT41    0x0000020000000000ULL
+#define  BIT42    0x0000040000000000ULL
+#define  BIT43    0x0000080000000000ULL
+#define  BIT44    0x0000100000000000ULL
+#define  BIT45    0x0000200000000000ULL
+#define  BIT46    0x0000400000000000ULL
+#define  BIT47    0x0000800000000000ULL
+#define  BIT48    0x0001000000000000ULL
+#define  BIT49    0x0002000000000000ULL
+#define  BIT50    0x0004000000000000ULL
+#define  BIT51    0x0008000000000000ULL
+#define  BIT52    0x0010000000000000ULL
+#define  BIT53    0x0020000000000000ULL
+#define  BIT54    0x0040000000000000ULL
+#define  BIT55    0x0080000000000000ULL
+#define  BIT56    0x0100000000000000ULL
+#define  BIT57    0x0200000000000000ULL
+#define  BIT58    0x0400000000000000ULL
+#define  BIT59    0x0800000000000000ULL
+#define  BIT60    0x1000000000000000ULL
+#define  BIT61    0x2000000000000000ULL
+#define  BIT62    0x4000000000000000ULL
+#define  BIT63    0x8000000000000000ULL
+
+#define  SIZE_1KB    0x00000400
+#define  SIZE_2KB    0x00000800
+#define  SIZE_4KB    0x00001000
+#define  SIZE_8KB    0x00002000
+#define  SIZE_16KB   0x00004000
+#define  SIZE_32KB   0x00008000
+#define  SIZE_64KB   0x00010000
+#define  SIZE_128KB  0x00020000
+#define  SIZE_256KB  0x00040000
+#define  SIZE_512KB  0x00080000
+#define  SIZE_1MB    0x00100000
+#define  SIZE_2MB    0x00200000
+#define  SIZE_4MB    0x00400000
+#define  SIZE_8MB    0x00800000
+#define  SIZE_16MB   0x01000000
+#define  SIZE_32MB   0x02000000
+#define  SIZE_64MB   0x04000000
+#define  SIZE_128MB  0x08000000
+#define  SIZE_256MB  0x10000000
+#define  SIZE_512MB  0x20000000
+#define  SIZE_1GB    0x40000000
+#define  SIZE_2GB    0x80000000
+#define  SIZE_4GB    0x0000000100000000ULL
+#define  SIZE_8GB    0x0000000200000000ULL
+#define  SIZE_16GB   0x0000000400000000ULL
+#define  SIZE_32GB   0x0000000800000000ULL
+#define  SIZE_64GB   0x0000001000000000ULL
+#define  SIZE_128GB  0x0000002000000000ULL
+#define  SIZE_256GB  0x0000004000000000ULL
+#define  SIZE_512GB  0x0000008000000000ULL
+#define  SIZE_1TB    0x0000010000000000ULL
+#define  SIZE_2TB    0x0000020000000000ULL
+#define  SIZE_4TB    0x0000040000000000ULL
+#define  SIZE_8TB    0x0000080000000000ULL
+#define  SIZE_16TB   0x0000100000000000ULL
+#define  SIZE_32TB   0x0000200000000000ULL
+#define  SIZE_64TB   0x0000400000000000ULL
+#define  SIZE_128TB  0x0000800000000000ULL
+#define  SIZE_256TB  0x0001000000000000ULL
+#define  SIZE_512TB  0x0002000000000000ULL
+#define  SIZE_1PB    0x0004000000000000ULL
+#define  SIZE_2PB    0x0008000000000000ULL
+#define  SIZE_4PB    0x0010000000000000ULL
+#define  SIZE_8PB    0x0020000000000000ULL
+#define  SIZE_16PB   0x0040000000000000ULL
+#define  SIZE_32PB   0x0080000000000000ULL
+#define  SIZE_64PB   0x0100000000000000ULL
+#define  SIZE_128PB  0x0200000000000000ULL
+#define  SIZE_256PB  0x0400000000000000ULL
+#define  SIZE_512PB  0x0800000000000000ULL
+#define  SIZE_1EB    0x1000000000000000ULL
+#define  SIZE_2EB    0x2000000000000000ULL
+#define  SIZE_4EB    0x4000000000000000ULL
+#define  SIZE_8EB    0x8000000000000000ULL
+
+#define  BASE_1KB    0x00000400
+#define  BASE_2KB    0x00000800
+#define  BASE_4KB    0x00001000
+#define  BASE_8KB    0x00002000
+#define  BASE_16KB   0x00004000
+#define  BASE_32KB   0x00008000
+#define  BASE_64KB   0x00010000
+#define  BASE_128KB  0x00020000
+#define  BASE_256KB  0x00040000
+#define  BASE_512KB  0x00080000
+#define  BASE_1MB    0x00100000
+#define  BASE_2MB    0x00200000
+#define  BASE_4MB    0x00400000
+#define  BASE_8MB    0x00800000
+#define  BASE_16MB   0x01000000
+#define  BASE_32MB   0x02000000
+#define  BASE_64MB   0x04000000
+#define  BASE_128MB  0x08000000
+#define  BASE_256MB  0x10000000
+#define  BASE_512MB  0x20000000
+#define  BASE_1GB    0x40000000
+#define  BASE_2GB    0x80000000
+#define  BASE_4GB    0x0000000100000000ULL
+#define  BASE_8GB    0x0000000200000000ULL
+#define  BASE_16GB   0x0000000400000000ULL
+#define  BASE_32GB   0x0000000800000000ULL
+#define  BASE_64GB   0x0000001000000000ULL
+#define  BASE_128GB  0x0000002000000000ULL
+#define  BASE_256GB  0x0000004000000000ULL
+#define  BASE_512GB  0x0000008000000000ULL
+#define  BASE_1TB    0x0000010000000000ULL
+#define  BASE_2TB    0x0000020000000000ULL
+#define  BASE_4TB    0x0000040000000000ULL
+#define  BASE_8TB    0x0000080000000000ULL
+#define  BASE_16TB   0x0000100000000000ULL
+#define  BASE_32TB   0x0000200000000000ULL
+#define  BASE_64TB   0x0000400000000000ULL
+#define  BASE_128TB  0x0000800000000000ULL
+#define  BASE_256TB  0x0001000000000000ULL
+#define  BASE_512TB  0x0002000000000000ULL
+#define  BASE_1PB    0x0004000000000000ULL
+#define  BASE_2PB    0x0008000000000000ULL
+#define  BASE_4PB    0x0010000000000000ULL
+#define  BASE_8PB    0x0020000000000000ULL
+#define  BASE_16PB   0x0040000000000000ULL
+#define  BASE_32PB   0x0080000000000000ULL
+#define  BASE_64PB   0x0100000000000000ULL
+#define  BASE_128PB  0x0200000000000000ULL
+#define  BASE_256PB  0x0400000000000000ULL
+#define  BASE_512PB  0x0800000000000000ULL
+#define  BASE_1EB    0x1000000000000000ULL
+#define  BASE_2EB    0x2000000000000000ULL
+#define  BASE_4EB    0x4000000000000000ULL
+#define  BASE_8EB    0x8000000000000000ULL
+
+//
+//  Support for variable length argument lists using the ANSI standard.
+//
+//  Since we are using the ANSI standard we used the standard naming and
+//  did not follow the coding convention
+//
+//  VA_LIST  - typedef for argument list.
+//  VA_START (VA_LIST Marker, argument before the ...) - Init Marker for use.
+//  VA_END (VA_LIST Marker) - Clear Marker
+//  VA_ARG (VA_LIST Marker, var arg size) - Use Marker to get an argument from
+//    the ... list. You must know the size and pass it in this macro.
+//  VA_COPY (VA_LIST Dest, VA_LIST Start) - Initialize Dest as a copy of Start.
+//
+//  example:
+//
+//  UINTN
+//  ExampleVarArg (
+//    IN UINTN  NumberOfArgs,
+//    ...
+//    )
+//  {
+//    VA_LIST Marker;
+//    UINTN   Index;
+//    UINTN   Result;
+//
+//    //
+//    // Initialize the Marker
+//    //
+//    VA_START (Marker, NumberOfArgs);
+//    for (Index = 0, Result = 0; Index < NumberOfArgs; Index++) {
+//      //
+//      // The ... list is a series of UINTN values, so average them up.
+//      //
+//      Result += VA_ARG (Marker, UINTN);
+//    }
+//
+//    VA_END (Marker);
+//    return Result
+//  }
+//
+
+/**
+  Return the size of argument that has been aligned to sizeof (UINTN).
+
+  @param  n    The parameter size to be aligned.
+
+  @return The aligned size.
+**/
+#define _INT_SIZE_OF(n) ((sizeof (n) + sizeof (UINTN) - 1) &~(sizeof (UINTN) - 1))
+
+#if defined(__CC_ARM)
+//
+// RVCT ARM variable argument list support.
+//
+
+///
+/// Variable used to traverse the list of arguments. This type can vary by
+/// implementation and could be an array or structure.
+///
+#ifdef __APCS_ADSABI
+  typedef int         *va_list[1];
+  #define VA_LIST     va_list
+#else
+  typedef struct __va_list { void *__ap; } va_list;
+  #define VA_LIST                          va_list
+#endif
+
+#define VA_START(Marker, Parameter)   __va_start(Marker, Parameter)
+
+#define VA_ARG(Marker, TYPE)          __va_arg(Marker, TYPE)
+
+#define VA_END(Marker)                ((void)0)
+
+// For some ARM RVCT compilers, __va_copy is not defined
+#ifndef __va_copy
+  #define __va_copy(dest, src) ((void)((dest) = (src)))
+#endif
+
+#define VA_COPY(Dest, Start)          __va_copy (Dest, Start)
+
+#elif defined(__GNUC__) && !defined(NO_BUILTIN_VA_FUNCS)
+//
+// Use GCC built-in macros for variable argument lists.
+//
+
+///
+/// Variable used to traverse the list of arguments. This type can vary by
+/// implementation and could be an array or structure.
+///
+typedef __builtin_va_list VA_LIST;
+
+#define VA_START(Marker, Parameter)  __builtin_va_start (Marker, Parameter)
+
+#define VA_ARG(Marker, TYPE)         ((sizeof (TYPE) < sizeof (UINTN)) ? (TYPE)(__builtin_va_arg (Marker, UINTN)) : (TYPE)(__builtin_va_arg (Marker, TYPE)))
+
+#define VA_END(Marker)               __builtin_va_end (Marker)
+
+#define VA_COPY(Dest, Start)         __builtin_va_copy (Dest, Start)
+
+#else
+///
+/// Variable used to traverse the list of arguments. This type can vary by
+/// implementation and could be an array or structure.
+///
+typedef CHAR8 *VA_LIST;
+
+/**
+  Retrieves a pointer to the beginning of a variable argument list, based on
+  the name of the parameter that immediately precedes the variable argument list.
+
+  This function initializes Marker to point to the beginning of the variable
+  argument list that immediately follows Parameter.  The method for computing the
+  pointer to the next argument in the argument list is CPU-specific following the
+  EFIAPI ABI.
+
+  @param   Marker       The VA_LIST used to traverse the list of arguments.
+  @param   Parameter    The name of the parameter that immediately precedes
+                        the variable argument list.
+
+  @return  A pointer to the beginning of a variable argument list.
+
+**/
+#define VA_START(Marker, Parameter) (Marker = (VA_LIST) ((UINTN) & (Parameter) + _INT_SIZE_OF (Parameter)))
+
+/**
+  Returns an argument of a specified type from a variable argument list and updates
+  the pointer to the variable argument list to point to the next argument.
+
+  This function returns an argument of the type specified by TYPE from the beginning
+  of the variable argument list specified by Marker.  Marker is then updated to point
+  to the next argument in the variable argument list.  The method for computing the
+  pointer to the next argument in the argument list is CPU-specific following the EFIAPI ABI.
+
+  @param   Marker   VA_LIST used to traverse the list of arguments.
+  @param   TYPE     The type of argument to retrieve from the beginning
+                    of the variable argument list.
+
+  @return  An argument of the type specified by TYPE.
+
+**/
+#define VA_ARG(Marker, TYPE)   (*(TYPE *) ((Marker += _INT_SIZE_OF (TYPE)) - _INT_SIZE_OF (TYPE)))
+
+/**
+  Terminates the use of a variable argument list.
+
+  This function initializes Marker so it can no longer be used with VA_ARG().
+  After this macro is used, the only way to access the variable argument list is
+  by using VA_START() again.
+
+  @param   Marker   VA_LIST used to traverse the list of arguments.
+
+**/
+#define VA_END(Marker)      (Marker = (VA_LIST) 0)
+
+/**
+  Initializes a VA_LIST as a copy of an existing VA_LIST.
+
+  This macro initializes Dest as a copy of Start, as if the VA_START macro had been applied to Dest
+  followed by the same sequence of uses of the VA_ARG macro as had previously been used to reach
+  the present state of Start.
+
+  @param   Dest   VA_LIST used to traverse the list of arguments.
+  @param   Start  VA_LIST used to traverse the list of arguments.
+
+**/
+#define VA_COPY(Dest, Start)  ((void)((Dest) = (Start)))
+
+#endif
+
+///
+/// Pointer to the start of a variable argument list stored in a memory buffer. Same as UINT8 *.
+///
+typedef UINTN  *BASE_LIST;
+
+/**
+  Returns the size of a data type in sizeof(UINTN) units rounded up to the nearest UINTN boundary.
+
+  @param  TYPE  The date type to determine the size of.
+
+  @return The size of TYPE in sizeof (UINTN) units rounded up to the nearest UINTN boundary.
+**/
+#define _BASE_INT_SIZE_OF(TYPE) ((sizeof (TYPE) + sizeof (UINTN) - 1) / sizeof (UINTN))
+
+/**
+  Returns an argument of a specified type from a variable argument list and updates
+  the pointer to the variable argument list to point to the next argument.
+
+  This function returns an argument of the type specified by TYPE from the beginning
+  of the variable argument list specified by Marker.  Marker is then updated to point
+  to the next argument in the variable argument list.  The method for computing the
+  pointer to the next argument in the argument list is CPU specific following the EFIAPI ABI.
+
+  @param   Marker   The pointer to the beginning of a variable argument list.
+  @param   TYPE     The type of argument to retrieve from the beginning
+                    of the variable argument list.
+
+  @return  An argument of the type specified by TYPE.
+
+**/
+#define BASE_ARG(Marker, TYPE)   (*(TYPE *) ((Marker += _BASE_INT_SIZE_OF (TYPE)) - _BASE_INT_SIZE_OF (TYPE)))
+
+/**
+  The macro that returns the byte offset of a field in a data structure.
+
+  This function returns the offset, in bytes, of field specified by Field from the
+  beginning of the  data structure specified by TYPE. If TYPE does not contain Field,
+  the module will not compile.
+
+  @param   TYPE     The name of the data structure that contains the field specified by Field.
+  @param   Field    The name of the field in the data structure.
+
+  @return  Offset, in bytes, of field.
+
+**/
+#ifdef __GNUC__
+#if __GNUC__ >= 4
+#define OFFSET_OF(TYPE, Field) ((UINTN) __builtin_offsetof(TYPE, Field))
+#endif
+#endif
+
+#ifndef OFFSET_OF
+#define OFFSET_OF(TYPE, Field) ((UINTN) &(((TYPE *)0)->Field))
+#endif
+
+/**
+  Macro that returns a pointer to the data structure that contains a specified field of
+  that data structure.  This is a lightweight method to hide information by placing a
+  public data structure inside a larger private data structure and using a pointer to
+  the public data structure to retrieve a pointer to the private data structure.
+
+  This function computes the offset, in bytes, of field specified by Field from the beginning
+  of the  data structure specified by TYPE.  This offset is subtracted from Record, and is
+  used to return a pointer to a data structure of the type specified by TYPE. If the data type
+  specified by TYPE does not contain the field specified by Field, then the module will not compile.
+
+  @param   Record   Pointer to the field specified by Field within a data structure of type TYPE.
+  @param   TYPE     The name of the data structure type to return.  This data structure must
+                    contain the field specified by Field.
+  @param   Field    The name of the field in the data structure specified by TYPE to which Record points.
+
+  @return  A pointer to the structure from one of it's elements.
+
+**/
+#define BASE_CR(Record, TYPE, Field)  ((TYPE *) ((CHAR8 *) (Record) - (CHAR8 *) &(((TYPE *) 0)->Field)))
+
+/**
+  Rounds a value up to the next boundary using a specified alignment.
+
+  This function rounds Value up to the next boundary using the specified Alignment.
+  This aligned value is returned.
+
+  @param   Value      The value to round up.
+  @param   Alignment  The alignment boundary used to return the aligned value.
+
+  @return  A value up to the next boundary.
+
+**/
+#define ALIGN_VALUE(Value, Alignment) ((Value) + (((Alignment) - (Value)) & ((Alignment) - 1)))
+
+/**
+  Adjust a pointer by adding the minimum offset required for it to be aligned on
+  a specified alignment boundary.
+
+  This function rounds the pointer specified by Pointer to the next alignment boundary
+  specified by Alignment. The pointer to the aligned address is returned.
+
+  @param   Pointer    The pointer to round up.
+  @param   Alignment  The alignment boundary to use to return an aligned pointer.
+
+  @return  Pointer to the aligned address.
+
+**/
+#define ALIGN_POINTER(Pointer, Alignment) ((VOID *) (ALIGN_VALUE ((UINTN)(Pointer), (Alignment))))
+
+/**
+  Rounds a value up to the next natural boundary for the current CPU.
+  This is 4-bytes for 32-bit CPUs and 8-bytes for 64-bit CPUs.
+
+  This function rounds the value specified by Value up to the next natural boundary for the
+  current CPU. This rounded value is returned.
+
+  @param   Value      The value to round up.
+
+  @return  Rounded value specified by Value.
+
+**/
+#define ALIGN_VARIABLE(Value)  ALIGN_VALUE ((Value), sizeof (UINTN))
+
+
+/**
+  Return the maximum of two operands.
+
+  This macro returns the maximum of two operand specified by a and b.
+  Both a and b must be the same numerical types, signed or unsigned.
+
+  @param   a        The first operand with any numerical type.
+  @param   b        The second operand. Can be any numerical type as long as is
+                    the same type as a.
+
+  @return  Maximum of two operands.
+
+**/
+#ifndef MAX
+#define MAX(a, b)                       \
+  (((a) > (b)) ? (a) : (b))
+#endif
+
+/**
+  Return the minimum of two operands.
+
+  This macro returns the minimal of two operand specified by a and b.
+  Both a and b must be the same numerical types, signed or unsigned.
+
+  @param   a        The first operand with any numerical type.
+  @param   b        The second operand. It should be the same any numerical type with a.
+
+  @return  Minimum of two operands.
+
+**/
+#ifndef MIN
+#define MIN(a, b)                       \
+  (((a) < (b)) ? (a) : (b))
+#endif
+
+/**
+  Return the absolute value of a signed operand.
+
+  This macro returns the absolute value of the signed operand specified by a.
+
+  @param   a        The signed operand.
+
+  @return  The absolute value of the signed operand.
+
+**/
+#ifndef ABS
+#define ABS(a)                          \
+  (((a) < 0) ? (-(a)) : (a))
+#endif
+
+//
+// Status codes common to all execution phases
+//
+typedef UINTN RETURN_STATUS;
+
+/**
+  Produces a RETURN_STATUS code with the highest bit set.
+
+  @param  StatusCode    The status code value to convert into a warning code.
+                        StatusCode must be in the range 0x00000000..0x7FFFFFFF.
+
+  @return The value specified by StatusCode with the highest bit set.
+
+**/
+#define ENCODE_ERROR(StatusCode)     ((RETURN_STATUS)(MAX_BIT | (StatusCode)))
+
+/**
+  Produces a RETURN_STATUS code with the highest bit clear.
+
+  @param  StatusCode    The status code value to convert into a warning code.
+                        StatusCode must be in the range 0x00000000..0x7FFFFFFF.
+
+  @return The value specified by StatusCode with the highest bit clear.
+
+**/
+#define ENCODE_WARNING(StatusCode)   ((RETURN_STATUS)(StatusCode))
+
+/**
+  Returns TRUE if a specified RETURN_STATUS code is an error code.
+
+  This function returns TRUE if StatusCode has the high bit set.  Otherwise, FALSE is returned.
+
+  @param  StatusCode    The status code value to evaluate.
+
+  @retval TRUE          The high bit of StatusCode is set.
+  @retval FALSE         The high bit of StatusCode is clear.
+
+**/
+#define RETURN_ERROR(StatusCode)     (((INTN)(RETURN_STATUS)(StatusCode)) < 0)
+
+///
+/// The operation completed successfully.
+///
+#define RETURN_SUCCESS               0
+
+///
+/// The image failed to load.
+///
+#define RETURN_LOAD_ERROR            ENCODE_ERROR (1)
+
+///
+/// The parameter was incorrect.
+///
+#define RETURN_INVALID_PARAMETER     ENCODE_ERROR (2)
+
+///
+/// The operation is not supported.
+///
+#define RETURN_UNSUPPORTED           ENCODE_ERROR (3)
+
+///
+/// The buffer was not the proper size for the request.
+///
+#define RETURN_BAD_BUFFER_SIZE       ENCODE_ERROR (4)
+
+///
+/// The buffer was not large enough to hold the requested data.
+/// The required buffer size is returned in the appropriate
+/// parameter when this error occurs.
+///
+#define RETURN_BUFFER_TOO_SMALL      ENCODE_ERROR (5)
+
+///
+/// There is no data pending upon return.
+///
+#define RETURN_NOT_READY             ENCODE_ERROR (6)
+
+///
+/// The physical device reported an error while attempting the
+/// operation.
+///
+#define RETURN_DEVICE_ERROR          ENCODE_ERROR (7)
+
+///
+/// The device can not be written to.
+///
+#define RETURN_WRITE_PROTECTED       ENCODE_ERROR (8)
+
+///
+/// The resource has run out.
+///
+#define RETURN_OUT_OF_RESOURCES      ENCODE_ERROR (9)
+
+///
+/// An inconsistency was detected on the file system causing the
+/// operation to fail.
+///
+#define RETURN_VOLUME_CORRUPTED      ENCODE_ERROR (10)
+
+///
+/// There is no more space on the file system.
+///
+#define RETURN_VOLUME_FULL           ENCODE_ERROR (11)
+
+///
+/// The device does not contain any medium to perform the
+/// operation.
+///
+#define RETURN_NO_MEDIA              ENCODE_ERROR (12)
+
+///
+/// The medium in the device has changed since the last
+/// access.
+///
+#define RETURN_MEDIA_CHANGED         ENCODE_ERROR (13)
+
+///
+/// The item was not found.
+///
+#define RETURN_NOT_FOUND             ENCODE_ERROR (14)
+
+///
+/// Access was denied.
+///
+#define RETURN_ACCESS_DENIED         ENCODE_ERROR (15)
+
+///
+/// The server was not found or did not respond to the request.
+///
+#define RETURN_NO_RESPONSE           ENCODE_ERROR (16)
+
+///
+/// A mapping to the device does not exist.
+///
+#define RETURN_NO_MAPPING            ENCODE_ERROR (17)
+
+///
+/// A timeout time expired.
+///
+#define RETURN_TIMEOUT               ENCODE_ERROR (18)
+
+///
+/// The protocol has not been started.
+///
+#define RETURN_NOT_STARTED           ENCODE_ERROR (19)
+
+///
+/// The protocol has already been started.
+///
+#define RETURN_ALREADY_STARTED       ENCODE_ERROR (20)
+
+///
+/// The operation was aborted.
+///
+#define RETURN_ABORTED               ENCODE_ERROR (21)
+
+///
+/// An ICMP error occurred during the network operation.
+///
+#define RETURN_ICMP_ERROR            ENCODE_ERROR (22)
+
+///
+/// A TFTP error occurred during the network operation.
+///
+#define RETURN_TFTP_ERROR            ENCODE_ERROR (23)
+
+///
+/// A protocol error occurred during the network operation.
+///
+#define RETURN_PROTOCOL_ERROR        ENCODE_ERROR (24)
+
+///
+/// A function encountered an internal version that was
+/// incompatible with a version requested by the caller.
+///
+#define RETURN_INCOMPATIBLE_VERSION  ENCODE_ERROR (25)
+
+///
+/// The function was not performed due to a security violation.
+///
+#define RETURN_SECURITY_VIOLATION    ENCODE_ERROR (26)
+
+///
+/// A CRC error was detected.
+///
+#define RETURN_CRC_ERROR             ENCODE_ERROR (27)
+
+///
+/// The beginning or end of media was reached.
+///
+#define RETURN_END_OF_MEDIA          ENCODE_ERROR (28)
+
+///
+/// The end of the file was reached.
+///
+#define RETURN_END_OF_FILE           ENCODE_ERROR (31)
+
+///
+/// The language specified was invalid.
+///
+#define RETURN_INVALID_LANGUAGE      ENCODE_ERROR (32)
+
+///
+/// The security status of the data is unknown or compromised
+/// and the data must be updated or replaced to restore a valid
+/// security status.
+///
+#define RETURN_COMPROMISED_DATA      ENCODE_ERROR (33)
+
+///
+/// The string contained one or more characters that
+/// the device could not render and were skipped.
+///
+#define RETURN_WARN_UNKNOWN_GLYPH    ENCODE_WARNING (1)
+
+///
+/// The handle was closed, but the file was not deleted.
+///
+#define RETURN_WARN_DELETE_FAILURE   ENCODE_WARNING (2)
+
+///
+/// The handle was closed, but the data to the file was not
+/// flushed properly.
+///
+#define RETURN_WARN_WRITE_FAILURE    ENCODE_WARNING (3)
+
+///
+/// The resulting buffer was too small, and the data was
+/// truncated to the buffer size.
+///
+#define RETURN_WARN_BUFFER_TOO_SMALL ENCODE_WARNING (4)
+
+///
+/// The data has not been updated within the timeframe set by
+/// local policy for this type of data.
+///
+#define RETURN_WARN_STALE_DATA       ENCODE_WARNING (5)
+
+/**
+  Returns a 16-bit signature built from 2 ASCII characters.
+
+  This macro returns a 16-bit value built from the two ASCII characters specified
+  by A and B.
+
+  @param  A    The first ASCII character.
+  @param  B    The second ASCII character.
+
+  @return A 16-bit value built from the two ASCII characters specified by A and B.
+
+**/
+#define SIGNATURE_16(A, B)        ((A) | (B << 8))
+
+/**
+  Returns a 32-bit signature built from 4 ASCII characters.
+
+  This macro returns a 32-bit value built from the four ASCII characters specified
+  by A, B, C, and D.
+
+  @param  A    The first ASCII character.
+  @param  B    The second ASCII character.
+  @param  C    The third ASCII character.
+  @param  D    The fourth ASCII character.
+
+  @return A 32-bit value built from the two ASCII characters specified by A, B,
+          C and D.
+
+**/
+#define SIGNATURE_32(A, B, C, D)  (SIGNATURE_16 (A, B) | (SIGNATURE_16 (C, D) << 16))
+
+/**
+  Returns a 64-bit signature built from 8 ASCII characters.
+
+  This macro returns a 64-bit value built from the eight ASCII characters specified
+  by A, B, C, D, E, F, G,and H.
+
+  @param  A    The first ASCII character.
+  @param  B    The second ASCII character.
+  @param  C    The third ASCII character.
+  @param  D    The fourth ASCII character.
+  @param  E    The fifth ASCII character.
+  @param  F    The sixth ASCII character.
+  @param  G    The seventh ASCII character.
+  @param  H    The eighth ASCII character.
+
+  @return A 64-bit value built from the two ASCII characters specified by A, B,
+          C, D, E, F, G and H.
+
+**/
+#define SIGNATURE_64(A, B, C, D, E, F, G, H) \
+    (SIGNATURE_32 (A, B, C, D) | ((UINT64) (SIGNATURE_32 (E, F, G, H)) << 32))
+
+#endif
+
diff --git a/tools/cbfstool/edk2/Guid/FirmwareFileSystem2.h b/tools/cbfstool/edk2/Guid/FirmwareFileSystem2.h
new file mode 100644
index 0000000000..1aaa3b1092
--- /dev/null
+++ b/tools/cbfstool/edk2/Guid/FirmwareFileSystem2.h
@@ -0,0 +1,40 @@
+/** @file
+  Guid used to define the Firmware File System 2.
+
+  Copyright (c) 2006 - 2008, Intel Corporation. All rights reserved.<BR>
+  This program and the accompanying materials
+  are licensed and made available under the terms and conditions of the BSD License
+  which accompanies this distribution.  The full text of the license may be found at
+  http://opensource.org/licenses/bsd-license.php
+
+  THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+  WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+  @par Revision Reference:
+  GUIDs introduced in PI Version 1.0.
+
+**/
+
+#ifndef __FIRMWARE_FILE_SYSTEM2_GUID_H__
+#define __FIRMWARE_FILE_SYSTEM2_GUID_H__
+
+///
+/// The firmware volume header contains a data field for
+/// the file system GUID
+///
+#define EFI_FIRMWARE_FILE_SYSTEM2_GUID \
+  { 0x8c8ce578, 0x8a3d, 0x4f1c, { 0x99, 0x35, 0x89, 0x61, 0x85, 0xc3, 0x2d, 0xd3 } }
+
+///
+/// A Volume Top File (VTF) is a file that must be
+/// located such that the last byte of the file is
+/// also the last byte of the firmware volume
+///
+#define EFI_FFS_VOLUME_TOP_FILE_GUID \
+  { 0x1BA0062E, 0xC779, 0x4582, { 0x85, 0x66, 0x33, 0x6A, 0xE8, 0xF7, 0x8F, 0x9 } }
+
+
+extern EFI_GUID gEfiFirmwareFileSystem2Guid;
+extern EFI_GUID gEfiFirmwareVolumeTopFileGuid;
+
+#endif
diff --git a/tools/cbfstool/edk2/Guid/WinCertificate.h b/tools/cbfstool/edk2/Guid/WinCertificate.h
new file mode 100644
index 0000000000..6dea446ba0
--- /dev/null
+++ b/tools/cbfstool/edk2/Guid/WinCertificate.h
@@ -0,0 +1,128 @@
+/** @file
+  GUID for UEFI WIN_CERTIFICATE structure.
+
+  Copyright (c) 2006 - 2012, Intel Corporation. All rights reserved.<BR>
+  This program and the accompanying materials
+  are licensed and made available under the terms and conditions of the BSD License
+  which accompanies this distribution.  The full text of the license may be found at
+  http://opensource.org/licenses/bsd-license.php
+
+  THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+  WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+  @par Revision Reference:
+  GUID defined in UEFI 2.0 spec.
+**/
+
+#ifndef __EFI_WIN_CERTIFICATE_H__
+#define __EFI_WIN_CERTIFICATE_H__
+
+//
+// _WIN_CERTIFICATE.wCertificateType
+//
+#define WIN_CERT_TYPE_PKCS_SIGNED_DATA 0x0002
+#define WIN_CERT_TYPE_EFI_PKCS115      0x0EF0
+#define WIN_CERT_TYPE_EFI_GUID         0x0EF1
+
+///
+/// The WIN_CERTIFICATE structure is part of the PE/COFF specification.
+///
+typedef struct {
+  ///
+  /// The length of the entire certificate,
+  /// including the length of the header, in bytes.
+  ///
+  UINT32  dwLength;
+  ///
+  /// The revision level of the WIN_CERTIFICATE
+  /// structure. The current revision level is 0x0200.
+  ///
+  UINT16  wRevision;
+  ///
+  /// The certificate type. See WIN_CERT_TYPE_xxx for the UEFI
+  /// certificate types. The UEFI specification reserves the range of
+  /// certificate type values from 0x0EF0 to 0x0EFF.
+  ///
+  UINT16  wCertificateType;
+  ///
+  /// The following is the actual certificate. The format of
+  /// the certificate depends on wCertificateType.
+  ///
+  /// UINT8 bCertificate[ANYSIZE_ARRAY];
+  ///
+} WIN_CERTIFICATE;
+
+///
+/// WIN_CERTIFICATE_UEFI_GUID.CertType
+///
+#define EFI_CERT_TYPE_RSA2048_SHA256_GUID \
+  {0xa7717414, 0xc616, 0x4977, {0x94, 0x20, 0x84, 0x47, 0x12, 0xa7, 0x35, 0xbf } }
+
+///
+/// WIN_CERTIFICATE_UEFI_GUID.CertData
+///
+typedef struct {
+  EFI_GUID  HashType;
+  UINT8     PublicKey[256];
+  UINT8     Signature[256];
+} EFI_CERT_BLOCK_RSA_2048_SHA256;
+
+
+///
+/// Certificate which encapsulates a GUID-specific digital signature
+///
+typedef struct {
+  ///
+  /// This is the standard WIN_CERTIFICATE header, where
+  /// wCertificateType is set to WIN_CERT_TYPE_EFI_GUID.
+  ///
+  WIN_CERTIFICATE   Hdr;
+  ///
+  /// This is the unique id which determines the
+  /// format of the CertData. .
+  ///
+  EFI_GUID          CertType;
+  ///
+  /// The following is the certificate data. The format of
+  /// the data is determined by the CertType.
+  /// If CertType is EFI_CERT_TYPE_RSA2048_SHA256_GUID,
+  /// the CertData will be EFI_CERT_BLOCK_RSA_2048_SHA256 structure.
+  ///
+  UINT8            CertData[1];
+} WIN_CERTIFICATE_UEFI_GUID;
+
+
+///
+/// Certificate which encapsulates the RSASSA_PKCS1-v1_5 digital signature.
+///
+/// The WIN_CERTIFICATE_UEFI_PKCS1_15 structure is derived from
+/// WIN_CERTIFICATE and encapsulate the information needed to
+/// implement the RSASSA-PKCS1-v1_5 digital signature algorithm as
+/// specified in RFC2437.
+///
+typedef struct {
+  ///
+  /// This is the standard WIN_CERTIFICATE header, where
+  /// wCertificateType is set to WIN_CERT_TYPE_UEFI_PKCS1_15.
+  ///
+  WIN_CERTIFICATE Hdr;
+  ///
+  /// This is the hashing algorithm which was performed on the
+  /// UEFI executable when creating the digital signature.
+  ///
+  EFI_GUID        HashAlgorithm;
+  ///
+  /// The following is the actual digital signature. The
+  /// size of the signature is the same size as the key
+  /// (1024-bit key is 128 bytes) and can be determined by
+  /// subtracting the length of the other parts of this header
+  /// from the total length of the certificate as found in
+  /// Hdr.dwLength.
+  ///
+  /// UINT8 Signature[];
+  ///
+} WIN_CERTIFICATE_EFI_PKCS1_15;
+
+extern EFI_GUID gEfiCertTypeRsa2048Sha256Guid;
+
+#endif
diff --git a/tools/cbfstool/edk2/IndustryStandard/PeImage.h b/tools/cbfstool/edk2/IndustryStandard/PeImage.h
new file mode 100644
index 0000000000..254e5d2ec2
--- /dev/null
+++ b/tools/cbfstool/edk2/IndustryStandard/PeImage.h
@@ -0,0 +1,756 @@
+/** @file
+  EFI image format for PE32, PE32+ and TE. Please note some data structures are
+  different for PE32 and PE32+. EFI_IMAGE_NT_HEADERS32 is for PE32 and
+  EFI_IMAGE_NT_HEADERS64 is for PE32+.
+
+  This file is coded to the Visual Studio, Microsoft Portable Executable and
+  Common Object File Format Specification, Revision 8.3 - February 6, 2013.
+  This file also includes some definitions in PI Specification, Revision 1.0.
+
+Copyright (c) 2006 - 2010, Intel Corporation. All rights reserved.<BR>
+Portions copyright (c) 2008 - 2009, Apple Inc. All rights reserved.<BR>
+This program and the accompanying materials
+are licensed and made available under the terms and conditions of the BSD License
+which accompanies this distribution.  The full text of the license may be found at
+http://opensource.org/licenses/bsd-license.php.
+
+THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+**/
+
+#ifndef __PE_IMAGE_H__
+#define __PE_IMAGE_H__
+
+//
+// PE32+ Subsystem type for EFI images
+//
+#define EFI_IMAGE_SUBSYSTEM_EFI_APPLICATION         10
+#define EFI_IMAGE_SUBSYSTEM_EFI_BOOT_SERVICE_DRIVER 11
+#define EFI_IMAGE_SUBSYSTEM_EFI_RUNTIME_DRIVER      12
+#define EFI_IMAGE_SUBSYSTEM_SAL_RUNTIME_DRIVER      13 ///< defined PI Specification, 1.0
+
+
+//
+// PE32+ Machine type for EFI images
+//
+#define IMAGE_FILE_MACHINE_I386            0x014c
+#define IMAGE_FILE_MACHINE_IA64            0x0200
+#define IMAGE_FILE_MACHINE_EBC             0x0EBC
+#define IMAGE_FILE_MACHINE_X64             0x8664
+#define IMAGE_FILE_MACHINE_ARMTHUMB_MIXED  0x01c2
+#define IMAGE_FILE_MACHINE_ARM64           0xAA64
+
+//
+// EXE file formats
+//
+#define EFI_IMAGE_DOS_SIGNATURE     SIGNATURE_16('M', 'Z')
+#define EFI_IMAGE_OS2_SIGNATURE     SIGNATURE_16('N', 'E')
+#define EFI_IMAGE_OS2_SIGNATURE_LE  SIGNATURE_16('L', 'E')
+#define EFI_IMAGE_NT_SIGNATURE      SIGNATURE_32('P', 'E', '\0', '\0')
+
+///
+/// PE images can start with an optional DOS header, so if an image is run
+/// under DOS it can print an error message.
+///
+typedef struct {
+  UINT16  e_magic;    ///< Magic number.
+  UINT16  e_cblp;     ///< Bytes on last page of file.
+  UINT16  e_cp;       ///< Pages in file.
+  UINT16  e_crlc;     ///< Relocations.
+  UINT16  e_cparhdr;  ///< Size of header in paragraphs.
+  UINT16  e_minalloc; ///< Minimum extra paragraphs needed.
+  UINT16  e_maxalloc; ///< Maximum extra paragraphs needed.
+  UINT16  e_ss;       ///< Initial (relative) SS value.
+  UINT16  e_sp;       ///< Initial SP value.
+  UINT16  e_csum;     ///< Checksum.
+  UINT16  e_ip;       ///< Initial IP value.
+  UINT16  e_cs;       ///< Initial (relative) CS value.
+  UINT16  e_lfarlc;   ///< File address of relocation table.
+  UINT16  e_ovno;     ///< Overlay number.
+  UINT16  e_res[4];   ///< Reserved words.
+  UINT16  e_oemid;    ///< OEM identifier (for e_oeminfo).
+  UINT16  e_oeminfo;  ///< OEM information; e_oemid specific.
+  UINT16  e_res2[10]; ///< Reserved words.
+  UINT32  e_lfanew;   ///< File address of new exe header.
+} EFI_IMAGE_DOS_HEADER;
+
+///
+/// COFF File Header (Object and Image).
+///
+typedef struct {
+  UINT16  Machine;
+  UINT16  NumberOfSections;
+  UINT32  TimeDateStamp;
+  UINT32  PointerToSymbolTable;
+  UINT32  NumberOfSymbols;
+  UINT16  SizeOfOptionalHeader;
+  UINT16  Characteristics;
+} EFI_IMAGE_FILE_HEADER;
+
+///
+/// Size of EFI_IMAGE_FILE_HEADER.
+///
+#define EFI_IMAGE_SIZEOF_FILE_HEADER        20
+
+//
+// Characteristics
+//
+#define EFI_IMAGE_FILE_RELOCS_STRIPPED      BIT0     ///< 0x0001  Relocation info stripped from file.
+#define EFI_IMAGE_FILE_EXECUTABLE_IMAGE     BIT1     ///< 0x0002  File is executable  (i.e. no unresolved externel references).
+#define EFI_IMAGE_FILE_LINE_NUMS_STRIPPED   BIT2     ///< 0x0004  Line nunbers stripped from file.
+#define EFI_IMAGE_FILE_LOCAL_SYMS_STRIPPED  BIT3     ///< 0x0008  Local symbols stripped from file.
+#define EFI_IMAGE_FILE_BYTES_REVERSED_LO    BIT7     ///< 0x0080  Bytes of machine word are reversed.
+#define EFI_IMAGE_FILE_32BIT_MACHINE        BIT8     ///< 0x0100  32 bit word machine.
+#define EFI_IMAGE_FILE_DEBUG_STRIPPED       BIT9     ///< 0x0200  Debugging info stripped from file in .DBG file.
+#define EFI_IMAGE_FILE_SYSTEM               BIT12    ///< 0x1000  System File.
+#define EFI_IMAGE_FILE_DLL                  BIT13    ///< 0x2000  File is a DLL.
+#define EFI_IMAGE_FILE_BYTES_REVERSED_HI    BIT15    ///< 0x8000  Bytes of machine word are reversed.
+
+///
+/// Header Data Directories.
+///
+typedef struct {
+  UINT32  VirtualAddress;
+  UINT32  Size;
+} EFI_IMAGE_DATA_DIRECTORY;
+
+//
+// Directory Entries
+//
+#define EFI_IMAGE_DIRECTORY_ENTRY_EXPORT      0
+#define EFI_IMAGE_DIRECTORY_ENTRY_IMPORT      1
+#define EFI_IMAGE_DIRECTORY_ENTRY_RESOURCE    2
+#define EFI_IMAGE_DIRECTORY_ENTRY_EXCEPTION   3
+#define EFI_IMAGE_DIRECTORY_ENTRY_SECURITY    4
+#define EFI_IMAGE_DIRECTORY_ENTRY_BASERELOC   5
+#define EFI_IMAGE_DIRECTORY_ENTRY_DEBUG       6
+#define EFI_IMAGE_DIRECTORY_ENTRY_COPYRIGHT   7
+#define EFI_IMAGE_DIRECTORY_ENTRY_GLOBALPTR   8
+#define EFI_IMAGE_DIRECTORY_ENTRY_TLS         9
+#define EFI_IMAGE_DIRECTORY_ENTRY_LOAD_CONFIG 10
+
+#define EFI_IMAGE_NUMBER_OF_DIRECTORY_ENTRIES 16
+
+///
+/// @attention
+/// EFI_IMAGE_NT_OPTIONAL_HDR32_MAGIC means PE32 and
+/// EFI_IMAGE_OPTIONAL_HEADER32 must be used. The data structures only vary
+/// after NT additional fields.
+///
+#define EFI_IMAGE_NT_OPTIONAL_HDR32_MAGIC 0x10b
+
+///
+/// Optional Header Standard Fields for PE32.
+///
+typedef struct {
+  ///
+  /// Standard fields.
+  ///
+  UINT16                    Magic;
+  UINT8                     MajorLinkerVersion;
+  UINT8                     MinorLinkerVersion;
+  UINT32                    SizeOfCode;
+  UINT32                    SizeOfInitializedData;
+  UINT32                    SizeOfUninitializedData;
+  UINT32                    AddressOfEntryPoint;
+  UINT32                    BaseOfCode;
+  UINT32                    BaseOfData;  ///< PE32 contains this additional field, which is absent in PE32+.
+  ///
+  /// Optional Header Windows-Specific Fields.
+  ///
+  UINT32                    ImageBase;
+  UINT32                    SectionAlignment;
+  UINT32                    FileAlignment;
+  UINT16                    MajorOperatingSystemVersion;
+  UINT16                    MinorOperatingSystemVersion;
+  UINT16                    MajorImageVersion;
+  UINT16                    MinorImageVersion;
+  UINT16                    MajorSubsystemVersion;
+  UINT16                    MinorSubsystemVersion;
+  UINT32                    Win32VersionValue;
+  UINT32                    SizeOfImage;
+  UINT32                    SizeOfHeaders;
+  UINT32                    CheckSum;
+  UINT16                    Subsystem;
+  UINT16                    DllCharacteristics;
+  UINT32                    SizeOfStackReserve;
+  UINT32                    SizeOfStackCommit;
+  UINT32                    SizeOfHeapReserve;
+  UINT32                    SizeOfHeapCommit;
+  UINT32                    LoaderFlags;
+  UINT32                    NumberOfRvaAndSizes;
+  EFI_IMAGE_DATA_DIRECTORY  DataDirectory[EFI_IMAGE_NUMBER_OF_DIRECTORY_ENTRIES];
+} EFI_IMAGE_OPTIONAL_HEADER32;
+
+///
+/// @attention
+/// EFI_IMAGE_NT_OPTIONAL_HDR64_MAGIC means PE32+ and
+/// EFI_IMAGE_OPTIONAL_HEADER64 must be used. The data structures only vary
+/// after NT additional fields.
+///
+#define EFI_IMAGE_NT_OPTIONAL_HDR64_MAGIC 0x20b
+
+///
+/// Optional Header Standard Fields for PE32+.
+///
+typedef struct {
+  ///
+  /// Standard fields.
+  ///
+  UINT16                    Magic;
+  UINT8                     MajorLinkerVersion;
+  UINT8                     MinorLinkerVersion;
+  UINT32                    SizeOfCode;
+  UINT32                    SizeOfInitializedData;
+  UINT32                    SizeOfUninitializedData;
+  UINT32                    AddressOfEntryPoint;
+  UINT32                    BaseOfCode;
+  ///
+  /// Optional Header Windows-Specific Fields.
+  ///
+  UINT64                    ImageBase;
+  UINT32                    SectionAlignment;
+  UINT32                    FileAlignment;
+  UINT16                    MajorOperatingSystemVersion;
+  UINT16                    MinorOperatingSystemVersion;
+  UINT16                    MajorImageVersion;
+  UINT16                    MinorImageVersion;
+  UINT16                    MajorSubsystemVersion;
+  UINT16                    MinorSubsystemVersion;
+  UINT32                    Win32VersionValue;
+  UINT32                    SizeOfImage;
+  UINT32                    SizeOfHeaders;
+  UINT32                    CheckSum;
+  UINT16                    Subsystem;
+  UINT16                    DllCharacteristics;
+  UINT64                    SizeOfStackReserve;
+  UINT64                    SizeOfStackCommit;
+  UINT64                    SizeOfHeapReserve;
+  UINT64                    SizeOfHeapCommit;
+  UINT32                    LoaderFlags;
+  UINT32                    NumberOfRvaAndSizes;
+  EFI_IMAGE_DATA_DIRECTORY  DataDirectory[EFI_IMAGE_NUMBER_OF_DIRECTORY_ENTRIES];
+} EFI_IMAGE_OPTIONAL_HEADER64;
+
+
+///
+/// @attention
+/// EFI_IMAGE_NT_HEADERS32 is for use ONLY by tools.
+///
+typedef struct {
+  UINT32                      Signature;
+  EFI_IMAGE_FILE_HEADER       FileHeader;
+  EFI_IMAGE_OPTIONAL_HEADER32 OptionalHeader;
+} EFI_IMAGE_NT_HEADERS32;
+
+#define EFI_IMAGE_SIZEOF_NT_OPTIONAL32_HEADER sizeof (EFI_IMAGE_NT_HEADERS32)
+
+///
+/// @attention
+/// EFI_IMAGE_HEADERS64 is for use ONLY by tools.
+///
+typedef struct {
+  UINT32                      Signature;
+  EFI_IMAGE_FILE_HEADER       FileHeader;
+  EFI_IMAGE_OPTIONAL_HEADER64 OptionalHeader;
+} EFI_IMAGE_NT_HEADERS64;
+
+#define EFI_IMAGE_SIZEOF_NT_OPTIONAL64_HEADER sizeof (EFI_IMAGE_NT_HEADERS64)
+
+//
+// Other Windows Subsystem Values
+//
+#define EFI_IMAGE_SUBSYSTEM_UNKNOWN     0
+#define EFI_IMAGE_SUBSYSTEM_NATIVE      1
+#define EFI_IMAGE_SUBSYSTEM_WINDOWS_GUI 2
+#define EFI_IMAGE_SUBSYSTEM_WINDOWS_CUI 3
+#define EFI_IMAGE_SUBSYSTEM_OS2_CUI     5
+#define EFI_IMAGE_SUBSYSTEM_POSIX_CUI   7
+
+///
+/// Length of ShortName.
+///
+#define EFI_IMAGE_SIZEOF_SHORT_NAME 8
+
+///
+/// Section Table. This table immediately follows the optional header.
+///
+typedef struct {
+  UINT8 Name[EFI_IMAGE_SIZEOF_SHORT_NAME];
+  union {
+    UINT32  PhysicalAddress;
+    UINT32  VirtualSize;
+  } Misc;
+  UINT32  VirtualAddress;
+  UINT32  SizeOfRawData;
+  UINT32  PointerToRawData;
+  UINT32  PointerToRelocations;
+  UINT32  PointerToLinenumbers;
+  UINT16  NumberOfRelocations;
+  UINT16  NumberOfLinenumbers;
+  UINT32  Characteristics;
+} EFI_IMAGE_SECTION_HEADER;
+
+///
+/// Size of EFI_IMAGE_SECTION_HEADER.
+///
+#define EFI_IMAGE_SIZEOF_SECTION_HEADER       40
+
+//
+// Section Flags Values
+//
+#define EFI_IMAGE_SCN_TYPE_NO_PAD                  BIT3   ///< 0x00000008  ///< Reserved.
+#define EFI_IMAGE_SCN_CNT_CODE                     BIT5   ///< 0x00000020
+#define EFI_IMAGE_SCN_CNT_INITIALIZED_DATA         BIT6   ///< 0x00000040
+#define EFI_IMAGE_SCN_CNT_UNINITIALIZED_DATA       BIT7   ///< 0x00000080
+
+#define EFI_IMAGE_SCN_LNK_OTHER                    BIT8   ///< 0x00000100  ///< Reserved.
+#define EFI_IMAGE_SCN_LNK_INFO                     BIT9   ///< 0x00000200  ///< Section contains comments or some other type of information.
+#define EFI_IMAGE_SCN_LNK_REMOVE                   BIT11  ///< 0x00000800  ///< Section contents will not become part of image.
+#define EFI_IMAGE_SCN_LNK_COMDAT                   BIT12  ///< 0x00001000
+
+#define EFI_IMAGE_SCN_ALIGN_1BYTES                 BIT20  ///< 0x00100000
+#define EFI_IMAGE_SCN_ALIGN_2BYTES                 BIT21  ///< 0x00200000
+#define EFI_IMAGE_SCN_ALIGN_4BYTES          (BIT20|BIT21) ///< 0x00300000
+#define EFI_IMAGE_SCN_ALIGN_8BYTES                 BIT22  ///< 0x00400000
+#define EFI_IMAGE_SCN_ALIGN_16BYTES         (BIT20|BIT22) ///< 0x00500000
+#define EFI_IMAGE_SCN_ALIGN_32BYTES         (BIT21|BIT22) ///< 0x00600000
+#define EFI_IMAGE_SCN_ALIGN_64BYTES   (BIT20|BIT21|BIT22) ///< 0x00700000
+
+#define EFI_IMAGE_SCN_MEM_DISCARDABLE              BIT25  ///< 0x02000000
+#define EFI_IMAGE_SCN_MEM_NOT_CACHED               BIT26  ///< 0x04000000
+#define EFI_IMAGE_SCN_MEM_NOT_PAGED                BIT27  ///< 0x08000000
+#define EFI_IMAGE_SCN_MEM_SHARED                   BIT28  ///< 0x10000000
+#define EFI_IMAGE_SCN_MEM_EXECUTE                  BIT29  ///< 0x20000000
+#define EFI_IMAGE_SCN_MEM_READ                     BIT30  ///< 0x40000000
+#define EFI_IMAGE_SCN_MEM_WRITE                    BIT31  ///< 0x80000000
+
+///
+/// Size of a Symbol Table Record.
+///
+#define EFI_IMAGE_SIZEOF_SYMBOL 18
+
+//
+// Symbols have a section number of the section in which they are
+// defined. Otherwise, section numbers have the following meanings:
+//
+#define EFI_IMAGE_SYM_UNDEFINED (UINT16) 0  ///< Symbol is undefined or is common.
+#define EFI_IMAGE_SYM_ABSOLUTE  (UINT16) -1 ///< Symbol is an absolute value.
+#define EFI_IMAGE_SYM_DEBUG     (UINT16) -2 ///< Symbol is a special debug item.
+
+//
+// Symbol Type (fundamental) values.
+//
+#define EFI_IMAGE_SYM_TYPE_NULL   0   ///< no type.
+#define EFI_IMAGE_SYM_TYPE_VOID   1   ///< no valid type.
+#define EFI_IMAGE_SYM_TYPE_CHAR   2   ///< type character.
+#define EFI_IMAGE_SYM_TYPE_SHORT  3   ///< type short integer.
+#define EFI_IMAGE_SYM_TYPE_INT    4
+#define EFI_IMAGE_SYM_TYPE_LONG   5
+#define EFI_IMAGE_SYM_TYPE_FLOAT  6
+#define EFI_IMAGE_SYM_TYPE_DOUBLE 7
+#define EFI_IMAGE_SYM_TYPE_STRUCT 8
+#define EFI_IMAGE_SYM_TYPE_UNION  9
+#define EFI_IMAGE_SYM_TYPE_ENUM   10  ///< enumeration.
+#define EFI_IMAGE_SYM_TYPE_MOE    11  ///< member of enumeration.
+#define EFI_IMAGE_SYM_TYPE_BYTE   12
+#define EFI_IMAGE_SYM_TYPE_WORD   13
+#define EFI_IMAGE_SYM_TYPE_UINT   14
+#define EFI_IMAGE_SYM_TYPE_DWORD  15
+
+//
+// Symbol Type (derived) values.
+//
+#define EFI_IMAGE_SYM_DTYPE_NULL      0 ///< no derived type.
+#define EFI_IMAGE_SYM_DTYPE_POINTER   1
+#define EFI_IMAGE_SYM_DTYPE_FUNCTION  2
+#define EFI_IMAGE_SYM_DTYPE_ARRAY     3
+
+//
+// Storage classes.
+//
+#define EFI_IMAGE_SYM_CLASS_END_OF_FUNCTION   ((UINT8) -1)
+#define EFI_IMAGE_SYM_CLASS_NULL              0
+#define EFI_IMAGE_SYM_CLASS_AUTOMATIC         1
+#define EFI_IMAGE_SYM_CLASS_EXTERNAL          2
+#define EFI_IMAGE_SYM_CLASS_STATIC            3
+#define EFI_IMAGE_SYM_CLASS_REGISTER          4
+#define EFI_IMAGE_SYM_CLASS_EXTERNAL_DEF      5
+#define EFI_IMAGE_SYM_CLASS_LABEL             6
+#define EFI_IMAGE_SYM_CLASS_UNDEFINED_LABEL   7
+#define EFI_IMAGE_SYM_CLASS_MEMBER_OF_STRUCT  8
+#define EFI_IMAGE_SYM_CLASS_ARGUMENT          9
+#define EFI_IMAGE_SYM_CLASS_STRUCT_TAG        10
+#define EFI_IMAGE_SYM_CLASS_MEMBER_OF_UNION   11
+#define EFI_IMAGE_SYM_CLASS_UNION_TAG         12
+#define EFI_IMAGE_SYM_CLASS_TYPE_DEFINITION   13
+#define EFI_IMAGE_SYM_CLASS_UNDEFINED_STATIC  14
+#define EFI_IMAGE_SYM_CLASS_ENUM_TAG          15
+#define EFI_IMAGE_SYM_CLASS_MEMBER_OF_ENUM    16
+#define EFI_IMAGE_SYM_CLASS_REGISTER_PARAM    17
+#define EFI_IMAGE_SYM_CLASS_BIT_FIELD         18
+#define EFI_IMAGE_SYM_CLASS_BLOCK             100
+#define EFI_IMAGE_SYM_CLASS_FUNCTION          101
+#define EFI_IMAGE_SYM_CLASS_END_OF_STRUCT     102
+#define EFI_IMAGE_SYM_CLASS_FILE              103
+#define EFI_IMAGE_SYM_CLASS_SECTION           104
+#define EFI_IMAGE_SYM_CLASS_WEAK_EXTERNAL     105
+
+//
+// type packing constants
+//
+#define EFI_IMAGE_N_BTMASK  017
+#define EFI_IMAGE_N_TMASK   060
+#define EFI_IMAGE_N_TMASK1  0300
+#define EFI_IMAGE_N_TMASK2  0360
+#define EFI_IMAGE_N_BTSHFT  4
+#define EFI_IMAGE_N_TSHIFT  2
+
+//
+// Communal selection types.
+//
+#define EFI_IMAGE_COMDAT_SELECT_NODUPLICATES    1
+#define EFI_IMAGE_COMDAT_SELECT_ANY             2
+#define EFI_IMAGE_COMDAT_SELECT_SAME_SIZE       3
+#define EFI_IMAGE_COMDAT_SELECT_EXACT_MATCH     4
+#define EFI_IMAGE_COMDAT_SELECT_ASSOCIATIVE     5
+
+//
+// the following values only be referred in PeCoff, not defined in PECOFF.
+//
+#define EFI_IMAGE_WEAK_EXTERN_SEARCH_NOLIBRARY  1
+#define EFI_IMAGE_WEAK_EXTERN_SEARCH_LIBRARY    2
+#define EFI_IMAGE_WEAK_EXTERN_SEARCH_ALIAS      3
+
+///
+/// Relocation format.
+///
+typedef struct {
+  UINT32  VirtualAddress;
+  UINT32  SymbolTableIndex;
+  UINT16  Type;
+} EFI_IMAGE_RELOCATION;
+
+///
+/// Size of EFI_IMAGE_RELOCATION
+///
+#define EFI_IMAGE_SIZEOF_RELOCATION 10
+
+//
+// I386 relocation types.
+//
+#define EFI_IMAGE_REL_I386_ABSOLUTE 0x0000  ///< Reference is absolute, no relocation is necessary.
+#define EFI_IMAGE_REL_I386_DIR16    0x0001  ///< Direct 16-bit reference to the symbols virtual address.
+#define EFI_IMAGE_REL_I386_REL16    0x0002  ///< PC-relative 16-bit reference to the symbols virtual address.
+#define EFI_IMAGE_REL_I386_DIR32    0x0006  ///< Direct 32-bit reference to the symbols virtual address.
+#define EFI_IMAGE_REL_I386_DIR32NB  0x0007  ///< Direct 32-bit reference to the symbols virtual address, base not included.
+#define EFI_IMAGE_REL_I386_SEG12    0x0009  ///< Direct 16-bit reference to the segment-selector bits of a 32-bit virtual address.
+#define EFI_IMAGE_REL_I386_SECTION  0x000A
+#define EFI_IMAGE_REL_I386_SECREL   0x000B
+#define EFI_IMAGE_REL_I386_REL32    0x0014  ///< PC-relative 32-bit reference to the symbols virtual address.
+
+//
+// x64 processor relocation types.
+//
+#define IMAGE_REL_AMD64_ABSOLUTE  0x0000
+#define IMAGE_REL_AMD64_ADDR64    0x0001
+#define IMAGE_REL_AMD64_ADDR32    0x0002
+#define IMAGE_REL_AMD64_ADDR32NB  0x0003
+#define IMAGE_REL_AMD64_REL32     0x0004
+#define IMAGE_REL_AMD64_REL32_1   0x0005
+#define IMAGE_REL_AMD64_REL32_2   0x0006
+#define IMAGE_REL_AMD64_REL32_3   0x0007
+#define IMAGE_REL_AMD64_REL32_4   0x0008
+#define IMAGE_REL_AMD64_REL32_5   0x0009
+#define IMAGE_REL_AMD64_SECTION   0x000A
+#define IMAGE_REL_AMD64_SECREL    0x000B
+#define IMAGE_REL_AMD64_SECREL7   0x000C
+#define IMAGE_REL_AMD64_TOKEN     0x000D
+#define IMAGE_REL_AMD64_SREL32    0x000E
+#define IMAGE_REL_AMD64_PAIR      0x000F
+#define IMAGE_REL_AMD64_SSPAN32   0x0010
+
+///
+/// Based relocation format.
+///
+typedef struct {
+  UINT32  VirtualAddress;
+  UINT32  SizeOfBlock;
+} EFI_IMAGE_BASE_RELOCATION;
+
+///
+/// Size of EFI_IMAGE_BASE_RELOCATION.
+///
+#define EFI_IMAGE_SIZEOF_BASE_RELOCATION  8
+
+//
+// Based relocation types.
+//
+#define EFI_IMAGE_REL_BASED_ABSOLUTE        0
+#define EFI_IMAGE_REL_BASED_HIGH            1
+#define EFI_IMAGE_REL_BASED_LOW             2
+#define EFI_IMAGE_REL_BASED_HIGHLOW         3
+#define EFI_IMAGE_REL_BASED_HIGHADJ         4
+#define EFI_IMAGE_REL_BASED_MIPS_JMPADDR    5
+#define EFI_IMAGE_REL_BASED_ARM_MOV32A      5
+#define EFI_IMAGE_REL_BASED_ARM_MOV32T      7
+#define EFI_IMAGE_REL_BASED_IA64_IMM64      9
+#define EFI_IMAGE_REL_BASED_MIPS_JMPADDR16  9
+#define EFI_IMAGE_REL_BASED_DIR64           10
+
+///
+/// Line number format.
+///
+typedef struct {
+  union {
+    UINT32  SymbolTableIndex; ///< Symbol table index of function name if Linenumber is 0.
+    UINT32  VirtualAddress;   ///< Virtual address of line number.
+  } Type;
+  UINT16  Linenumber;         ///< Line number.
+} EFI_IMAGE_LINENUMBER;
+
+///
+/// Size of EFI_IMAGE_LINENUMBER.
+///
+#define EFI_IMAGE_SIZEOF_LINENUMBER 6
+
+//
+// Archive format.
+//
+#define EFI_IMAGE_ARCHIVE_START_SIZE        8
+#define EFI_IMAGE_ARCHIVE_START             "!<arch>\n"
+#define EFI_IMAGE_ARCHIVE_END               "`\n"
+#define EFI_IMAGE_ARCHIVE_PAD               "\n"
+#define EFI_IMAGE_ARCHIVE_LINKER_MEMBER     "/               "
+#define EFI_IMAGE_ARCHIVE_LONGNAMES_MEMBER  "//              "
+
+///
+/// Archive Member Headers
+///
+typedef struct {
+  UINT8 Name[16];     ///< File member name - `/' terminated.
+  UINT8 Date[12];     ///< File member date - decimal.
+  UINT8 UserID[6];    ///< File member user id - decimal.
+  UINT8 GroupID[6];   ///< File member group id - decimal.
+  UINT8 Mode[8];      ///< File member mode - octal.
+  UINT8 Size[10];     ///< File member size - decimal.
+  UINT8 EndHeader[2]; ///< String to end header. (0x60 0x0A).
+} EFI_IMAGE_ARCHIVE_MEMBER_HEADER;
+
+///
+/// Size of EFI_IMAGE_ARCHIVE_MEMBER_HEADER.
+///
+#define EFI_IMAGE_SIZEOF_ARCHIVE_MEMBER_HDR 60
+
+
+//
+// DLL Support
+//
+
+///
+/// Export Directory Table.
+///
+typedef struct {
+  UINT32  Characteristics;
+  UINT32  TimeDateStamp;
+  UINT16  MajorVersion;
+  UINT16  MinorVersion;
+  UINT32  Name;
+  UINT32  Base;
+  UINT32  NumberOfFunctions;
+  UINT32  NumberOfNames;
+  UINT32  AddressOfFunctions;
+  UINT32  AddressOfNames;
+  UINT32  AddressOfNameOrdinals;
+} EFI_IMAGE_EXPORT_DIRECTORY;
+
+///
+/// Hint/Name Table.
+///
+typedef struct {
+  UINT16  Hint;
+  UINT8   Name[1];
+} EFI_IMAGE_IMPORT_BY_NAME;
+
+///
+/// Import Address Table RVA (Thunk Table).
+///
+typedef struct {
+  union {
+    UINT32                    Function;
+    UINT32                    Ordinal;
+    EFI_IMAGE_IMPORT_BY_NAME  *AddressOfData;
+  } u1;
+} EFI_IMAGE_THUNK_DATA;
+
+#define EFI_IMAGE_ORDINAL_FLAG              BIT31    ///< Flag for PE32.
+#define EFI_IMAGE_SNAP_BY_ORDINAL(Ordinal)  ((Ordinal & EFI_IMAGE_ORDINAL_FLAG) != 0)
+#define EFI_IMAGE_ORDINAL(Ordinal)          (Ordinal & 0xffff)
+
+///
+/// Import Directory Table
+///
+typedef struct {
+  UINT32                Characteristics;
+  UINT32                TimeDateStamp;
+  UINT32                ForwarderChain;
+  UINT32                Name;
+  EFI_IMAGE_THUNK_DATA  *FirstThunk;
+} EFI_IMAGE_IMPORT_DESCRIPTOR;
+
+
+///
+/// Debug Directory Format.
+///
+typedef struct {
+  UINT32  Characteristics;
+  UINT32  TimeDateStamp;
+  UINT16  MajorVersion;
+  UINT16  MinorVersion;
+  UINT32  Type;
+  UINT32  SizeOfData;
+  UINT32  RVA;           ///< The address of the debug data when loaded, relative to the image base.
+  UINT32  FileOffset;    ///< The file pointer to the debug data.
+} EFI_IMAGE_DEBUG_DIRECTORY_ENTRY;
+
+#define EFI_IMAGE_DEBUG_TYPE_CODEVIEW 2     ///< The Visual C++ debug information.
+
+///
+/// Debug Data Structure defined in Microsoft C++.
+///
+#define CODEVIEW_SIGNATURE_NB10  SIGNATURE_32('N', 'B', '1', '0')
+typedef struct {
+  UINT32  Signature;                        ///< "NB10"
+  UINT32  Unknown;
+  UINT32  Unknown2;
+  UINT32  Unknown3;
+  //
+  // Filename of .PDB goes here
+  //
+} EFI_IMAGE_DEBUG_CODEVIEW_NB10_ENTRY;
+
+///
+/// Debug Data Structure defined in Microsoft C++.
+///
+#define CODEVIEW_SIGNATURE_RSDS  SIGNATURE_32('R', 'S', 'D', 'S')
+typedef struct {
+  UINT32  Signature;                        ///< "RSDS".
+  UINT32  Unknown;
+  UINT32  Unknown2;
+  UINT32  Unknown3;
+  UINT32  Unknown4;
+  UINT32  Unknown5;
+  //
+  // Filename of .PDB goes here
+  //
+} EFI_IMAGE_DEBUG_CODEVIEW_RSDS_ENTRY;
+
+
+///
+/// Debug Data Structure defined by Apple Mach-O to Coff utility.
+///
+#define CODEVIEW_SIGNATURE_MTOC  SIGNATURE_32('M', 'T', 'O', 'C')
+typedef struct {
+  UINT32    Signature;                       ///< "MTOC".
+  GUID      MachOUuid;
+  //
+  //  Filename of .DLL (Mach-O with debug info) goes here
+  //
+} EFI_IMAGE_DEBUG_CODEVIEW_MTOC_ENTRY;
+
+///
+/// Resource format.
+///
+typedef struct {
+  UINT32  Characteristics;
+  UINT32  TimeDateStamp;
+  UINT16  MajorVersion;
+  UINT16  MinorVersion;
+  UINT16  NumberOfNamedEntries;
+  UINT16  NumberOfIdEntries;
+  //
+  // Array of EFI_IMAGE_RESOURCE_DIRECTORY_ENTRY entries goes here.
+  //
+} EFI_IMAGE_RESOURCE_DIRECTORY;
+
+///
+/// Resource directory entry format.
+///
+typedef struct {
+  union {
+    struct {
+      UINT32  NameOffset:31;
+      UINT32  NameIsString:1;
+    } s;
+    UINT32  Id;
+  } u1;
+  union {
+    UINT32  OffsetToData;
+    struct {
+      UINT32  OffsetToDirectory:31;
+      UINT32  DataIsDirectory:1;
+    } s;
+  } u2;
+} EFI_IMAGE_RESOURCE_DIRECTORY_ENTRY;
+
+///
+/// Resource directory entry for string.
+///
+typedef struct {
+  UINT16  Length;
+  CHAR16  String[1];
+} EFI_IMAGE_RESOURCE_DIRECTORY_STRING;
+
+///
+/// Resource directory entry for data array.
+///
+typedef struct {
+  UINT32  OffsetToData;
+  UINT32  Size;
+  UINT32  CodePage;
+  UINT32  Reserved;
+} EFI_IMAGE_RESOURCE_DATA_ENTRY;
+
+///
+/// Header format for TE images, defined in the PI Specification, 1.0.
+///
+typedef struct {
+  UINT16                    Signature;            ///< The signature for TE format = "VZ".
+  UINT16                    Machine;              ///< From the original file header.
+  UINT8                     NumberOfSections;     ///< From the original file header.
+  UINT8                     Subsystem;            ///< From original optional header.
+  UINT16                    StrippedSize;         ///< Number of bytes we removed from the header.
+  UINT32                    AddressOfEntryPoint;  ///< Offset to entry point -- from original optional header.
+  UINT32                    BaseOfCode;           ///< From original image -- required for ITP debug.
+  UINT64                    ImageBase;            ///< From original file header.
+  EFI_IMAGE_DATA_DIRECTORY  DataDirectory[2];     ///< Only base relocation and debug directory.
+} EFI_TE_IMAGE_HEADER;
+
+
+#define EFI_TE_IMAGE_HEADER_SIGNATURE  SIGNATURE_16('V', 'Z')
+
+//
+// Data directory indexes in our TE image header
+//
+#define EFI_TE_IMAGE_DIRECTORY_ENTRY_BASERELOC  0
+#define EFI_TE_IMAGE_DIRECTORY_ENTRY_DEBUG      1
+
+
+///
+/// Union of PE32, PE32+, and TE headers.
+///
+typedef union {
+  EFI_IMAGE_NT_HEADERS32   Pe32;
+  EFI_IMAGE_NT_HEADERS64   Pe32Plus;
+  EFI_TE_IMAGE_HEADER      Te;
+} EFI_IMAGE_OPTIONAL_HEADER_UNION;
+
+typedef union {
+  EFI_IMAGE_NT_HEADERS32            *Pe32;
+  EFI_IMAGE_NT_HEADERS64            *Pe32Plus;
+  EFI_TE_IMAGE_HEADER               *Te;
+  EFI_IMAGE_OPTIONAL_HEADER_UNION   *Union;
+} EFI_IMAGE_OPTIONAL_HEADER_PTR_UNION;
+
+#endif
diff --git a/tools/cbfstool/edk2/IntelFspPkg/FspInfoHeader.h b/tools/cbfstool/edk2/IntelFspPkg/FspInfoHeader.h
new file mode 100644
index 0000000000..04d6d64bd4
--- /dev/null
+++ b/tools/cbfstool/edk2/IntelFspPkg/FspInfoHeader.h
@@ -0,0 +1,159 @@
+/** @file
+  Intel FSP Info Header definition from Intel Firmware Support Package External
+  Architecture Specification, April 2014, revision 001.
+
+  Copyright (c) 2014 - 2015, Intel Corporation. All rights reserved.<BR>
+  This program and the accompanying materials
+  are licensed and made available under the terms and conditions of the BSD License
+  which accompanies this distribution.  The full text of the license may be found at
+  http://opensource.org/licenses/bsd-license.php.
+
+  THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+  WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+**/
+
+#ifndef _FSP_INFO_HEADER_H_
+#define _FSP_INFO_HEADER_H_
+
+#define FSP_HEADER_REVISION_1   1
+#define FSP_HEADER_REVISION_2   2
+
+#define FSPE_HEADER_REVISION_1  1
+#define FSPP_HEADER_REVISION_1  1
+
+#define FSP_SIG		0x48505346	/* 'FSPH' */
+
+///
+/// Fixed FSP header offset in the FSP image
+///
+#define  FSP_INFO_HEADER_OFF    0x94
+
+#define  OFFSET_IN_FSP_INFO_HEADER(x)  (UINT32)&((FSP_INFO_HEADER *)(UINTN)0)->x
+
+#pragma pack(1)
+
+typedef struct  {
+  ///
+  /// Byte 0x00: Signature ('FSPH') for the FSP Information Header
+  ///
+  UINT32  Signature;
+  ///
+  /// Byte 0x04: Length of the FSP Information Header
+  ///
+  UINT32  HeaderLength;
+  ///
+  /// Byte 0x08: Reserved
+  ///
+  UINT8   Reserved1[3];
+  ///
+  /// Byte 0x0B: Revision of the FSP Information Header
+  ///
+  UINT8   HeaderRevision;
+  ///
+  /// Byte 0x0C: Revision of the FSP binary
+  ///
+  UINT32  ImageRevision;
+
+
+  ///
+  /// Byte 0x10: Signature string that will help match the FSP Binary to a supported
+  /// hardware configuration.
+  ///
+  CHAR8   ImageId[8];
+  ///
+  /// Byte 0x18: Size of the entire FSP binary
+  ///
+  UINT32  ImageSize;
+  ///
+  /// Byte 0x1C: FSP binary preferred base address
+  ///
+  UINT32  ImageBase;
+
+
+  ///
+  /// Byte 0x20: Attribute for the FSP binary
+  ///
+  UINT32  ImageAttribute;
+  ///
+  /// Byte 0x24: Offset of the FSP configuration region
+  ///
+  UINT32  CfgRegionOffset;
+  ///
+  /// Byte 0x28: Size of the FSP configuration region
+  ///
+  UINT32  CfgRegionSize;
+  ///
+  /// Byte 0x2C: Number of API entries this FSP supports
+  ///
+  UINT32  ApiEntryNum;
+
+
+  ///
+  /// Byte 0x30: The offset for the API to setup a temporary stack till the memory
+  ///            is initialized.
+  ///
+  UINT32  TempRamInitEntryOffset;
+  ///
+  /// Byte 0x34: The offset for the API to initialize the CPU and the chipset (SOC)
+  ///
+  UINT32  FspInitEntryOffset;
+  ///
+  /// Byte 0x38: The offset for the API to inform the FSP about the different stages
+  ///            in the boot process
+  ///
+  UINT32  NotifyPhaseEntryOffset;
+
+  ///
+  /// Below fields are added in FSP Revision 2
+  ///
+
+  ///
+  /// Byte 0x3C: The offset for the API to initialize the memory
+  ///
+  UINT32  FspMemoryInitEntryOffset;
+  ///
+  /// Byte 0x40: The offset for the API to tear down temporary RAM
+  ///
+  UINT32  TempRamExitEntryOffset;
+  ///
+  /// Byte 0x44: The offset for the API to initialize the CPU and chipset
+  ///
+  UINT32  FspSiliconInitEntryOffset;
+
+} FSP_INFO_HEADER;
+
+///
+/// Below structure is added in FSP version 2
+///
+typedef struct  {
+  ///
+  /// Byte 0x00: Signature ('FSPE') for the FSP Extended Information Header
+  ///
+  UINT32  Signature;
+  ///
+  /// Byte 0x04: Length of the FSP Extended Header
+  ///
+  UINT32  HeaderLength;
+  ///
+  /// Byte 0x08: Revision of the FSP Extended Header
+  ///
+  UINT8   Revision;
+  ///
+  /// Byte 0x09: Reserved for future use.
+  ///
+  UINT8   Reserved;
+  ///
+  /// Byte 0x0A: An OEM-supplied string that defines the OEM
+  ///
+  CHAR8   OemId[6];
+  ///
+  /// Byte 0x10: An OEM-supplied revision number. Larger numbers are assumed to be newer revisions.
+  ///
+  UINT32  OemRevision;
+
+} FSP_EXTENTED_HEADER;
+
+#pragma pack()
+
+#endif
diff --git a/tools/cbfstool/edk2/Library/HobLib.h b/tools/cbfstool/edk2/Library/HobLib.h
new file mode 100644
index 0000000000..ea95b5cb8d
--- /dev/null
+++ b/tools/cbfstool/edk2/Library/HobLib.h
@@ -0,0 +1,506 @@
+/** @file
+  Provides services to create and parse HOBs. Only available for PEI
+  and DXE module types.
+
+  The HOB Library supports the efficient creation and searching of HOBs
+  defined in the PI Specification.
+  A HOB is a Hand-Off Block, defined in the Framework architecture, that
+  allows the PEI phase to pass information to the DXE phase. HOBs are position
+  independent and can be relocated easily to different memory memory locations.
+
+Copyright (c) 2006 - 2012, Intel Corporation. All rights reserved.<BR>
+This program and the accompanying materials
+are licensed and made available under the terms and conditions of the BSD License
+which accompanies this distribution.  The full text of the license may be found at
+http://opensource.org/licenses/bsd-license.php
+
+THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+**/
+
+#ifndef __HOB_LIB_H__
+#define __HOB_LIB_H__
+
+/**
+  Returns the pointer to the HOB list.
+
+  This function returns the pointer to first HOB in the list.
+  For PEI phase, the PEI service GetHobList() can be used to retrieve the pointer
+  to the HOB list.  For the DXE phase, the HOB list pointer can be retrieved through
+  the EFI System Table by looking up theHOB list GUID in the System Configuration Table.
+  Since the System Configuration Table does not exist that the time the DXE Core is
+  launched, the DXE Core uses a global variable from the DXE Core Entry Point Library
+  to manage the pointer to the HOB list.
+
+  If the pointer to the HOB list is NULL, then ASSERT().
+
+  @return The pointer to the HOB list.
+
+**/
+VOID *
+EFIAPI
+GetHobList (
+  VOID
+  );
+
+/**
+  Returns the next instance of a HOB type from the starting HOB.
+
+  This function searches the first instance of a HOB type from the starting HOB pointer.
+  If there does not exist such HOB type from the starting HOB pointer, it will return NULL.
+  In contrast with macro GET_NEXT_HOB(), this function does not skip the starting HOB pointer
+  unconditionally: it returns HobStart back if HobStart itself meets the requirement;
+  caller is required to use GET_NEXT_HOB() if it wishes to skip current HobStart.
+
+  If HobStart is NULL, then ASSERT().
+
+  @param  Type          The HOB type to return.
+  @param  HobStart      The starting HOB pointer to search from.
+
+  @return The next instance of a HOB type from the starting HOB.
+
+**/
+VOID *
+EFIAPI
+GetNextHob (
+  IN UINT16                 Type,
+  IN CONST VOID             *HobStart
+  );
+
+/**
+  Returns the first instance of a HOB type among the whole HOB list.
+
+  This function searches the first instance of a HOB type among the whole HOB list.
+  If there does not exist such HOB type in the HOB list, it will return NULL.
+
+  If the pointer to the HOB list is NULL, then ASSERT().
+
+  @param  Type          The HOB type to return.
+
+  @return The next instance of a HOB type from the starting HOB.
+
+**/
+VOID *
+EFIAPI
+GetFirstHob (
+  IN UINT16                 Type
+  );
+
+/**
+  Returns the next instance of the matched GUID HOB from the starting HOB.
+
+  This function searches the first instance of a HOB from the starting HOB pointer.
+  Such HOB should satisfy two conditions:
+  its HOB type is EFI_HOB_TYPE_GUID_EXTENSION and its GUID Name equals to the input Guid.
+  If there does not exist such HOB from the starting HOB pointer, it will return NULL.
+  Caller is required to apply GET_GUID_HOB_DATA () and GET_GUID_HOB_DATA_SIZE ()
+  to extract the data section and its size info respectively.
+  In contrast with macro GET_NEXT_HOB(), this function does not skip the starting HOB pointer
+  unconditionally: it returns HobStart back if HobStart itself meets the requirement;
+  caller is required to use GET_NEXT_HOB() if it wishes to skip current HobStart.
+
+  If Guid is NULL, then ASSERT().
+  If HobStart is NULL, then ASSERT().
+
+  @param  Guid          The GUID to match with in the HOB list.
+  @param  HobStart      A pointer to a Guid.
+
+  @return The next instance of the matched GUID HOB from the starting HOB.
+
+**/
+VOID *
+EFIAPI
+GetNextGuidHob (
+  IN CONST EFI_GUID         *Guid,
+  IN CONST VOID             *HobStart
+  );
+
+/**
+  Returns the first instance of the matched GUID HOB among the whole HOB list.
+
+  This function searches the first instance of a HOB among the whole HOB list.
+  Such HOB should satisfy two conditions:
+  its HOB type is EFI_HOB_TYPE_GUID_EXTENSION and its GUID Name equals to the input Guid.
+  If there does not exist such HOB from the starting HOB pointer, it will return NULL.
+  Caller is required to apply GET_GUID_HOB_DATA () and GET_GUID_HOB_DATA_SIZE ()
+  to extract the data section and its size info respectively.
+
+  If the pointer to the HOB list is NULL, then ASSERT().
+  If Guid is NULL, then ASSERT().
+
+  @param  Guid          The GUID to match with in the HOB list.
+
+  @return The first instance of the matched GUID HOB among the whole HOB list.
+
+**/
+VOID *
+EFIAPI
+GetFirstGuidHob (
+  IN CONST EFI_GUID         *Guid
+  );
+
+/**
+  Get the system boot mode from the HOB list.
+
+  This function returns the system boot mode information from the
+  PHIT HOB in HOB list.
+
+  If the pointer to the HOB list is NULL, then ASSERT().
+
+  @param  VOID
+
+  @return The Boot Mode.
+
+**/
+EFI_BOOT_MODE
+EFIAPI
+GetBootModeHob (
+  VOID
+  );
+
+/**
+  Builds a HOB for a loaded PE32 module.
+
+  This function builds a HOB for a loaded PE32 module.
+  It can only be invoked during PEI phase;
+  for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+
+  If ModuleName is NULL, then ASSERT().
+  If there is no additional space for HOB creation, then ASSERT().
+
+  @param  ModuleName              The GUID File Name of the module.
+  @param  MemoryAllocationModule  The 64 bit physical address of the module.
+  @param  ModuleLength            The length of the module in bytes.
+  @param  EntryPoint              The 64 bit physical address of the module entry point.
+
+**/
+VOID
+EFIAPI
+BuildModuleHob (
+  IN CONST EFI_GUID         *ModuleName,
+  IN EFI_PHYSICAL_ADDRESS   MemoryAllocationModule,
+  IN UINT64                 ModuleLength,
+  IN EFI_PHYSICAL_ADDRESS   EntryPoint
+  );
+
+/**
+  Builds a HOB that describes a chunk of system memory.
+
+  This function builds a HOB that describes a chunk of system memory.
+  It can only be invoked during PEI phase;
+  for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+
+  If there is no additional space for HOB creation, then ASSERT().
+
+  @param  ResourceType        The type of resource described by this HOB.
+  @param  ResourceAttribute   The resource attributes of the memory described by this HOB.
+  @param  PhysicalStart       The 64 bit physical address of memory described by this HOB.
+  @param  NumberOfBytes       The length of the memory described by this HOB in bytes.
+
+**/
+VOID
+EFIAPI
+BuildResourceDescriptorHob (
+  IN EFI_RESOURCE_TYPE            ResourceType,
+  IN EFI_RESOURCE_ATTRIBUTE_TYPE  ResourceAttribute,
+  IN EFI_PHYSICAL_ADDRESS         PhysicalStart,
+  IN UINT64                       NumberOfBytes
+  );
+
+/**
+  Builds a customized HOB tagged with a GUID for identification and returns
+  the start address of GUID HOB data.
+
+  This function builds a customized HOB tagged with a GUID for identification
+  and returns the start address of GUID HOB data so that caller can fill the customized data.
+  The HOB Header and Name field is already stripped.
+  It can only be invoked during PEI phase;
+  for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+
+  If Guid is NULL, then ASSERT().
+  If there is no additional space for HOB creation, then ASSERT().
+  If DataLength > (0xFFF8 - sizeof (EFI_HOB_GUID_TYPE)), then ASSERT().
+  HobLength is UINT16 and multiples of 8 bytes, so the max HobLength is 0xFFF8.
+
+  @param  Guid          The GUID to tag the customized HOB.
+  @param  DataLength    The size of the data payload for the GUID HOB.
+
+  @retval  NULL         The GUID HOB could not be allocated.
+  @retval  others       The start address of GUID HOB data.
+
+**/
+VOID *
+EFIAPI
+BuildGuidHob (
+  IN CONST EFI_GUID              *Guid,
+  IN UINTN                       DataLength
+  );
+
+/**
+  Builds a customized HOB tagged with a GUID for identification, copies the input data to the HOB
+  data field, and returns the start address of the GUID HOB data.
+
+  This function builds a customized HOB tagged with a GUID for identification and copies the input
+  data to the HOB data field and returns the start address of the GUID HOB data.  It can only be
+  invoked during PEI phase; for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+  The HOB Header and Name field is already stripped.
+  It can only be invoked during PEI phase;
+  for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+
+  If Guid is NULL, then ASSERT().
+  If Data is NULL and DataLength > 0, then ASSERT().
+  If there is no additional space for HOB creation, then ASSERT().
+  If DataLength > (0xFFF8 - sizeof (EFI_HOB_GUID_TYPE)), then ASSERT().
+  HobLength is UINT16 and multiples of 8 bytes, so the max HobLength is 0xFFF8.
+
+  @param  Guid          The GUID to tag the customized HOB.
+  @param  Data          The data to be copied into the data field of the GUID HOB.
+  @param  DataLength    The size of the data payload for the GUID HOB.
+
+  @retval  NULL         The GUID HOB could not be allocated.
+  @retval  others       The start address of GUID HOB data.
+
+**/
+VOID *
+EFIAPI
+BuildGuidDataHob (
+  IN CONST EFI_GUID              *Guid,
+  IN VOID                        *Data,
+  IN UINTN                       DataLength
+  );
+
+/**
+  Builds a Firmware Volume HOB.
+
+  This function builds a Firmware Volume HOB.
+  It can only be invoked during PEI phase;
+  for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+
+  If there is no additional space for HOB creation, then ASSERT().
+
+  @param  BaseAddress   The base address of the Firmware Volume.
+  @param  Length        The size of the Firmware Volume in bytes.
+
+**/
+VOID
+EFIAPI
+BuildFvHob (
+  IN EFI_PHYSICAL_ADDRESS        BaseAddress,
+  IN UINT64                      Length
+  );
+
+/**
+  Builds a EFI_HOB_TYPE_FV2 HOB.
+
+  This function builds a EFI_HOB_TYPE_FV2 HOB.
+  It can only be invoked during PEI phase;
+  for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+
+  If there is no additional space for HOB creation, then ASSERT().
+
+  @param  BaseAddress   The base address of the Firmware Volume.
+  @param  Length        The size of the Firmware Volume in bytes.
+  @param  FvName        The name of the Firmware Volume.
+  @param  FileName      The name of the file.
+
+**/
+VOID
+EFIAPI
+BuildFv2Hob (
+  IN          EFI_PHYSICAL_ADDRESS        BaseAddress,
+  IN          UINT64                      Length,
+  IN CONST    EFI_GUID                    *FvName,
+  IN CONST    EFI_GUID                    *FileName
+  );
+
+/**
+  Builds a Capsule Volume HOB.
+
+  This function builds a Capsule Volume HOB.
+  It can only be invoked during PEI phase;
+  for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+
+  If the platform does not support Capsule Volume HOBs, then ASSERT().
+  If there is no additional space for HOB creation, then ASSERT().
+
+  @param  BaseAddress   The base address of the Capsule Volume.
+  @param  Length        The size of the Capsule Volume in bytes.
+
+**/
+VOID
+EFIAPI
+BuildCvHob (
+  IN EFI_PHYSICAL_ADDRESS        BaseAddress,
+  IN UINT64                      Length
+  );
+
+/**
+  Builds a HOB for the CPU.
+
+  This function builds a HOB for the CPU.
+  It can only be invoked during PEI phase;
+  for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+
+  If there is no additional space for HOB creation, then ASSERT().
+
+  @param  SizeOfMemorySpace   The maximum physical memory addressability of the processor.
+  @param  SizeOfIoSpace       The maximum physical I/O addressability of the processor.
+
+**/
+VOID
+EFIAPI
+BuildCpuHob (
+  IN UINT8                       SizeOfMemorySpace,
+  IN UINT8                       SizeOfIoSpace
+  );
+
+/**
+  Builds a HOB for the Stack.
+
+  This function builds a HOB for the stack.
+  It can only be invoked during PEI phase;
+  for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+
+  If there is no additional space for HOB creation, then ASSERT().
+
+  @param  BaseAddress   The 64 bit physical address of the Stack.
+  @param  Length        The length of the stack in bytes.
+
+**/
+VOID
+EFIAPI
+BuildStackHob (
+  IN EFI_PHYSICAL_ADDRESS        BaseAddress,
+  IN UINT64                      Length
+  );
+
+/**
+  Builds a HOB for the BSP store.
+
+  This function builds a HOB for BSP store.
+  It can only be invoked during PEI phase;
+  for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+
+  If there is no additional space for HOB creation, then ASSERT().
+
+  @param  BaseAddress   The 64 bit physical address of the BSP.
+  @param  Length        The length of the BSP store in bytes.
+  @param  MemoryType    Type of memory allocated by this HOB.
+
+**/
+VOID
+EFIAPI
+BuildBspStoreHob (
+  IN EFI_PHYSICAL_ADDRESS        BaseAddress,
+  IN UINT64                      Length,
+  IN EFI_MEMORY_TYPE             MemoryType
+  );
+
+/**
+  Builds a HOB for the memory allocation.
+
+  This function builds a HOB for the memory allocation.
+  It can only be invoked during PEI phase;
+  for DXE phase, it will ASSERT() since PEI HOB is read-only for DXE phase.
+
+  If there is no additional space for HOB creation, then ASSERT().
+
+  @param  BaseAddress   The 64 bit physical address of the memory.
+  @param  Length        The length of the memory allocation in bytes.
+  @param  MemoryType    Type of memory allocated by this HOB.
+
+**/
+VOID
+EFIAPI
+BuildMemoryAllocationHob (
+  IN EFI_PHYSICAL_ADDRESS        BaseAddress,
+  IN UINT64                      Length,
+  IN EFI_MEMORY_TYPE             MemoryType
+  );
+
+/**
+  Returns the type of a HOB.
+
+  This macro returns the HobType field from the HOB header for the
+  HOB specified by HobStart.
+
+  @param  HobStart   A pointer to a HOB.
+
+  @return HobType.
+
+**/
+#define GET_HOB_TYPE(HobStart) \
+	(((EFI_HOB_GENERIC_HEADER *)HobStart)->HobType)
+
+/**
+  Returns the length, in bytes, of a HOB.
+
+  This macro returns the HobLength field from the HOB header for the
+  HOB specified by HobStart.
+
+  @param  HobStart   A pointer to a HOB.
+
+  @return HobLength.
+
+**/
+#define GET_HOB_LENGTH(HobStart) \
+	(((EFI_HOB_GENERIC_HEADER *)HobStart)->HobLength)
+
+/**
+  Returns a pointer to the next HOB in the HOB list.
+
+  This macro returns a pointer to HOB that follows the
+  HOB specified by HobStart in the HOB List.
+
+  @param  HobStart   A pointer to a HOB.
+
+  @return A pointer to the next HOB in the HOB list.
+
+**/
+#define GET_NEXT_HOB(HobStart) \
+	(VOID *)((UINT8 *)(HobStart) + GET_HOB_LENGTH(HobStart))
+
+/**
+  Determines if a HOB is the last HOB in the HOB list.
+
+  This macro determine if the HOB specified by HobStart is the
+  last HOB in the HOB list.  If HobStart is last HOB in the HOB list,
+  then TRUE is returned.  Otherwise, FALSE is returned.
+
+  @param  HobStart   A pointer to a HOB.
+
+  @retval TRUE       The HOB specified by HobStart is the last HOB in the HOB list.
+  @retval FALSE      The HOB specified by HobStart is not the last HOB in the HOB list.
+
+**/
+#define END_OF_HOB_LIST(HobStart)  (GET_HOB_TYPE (HobStart) == (UINT16)EFI_HOB_TYPE_END_OF_HOB_LIST)
+
+/**
+  Returns a pointer to data buffer from a HOB of type EFI_HOB_TYPE_GUID_EXTENSION.
+
+  This macro returns a pointer to the data buffer in a HOB specified by HobStart.
+  HobStart is assumed to be a HOB of type EFI_HOB_TYPE_GUID_EXTENSION.
+
+  @param   GuidHob   A pointer to a HOB.
+
+  @return  A pointer to the data buffer in a HOB.
+
+**/
+#define GET_GUID_HOB_DATA(HobStart) \
+	(VOID *)((UINT8 *)(HobStart) + sizeof(EFI_HOB_GUID_TYPE))
+
+/**
+  Returns the size of the data buffer from a HOB of type EFI_HOB_TYPE_GUID_EXTENSION.
+
+  This macro returns the size, in bytes, of the data buffer in a HOB specified by HobStart.
+  HobStart is assumed to be a HOB of type EFI_HOB_TYPE_GUID_EXTENSION.
+
+  @param   GuidHob   A pointer to a HOB.
+
+  @return  The size of the data buffer.
+**/
+#define GET_GUID_HOB_DATA_SIZE(HobStart) \
+	(UINT16)(GET_HOB_LENGTH(HobStart) - sizeof(EFI_HOB_GUID_TYPE))
+
+#endif
diff --git a/tools/cbfstool/edk2/Pi/PiBootMode.h b/tools/cbfstool/edk2/Pi/PiBootMode.h
new file mode 100644
index 0000000000..793833bccd
--- /dev/null
+++ b/tools/cbfstool/edk2/Pi/PiBootMode.h
@@ -0,0 +1,42 @@
+/** @file
+  Present the boot mode values in PI.
+
+  Copyright (c) 2006 - 2012, Intel Corporation. All rights reserved.<BR>
+  This program and the accompanying materials
+  are licensed and made available under the terms and conditions of the BSD License
+  which accompanies this distribution.  The full text of the license may be found at
+  http://opensource.org/licenses/bsd-license.php
+
+  THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+  WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+  @par Revision Reference:
+  PI Version 1.2.1A
+
+**/
+
+#ifndef __PI_BOOT_MODE_H__
+#define __PI_BOOT_MODE_H__
+
+///
+/// EFI boot mode
+///
+typedef UINT32  EFI_BOOT_MODE;
+
+//
+// 0x21 - 0xf..f are reserved.
+//
+#define BOOT_WITH_FULL_CONFIGURATION                  0x00
+#define BOOT_WITH_MINIMAL_CONFIGURATION               0x01
+#define BOOT_ASSUMING_NO_CONFIGURATION_CHANGES        0x02
+#define BOOT_WITH_FULL_CONFIGURATION_PLUS_DIAGNOSTICS 0x03
+#define BOOT_WITH_DEFAULT_SETTINGS                    0x04
+#define BOOT_ON_S4_RESUME                             0x05
+#define BOOT_ON_S5_RESUME                             0x06
+#define BOOT_WITH_MFG_MODE_SETTINGS                   0x07
+#define BOOT_ON_S2_RESUME                             0x10
+#define BOOT_ON_S3_RESUME                             0x11
+#define BOOT_ON_FLASH_UPDATE                          0x12
+#define BOOT_IN_RECOVERY_MODE                         0x20
+
+#endif
diff --git a/tools/cbfstool/edk2/Pi/PiFirmwareFile.h b/tools/cbfstool/edk2/Pi/PiFirmwareFile.h
new file mode 100644
index 0000000000..750ba7091e
--- /dev/null
+++ b/tools/cbfstool/edk2/Pi/PiFirmwareFile.h
@@ -0,0 +1,494 @@
+/** @file
+  The firmware file related definitions in PI.
+
+Copyright (c) 2006 - 2011, Intel Corporation. All rights reserved.<BR>
+This program and the accompanying materials are licensed and made available under
+the terms and conditions of the BSD License that accompanies this distribution.
+The full text of the license may be found at
+http://opensource.org/licenses/bsd-license.php.
+
+THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+  @par Revision Reference:
+  PI Version 1.2.
+
+**/
+
+
+#ifndef __PI_FIRMWARE_FILE_H__
+#define __PI_FIRMWARE_FILE_H__
+
+#pragma pack(1)
+///
+/// Used to verify the integrity of the file.
+///
+typedef union {
+  struct {
+    ///
+    /// The IntegrityCheck.Checksum.Header field is an 8-bit checksum of the file
+    /// header. The State and IntegrityCheck.Checksum.File fields are assumed
+    /// to be zero and the checksum is calculated such that the entire header sums to zero.
+    ///
+    UINT8   Header;
+    ///
+    /// If the FFS_ATTRIB_CHECKSUM (see definition below) bit of the Attributes
+    /// field is set to one, the IntegrityCheck.Checksum.File field is an 8-bit
+    /// checksum of the file data.
+    /// If the FFS_ATTRIB_CHECKSUM bit of the Attributes field is cleared to zero,
+    /// the IntegrityCheck.Checksum.File field must be initialized with a value of
+    /// 0xAA. The IntegrityCheck.Checksum.File field is valid any time the
+    /// EFI_FILE_DATA_VALID bit is set in the State field.
+    ///
+    UINT8   File;
+  } Checksum;
+  ///
+  /// This is the full 16 bits of the IntegrityCheck field.
+  ///
+  UINT16    Checksum16;
+} EFI_FFS_INTEGRITY_CHECK;
+
+///
+/// FFS_FIXED_CHECKSUM is the checksum value used when the
+/// FFS_ATTRIB_CHECKSUM attribute bit is clear.
+///
+#define FFS_FIXED_CHECKSUM  0xAA
+
+typedef UINT8 EFI_FV_FILETYPE;
+typedef UINT8 EFI_FFS_FILE_ATTRIBUTES;
+typedef UINT8 EFI_FFS_FILE_STATE;
+
+///
+/// File Types Definitions
+///
+#define EFI_FV_FILETYPE_ALL                   0x00
+#define EFI_FV_FILETYPE_RAW                   0x01
+#define EFI_FV_FILETYPE_FREEFORM              0x02
+#define EFI_FV_FILETYPE_SECURITY_CORE         0x03
+#define EFI_FV_FILETYPE_PEI_CORE              0x04
+#define EFI_FV_FILETYPE_DXE_CORE              0x05
+#define EFI_FV_FILETYPE_PEIM                  0x06
+#define EFI_FV_FILETYPE_DRIVER                0x07
+#define EFI_FV_FILETYPE_COMBINED_PEIM_DRIVER  0x08
+#define EFI_FV_FILETYPE_APPLICATION           0x09
+#define EFI_FV_FILETYPE_SMM                   0x0A
+#define EFI_FV_FILETYPE_FIRMWARE_VOLUME_IMAGE 0x0B
+#define EFI_FV_FILETYPE_COMBINED_SMM_DXE      0x0C
+#define EFI_FV_FILETYPE_SMM_CORE              0x0D
+#define EFI_FV_FILETYPE_OEM_MIN               0xc0
+#define EFI_FV_FILETYPE_OEM_MAX               0xdf
+#define EFI_FV_FILETYPE_DEBUG_MIN             0xe0
+#define EFI_FV_FILETYPE_DEBUG_MAX             0xef
+#define EFI_FV_FILETYPE_FFS_MIN               0xf0
+#define EFI_FV_FILETYPE_FFS_MAX               0xff
+#define EFI_FV_FILETYPE_FFS_PAD               0xf0
+///
+/// FFS File Attributes.
+///
+#define FFS_ATTRIB_LARGE_FILE         0x01
+#define FFS_ATTRIB_FIXED              0x04
+#define FFS_ATTRIB_DATA_ALIGNMENT     0x38
+#define FFS_ATTRIB_CHECKSUM           0x40
+
+///
+/// FFS File State Bits.
+///
+#define EFI_FILE_HEADER_CONSTRUCTION  0x01
+#define EFI_FILE_HEADER_VALID         0x02
+#define EFI_FILE_DATA_VALID           0x04
+#define EFI_FILE_MARKED_FOR_UPDATE    0x08
+#define EFI_FILE_DELETED              0x10
+#define EFI_FILE_HEADER_INVALID       0x20
+
+
+///
+/// Each file begins with the header that describe the
+/// contents and state of the files.
+///
+typedef struct {
+  ///
+  /// This GUID is the file name. It is used to uniquely identify the file.
+  ///
+  EFI_GUID                Name;
+  ///
+  /// Used to verify the integrity of the file.
+  ///
+  EFI_FFS_INTEGRITY_CHECK IntegrityCheck;
+  ///
+  /// Identifies the type of file.
+  ///
+  EFI_FV_FILETYPE         Type;
+  ///
+  /// Declares various file attribute bits.
+  ///
+  EFI_FFS_FILE_ATTRIBUTES Attributes;
+  ///
+  /// The length of the file in bytes, including the FFS header.
+  ///
+  UINT8                   Size[3];
+  ///
+  /// Used to track the state of the file throughout the life of the file from creation to deletion.
+  ///
+  EFI_FFS_FILE_STATE      State;
+} EFI_FFS_FILE_HEADER;
+
+typedef struct {
+  ///
+  /// This GUID is the file name. It is used to uniquely identify the file. There may be only
+  /// one instance of a file with the file name GUID of Name in any given firmware
+  /// volume, except if the file type is EFI_FV_FILETYPE_FFS_PAD.
+  ///
+  EFI_GUID                  Name;
+
+  ///
+  /// Used to verify the integrity of the file.
+  ///
+  EFI_FFS_INTEGRITY_CHECK   IntegrityCheck;
+
+  ///
+  /// Identifies the type of file.
+  ///
+  EFI_FV_FILETYPE           Type;
+
+  ///
+  /// Declares various file attribute bits.
+  ///
+  EFI_FFS_FILE_ATTRIBUTES   Attributes;
+
+  ///
+  /// The length of the file in bytes, including the FFS header.
+  /// The length of the file data is either (Size - sizeof(EFI_FFS_FILE_HEADER)). This calculation means a
+  /// zero-length file has a Size of 24 bytes, which is sizeof(EFI_FFS_FILE_HEADER).
+  /// Size is not required to be a multiple of 8 bytes. Given a file F, the next file header is
+  /// located at the next 8-byte aligned firmware volume offset following the last byte of the file F.
+  ///
+  UINT8                     Size[3];
+
+  ///
+  /// Used to track the state of the file throughout the life of the file from creation to deletion.
+  ///
+  EFI_FFS_FILE_STATE        State;
+
+  ///
+  /// If FFS_ATTRIB_LARGE_FILE is set in Attributes, then ExtendedSize exists and Size must be set to zero.
+  /// If FFS_ATTRIB_LARGE_FILE is not set then EFI_FFS_FILE_HEADER is used.
+  ///
+  UINT32                    ExtendedSize;
+} EFI_FFS_FILE_HEADER2;
+
+#define IS_FFS_FILE2(FfsFileHeaderPtr) \
+    (((((EFI_FFS_FILE_HEADER *) (UINTN) FfsFileHeaderPtr)->Attributes) & FFS_ATTRIB_LARGE_FILE) == FFS_ATTRIB_LARGE_FILE)
+
+#define FFS_FILE_SIZE(FfsFileHeaderPtr) \
+    ((UINT32) (*((UINT32 *) ((EFI_FFS_FILE_HEADER *) (UINTN) FfsFileHeaderPtr)->Size) & 0x00ffffff))
+
+#define FFS_FILE2_SIZE(FfsFileHeaderPtr) \
+    (((EFI_FFS_FILE_HEADER2 *) (UINTN) FfsFileHeaderPtr)->ExtendedSize)
+
+typedef UINT8 EFI_SECTION_TYPE;
+
+///
+/// Pseudo type. It is used as a wild card when retrieving sections.
+///  The section type EFI_SECTION_ALL matches all section types.
+///
+#define EFI_SECTION_ALL                   0x00
+
+///
+/// Encapsulation section Type values.
+///
+#define EFI_SECTION_COMPRESSION           0x01
+
+#define EFI_SECTION_GUID_DEFINED          0x02
+
+#define EFI_SECTION_DISPOSABLE            0x03
+
+///
+/// Leaf section Type values.
+///
+#define EFI_SECTION_PE32                  0x10
+#define EFI_SECTION_PIC                   0x11
+#define EFI_SECTION_TE                    0x12
+#define EFI_SECTION_DXE_DEPEX             0x13
+#define EFI_SECTION_VERSION               0x14
+#define EFI_SECTION_USER_INTERFACE        0x15
+#define EFI_SECTION_COMPATIBILITY16       0x16
+#define EFI_SECTION_FIRMWARE_VOLUME_IMAGE 0x17
+#define EFI_SECTION_FREEFORM_SUBTYPE_GUID 0x18
+#define EFI_SECTION_RAW                   0x19
+#define EFI_SECTION_PEI_DEPEX             0x1B
+#define EFI_SECTION_SMM_DEPEX             0x1C
+
+///
+/// Common section header.
+///
+typedef struct {
+  ///
+  /// A 24-bit unsigned integer that contains the total size of the section in bytes,
+  /// including the EFI_COMMON_SECTION_HEADER.
+  ///
+  UINT8             Size[3];
+  EFI_SECTION_TYPE  Type;
+  ///
+  /// Declares the section type.
+  ///
+} EFI_COMMON_SECTION_HEADER;
+
+typedef struct {
+  ///
+  /// A 24-bit unsigned integer that contains the total size of the section in bytes,
+  /// including the EFI_COMMON_SECTION_HEADER.
+  ///
+  UINT8             Size[3];
+
+  EFI_SECTION_TYPE  Type;
+
+  ///
+  /// If Size is 0xFFFFFF, then ExtendedSize contains the size of the section. If
+  /// Size is not equal to 0xFFFFFF, then this field does not exist.
+  ///
+  UINT32            ExtendedSize;
+} EFI_COMMON_SECTION_HEADER2;
+
+///
+/// Leaf section type that contains an
+/// IA-32 16-bit executable image.
+///
+typedef EFI_COMMON_SECTION_HEADER  EFI_COMPATIBILITY16_SECTION;
+typedef EFI_COMMON_SECTION_HEADER2 EFI_COMPATIBILITY16_SECTION2;
+
+///
+/// CompressionType of EFI_COMPRESSION_SECTION.
+///
+#define EFI_NOT_COMPRESSED        0x00
+#define EFI_STANDARD_COMPRESSION  0x01
+///
+/// An encapsulation section type in which the
+/// section data is compressed.
+///
+typedef struct {
+  ///
+  /// Usual common section header. CommonHeader.Type = EFI_SECTION_COMPRESSION.
+  ///
+  EFI_COMMON_SECTION_HEADER   CommonHeader;
+  ///
+  /// The UINT32 that indicates the size of the section data after decompression.
+  ///
+  UINT32                      UncompressedLength;
+  ///
+  /// Indicates which compression algorithm is used.
+  ///
+  UINT8                       CompressionType;
+} EFI_COMPRESSION_SECTION;
+
+typedef struct {
+  ///
+  /// Usual common section header. CommonHeader.Type = EFI_SECTION_COMPRESSION.
+  ///
+  EFI_COMMON_SECTION_HEADER2    CommonHeader;
+  ///
+  /// UINT32 that indicates the size of the section data after decompression.
+  ///
+  UINT32                        UncompressedLength;
+  ///
+  /// Indicates which compression algorithm is used.
+  ///
+  UINT8                         CompressionType;
+} EFI_COMPRESSION_SECTION2;
+
+///
+/// An encapsulation section type in which the section data is disposable.
+/// A disposable section is an encapsulation section in which the section data may be disposed of during
+/// the process of creating or updating a firmware image without significant impact on the usefulness of
+/// the file. The Type field in the section header is set to EFI_SECTION_DISPOSABLE. This
+/// allows optional or descriptive data to be included with the firmware file which can be removed in
+/// order to conserve space. The contents of this section are implementation specific, but might contain
+/// debug data or detailed integration instructions.
+///
+typedef EFI_COMMON_SECTION_HEADER   EFI_DISPOSABLE_SECTION;
+typedef EFI_COMMON_SECTION_HEADER2  EFI_DISPOSABLE_SECTION2;
+
+///
+/// The leaf section which could be used to determine the dispatch order of DXEs.
+///
+typedef EFI_COMMON_SECTION_HEADER   EFI_DXE_DEPEX_SECTION;
+typedef EFI_COMMON_SECTION_HEADER2  EFI_DXE_DEPEX_SECTION2;
+
+///
+/// The leaf section which contains a PI FV.
+///
+typedef EFI_COMMON_SECTION_HEADER   EFI_FIRMWARE_VOLUME_IMAGE_SECTION;
+typedef EFI_COMMON_SECTION_HEADER2  EFI_FIRMWARE_VOLUME_IMAGE_SECTION2;
+
+///
+/// The leaf section which contains a single GUID.
+///
+typedef struct {
+  ///
+  /// Common section header. CommonHeader.Type = EFI_SECTION_FREEFORM_SUBTYPE_GUID.
+  ///
+  EFI_COMMON_SECTION_HEADER   CommonHeader;
+  ///
+  /// This GUID is defined by the creator of the file. It is a vendor-defined file type.
+  ///
+  EFI_GUID                    SubTypeGuid;
+} EFI_FREEFORM_SUBTYPE_GUID_SECTION;
+
+typedef struct {
+  ///
+  /// The common section header. CommonHeader.Type = EFI_SECTION_FREEFORM_SUBTYPE_GUID.
+  ///
+  EFI_COMMON_SECTION_HEADER2    CommonHeader;
+  ///
+  /// This GUID is defined by the creator of the file. It is a vendor-defined file type.
+  ///
+  EFI_GUID                      SubTypeGuid;
+} EFI_FREEFORM_SUBTYPE_GUID_SECTION2;
+
+///
+/// Attributes of EFI_GUID_DEFINED_SECTION.
+///
+#define EFI_GUIDED_SECTION_PROCESSING_REQUIRED  0x01
+#define EFI_GUIDED_SECTION_AUTH_STATUS_VALID    0x02
+///
+/// The leaf section which is encapsulation defined by specific GUID.
+///
+typedef struct {
+  ///
+  /// The common section header. CommonHeader.Type = EFI_SECTION_GUID_DEFINED.
+  ///
+  EFI_COMMON_SECTION_HEADER   CommonHeader;
+  ///
+  /// The GUID that defines the format of the data that follows. It is a vendor-defined section type.
+  ///
+  EFI_GUID                    SectionDefinitionGuid;
+  ///
+  /// Contains the offset in bytes from the beginning of the common header to the first byte of the data.
+  ///
+  UINT16                      DataOffset;
+  ///
+  /// The bit field that declares some specific characteristics of the section contents.
+  ///
+  UINT16                      Attributes;
+} EFI_GUID_DEFINED_SECTION;
+
+typedef struct {
+  ///
+  /// The common section header. CommonHeader.Type = EFI_SECTION_GUID_DEFINED.
+  ///
+  EFI_COMMON_SECTION_HEADER2    CommonHeader;
+  ///
+  /// The GUID that defines the format of the data that follows. It is a vendor-defined section type.
+  ///
+  EFI_GUID                      SectionDefinitionGuid;
+  ///
+  /// Contains the offset in bytes from the beginning of the common header to the first byte of the data.
+  ///
+  UINT16                        DataOffset;
+  ///
+  /// The bit field that declares some specific characteristics of the section contents.
+  ///
+  UINT16                        Attributes;
+} EFI_GUID_DEFINED_SECTION2;
+
+///
+/// The leaf section which contains PE32+ image.
+///
+typedef EFI_COMMON_SECTION_HEADER   EFI_PE32_SECTION;
+typedef EFI_COMMON_SECTION_HEADER2  EFI_PE32_SECTION2;
+
+///
+/// The leaf section used to determine the dispatch order of PEIMs.
+///
+typedef EFI_COMMON_SECTION_HEADER   EFI_PEI_DEPEX_SECTION;
+typedef EFI_COMMON_SECTION_HEADER2  EFI_PEI_DEPEX_SECTION2;
+
+///
+/// A leaf section type that contains a position-independent-code (PIC) image.
+/// A PIC image section is a leaf section that contains a position-independent-code (PIC) image.
+/// In addition to normal PE32+ images that contain relocation information, PEIM executables may be
+/// PIC and are referred to as PIC images. A PIC image is the same as a PE32+ image except that all
+/// relocation information has been stripped from the image and the image can be moved and will
+/// execute correctly without performing any relocation or other fix-ups. EFI_PIC_SECTION2 must
+/// be used if the section is 16MB or larger.
+///
+typedef EFI_COMMON_SECTION_HEADER   EFI_PIC_SECTION;
+typedef EFI_COMMON_SECTION_HEADER2  EFI_PIC_SECTION2;
+
+///
+/// The leaf section which constains the position-independent-code image.
+///
+typedef EFI_COMMON_SECTION_HEADER   EFI_TE_SECTION;
+typedef EFI_COMMON_SECTION_HEADER2  EFI_TE_SECTION2;
+
+///
+/// The leaf section which contains an array of zero or more bytes.
+///
+typedef EFI_COMMON_SECTION_HEADER   EFI_RAW_SECTION;
+typedef EFI_COMMON_SECTION_HEADER2  EFI_RAW_SECTION2;
+
+///
+/// The SMM dependency expression section is a leaf section that contains a dependency expression that
+/// is used to determine the dispatch order for SMM drivers. Before the SMRAM invocation of the
+/// SMM driver's entry point, this dependency expression must evaluate to TRUE. See the Platform
+/// Initialization Specification, Volume 2, for details regarding the format of the dependency expression.
+/// The dependency expression may refer to protocols installed in either the UEFI or the SMM protocol
+/// database. EFI_SMM_DEPEX_SECTION2 must be used if the section is 16MB or larger.
+///
+typedef EFI_COMMON_SECTION_HEADER EFI_SMM_DEPEX_SECTION;
+typedef EFI_COMMON_SECTION_HEADER2 EFI_SMM_DEPEX_SECTION2;
+
+///
+/// The leaf section which contains a unicode string that
+/// is human readable file name.
+///
+typedef struct {
+  EFI_COMMON_SECTION_HEADER   CommonHeader;
+
+  ///
+  /// Array of unicode string.
+  ///
+  CHAR16                      FileNameString[1];
+} EFI_USER_INTERFACE_SECTION;
+
+typedef struct {
+  EFI_COMMON_SECTION_HEADER2    CommonHeader;
+  CHAR16                        FileNameString[1];
+} EFI_USER_INTERFACE_SECTION2;
+
+///
+/// The leaf section which contains a numeric build number and
+/// an optional unicode string that represents the file revision.
+///
+typedef struct {
+  EFI_COMMON_SECTION_HEADER   CommonHeader;
+  UINT16                      BuildNumber;
+
+  ///
+  /// Array of unicode string.
+  ///
+  CHAR16                      VersionString[1];
+} EFI_VERSION_SECTION;
+
+typedef struct {
+  EFI_COMMON_SECTION_HEADER2    CommonHeader;
+  ///
+  /// A UINT16 that represents a particular build. Subsequent builds have monotonically
+  /// increasing build numbers relative to earlier builds.
+  ///
+  UINT16                        BuildNumber;
+  CHAR16                        VersionString[1];
+} EFI_VERSION_SECTION2;
+
+#define IS_SECTION2(SectionHeaderPtr) \
+    ((UINT32) (*((UINT32 *) ((EFI_COMMON_SECTION_HEADER *) (UINTN) SectionHeaderPtr)->Size) & 0x00ffffff) == 0x00ffffff)
+
+#define SECTION_SIZE(SectionHeaderPtr) \
+    ((UINT32) (*((UINT32 *) ((EFI_COMMON_SECTION_HEADER *) (UINTN) SectionHeaderPtr)->Size) & 0x00ffffff))
+
+#define SECTION2_SIZE(SectionHeaderPtr) \
+    (((EFI_COMMON_SECTION_HEADER2 *) (UINTN) SectionHeaderPtr)->ExtendedSize)
+
+#pragma pack()
+
+#endif
+
diff --git a/tools/cbfstool/edk2/Pi/PiFirmwareVolume.h b/tools/cbfstool/edk2/Pi/PiFirmwareVolume.h
new file mode 100644
index 0000000000..6ef2f1fc33
--- /dev/null
+++ b/tools/cbfstool/edk2/Pi/PiFirmwareVolume.h
@@ -0,0 +1,234 @@
+/** @file
+  The firmware volume related definitions in PI.
+
+  Copyright (c) 2006 - 2013, Intel Corporation. All rights reserved.<BR>
+  This program and the accompanying materials
+  are licensed and made available under the terms and conditions of the BSD License
+  which accompanies this distribution.  The full text of the license may be found at
+  http://opensource.org/licenses/bsd-license.php
+
+  THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+  WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+  @par Revision Reference:
+  PI Version 1.3
+
+**/
+
+#ifndef __PI_FIRMWAREVOLUME_H__
+#define __PI_FIRMWAREVOLUME_H__
+
+///
+/// EFI_FV_FILE_ATTRIBUTES
+///
+typedef UINT32  EFI_FV_FILE_ATTRIBUTES;
+
+//
+// Value of EFI_FV_FILE_ATTRIBUTES.
+//
+#define EFI_FV_FILE_ATTRIB_ALIGNMENT      0x0000001F
+#define EFI_FV_FILE_ATTRIB_FIXED          0x00000100
+#define EFI_FV_FILE_ATTRIB_MEMORY_MAPPED  0x00000200
+
+///
+/// type of EFI FVB attribute
+///
+typedef UINT32  EFI_FVB_ATTRIBUTES_2;
+
+//
+// Attributes bit definitions
+//
+#define EFI_FVB2_READ_DISABLED_CAP  0x00000001
+#define EFI_FVB2_READ_ENABLED_CAP   0x00000002
+#define EFI_FVB2_READ_STATUS        0x00000004
+#define EFI_FVB2_WRITE_DISABLED_CAP 0x00000008
+#define EFI_FVB2_WRITE_ENABLED_CAP  0x00000010
+#define EFI_FVB2_WRITE_STATUS       0x00000020
+#define EFI_FVB2_LOCK_CAP           0x00000040
+#define EFI_FVB2_LOCK_STATUS        0x00000080
+#define EFI_FVB2_STICKY_WRITE       0x00000200
+#define EFI_FVB2_MEMORY_MAPPED      0x00000400
+#define EFI_FVB2_ERASE_POLARITY     0x00000800
+#define EFI_FVB2_READ_LOCK_CAP      0x00001000
+#define EFI_FVB2_READ_LOCK_STATUS   0x00002000
+#define EFI_FVB2_WRITE_LOCK_CAP     0x00004000
+#define EFI_FVB2_WRITE_LOCK_STATUS  0x00008000
+#define EFI_FVB2_ALIGNMENT          0x001F0000
+#define EFI_FVB2_ALIGNMENT_1        0x00000000
+#define EFI_FVB2_ALIGNMENT_2        0x00010000
+#define EFI_FVB2_ALIGNMENT_4        0x00020000
+#define EFI_FVB2_ALIGNMENT_8        0x00030000
+#define EFI_FVB2_ALIGNMENT_16       0x00040000
+#define EFI_FVB2_ALIGNMENT_32       0x00050000
+#define EFI_FVB2_ALIGNMENT_64       0x00060000
+#define EFI_FVB2_ALIGNMENT_128      0x00070000
+#define EFI_FVB2_ALIGNMENT_256      0x00080000
+#define EFI_FVB2_ALIGNMENT_512      0x00090000
+#define EFI_FVB2_ALIGNMENT_1K       0x000A0000
+#define EFI_FVB2_ALIGNMENT_2K       0x000B0000
+#define EFI_FVB2_ALIGNMENT_4K       0x000C0000
+#define EFI_FVB2_ALIGNMENT_8K       0x000D0000
+#define EFI_FVB2_ALIGNMENT_16K      0x000E0000
+#define EFI_FVB2_ALIGNMENT_32K      0x000F0000
+#define EFI_FVB2_ALIGNMENT_64K      0x00100000
+#define EFI_FVB2_ALIGNMENT_128K     0x00110000
+#define EFI_FVB2_ALIGNMENT_256K     0x00120000
+#define EFI_FVB2_ALIGNMENT_512K     0x00130000
+#define EFI_FVB2_ALIGNMENT_1M       0x00140000
+#define EFI_FVB2_ALIGNMENT_2M       0x00150000
+#define EFI_FVB2_ALIGNMENT_4M       0x00160000
+#define EFI_FVB2_ALIGNMENT_8M       0x00170000
+#define EFI_FVB2_ALIGNMENT_16M      0x00180000
+#define EFI_FVB2_ALIGNMENT_32M      0x00190000
+#define EFI_FVB2_ALIGNMENT_64M      0x001A0000
+#define EFI_FVB2_ALIGNMENT_128M     0x001B0000
+#define EFI_FVB2_ALIGNMENT_256M     0x001C0000
+#define EFI_FVB2_ALIGNMENT_512M     0x001D0000
+#define EFI_FVB2_ALIGNMENT_1G       0x001E0000
+#define EFI_FVB2_ALIGNMENT_2G       0x001F0000
+#define EFI_FVB2_WEAK_ALIGNMENT     0x80000000
+
+typedef struct {
+  ///
+  /// The number of sequential blocks which are of the same size.
+  ///
+  UINT32 NumBlocks;
+  ///
+  /// The size of the blocks.
+  ///
+  UINT32 Length;
+} EFI_FV_BLOCK_MAP_ENTRY;
+
+///
+/// Describes the features and layout of the firmware volume.
+///
+typedef struct {
+  ///
+  /// The first 16 bytes are reserved to allow for the reset vector of
+  /// processors whose reset vector is at address 0.
+  ///
+  UINT8                     ZeroVector[16];
+  ///
+  /// Declares the file system with which the firmware volume is formatted.
+  ///
+  EFI_GUID                  FileSystemGuid;
+  ///
+  /// Length in bytes of the complete firmware volume, including the header.
+  ///
+  UINT64                    FvLength;
+  ///
+  /// Set to EFI_FVH_SIGNATURE
+  ///
+  UINT32                    Signature;
+  ///
+  /// Declares capabilities and power-on defaults for the firmware volume.
+  ///
+  EFI_FVB_ATTRIBUTES_2      Attributes;
+  ///
+  /// Length in bytes of the complete firmware volume header.
+  ///
+  UINT16                    HeaderLength;
+  ///
+  /// A 16-bit checksum of the firmware volume header. A valid header sums to zero.
+  ///
+  UINT16                    Checksum;
+  ///
+  /// Offset, relative to the start of the header, of the extended header
+  /// (EFI_FIRMWARE_VOLUME_EXT_HEADER) or zero if there is no extended header.
+  ///
+  UINT16                    ExtHeaderOffset;
+  ///
+  /// This field must always be set to zero.
+  ///
+  UINT8                     Reserved[1];
+  ///
+  /// Set to 2. Future versions of this specification may define new header fields and will
+  /// increment the Revision field accordingly.
+  ///
+  UINT8                     Revision;
+  ///
+  /// An array of run-length encoded FvBlockMapEntry structures. The array is
+  /// terminated with an entry of {0,0}.
+  ///
+  EFI_FV_BLOCK_MAP_ENTRY    BlockMap[1];
+} EFI_FIRMWARE_VOLUME_HEADER;
+
+#define EFI_FVH_SIGNATURE SIGNATURE_32 ('_', 'F', 'V', 'H')
+
+///
+/// Firmware Volume Header Revision definition
+///
+#define EFI_FVH_REVISION  0x02
+
+///
+/// Extension header pointed by ExtHeaderOffset of volume header.
+///
+typedef struct {
+  ///
+  /// Firmware volume name.
+  ///
+  EFI_GUID  FvName;
+  ///
+  /// Size of the rest of the extension header, including this structure.
+  ///
+  UINT32    ExtHeaderSize;
+} EFI_FIRMWARE_VOLUME_EXT_HEADER;
+
+///
+/// Entry struture for describing FV extension header
+///
+typedef struct {
+  ///
+  /// Size of this header extension.
+  ///
+  UINT16    ExtEntrySize;
+  ///
+  /// Type of the header.
+  ///
+  UINT16    ExtEntryType;
+} EFI_FIRMWARE_VOLUME_EXT_ENTRY;
+
+#define EFI_FV_EXT_TYPE_OEM_TYPE  0x01
+///
+/// This extension header provides a mapping between a GUID and an OEM file type.
+///
+typedef struct {
+  ///
+  /// Standard extension entry, with the type EFI_FV_EXT_TYPE_OEM_TYPE.
+  ///
+  EFI_FIRMWARE_VOLUME_EXT_ENTRY Hdr;
+  ///
+  /// A bit mask, one bit for each file type between 0xC0 (bit 0) and 0xDF (bit 31). If a bit
+  /// is '1', then the GUID entry exists in Types. If a bit is '0' then no GUID entry exists in Types.
+  ///
+  UINT32    TypeMask;
+  ///
+  /// An array of GUIDs, each GUID representing an OEM file type.
+  ///
+  /// EFI_GUID  Types[1];
+  ///
+} EFI_FIRMWARE_VOLUME_EXT_ENTRY_OEM_TYPE;
+
+#define EFI_FV_EXT_TYPE_GUID_TYPE 0x0002
+
+///
+/// This extension header EFI_FIRMWARE_VOLUME_EXT_ENTRY_GUID_TYPE provides a vendor specific
+/// GUID FormatType type which includes a length and a successive series of data bytes.
+///
+typedef struct {
+  ///
+  /// Standard extension entry, with the type EFI_FV_EXT_TYPE_OEM_TYPE.
+  ///
+  EFI_FIRMWARE_VOLUME_EXT_ENTRY     Hdr;
+  ///
+  /// Vendor-specific GUID.
+  ///
+  EFI_GUID                          FormatType;
+  ///
+  /// An arry of bytes of length Length.
+  ///
+  /// UINT8                             Data[1];
+  ///
+} EFI_FIRMWARE_VOLUME_EXT_ENTRY_GUID_TYPE;
+
+#endif
diff --git a/tools/cbfstool/edk2/Pi/PiHob.h b/tools/cbfstool/edk2/Pi/PiHob.h
new file mode 100644
index 0000000000..d7a6f2539a
--- /dev/null
+++ b/tools/cbfstool/edk2/Pi/PiHob.h
@@ -0,0 +1,452 @@
+/** @file
+  HOB related definitions in PI.
+
+Copyright (c) 2006 - 2011, Intel Corporation. All rights reserved.<BR>
+This program and the accompanying materials are licensed and made available under
+the terms and conditions of the BSD License that accompanies this distribution.
+The full text of the license may be found at
+http://opensource.org/licenses/bsd-license.php.
+
+THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+  @par Revision Reference:
+  PI Version 1.0
+
+**/
+
+#ifndef __PI_HOB_H__
+#define __PI_HOB_H__
+
+//
+// HobType of EFI_HOB_GENERIC_HEADER.
+//
+#define EFI_HOB_TYPE_HANDOFF              0x0001
+#define EFI_HOB_TYPE_MEMORY_ALLOCATION    0x0002
+#define EFI_HOB_TYPE_RESOURCE_DESCRIPTOR  0x0003
+#define EFI_HOB_TYPE_GUID_EXTENSION       0x0004
+#define EFI_HOB_TYPE_FV                   0x0005
+#define EFI_HOB_TYPE_CPU                  0x0006
+#define EFI_HOB_TYPE_MEMORY_POOL          0x0007
+#define EFI_HOB_TYPE_FV2                  0x0009
+#define EFI_HOB_TYPE_LOAD_PEIM_UNUSED     0x000A
+#define EFI_HOB_TYPE_UEFI_CAPSULE         0x000B
+#define EFI_HOB_TYPE_UNUSED               0xFFFE
+#define EFI_HOB_TYPE_END_OF_HOB_LIST      0xFFFF
+
+///
+/// Describes the format and size of the data inside the HOB.
+/// All HOBs must contain this generic HOB header.
+///
+typedef struct {
+  ///
+  /// Identifies the HOB data structure type.
+  ///
+  UINT16    HobType;
+  ///
+  /// The length in bytes of the HOB.
+  ///
+  UINT16    HobLength;
+  ///
+  /// This field must always be set to zero.
+  ///
+  UINT32    Reserved;
+} EFI_HOB_GENERIC_HEADER;
+
+
+///
+/// Value of version  in EFI_HOB_HANDOFF_INFO_TABLE.
+///
+#define EFI_HOB_HANDOFF_TABLE_VERSION 0x0009
+
+///
+/// Contains general state information used by the HOB producer phase.
+/// This HOB must be the first one in the HOB list.
+///
+typedef struct {
+  ///
+  /// The HOB generic header. Header.HobType = EFI_HOB_TYPE_HANDOFF.
+  ///
+  EFI_HOB_GENERIC_HEADER  Header;
+  ///
+  /// The version number pertaining to the PHIT HOB definition.
+  /// This value is four bytes in length to provide an 8-byte aligned entry
+  /// when it is combined with the 4-byte BootMode.
+  ///
+  UINT32                  Version;
+  ///
+  /// The system boot mode as determined during the HOB producer phase.
+  ///
+  EFI_BOOT_MODE           BootMode;
+  ///
+  /// The highest address location of memory that is allocated for use by the HOB producer
+  /// phase. This address must be 4-KB aligned to meet page restrictions of UEFI.
+  ///
+  EFI_PHYSICAL_ADDRESS    EfiMemoryTop;
+  ///
+  /// The lowest address location of memory that is allocated for use by the HOB producer phase.
+  ///
+  EFI_PHYSICAL_ADDRESS    EfiMemoryBottom;
+  ///
+  /// The highest address location of free memory that is currently available
+  /// for use by the HOB producer phase.
+  ///
+  EFI_PHYSICAL_ADDRESS    EfiFreeMemoryTop;
+  ///
+  /// The lowest address location of free memory that is available for use by the HOB producer phase.
+  ///
+  EFI_PHYSICAL_ADDRESS    EfiFreeMemoryBottom;
+  ///
+  /// The end of the HOB list.
+  ///
+  EFI_PHYSICAL_ADDRESS    EfiEndOfHobList;
+} EFI_HOB_HANDOFF_INFO_TABLE;
+
+///
+/// EFI_HOB_MEMORY_ALLOCATION_HEADER describes the
+/// various attributes of the logical memory allocation. The type field will be used for
+/// subsequent inclusion in the UEFI memory map.
+///
+typedef struct {
+  ///
+  /// A GUID that defines the memory allocation region's type and purpose, as well as
+  /// other fields within the memory allocation HOB. This GUID is used to define the
+  /// additional data within the HOB that may be present for the memory allocation HOB.
+  /// Type EFI_GUID is defined in InstallProtocolInterface() in the UEFI 2.0
+  /// specification.
+  ///
+  EFI_GUID              Name;
+
+  ///
+  /// The base address of memory allocated by this HOB. Type
+  /// EFI_PHYSICAL_ADDRESS is defined in AllocatePages() in the UEFI 2.0
+  /// specification.
+  ///
+  EFI_PHYSICAL_ADDRESS  MemoryBaseAddress;
+
+  ///
+  /// The length in bytes of memory allocated by this HOB.
+  ///
+  UINT64                MemoryLength;
+
+  ///
+  /// Defines the type of memory allocated by this HOB. The memory type definition
+  /// follows the EFI_MEMORY_TYPE definition. Type EFI_MEMORY_TYPE is defined
+  /// in AllocatePages() in the UEFI 2.0 specification.
+  ///
+  EFI_MEMORY_TYPE       MemoryType;
+
+  ///
+  /// Padding for Itanium processor family
+  ///
+  UINT8                 Reserved[4];
+} EFI_HOB_MEMORY_ALLOCATION_HEADER;
+
+///
+/// Describes all memory ranges used during the HOB producer
+/// phase that exist outside the HOB list. This HOB type
+/// describes how memory is used, not the physical attributes of memory.
+///
+typedef struct {
+  ///
+  /// The HOB generic header. Header.HobType = EFI_HOB_TYPE_MEMORY_ALLOCATION.
+  ///
+  EFI_HOB_GENERIC_HEADER            Header;
+  ///
+  /// An instance of the EFI_HOB_MEMORY_ALLOCATION_HEADER that describes the
+  /// various attributes of the logical memory allocation.
+  ///
+  EFI_HOB_MEMORY_ALLOCATION_HEADER  AllocDescriptor;
+  //
+  // Additional data pertaining to the "Name" Guid memory
+  // may go here.
+  //
+} EFI_HOB_MEMORY_ALLOCATION;
+
+
+///
+/// Describes the memory stack that is produced by the HOB producer
+/// phase and upon which all post-memory-installed executable
+/// content in the HOB producer phase is executing.
+///
+typedef struct {
+  ///
+  /// The HOB generic header. Header.HobType = EFI_HOB_TYPE_MEMORY_ALLOCATION.
+  ///
+  EFI_HOB_GENERIC_HEADER            Header;
+  ///
+  /// An instance of the EFI_HOB_MEMORY_ALLOCATION_HEADER that describes the
+  /// various attributes of the logical memory allocation.
+  ///
+  EFI_HOB_MEMORY_ALLOCATION_HEADER  AllocDescriptor;
+} EFI_HOB_MEMORY_ALLOCATION_STACK;
+
+///
+/// Defines the location of the boot-strap
+/// processor (BSP) BSPStore ("Backing Store Pointer Store").
+/// This HOB is valid for the Itanium processor family only
+/// register overflow store.
+///
+typedef struct {
+  ///
+  /// The HOB generic header. Header.HobType = EFI_HOB_TYPE_MEMORY_ALLOCATION.
+  ///
+  EFI_HOB_GENERIC_HEADER            Header;
+  ///
+  /// An instance of the EFI_HOB_MEMORY_ALLOCATION_HEADER that describes the
+  /// various attributes of the logical memory allocation.
+  ///
+  EFI_HOB_MEMORY_ALLOCATION_HEADER  AllocDescriptor;
+} EFI_HOB_MEMORY_ALLOCATION_BSP_STORE;
+
+///
+/// Defines the location and entry point of the HOB consumer phase.
+///
+typedef struct {
+  ///
+  /// The HOB generic header. Header.HobType = EFI_HOB_TYPE_MEMORY_ALLOCATION.
+  ///
+  EFI_HOB_GENERIC_HEADER            Header;
+  ///
+  /// An instance of the EFI_HOB_MEMORY_ALLOCATION_HEADER that describes the
+  /// various attributes of the logical memory allocation.
+  ///
+  EFI_HOB_MEMORY_ALLOCATION_HEADER  MemoryAllocationHeader;
+  ///
+  /// The GUID specifying the values of the firmware file system name
+  /// that contains the HOB consumer phase component.
+  ///
+  EFI_GUID                          ModuleName;
+  ///
+  /// The address of the memory-mapped firmware volume
+  /// that contains the HOB consumer phase firmware file.
+  ///
+  EFI_PHYSICAL_ADDRESS              EntryPoint;
+} EFI_HOB_MEMORY_ALLOCATION_MODULE;
+
+///
+/// The resource type.
+///
+typedef UINT32 EFI_RESOURCE_TYPE;
+
+//
+// Value of ResourceType in EFI_HOB_RESOURCE_DESCRIPTOR.
+//
+#define EFI_RESOURCE_SYSTEM_MEMORY          0x00000000
+#define EFI_RESOURCE_MEMORY_MAPPED_IO       0x00000001
+#define EFI_RESOURCE_IO                     0x00000002
+#define EFI_RESOURCE_FIRMWARE_DEVICE        0x00000003
+#define EFI_RESOURCE_MEMORY_MAPPED_IO_PORT  0x00000004
+#define EFI_RESOURCE_MEMORY_RESERVED        0x00000005
+#define EFI_RESOURCE_IO_RESERVED            0x00000006
+#define EFI_RESOURCE_MAX_MEMORY_TYPE        0x00000007
+
+///
+/// A type of recount attribute type.
+///
+typedef UINT32 EFI_RESOURCE_ATTRIBUTE_TYPE;
+
+//
+// These types can be ORed together as needed.
+//
+// The following attributes are used to describe settings
+//
+#define EFI_RESOURCE_ATTRIBUTE_PRESENT                  0x00000001
+#define EFI_RESOURCE_ATTRIBUTE_INITIALIZED              0x00000002
+#define EFI_RESOURCE_ATTRIBUTE_TESTED                   0x00000004
+#define EFI_RESOURCE_ATTRIBUTE_READ_PROTECTED           0x00000080
+#define EFI_RESOURCE_ATTRIBUTE_WRITE_PROTECTED          0x00000100
+#define EFI_RESOURCE_ATTRIBUTE_EXECUTION_PROTECTED      0x00000200
+//
+// The rest of the attributes are used to describe capabilities
+//
+#define EFI_RESOURCE_ATTRIBUTE_SINGLE_BIT_ECC           0x00000008
+#define EFI_RESOURCE_ATTRIBUTE_MULTIPLE_BIT_ECC         0x00000010
+#define EFI_RESOURCE_ATTRIBUTE_ECC_RESERVED_1           0x00000020
+#define EFI_RESOURCE_ATTRIBUTE_ECC_RESERVED_2           0x00000040
+#define EFI_RESOURCE_ATTRIBUTE_UNCACHEABLE              0x00000400
+#define EFI_RESOURCE_ATTRIBUTE_WRITE_COMBINEABLE        0x00000800
+#define EFI_RESOURCE_ATTRIBUTE_WRITE_THROUGH_CACHEABLE  0x00001000
+#define EFI_RESOURCE_ATTRIBUTE_WRITE_BACK_CACHEABLE     0x00002000
+#define EFI_RESOURCE_ATTRIBUTE_16_BIT_IO                0x00004000
+#define EFI_RESOURCE_ATTRIBUTE_32_BIT_IO                0x00008000
+#define EFI_RESOURCE_ATTRIBUTE_64_BIT_IO                0x00010000
+#define EFI_RESOURCE_ATTRIBUTE_UNCACHED_EXPORTED        0x00020000
+#define EFI_RESOURCE_ATTRIBUTE_READ_PROTECTABLE         0x00100000
+#define EFI_RESOURCE_ATTRIBUTE_WRITE_PROTECTABLE        0x00200000
+#define EFI_RESOURCE_ATTRIBUTE_EXECUTION_PROTECTABLE    0x00400000
+
+///
+/// Describes the resource properties of all fixed,
+/// nonrelocatable resource ranges found on the processor
+/// host bus during the HOB producer phase.
+///
+typedef struct {
+  ///
+  /// The HOB generic header. Header.HobType = EFI_HOB_TYPE_RESOURCE_DESCRIPTOR.
+  ///
+  EFI_HOB_GENERIC_HEADER      Header;
+  ///
+  /// A GUID representing the owner of the resource. This GUID is used by HOB
+  /// consumer phase components to correlate device ownership of a resource.
+  ///
+  EFI_GUID                    Owner;
+  ///
+  /// The resource type enumeration as defined by EFI_RESOURCE_TYPE.
+  ///
+  EFI_RESOURCE_TYPE           ResourceType;
+  ///
+  /// Resource attributes as defined by EFI_RESOURCE_ATTRIBUTE_TYPE.
+  ///
+  EFI_RESOURCE_ATTRIBUTE_TYPE ResourceAttribute;
+  ///
+  /// The physical start address of the resource region.
+  ///
+  EFI_PHYSICAL_ADDRESS        PhysicalStart;
+  ///
+  /// The number of bytes of the resource region.
+  ///
+  UINT64                      ResourceLength;
+} EFI_HOB_RESOURCE_DESCRIPTOR;
+
+///
+/// Allows writers of executable content in the HOB producer phase to
+/// maintain and manage HOBs with specific GUID.
+///
+typedef struct {
+  ///
+  /// The HOB generic header. Header.HobType = EFI_HOB_TYPE_GUID_EXTENSION.
+  ///
+  EFI_HOB_GENERIC_HEADER      Header;
+  ///
+  /// A GUID that defines the contents of this HOB.
+  ///
+  EFI_GUID                    Name;
+  //
+  // Guid specific data goes here
+  //
+} EFI_HOB_GUID_TYPE;
+
+///
+/// Details the location of firmware volumes that contain firmware files.
+///
+typedef struct {
+  ///
+  /// The HOB generic header. Header.HobType = EFI_HOB_TYPE_FV.
+  ///
+  EFI_HOB_GENERIC_HEADER Header;
+  ///
+  /// The physical memory-mapped base address of the firmware volume.
+  ///
+  EFI_PHYSICAL_ADDRESS   BaseAddress;
+  ///
+  /// The length in bytes of the firmware volume.
+  ///
+  UINT64                 Length;
+} EFI_HOB_FIRMWARE_VOLUME;
+
+///
+/// Details the location of a firmware volume that was extracted
+/// from a file within another firmware volume.
+///
+typedef struct {
+  ///
+  /// The HOB generic header. Header.HobType = EFI_HOB_TYPE_FV2.
+  ///
+  EFI_HOB_GENERIC_HEADER  Header;
+  ///
+  /// The physical memory-mapped base address of the firmware volume.
+  ///
+  EFI_PHYSICAL_ADDRESS    BaseAddress;
+  ///
+  /// The length in bytes of the firmware volume.
+  ///
+  UINT64                  Length;
+  ///
+  /// The name of the firmware volume.
+  ///
+  EFI_GUID                FvName;
+  ///
+  /// The name of the firmware file that contained this firmware volume.
+  ///
+  EFI_GUID                FileName;
+} EFI_HOB_FIRMWARE_VOLUME2;
+
+
+///
+/// Describes processor information, such as address space and I/O space capabilities.
+///
+typedef struct {
+  ///
+  /// The HOB generic header. Header.HobType = EFI_HOB_TYPE_CPU.
+  ///
+  EFI_HOB_GENERIC_HEADER  Header;
+  ///
+  /// Identifies the maximum physical memory addressability of the processor.
+  ///
+  UINT8                   SizeOfMemorySpace;
+  ///
+  /// Identifies the maximum physical I/O addressability of the processor.
+  ///
+  UINT8                   SizeOfIoSpace;
+  ///
+  /// This field will always be set to zero.
+  ///
+  UINT8                   Reserved[6];
+} EFI_HOB_CPU;
+
+
+///
+/// Describes pool memory allocations.
+///
+typedef struct {
+  ///
+  /// The HOB generic header. Header.HobType = EFI_HOB_TYPE_MEMORY_POOL.
+  ///
+  EFI_HOB_GENERIC_HEADER  Header;
+} EFI_HOB_MEMORY_POOL;
+
+///
+/// Each UEFI capsule HOB details the location of a UEFI capsule. It includes a base address and length
+/// which is based upon memory blocks with a EFI_CAPSULE_HEADER and the associated
+/// CapsuleImageSize-based payloads. These HOB's shall be created by the PEI PI firmware
+/// sometime after the UEFI UpdateCapsule service invocation with the
+/// CAPSULE_FLAGS_POPULATE_SYSTEM_TABLE flag set in the EFI_CAPSULE_HEADER.
+///
+typedef struct {
+  ///
+  /// The HOB generic header where Header.HobType = EFI_HOB_TYPE_UEFI_CAPSULE.
+  ///
+  EFI_HOB_GENERIC_HEADER Header;
+
+  ///
+  /// The physical memory-mapped base address of an UEFI capsule. This value is set to
+  /// point to the base of the contiguous memory of the UEFI capsule.
+  /// The length of the contiguous memory in bytes.
+  ///
+  EFI_PHYSICAL_ADDRESS   BaseAddress;
+  UINT64                 Length;
+} EFI_HOB_UEFI_CAPSULE;
+
+///
+/// Union of all the possible HOB Types.
+///
+typedef union {
+  EFI_HOB_GENERIC_HEADER              *Header;
+  EFI_HOB_HANDOFF_INFO_TABLE          *HandoffInformationTable;
+  EFI_HOB_MEMORY_ALLOCATION           *MemoryAllocation;
+  EFI_HOB_MEMORY_ALLOCATION_BSP_STORE *MemoryAllocationBspStore;
+  EFI_HOB_MEMORY_ALLOCATION_STACK     *MemoryAllocationStack;
+  EFI_HOB_MEMORY_ALLOCATION_MODULE    *MemoryAllocationModule;
+  EFI_HOB_RESOURCE_DESCRIPTOR         *ResourceDescriptor;
+  EFI_HOB_GUID_TYPE                   *Guid;
+  EFI_HOB_FIRMWARE_VOLUME             *FirmwareVolume;
+  EFI_HOB_FIRMWARE_VOLUME2            *FirmwareVolume2;
+  EFI_HOB_CPU                         *Cpu;
+  EFI_HOB_MEMORY_POOL                 *Pool;
+  EFI_HOB_UEFI_CAPSULE                *Capsule;
+  UINT8                               *Raw;
+} EFI_PEI_HOB_POINTERS;
+
+
+#endif
diff --git a/tools/cbfstool/edk2/Protocol/GraphicsOutput.h b/tools/cbfstool/edk2/Protocol/GraphicsOutput.h
new file mode 100644
index 0000000000..0621b577c5
--- /dev/null
+++ b/tools/cbfstool/edk2/Protocol/GraphicsOutput.h
@@ -0,0 +1,276 @@
+/** @file
+  Graphics Output Protocol from the UEFI 2.0 specification.
+
+  Abstraction of a very simple graphics device.
+
+  Copyright (c) 2006 - 2012, Intel Corporation. All rights reserved.<BR>
+  This program and the accompanying materials
+  are licensed and made available under the terms and conditions of the BSD License
+  which accompanies this distribution.  The full text of the license may be found at
+  http://opensource.org/licenses/bsd-license.php
+
+  THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+  WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+**/
+
+#ifndef __GRAPHICS_OUTPUT_H__
+#define __GRAPHICS_OUTPUT_H__
+
+#define EFI_GRAPHICS_OUTPUT_PROTOCOL_GUID \
+  { \
+    0x9042a9de, 0x23dc, 0x4a38, {0x96, 0xfb, 0x7a, 0xde, 0xd0, 0x80, 0x51, 0x6a } \
+  }
+
+typedef struct _EFI_GRAPHICS_OUTPUT_PROTOCOL EFI_GRAPHICS_OUTPUT_PROTOCOL;
+
+typedef struct {
+  UINT32            RedMask;
+  UINT32            GreenMask;
+  UINT32            BlueMask;
+  UINT32            ReservedMask;
+} EFI_PIXEL_BITMASK;
+
+typedef enum {
+  ///
+  /// A pixel is 32-bits and byte zero represents red, byte one represents green,
+  /// byte two represents blue, and byte three is reserved. This is the definition
+  /// for the physical frame buffer. The byte values for the red, green, and blue
+  /// components represent the color intensity. This color intensity value range
+  /// from a minimum intensity of 0 to maximum intensity of 255.
+  ///
+  PixelRedGreenBlueReserved8BitPerColor,
+  ///
+  /// A pixel is 32-bits and byte zero represents blue, byte one represents green,
+  /// byte two represents red, and byte three is reserved. This is the definition
+  /// for the physical frame buffer. The byte values for the red, green, and blue
+  /// components represent the color intensity. This color intensity value range
+  /// from a minimum intensity of 0 to maximum intensity of 255.
+  ///
+  PixelBlueGreenRedReserved8BitPerColor,
+  ///
+  /// The Pixel definition of the physical frame buffer.
+  ///
+  PixelBitMask,
+  ///
+  /// This mode does not support a physical frame buffer.
+  ///
+  PixelBltOnly,
+  ///
+  /// Valid EFI_GRAPHICS_PIXEL_FORMAT enum values are less than this value.
+  ///
+  PixelFormatMax
+} EFI_GRAPHICS_PIXEL_FORMAT;
+
+typedef struct {
+  ///
+  /// The version of this data structure. A value of zero represents the
+  /// EFI_GRAPHICS_OUTPUT_MODE_INFORMATION structure as defined in this specification.
+  ///
+  UINT32                     Version;
+  ///
+  /// The size of video screen in pixels in the X dimension.
+  ///
+  UINT32                     HorizontalResolution;
+  ///
+  /// The size of video screen in pixels in the Y dimension.
+  ///
+  UINT32                     VerticalResolution;
+  ///
+  /// Enumeration that defines the physical format of the pixel. A value of PixelBltOnly
+  /// implies that a linear frame buffer is not available for this mode.
+  ///
+  EFI_GRAPHICS_PIXEL_FORMAT  PixelFormat;
+  ///
+  /// This bit-mask is only valid if PixelFormat is set to PixelPixelBitMask.
+  /// A bit being set defines what bits are used for what purpose such as Red, Green, Blue, or Reserved.
+  ///
+  EFI_PIXEL_BITMASK          PixelInformation;
+  ///
+  /// Defines the number of pixel elements per video memory line.
+  ///
+  UINT32                     PixelsPerScanLine;
+} EFI_GRAPHICS_OUTPUT_MODE_INFORMATION;
+
+/**
+  Returns information for an available graphics mode that the graphics device
+  and the set of active video output devices supports.
+
+  @param  This                  The EFI_GRAPHICS_OUTPUT_PROTOCOL instance.
+  @param  ModeNumber            The mode number to return information on.
+  @param  SizeOfInfo            A pointer to the size, in bytes, of the Info buffer.
+  @param  Info                  A pointer to callee allocated buffer that returns information about ModeNumber.
+
+  @retval EFI_SUCCESS           Valid mode information was returned.
+  @retval EFI_DEVICE_ERROR      A hardware error occurred trying to retrieve the video mode.
+  @retval EFI_INVALID_PARAMETER ModeNumber is not valid.
+
+**/
+typedef
+EFI_STATUS
+(EFIAPI *EFI_GRAPHICS_OUTPUT_PROTOCOL_QUERY_MODE)(
+  IN  EFI_GRAPHICS_OUTPUT_PROTOCOL          *This,
+  IN  UINT32                                ModeNumber,
+  OUT UINTN                                 *SizeOfInfo,
+  OUT EFI_GRAPHICS_OUTPUT_MODE_INFORMATION  **Info
+  );
+
+/**
+  Set the video device into the specified mode and clears the visible portions of
+  the output display to black.
+
+  @param  This              The EFI_GRAPHICS_OUTPUT_PROTOCOL instance.
+  @param  ModeNumber        Abstraction that defines the current video mode.
+
+  @retval EFI_SUCCESS       The graphics mode specified by ModeNumber was selected.
+  @retval EFI_DEVICE_ERROR  The device had an error and could not complete the request.
+  @retval EFI_UNSUPPORTED   ModeNumber is not supported by this device.
+
+**/
+typedef
+EFI_STATUS
+(EFIAPI *EFI_GRAPHICS_OUTPUT_PROTOCOL_SET_MODE)(
+  IN  EFI_GRAPHICS_OUTPUT_PROTOCOL *This,
+  IN  UINT32                       ModeNumber
+  );
+
+typedef struct {
+  UINT8 Blue;
+  UINT8 Green;
+  UINT8 Red;
+  UINT8 Reserved;
+} EFI_GRAPHICS_OUTPUT_BLT_PIXEL;
+
+typedef union {
+  EFI_GRAPHICS_OUTPUT_BLT_PIXEL Pixel;
+  UINT32                        Raw;
+} EFI_GRAPHICS_OUTPUT_BLT_PIXEL_UNION;
+
+///
+/// actions for BltOperations
+///
+typedef enum {
+  ///
+  /// Write data from the BltBuffer pixel (0, 0)
+  /// directly to every pixel of the video display rectangle
+  /// (DestinationX, DestinationY) (DestinationX + Width, DestinationY + Height).
+  /// Only one pixel will be used from the BltBuffer. Delta is NOT used.
+  ///
+  EfiBltVideoFill,
+
+  ///
+  /// Read data from the video display rectangle
+  /// (SourceX, SourceY) (SourceX + Width, SourceY + Height) and place it in
+  /// the BltBuffer rectangle (DestinationX, DestinationY )
+  /// (DestinationX + Width, DestinationY + Height). If DestinationX or
+  /// DestinationY is not zero then Delta must be set to the length in bytes
+  /// of a row in the BltBuffer.
+  ///
+  EfiBltVideoToBltBuffer,
+
+  ///
+  /// Write data from the BltBuffer rectangle
+  /// (SourceX, SourceY) (SourceX + Width, SourceY + Height) directly to the
+  /// video display rectangle (DestinationX, DestinationY)
+  /// (DestinationX + Width, DestinationY + Height). If SourceX or SourceY is
+  /// not zero then Delta must be set to the length in bytes of a row in the
+  /// BltBuffer.
+  ///
+  EfiBltBufferToVideo,
+
+  ///
+  /// Copy from the video display rectangle (SourceX, SourceY)
+  /// (SourceX + Width, SourceY + Height) to the video display rectangle
+  /// (DestinationX, DestinationY) (DestinationX + Width, DestinationY + Height).
+  /// The BltBuffer and Delta are not used in this mode.
+  ///
+  EfiBltVideoToVideo,
+
+  EfiGraphicsOutputBltOperationMax
+} EFI_GRAPHICS_OUTPUT_BLT_OPERATION;
+
+/**
+  Blt a rectangle of pixels on the graphics screen. Blt stands for BLock Transfer.
+
+  @param  This         Protocol instance pointer.
+  @param  BltBuffer    The data to transfer to the graphics screen.
+                       Size is at least Width*Height*sizeof(EFI_GRAPHICS_OUTPUT_BLT_PIXEL).
+  @param  BltOperation The operation to perform when copying BltBuffer on to the graphics screen.
+  @param  SourceX      The X coordinate of source for the BltOperation.
+  @param  SourceY      The Y coordinate of source for the BltOperation.
+  @param  DestinationX The X coordinate of destination for the BltOperation.
+  @param  DestinationY The Y coordinate of destination for the BltOperation.
+  @param  Width        The width of a rectangle in the blt rectangle in pixels.
+  @param  Height       The height of a rectangle in the blt rectangle in pixels.
+  @param  Delta        Not used for EfiBltVideoFill or the EfiBltVideoToVideo operation.
+                       If a Delta of zero is used, the entire BltBuffer is being operated on.
+                       If a subrectangle of the BltBuffer is being used then Delta
+                       represents the number of bytes in a row of the BltBuffer.
+
+  @retval EFI_SUCCESS           BltBuffer was drawn to the graphics screen.
+  @retval EFI_INVALID_PARAMETER BltOperation is not valid.
+  @retval EFI_DEVICE_ERROR      The device had an error and could not complete the request.
+
+**/
+typedef
+EFI_STATUS
+(EFIAPI *EFI_GRAPHICS_OUTPUT_PROTOCOL_BLT)(
+  IN  EFI_GRAPHICS_OUTPUT_PROTOCOL            *This,
+  IN  EFI_GRAPHICS_OUTPUT_BLT_PIXEL           *BltBuffer,   OPTIONAL
+  IN  EFI_GRAPHICS_OUTPUT_BLT_OPERATION       BltOperation,
+  IN  UINTN                                   SourceX,
+  IN  UINTN                                   SourceY,
+  IN  UINTN                                   DestinationX,
+  IN  UINTN                                   DestinationY,
+  IN  UINTN                                   Width,
+  IN  UINTN                                   Height,
+  IN  UINTN                                   Delta         OPTIONAL
+  );
+
+typedef struct {
+  ///
+  /// The number of modes supported by QueryMode() and SetMode().
+  ///
+  UINT32                                 MaxMode;
+  ///
+  /// Current Mode of the graphics device. Valid mode numbers are 0 to MaxMode -1.
+  ///
+  UINT32                                 Mode;
+  ///
+  /// Pointer to read-only EFI_GRAPHICS_OUTPUT_MODE_INFORMATION data.
+  ///
+  EFI_GRAPHICS_OUTPUT_MODE_INFORMATION   *Info;
+  ///
+  /// Size of Info structure in bytes.
+  ///
+  UINTN                                  SizeOfInfo;
+  ///
+  /// Base address of graphics linear frame buffer.
+  /// Offset zero in FrameBufferBase represents the upper left pixel of the display.
+  ///
+  EFI_PHYSICAL_ADDRESS                   FrameBufferBase;
+  ///
+  /// Amount of frame buffer needed to support the active mode as defined by
+  /// PixelsPerScanLine xVerticalResolution x PixelElementSize.
+  ///
+  UINTN                                  FrameBufferSize;
+} EFI_GRAPHICS_OUTPUT_PROTOCOL_MODE;
+
+///
+/// Provides a basic abstraction to set video modes and copy pixels to and from
+/// the graphics controller's frame buffer. The linear address of the hardware
+/// frame buffer is also exposed so software can write directly to the video hardware.
+///
+struct _EFI_GRAPHICS_OUTPUT_PROTOCOL {
+  EFI_GRAPHICS_OUTPUT_PROTOCOL_QUERY_MODE  QueryMode;
+  EFI_GRAPHICS_OUTPUT_PROTOCOL_SET_MODE    SetMode;
+  EFI_GRAPHICS_OUTPUT_PROTOCOL_BLT         Blt;
+  ///
+  /// Pointer to EFI_GRAPHICS_OUTPUT_PROTOCOL_MODE data.
+  ///
+  EFI_GRAPHICS_OUTPUT_PROTOCOL_MODE        *Mode;
+};
+
+extern EFI_GUID gEfiGraphicsOutputProtocolGuid;
+
+#endif
diff --git a/tools/cbfstool/edk2/Uefi/UefiBaseType.h b/tools/cbfstool/edk2/Uefi/UefiBaseType.h
new file mode 100644
index 0000000000..e0404231e1
--- /dev/null
+++ b/tools/cbfstool/edk2/Uefi/UefiBaseType.h
@@ -0,0 +1,301 @@
+/** @file
+  Defines data types and constants introduced in UEFI.
+
+Copyright (c) 2006 - 2011, Intel Corporation. All rights reserved.<BR>
+Portions copyright (c) 2011 - 2013, ARM Ltd. All rights reserved.<BR>
+
+This program and the accompanying materials are licensed and made available under
+the terms and conditions of the BSD License that accompanies this distribution.
+The full text of the license may be found at
+http://opensource.org/licenses/bsd-license.php.
+
+THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+**/
+
+#ifndef __UEFI_BASETYPE_H__
+#define __UEFI_BASETYPE_H__
+
+#include <Base.h>
+
+//
+// Basic data type definitions introduced in UEFI.
+//
+
+///
+/// 128-bit buffer containing a unique identifier value.
+///
+typedef GUID                      EFI_GUID;
+///
+/// Function return status for EFI API.
+///
+typedef RETURN_STATUS             EFI_STATUS;
+///
+/// A collection of related interfaces.
+///
+typedef VOID                      *EFI_HANDLE;
+///
+/// Handle to an event structure.
+///
+typedef VOID                      *EFI_EVENT;
+///
+/// Task priority level.
+///
+typedef UINTN                     EFI_TPL;
+///
+/// Logical block address.
+///
+typedef UINT64                    EFI_LBA;
+
+///
+/// 64-bit physical memory address.
+///
+typedef UINT64                    EFI_PHYSICAL_ADDRESS;
+
+///
+/// 64-bit virtual memory address.
+///
+typedef UINT64                    EFI_VIRTUAL_ADDRESS;
+
+///
+/// EFI Time Abstraction:
+///  Year:       1900 - 9999
+///  Month:      1 - 12
+///  Day:        1 - 31
+///  Hour:       0 - 23
+///  Minute:     0 - 59
+///  Second:     0 - 59
+///  Nanosecond: 0 - 999,999,999
+///  TimeZone:   -1440 to 1440 or 2047
+///
+typedef struct {
+  UINT16  Year;
+  UINT8   Month;
+  UINT8   Day;
+  UINT8   Hour;
+  UINT8   Minute;
+  UINT8   Second;
+  UINT8   Pad1;
+  UINT32  Nanosecond;
+  INT16   TimeZone;
+  UINT8   Daylight;
+  UINT8   Pad2;
+} EFI_TIME;
+
+
+///
+/// 4-byte buffer. An IPv4 internet protocol address.
+///
+typedef struct {
+  UINT8 Addr[4];
+} EFI_IPv4_ADDRESS;
+
+///
+/// 16-byte buffer. An IPv6 internet protocol address.
+///
+typedef struct {
+  UINT8 Addr[16];
+} EFI_IPv6_ADDRESS;
+
+///
+/// 32-byte buffer containing a network Media Access Control address.
+///
+typedef struct {
+  UINT8 Addr[32];
+} EFI_MAC_ADDRESS;
+
+///
+/// 16-byte buffer aligned on a 4-byte boundary.
+/// An IPv4 or IPv6 internet protocol address.
+///
+typedef union {
+  UINT32            Addr[4];
+  EFI_IPv4_ADDRESS  v4;
+  EFI_IPv6_ADDRESS  v6;
+} EFI_IP_ADDRESS;
+
+
+///
+/// Enumeration of EFI_STATUS.
+///@{
+#define EFI_SUCCESS               RETURN_SUCCESS
+#define EFI_LOAD_ERROR            RETURN_LOAD_ERROR
+#define EFI_INVALID_PARAMETER     RETURN_INVALID_PARAMETER
+#define EFI_UNSUPPORTED           RETURN_UNSUPPORTED
+#define EFI_BAD_BUFFER_SIZE       RETURN_BAD_BUFFER_SIZE
+#define EFI_BUFFER_TOO_SMALL      RETURN_BUFFER_TOO_SMALL
+#define EFI_NOT_READY             RETURN_NOT_READY
+#define EFI_DEVICE_ERROR          RETURN_DEVICE_ERROR
+#define EFI_WRITE_PROTECTED       RETURN_WRITE_PROTECTED
+#define EFI_OUT_OF_RESOURCES      RETURN_OUT_OF_RESOURCES
+#define EFI_VOLUME_CORRUPTED      RETURN_VOLUME_CORRUPTED
+#define EFI_VOLUME_FULL           RETURN_VOLUME_FULL
+#define EFI_NO_MEDIA              RETURN_NO_MEDIA
+#define EFI_MEDIA_CHANGED         RETURN_MEDIA_CHANGED
+#define EFI_NOT_FOUND             RETURN_NOT_FOUND
+#define EFI_ACCESS_DENIED         RETURN_ACCESS_DENIED
+#define EFI_NO_RESPONSE           RETURN_NO_RESPONSE
+#define EFI_NO_MAPPING            RETURN_NO_MAPPING
+#define EFI_TIMEOUT               RETURN_TIMEOUT
+#define EFI_NOT_STARTED           RETURN_NOT_STARTED
+#define EFI_ALREADY_STARTED       RETURN_ALREADY_STARTED
+#define EFI_ABORTED               RETURN_ABORTED
+#define EFI_ICMP_ERROR            RETURN_ICMP_ERROR
+#define EFI_TFTP_ERROR            RETURN_TFTP_ERROR
+#define EFI_PROTOCOL_ERROR        RETURN_PROTOCOL_ERROR
+#define EFI_INCOMPATIBLE_VERSION  RETURN_INCOMPATIBLE_VERSION
+#define EFI_SECURITY_VIOLATION    RETURN_SECURITY_VIOLATION
+#define EFI_CRC_ERROR             RETURN_CRC_ERROR
+#define EFI_END_OF_MEDIA          RETURN_END_OF_MEDIA
+#define EFI_END_OF_FILE           RETURN_END_OF_FILE
+#define EFI_INVALID_LANGUAGE      RETURN_INVALID_LANGUAGE
+#define EFI_COMPROMISED_DATA      RETURN_COMPROMISED_DATA
+
+#define EFI_WARN_UNKNOWN_GLYPH    RETURN_WARN_UNKNOWN_GLYPH
+#define EFI_WARN_DELETE_FAILURE   RETURN_WARN_DELETE_FAILURE
+#define EFI_WARN_WRITE_FAILURE    RETURN_WARN_WRITE_FAILURE
+#define EFI_WARN_BUFFER_TOO_SMALL RETURN_WARN_BUFFER_TOO_SMALL
+#define EFI_WARN_STALE_DATA       RETURN_WARN_STALE_DATA
+///@}
+
+///
+/// Define macro to encode the status code.
+///
+#define EFIERR(_a)                ENCODE_ERROR(_a)
+
+#define EFI_ERROR(A)              RETURN_ERROR(A)
+
+///
+/// ICMP error definitions
+///@{
+#define EFI_NETWORK_UNREACHABLE   EFIERR(100)
+#define EFI_HOST_UNREACHABLE      EFIERR(101)
+#define EFI_PROTOCOL_UNREACHABLE  EFIERR(102)
+#define EFI_PORT_UNREACHABLE      EFIERR(103)
+///@}
+
+///
+/// Tcp connection status definitions
+///@{
+#define EFI_CONNECTION_FIN        EFIERR(104)
+#define EFI_CONNECTION_RESET      EFIERR(105)
+#define EFI_CONNECTION_REFUSED    EFIERR(106)
+///@}
+
+//
+// The EFI memory allocation functions work in units of EFI_PAGEs that are
+// 4KB. This should in no way be confused with the page size of the processor.
+// An EFI_PAGE is just the quanta of memory in EFI.
+//
+#define EFI_PAGE_SIZE             SIZE_4KB
+#define EFI_PAGE_MASK             0xFFF
+#define EFI_PAGE_SHIFT            12
+
+/**
+  Macro that converts a size, in bytes, to a number of EFI_PAGESs.
+
+  @param  Size      A size in bytes.  This parameter is assumed to be type UINTN.
+                    Passing in a parameter that is larger than UINTN may produce
+                    unexpected results.
+
+  @return  The number of EFI_PAGESs associated with the number of bytes specified
+           by Size.
+
+**/
+#define EFI_SIZE_TO_PAGES(Size)  (((Size) >> EFI_PAGE_SHIFT) + (((Size) & EFI_PAGE_MASK) ? 1 : 0))
+
+/**
+  Macro that converts a number of EFI_PAGEs to a size in bytes.
+
+  @param  Pages     The number of EFI_PAGES.  This parameter is assumed to be
+                    type UINTN.  Passing in a parameter that is larger than
+                    UINTN may produce unexpected results.
+
+  @return  The number of bytes associated with the number of EFI_PAGEs specified
+           by Pages.
+
+**/
+#define EFI_PAGES_TO_SIZE(Pages)  ((Pages) << EFI_PAGE_SHIFT)
+
+///
+/// PE32+ Machine type for IA32 UEFI images.
+///
+#define EFI_IMAGE_MACHINE_IA32            0x014C
+
+///
+/// PE32+ Machine type for IA64 UEFI images.
+///
+#define EFI_IMAGE_MACHINE_IA64            0x0200
+
+///
+/// PE32+ Machine type for EBC UEFI images.
+///
+#define EFI_IMAGE_MACHINE_EBC             0x0EBC
+
+///
+/// PE32+ Machine type for X64 UEFI images.
+///
+#define EFI_IMAGE_MACHINE_X64             0x8664
+
+///
+/// PE32+ Machine type for ARM mixed ARM and Thumb/Thumb2 images.
+///
+#define EFI_IMAGE_MACHINE_ARMTHUMB_MIXED  0x01C2
+
+///
+/// PE32+ Machine type for AARCH64 A64 images.
+///
+#define EFI_IMAGE_MACHINE_AARCH64  0xAA64
+
+
+#if   defined (MDE_CPU_IA32)
+
+#define EFI_IMAGE_MACHINE_TYPE_SUPPORTED(Machine) \
+  (((Machine) == EFI_IMAGE_MACHINE_IA32) || ((Machine) == EFI_IMAGE_MACHINE_EBC))
+
+#define EFI_IMAGE_MACHINE_CROSS_TYPE_SUPPORTED(Machine) ((Machine) == EFI_IMAGE_MACHINE_X64)
+
+#elif defined (MDE_CPU_IPF)
+
+#define EFI_IMAGE_MACHINE_TYPE_SUPPORTED(Machine) \
+  (((Machine) == EFI_IMAGE_MACHINE_IA64) || ((Machine) == EFI_IMAGE_MACHINE_EBC))
+
+#define EFI_IMAGE_MACHINE_CROSS_TYPE_SUPPORTED(Machine) (FALSE)
+
+#elif defined (MDE_CPU_X64)
+
+#define EFI_IMAGE_MACHINE_TYPE_SUPPORTED(Machine) \
+  (((Machine) == EFI_IMAGE_MACHINE_X64) || ((Machine) == EFI_IMAGE_MACHINE_EBC))
+
+#define EFI_IMAGE_MACHINE_CROSS_TYPE_SUPPORTED(Machine) ((Machine) == EFI_IMAGE_MACHINE_IA32)
+
+#elif defined (MDE_CPU_ARM)
+
+#define EFI_IMAGE_MACHINE_TYPE_SUPPORTED(Machine) \
+  (((Machine) == EFI_IMAGE_MACHINE_ARMTHUMB_MIXED) || ((Machine) == EFI_IMAGE_MACHINE_EBC))
+
+#define EFI_IMAGE_MACHINE_CROSS_TYPE_SUPPORTED(Machine) ((Machine) == EFI_IMAGE_MACHINE_ARMTHUMB_MIXED)
+
+#elif defined (MDE_CPU_AARCH64)
+
+#define EFI_IMAGE_MACHINE_TYPE_SUPPORTED(Machine) \
+  (((Machine) == EFI_IMAGE_MACHINE_AARCH64) || ((Machine) == EFI_IMAGE_MACHINE_EBC))
+
+#define EFI_IMAGE_MACHINE_CROSS_TYPE_SUPPORTED(Machine) (FALSE)
+
+#elif defined (MDE_CPU_EBC)
+
+///
+/// This is just to make sure you can cross compile with the EBC compiler.
+/// It does not make sense to have a PE loader coded in EBC.
+///
+#define EFI_IMAGE_MACHINE_TYPE_SUPPORTED(Machine) ((Machine) == EFI_IMAGE_MACHINE_EBC)
+
+#define EFI_IMAGE_MACHINE_CROSS_TYPE_SUPPORTED(Machine) (FALSE)
+
+#else
+#error Unknown Processor Type
+#endif
+
+#endif
diff --git a/tools/cbfstool/edk2/Uefi/UefiMultiPhase.h b/tools/cbfstool/edk2/Uefi/UefiMultiPhase.h
new file mode 100644
index 0000000000..6c0f0516e9
--- /dev/null
+++ b/tools/cbfstool/edk2/Uefi/UefiMultiPhase.h
@@ -0,0 +1,193 @@
+/** @file
+  This includes some definitions introduced in UEFI that will be used in both PEI and DXE phases.
+
+Copyright (c) 2006 - 2011, Intel Corporation. All rights reserved.<BR>
+This program and the accompanying materials are licensed and made available under
+the terms and conditions of the BSD License that accompanies this distribution.
+The full text of the license may be found at
+http://opensource.org/licenses/bsd-license.php.
+
+THE PROGRAM IS DISTRIBUTED UNDER THE BSD LICENSE ON AN "AS IS" BASIS,
+WITHOUT WARRANTIES OR REPRESENTATIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED.
+
+**/
+
+#ifndef __UEFI_MULTIPHASE_H__
+#define __UEFI_MULTIPHASE_H__
+
+#include <Guid/WinCertificate.h>
+///
+/// Enumeration of memory types introduced in UEFI.
+///
+typedef enum {
+  ///
+  /// Not used.
+  ///
+  EfiReservedMemoryType,
+  ///
+  /// The code portions of a loaded application.
+  /// (Note that UEFI OS loaders are UEFI applications.)
+  ///
+  EfiLoaderCode,
+  ///
+  /// The data portions of a loaded application and the default data allocation
+  /// type used by an application to allocate pool memory.
+  ///
+  EfiLoaderData,
+  ///
+  /// The code portions of a loaded Boot Services Driver.
+  ///
+  EfiBootServicesCode,
+  ///
+  /// The data portions of a loaded Boot Serves Driver, and the default data
+  /// allocation type used by a Boot Services Driver to allocate pool memory.
+  ///
+  EfiBootServicesData,
+  ///
+  /// The code portions of a loaded Runtime Services Driver.
+  ///
+  EfiRuntimeServicesCode,
+  ///
+  /// The data portions of a loaded Runtime Services Driver and the default
+  /// data allocation type used by a Runtime Services Driver to allocate pool memory.
+  ///
+  EfiRuntimeServicesData,
+  ///
+  /// Free (unallocated) memory.
+  ///
+  EfiConventionalMemory,
+  ///
+  /// Memory in which errors have been detected.
+  ///
+  EfiUnusableMemory,
+  ///
+  /// Memory that holds the ACPI tables.
+  ///
+  EfiACPIReclaimMemory,
+  ///
+  /// Address space reserved for use by the firmware.
+  ///
+  EfiACPIMemoryNVS,
+  ///
+  /// Used by system firmware to request that a memory-mapped IO region
+  /// be mapped by the OS to a virtual address so it can be accessed by EFI runtime services.
+  ///
+  EfiMemoryMappedIO,
+  ///
+  /// System memory-mapped IO region that is used to translate memory
+  /// cycles to IO cycles by the processor.
+  ///
+  EfiMemoryMappedIOPortSpace,
+  ///
+  /// Address space reserved by the firmware for code that is part of the processor.
+  ///
+  EfiPalCode,
+  EfiMaxMemoryType
+} EFI_MEMORY_TYPE;
+
+///
+/// Data structure that precedes all of the standard EFI table types.
+///
+typedef struct {
+  ///
+  /// A 64-bit signature that identifies the type of table that follows.
+  /// Unique signatures have been generated for the EFI System Table,
+  /// the EFI Boot Services Table, and the EFI Runtime Services Table.
+  ///
+  UINT64  Signature;
+  ///
+  /// The revision of the EFI Specification to which this table
+  /// conforms. The upper 16 bits of this field contain the major
+  /// revision value, and the lower 16 bits contain the minor revision
+  /// value. The minor revision values are limited to the range of 00..99.
+  ///
+  UINT32  Revision;
+  ///
+  /// The size, in bytes, of the entire table including the EFI_TABLE_HEADER.
+  ///
+  UINT32  HeaderSize;
+  ///
+  /// The 32-bit CRC for the entire table. This value is computed by
+  /// setting this field to 0, and computing the 32-bit CRC for HeaderSize bytes.
+  ///
+  UINT32  CRC32;
+  ///
+  /// Reserved field that must be set to 0.
+  ///
+  UINT32  Reserved;
+} EFI_TABLE_HEADER;
+
+///
+/// Attributes of variable.
+///
+#define EFI_VARIABLE_NON_VOLATILE                            0x00000001
+#define EFI_VARIABLE_BOOTSERVICE_ACCESS                      0x00000002
+#define EFI_VARIABLE_RUNTIME_ACCESS                          0x00000004
+///
+/// This attribute is identified by the mnemonic 'HR'
+/// elsewhere in this specification.
+///
+#define EFI_VARIABLE_HARDWARE_ERROR_RECORD                   0x00000008
+///
+/// Attributes of Authenticated Variable
+///
+#define EFI_VARIABLE_AUTHENTICATED_WRITE_ACCESS              0x00000010
+#define EFI_VARIABLE_TIME_BASED_AUTHENTICATED_WRITE_ACCESS   0x00000020
+#define EFI_VARIABLE_APPEND_WRITE                            0x00000040
+
+
+///
+/// AuthInfo is a WIN_CERTIFICATE using the wCertificateType
+/// WIN_CERTIFICATE_UEFI_GUID and the CertType
+/// EFI_CERT_TYPE_RSA2048_SHA256_GUID. If the attribute specifies
+/// authenticated access, then the Data buffer should begin with an
+/// authentication descriptor prior to the data payload and DataSize
+/// should reflect the data.and descriptor size. The caller
+/// shall digest the Monotonic Count value and the associated data
+/// for the variable update using the SHA-256 1-way hash algorithm.
+/// The ensuing the 32-byte digest will be signed using the private
+/// key associated w/ the public/private 2048-bit RSA key-pair. The
+/// WIN_CERTIFICATE shall be used to describe the signature of the
+/// Variable data *Data. In addition, the signature will also
+/// include the MonotonicCount value to guard against replay attacks.
+///
+typedef struct {
+  ///
+  /// Included in the signature of
+  /// AuthInfo.Used to ensure freshness/no
+  /// replay. Incremented during each
+  /// "Write" access.
+  ///
+  UINT64                      MonotonicCount;
+  ///
+  /// Provides the authorization for the variable
+  /// access. It is a signature across the
+  /// variable data and the  Monotonic Count
+  /// value. Caller uses Private key that is
+  /// associated with a public key that has been
+  /// provisioned via the key exchange.
+  ///
+  WIN_CERTIFICATE_UEFI_GUID   AuthInfo;
+} EFI_VARIABLE_AUTHENTICATION;
+
+///
+/// When the attribute EFI_VARIABLE_TIME_BASED_AUTHENTICATED_WRITE_ACCESS is
+/// set, then the Data buffer shall begin with an instance of a complete (and serialized)
+/// EFI_VARIABLE_AUTHENTICATION_2 descriptor. The descriptor shall be followed by the new
+/// variable value and DataSize shall reflect the combined size of the descriptor and the new
+/// variable value. The authentication descriptor is not part of the variable data and is not
+/// returned by subsequent calls to GetVariable().
+///
+typedef struct {
+  ///
+  /// For the TimeStamp value, components Pad1, Nanosecond, TimeZone, Daylight and
+  /// Pad2 shall be set to 0. This means that the time shall always be expressed in GMT.
+  ///
+  EFI_TIME                    TimeStamp;
+  ///
+  /// Only a CertType of  EFI_CERT_TYPE_PKCS7_GUID is accepted.
+  ///
+  WIN_CERTIFICATE_UEFI_GUID   AuthInfo;
+ } EFI_VARIABLE_AUTHENTICATION_2;
+
+#endif
diff --git a/tools/cbfstool/edk2/Uefi/uefi_types.h b/tools/cbfstool/edk2/Uefi/uefi_types.h
new file mode 100644
index 0000000000..910730bc5f
--- /dev/null
+++ b/tools/cbfstool/edk2/Uefi/uefi_types.h
@@ -0,0 +1,131 @@
+/**
+
+Copyright (C) 2013, Intel Corporation
+
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+* Redistributions of source code must retain the above copyright notice, this
+  list of conditions and the following disclaimer.
+* Redistributions in binary form must reproduce the above copyright notice, this
+  list of conditions and the following disclaimer in the documentation and/or
+  other materials provided with the distribution.
+* Neither the name of Intel Corporation nor the names of its contributors may
+  be used to endorse or promote products derived from this software without
+  specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
+  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+**/
+
+#ifndef __UEFI_TYPES_H__
+#define __UEFI_TYPES_H__
+
+//
+// Set the UEFI types and attributes
+//
+#include <stdlib.h>
+#include <Uefi/UefiBaseType.h>
+#include <Pi/PiBootMode.h>
+#include <Pi/PiFirmwareFile.h>
+#include <Pi/PiFirmwareVolume.h>
+#include <Uefi/UefiMultiPhase.h>
+#include <Pi/PiHob.h>
+#include <Protocol/GraphicsOutput.h>
+#include <Library/HobLib.h>
+#include <Guid/FirmwareFileSystem2.h>
+#include <IndustryStandard/PeImage.h>
+
+///
+/// For GNU assembly code, .global or .globl can declare global symbols.
+/// Define this macro to unify the usage.
+///
+#if defined(ASM_GLOBAL)
+#undef ASM_GLOBAL
+#endif
+#define ASM_GLOBAL .global
+
+//
+// Define the ASSERT support
+//
+static inline void debug_dead_loop(void)
+{
+	for (;;)
+		;
+}
+
+#define _ASSERT(expression)  debug_dead_loop()
+#ifndef ASSERT
+#define ASSERT(expression)			\
+	do {					\
+		if (!(expression)) {		\
+			_ASSERT(expression);	\
+		}				\
+	} while (FALSE)
+#endif
+
+//
+// Contents of the PEI_GRAPHICS_INFO_HOB
+//
+typedef struct {
+	EFI_PHYSICAL_ADDRESS			FrameBufferBase;
+	UINT32					FrameBufferSize;
+	EFI_GRAPHICS_OUTPUT_MODE_INFORMATION	GraphicsMode;
+} EFI_PEI_GRAPHICS_INFO_HOB;
+
+//
+// Define the known GUIDs
+//
+#define EFI_PEI_GRAPHICS_INFO_HOB_GUID				\
+{								\
+	0x39f62cce, 0x6825, 0x4669,				\
+	{ 0xbb, 0x56, 0x54, 0x1a, 0xba, 0x75, 0x3a, 0x07 }	\
+}
+
+#define FSP_BOOTLOADER_TEMP_MEMORY_HOB_GUID			\
+{								\
+	0xbbcff46c, 0xc8d3, 0x4113,				\
+	{0x89, 0x85, 0xb9, 0xd4, 0xf3, 0xb3, 0xf6, 0x4e}	\
+}
+
+#define FSP_BOOTLOADER_TOLUM_HOB_GUID				\
+{								\
+	0x73ff4f56, 0xaa8e, 0x4451,				\
+	{ 0xb3, 0x16, 0x36, 0x35, 0x36, 0x67, 0xad, 0x44 }	\
+}
+
+#define FSP_INFO_HEADER_GUID					\
+{								\
+	0x912740BE, 0x2284, 0x4734,				\
+	{0xB9, 0x71, 0x84, 0xB0, 0x27, 0x35, 0x3F, 0x0C}	\
+}
+
+#define FSP_NON_VOLATILE_STORAGE_HOB_GUID			\
+{								\
+	0x721acf02, 0x4d77, 0x4c2a,				\
+	{0xb3, 0xdc, 0x27, 0x0b, 0x7b, 0xa9, 0xe4, 0xb0}	\
+}
+
+#define FSP_RESERVED_MEMORY_RESOURCE_HOB_GUID			\
+{								\
+	0x69a79759, 0x1373, 0x4367,				\
+	{ 0xa6, 0xc4, 0xc7, 0xf5, 0x9e, 0xfd, 0x98, 0x6e }	\
+}
+
+#define FSP_SMBIOS_MEMORY_INFO_GUID				\
+{								\
+	0x01a1108c, 0x9dee, 0x4984,				\
+	{ 0x88, 0xc3, 0xee, 0xe8, 0xc4, 0x9e, 0xfb, 0x89 }	\
+}
+
+#endif	/* __UEFI_TYPES_H__*/
diff --git a/tools/cbfstool/edk2/uefi_types.h b/tools/cbfstool/edk2/uefi_types.h
new file mode 100644
index 0000000000..910730bc5f
--- /dev/null
+++ b/tools/cbfstool/edk2/uefi_types.h
@@ -0,0 +1,131 @@
+/**
+
+Copyright (C) 2013, Intel Corporation
+
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+* Redistributions of source code must retain the above copyright notice, this
+  list of conditions and the following disclaimer.
+* Redistributions in binary form must reproduce the above copyright notice, this
+  list of conditions and the following disclaimer in the documentation and/or
+  other materials provided with the distribution.
+* Neither the name of Intel Corporation nor the names of its contributors may
+  be used to endorse or promote products derived from this software without
+  specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
+  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+**/
+
+#ifndef __UEFI_TYPES_H__
+#define __UEFI_TYPES_H__
+
+//
+// Set the UEFI types and attributes
+//
+#include <stdlib.h>
+#include <Uefi/UefiBaseType.h>
+#include <Pi/PiBootMode.h>
+#include <Pi/PiFirmwareFile.h>
+#include <Pi/PiFirmwareVolume.h>
+#include <Uefi/UefiMultiPhase.h>
+#include <Pi/PiHob.h>
+#include <Protocol/GraphicsOutput.h>
+#include <Library/HobLib.h>
+#include <Guid/FirmwareFileSystem2.h>
+#include <IndustryStandard/PeImage.h>
+
+///
+/// For GNU assembly code, .global or .globl can declare global symbols.
+/// Define this macro to unify the usage.
+///
+#if defined(ASM_GLOBAL)
+#undef ASM_GLOBAL
+#endif
+#define ASM_GLOBAL .global
+
+//
+// Define the ASSERT support
+//
+static inline void debug_dead_loop(void)
+{
+	for (;;)
+		;
+}
+
+#define _ASSERT(expression)  debug_dead_loop()
+#ifndef ASSERT
+#define ASSERT(expression)			\
+	do {					\
+		if (!(expression)) {		\
+			_ASSERT(expression);	\
+		}				\
+	} while (FALSE)
+#endif
+
+//
+// Contents of the PEI_GRAPHICS_INFO_HOB
+//
+typedef struct {
+	EFI_PHYSICAL_ADDRESS			FrameBufferBase;
+	UINT32					FrameBufferSize;
+	EFI_GRAPHICS_OUTPUT_MODE_INFORMATION	GraphicsMode;
+} EFI_PEI_GRAPHICS_INFO_HOB;
+
+//
+// Define the known GUIDs
+//
+#define EFI_PEI_GRAPHICS_INFO_HOB_GUID				\
+{								\
+	0x39f62cce, 0x6825, 0x4669,				\
+	{ 0xbb, 0x56, 0x54, 0x1a, 0xba, 0x75, 0x3a, 0x07 }	\
+}
+
+#define FSP_BOOTLOADER_TEMP_MEMORY_HOB_GUID			\
+{								\
+	0xbbcff46c, 0xc8d3, 0x4113,				\
+	{0x89, 0x85, 0xb9, 0xd4, 0xf3, 0xb3, 0xf6, 0x4e}	\
+}
+
+#define FSP_BOOTLOADER_TOLUM_HOB_GUID				\
+{								\
+	0x73ff4f56, 0xaa8e, 0x4451,				\
+	{ 0xb3, 0x16, 0x36, 0x35, 0x36, 0x67, 0xad, 0x44 }	\
+}
+
+#define FSP_INFO_HEADER_GUID					\
+{								\
+	0x912740BE, 0x2284, 0x4734,				\
+	{0xB9, 0x71, 0x84, 0xB0, 0x27, 0x35, 0x3F, 0x0C}	\
+}
+
+#define FSP_NON_VOLATILE_STORAGE_HOB_GUID			\
+{								\
+	0x721acf02, 0x4d77, 0x4c2a,				\
+	{0xb3, 0xdc, 0x27, 0x0b, 0x7b, 0xa9, 0xe4, 0xb0}	\
+}
+
+#define FSP_RESERVED_MEMORY_RESOURCE_HOB_GUID			\
+{								\
+	0x69a79759, 0x1373, 0x4367,				\
+	{ 0xa6, 0xc4, 0xc7, 0xf5, 0x9e, 0xfd, 0x98, 0x6e }	\
+}
+
+#define FSP_SMBIOS_MEMORY_INFO_GUID				\
+{								\
+	0x01a1108c, 0x9dee, 0x4984,				\
+	{ 0x88, 0xc3, 0xee, 0xe8, 0xc4, 0x9e, 0xfb, 0x89 }	\
+}
+
+#endif	/* __UEFI_TYPES_H__*/
diff --git a/tools/cbfstool/elf.h b/tools/cbfstool/elf.h
new file mode 100644
index 0000000000..43fd7f33eb
--- /dev/null
+++ b/tools/cbfstool/elf.h
@@ -0,0 +1,2935 @@
+/* This file defines standard ELF types, structures, and macros.
+   Copyright (C) 1995-2003,2004,2005,2006,2007 Free Software Foundation, Inc.
+   This file is part of the GNU C Library.
+
+   The GNU C Library is free software; you can redistribute it and/or
+   modify it under the terms of the GNU Lesser General Public
+   License as published by the Free Software Foundation; either
+   version 2.1 of the License, or (at your option) any later version.
+
+   The GNU C Library is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   Lesser General Public License for more details.
+*/
+
+#ifndef _ELF_H
+#define	_ELF_H 1
+
+#include <stdint.h>
+
+/* Type for a 16-bit quantity.  */
+typedef uint16_t Elf32_Half;
+typedef uint16_t Elf64_Half;
+
+/* Types for signed and unsigned 32-bit quantities.  */
+typedef uint32_t Elf32_Word;
+typedef	int32_t  Elf32_Sword;
+typedef uint32_t Elf64_Word;
+typedef	int32_t  Elf64_Sword;
+
+/* Types for signed and unsigned 64-bit quantities.  */
+typedef uint64_t Elf32_Xword;
+typedef	int64_t  Elf32_Sxword;
+typedef uint64_t Elf64_Xword;
+typedef	int64_t  Elf64_Sxword;
+
+/* Type of addresses.  */
+typedef uint32_t Elf32_Addr;
+typedef uint64_t Elf64_Addr;
+
+/* Type of file offsets.  */
+typedef uint32_t Elf32_Off;
+typedef uint64_t Elf64_Off;
+
+/* Type for section indices, which are 16-bit quantities.  */
+typedef uint16_t Elf32_Section;
+typedef uint16_t Elf64_Section;
+
+/* Type for version symbol information.  */
+typedef Elf32_Half Elf32_Versym;
+typedef Elf64_Half Elf64_Versym;
+
+
+/* The ELF file header.  This appears at the start of every ELF file.  */
+
+#define EI_NIDENT (16)
+
+typedef struct
+{
+  unsigned char	e_ident[EI_NIDENT];	/* Magic number and other info */
+  Elf32_Half	e_type;			/* Object file type */
+  Elf32_Half	e_machine;		/* Architecture */
+  Elf32_Word	e_version;		/* Object file version */
+  Elf32_Addr	e_entry;		/* Entry point virtual address */
+  Elf32_Off	e_phoff;		/* Program header table file offset */
+  Elf32_Off	e_shoff;		/* Section header table file offset */
+  Elf32_Word	e_flags;		/* Processor-specific flags */
+  Elf32_Half	e_ehsize;		/* ELF header size in bytes */
+  Elf32_Half	e_phentsize;		/* Program header table entry size */
+  Elf32_Half	e_phnum;		/* Program header table entry count */
+  Elf32_Half	e_shentsize;		/* Section header table entry size */
+  Elf32_Half	e_shnum;		/* Section header table entry count */
+  Elf32_Half	e_shstrndx;		/* Section header string table index */
+} Elf32_Ehdr;
+
+typedef struct
+{
+  unsigned char	e_ident[EI_NIDENT];	/* Magic number and other info */
+  Elf64_Half	e_type;			/* Object file type */
+  Elf64_Half	e_machine;		/* Architecture */
+  Elf64_Word	e_version;		/* Object file version */
+  Elf64_Addr	e_entry;		/* Entry point virtual address */
+  Elf64_Off	e_phoff;		/* Program header table file offset */
+  Elf64_Off	e_shoff;		/* Section header table file offset */
+  Elf64_Word	e_flags;		/* Processor-specific flags */
+  Elf64_Half	e_ehsize;		/* ELF header size in bytes */
+  Elf64_Half	e_phentsize;		/* Program header table entry size */
+  Elf64_Half	e_phnum;		/* Program header table entry count */
+  Elf64_Half	e_shentsize;		/* Section header table entry size */
+  Elf64_Half	e_shnum;		/* Section header table entry count */
+  Elf64_Half	e_shstrndx;		/* Section header string table index */
+} Elf64_Ehdr;
+
+/* Fields in the e_ident array.  The EI_* macros are indices into the
+   array.  The macros under each EI_* macro are the values the byte
+   may have.  */
+
+#define EI_MAG0		0		/* File identification byte 0 index */
+#define ELFMAG0		0x7f		/* Magic number byte 0 */
+
+#define EI_MAG1		1		/* File identification byte 1 index */
+#define ELFMAG1		'E'		/* Magic number byte 1 */
+
+#define EI_MAG2		2		/* File identification byte 2 index */
+#define ELFMAG2		'L'		/* Magic number byte 2 */
+
+#define EI_MAG3		3		/* File identification byte 3 index */
+#define ELFMAG3		'F'		/* Magic number byte 3 */
+
+/* Conglomeration of the identification bytes, for easy testing as a word.  */
+#define	ELFMAG		"\177ELF"
+#define	SELFMAG		4
+
+#define EI_CLASS	4		/* File class byte index */
+#define ELFCLASSNONE	0		/* Invalid class */
+#define ELFCLASS32	1		/* 32-bit objects */
+#define ELFCLASS64	2		/* 64-bit objects */
+#define ELFCLASSNUM	3
+
+#define EI_DATA		5		/* Data encoding byte index */
+#define ELFDATANONE	0		/* Invalid data encoding */
+#define ELFDATA2LSB	1		/* 2's complement, little endian */
+#define ELFDATA2MSB	2		/* 2's complement, big endian */
+#define ELFDATANUM	3
+
+#define EI_VERSION	6		/* File version byte index */
+					/* Value must be EV_CURRENT */
+
+#define EI_OSABI	7		/* OS ABI identification */
+#define ELFOSABI_NONE		0	/* UNIX System V ABI */
+#define ELFOSABI_SYSV		0	/* Alias.  */
+#define ELFOSABI_HPUX		1	/* HP-UX */
+#define ELFOSABI_NETBSD		2	/* NetBSD.  */
+#define ELFOSABI_LINUX		3	/* Linux.  */
+#define ELFOSABI_SOLARIS	6	/* Sun Solaris.  */
+#define ELFOSABI_AIX		7	/* IBM AIX.  */
+#define ELFOSABI_IRIX		8	/* SGI Irix.  */
+#define ELFOSABI_FREEBSD	9	/* FreeBSD.  */
+#define ELFOSABI_TRU64		10	/* Compaq TRU64 UNIX.  */
+#define ELFOSABI_MODESTO	11	/* Novell Modesto.  */
+#define ELFOSABI_OPENBSD	12	/* OpenBSD.  */
+#define ELFOSABI_ARM		97	/* ARM */
+#define ELFOSABI_STANDALONE	255	/* Standalone (embedded) application */
+
+#define EI_ABIVERSION	8		/* ABI version */
+
+#define EI_PAD		9		/* Byte index of padding bytes */
+
+/* Legal values for e_type (object file type).  */
+
+#define ET_NONE		0		/* No file type */
+#define ET_REL		1		/* Relocatable file */
+#define ET_EXEC		2		/* Executable file */
+#define ET_DYN		3		/* Shared object file */
+#define ET_CORE		4		/* Core file */
+#define	ET_NUM		5		/* Number of defined types */
+#define ET_LOOS		0xfe00		/* OS-specific range start */
+#define ET_HIOS		0xfeff		/* OS-specific range end */
+#define ET_LOPROC	0xff00		/* Processor-specific range start */
+#define ET_HIPROC	0xffff		/* Processor-specific range end */
+
+/* Legal values for e_machine (architecture).  */
+
+#define EM_NONE		 0		/* No machine */
+#define EM_M32		 1		/* AT&T WE 32100 */
+#define EM_SPARC	 2		/* SUN SPARC */
+#define EM_386		 3		/* Intel 80386 */
+#define EM_68K		 4		/* Motorola m68k family */
+#define EM_88K		 5		/* Motorola m88k family */
+#define EM_860		 7		/* Intel 80860 */
+#define EM_MIPS		 8		/* MIPS R3000 big-endian */
+#define EM_S370		 9		/* IBM System/370 */
+#define EM_MIPS_RS3_LE	10		/* MIPS R3000 little-endian */
+
+#define EM_PARISC	15		/* HPPA */
+#define EM_VPP500	17		/* Fujitsu VPP500 */
+#define EM_SPARC32PLUS	18		/* Sun's "v8plus" */
+#define EM_960		19		/* Intel 80960 */
+#define EM_PPC		20		/* PowerPC */
+#define EM_PPC64	21		/* PowerPC 64-bit */
+#define EM_S390		22		/* IBM S390 */
+
+#define EM_V800		36		/* NEC V800 series */
+#define EM_FR20		37		/* Fujitsu FR20 */
+#define EM_RH32		38		/* TRW RH-32 */
+#define EM_RCE		39		/* Motorola RCE */
+#define EM_ARM		40		/* ARM */
+#define EM_FAKE_ALPHA	41		/* Digital Alpha */
+#define EM_SH		42		/* Hitachi SH */
+#define EM_SPARCV9	43		/* SPARC v9 64-bit */
+#define EM_TRICORE	44		/* Siemens Tricore */
+#define EM_ARC		45		/* Argonaut RISC Core */
+#define EM_H8_300	46		/* Hitachi H8/300 */
+#define EM_H8_300H	47		/* Hitachi H8/300H */
+#define EM_H8S		48		/* Hitachi H8S */
+#define EM_H8_500	49		/* Hitachi H8/500 */
+#define EM_IA_64	50		/* Intel Merced */
+#define EM_MIPS_X	51		/* Stanford MIPS-X */
+#define EM_COLDFIRE	52		/* Motorola Coldfire */
+#define EM_68HC12	53		/* Motorola M68HC12 */
+#define EM_MMA		54		/* Fujitsu MMA Multimedia Accelerator*/
+#define EM_PCP		55		/* Siemens PCP */
+#define EM_NCPU		56		/* Sony nCPU embeeded RISC */
+#define EM_NDR1		57		/* Denso NDR1 microprocessor */
+#define EM_STARCORE	58		/* Motorola Start*Core processor */
+#define EM_ME16		59		/* Toyota ME16 processor */
+#define EM_ST100	60		/* STMicroelectronic ST100 processor */
+#define EM_TINYJ	61		/* Advanced Logic Corp. Tinyj emb.fam*/
+#define EM_X86_64	62		/* AMD x86-64 architecture */
+#define EM_PDSP		63		/* Sony DSP Processor */
+
+#define EM_FX66		66		/* Siemens FX66 microcontroller */
+#define EM_ST9PLUS	67		/* STMicroelectronics ST9+ 8/16 mc */
+#define EM_ST7		68		/* STmicroelectronics ST7 8 bit mc */
+#define EM_68HC16	69		/* Motorola MC68HC16 microcontroller */
+#define EM_68HC11	70		/* Motorola MC68HC11 microcontroller */
+#define EM_68HC08	71		/* Motorola MC68HC08 microcontroller */
+#define EM_68HC05	72		/* Motorola MC68HC05 microcontroller */
+#define EM_SVX		73		/* Silicon Graphics SVx */
+#define EM_ST19		74		/* STMicroelectronics ST19 8 bit mc */
+#define EM_VAX		75		/* Digital VAX */
+#define EM_CRIS		76		/* Axis Communications 32-bit embedded processor */
+#define EM_JAVELIN	77		/* Infineon Technologies 32-bit embedded processor */
+#define EM_FIREPATH	78		/* Element 14 64-bit DSP Processor */
+#define EM_ZSP		79		/* LSI Logic 16-bit DSP Processor */
+#define EM_MMIX		80		/* Donald Knuth's educational 64-bit processor */
+#define EM_HUANY	81		/* Harvard University machine-independent object files */
+#define EM_PRISM	82		/* SiTera Prism */
+#define EM_AVR		83		/* Atmel AVR 8-bit microcontroller */
+#define EM_FR30		84		/* Fujitsu FR30 */
+#define EM_D10V		85		/* Mitsubishi D10V */
+#define EM_D30V		86		/* Mitsubishi D30V */
+#define EM_V850		87		/* NEC v850 */
+#define EM_M32R		88		/* Mitsubishi M32R */
+#define EM_MN10300	89		/* Matsushita MN10300 */
+#define EM_MN10200	90		/* Matsushita MN10200 */
+#define EM_PJ		91		/* picoJava */
+#define EM_OPENRISC	92		/* OpenRISC 32-bit embedded processor */
+#define EM_ARC_A5	93		/* ARC Cores Tangent-A5 */
+#define EM_XTENSA	94		/* Tensilica Xtensa Architecture */
+#define EM_NUM		95
+#define EM_AARCH64	183		/* ARM AARCH64 */
+
+/* If it is necessary to assign new unofficial EM_* values, please
+   pick large random numbers (0x8523, 0xa7f2, etc.) to minimize the
+   chances of collision with official or non-GNU unofficial values.  */
+
+#define EM_ALPHA	0x9026
+
+/* Legal values for e_version (version).  */
+
+#define EV_NONE		0		/* Invalid ELF version */
+#define EV_CURRENT	1		/* Current version */
+#define EV_NUM		2
+
+/* Section header.  */
+
+typedef struct
+{
+  Elf32_Word	sh_name;		/* Section name (string tbl index) */
+  Elf32_Word	sh_type;		/* Section type */
+  Elf32_Word	sh_flags;		/* Section flags */
+  Elf32_Addr	sh_addr;		/* Section virtual addr at execution */
+  Elf32_Off	sh_offset;		/* Section file offset */
+  Elf32_Word	sh_size;		/* Section size in bytes */
+  Elf32_Word	sh_link;		/* Link to another section */
+  Elf32_Word	sh_info;		/* Additional section information */
+  Elf32_Word	sh_addralign;		/* Section alignment */
+  Elf32_Word	sh_entsize;		/* Entry size if section holds table */
+} Elf32_Shdr;
+
+typedef struct
+{
+  Elf64_Word	sh_name;		/* Section name (string tbl index) */
+  Elf64_Word	sh_type;		/* Section type */
+  Elf64_Xword	sh_flags;		/* Section flags */
+  Elf64_Addr	sh_addr;		/* Section virtual addr at execution */
+  Elf64_Off	sh_offset;		/* Section file offset */
+  Elf64_Xword	sh_size;		/* Section size in bytes */
+  Elf64_Word	sh_link;		/* Link to another section */
+  Elf64_Word	sh_info;		/* Additional section information */
+  Elf64_Xword	sh_addralign;		/* Section alignment */
+  Elf64_Xword	sh_entsize;		/* Entry size if section holds table */
+} Elf64_Shdr;
+
+/* Special section indices.  */
+
+#define SHN_UNDEF	0		/* Undefined section */
+#define SHN_LORESERVE	0xff00		/* Start of reserved indices */
+#define SHN_LOPROC	0xff00		/* Start of processor-specific */
+#define SHN_BEFORE	0xff00		/* Order section before all others
+					   (Solaris).  */
+#define SHN_AFTER	0xff01		/* Order section after all others
+					   (Solaris).  */
+#define SHN_HIPROC	0xff1f		/* End of processor-specific */
+#define SHN_LOOS	0xff20		/* Start of OS-specific */
+#define SHN_HIOS	0xff3f		/* End of OS-specific */
+#define SHN_ABS		0xfff1		/* Associated symbol is absolute */
+#define SHN_COMMON	0xfff2		/* Associated symbol is common */
+#define SHN_XINDEX	0xffff		/* Index is in extra table.  */
+#define SHN_HIRESERVE	0xffff		/* End of reserved indices */
+
+/* Legal values for sh_type (section type).  */
+
+#define SHT_NULL	  0		/* Section header table entry unused */
+#define SHT_PROGBITS	  1		/* Program data */
+#define SHT_SYMTAB	  2		/* Symbol table */
+#define SHT_STRTAB	  3		/* String table */
+#define SHT_RELA	  4		/* Relocation entries with addends */
+#define SHT_HASH	  5		/* Symbol hash table */
+#define SHT_DYNAMIC	  6		/* Dynamic linking information */
+#define SHT_NOTE	  7		/* Notes */
+#define SHT_NOBITS	  8		/* Program space with no data (bss) */
+#define SHT_REL		  9		/* Relocation entries, no addends */
+#define SHT_SHLIB	  10		/* Reserved */
+#define SHT_DYNSYM	  11		/* Dynamic linker symbol table */
+#define SHT_INIT_ARRAY	  14		/* Array of constructors */
+#define SHT_FINI_ARRAY	  15		/* Array of destructors */
+#define SHT_PREINIT_ARRAY 16		/* Array of pre-constructors */
+#define SHT_GROUP	  17		/* Section group */
+#define SHT_SYMTAB_SHNDX  18		/* Extended section indeces */
+#define	SHT_NUM		  19		/* Number of defined types.  */
+#define SHT_LOOS	  0x60000000	/* Start OS-specific.  */
+#define SHT_GNU_HASH	  0x6ffffff6	/* GNU-style hash table.  */
+#define SHT_GNU_LIBLIST	  0x6ffffff7	/* Prelink library list */
+#define SHT_CHECKSUM	  0x6ffffff8	/* Checksum for DSO content.  */
+#define SHT_LOSUNW	  0x6ffffffa	/* Sun-specific low bound.  */
+#define SHT_SUNW_move	  0x6ffffffa
+#define SHT_SUNW_COMDAT   0x6ffffffb
+#define SHT_SUNW_syminfo  0x6ffffffc
+#define SHT_GNU_verdef	  0x6ffffffd	/* Version definition section.  */
+#define SHT_GNU_verneed	  0x6ffffffe	/* Version needs section.  */
+#define SHT_GNU_versym	  0x6fffffff	/* Version symbol table.  */
+#define SHT_HISUNW	  0x6fffffff	/* Sun-specific high bound.  */
+#define SHT_HIOS	  0x6fffffff	/* End OS-specific type */
+#define SHT_LOPROC	  0x70000000	/* Start of processor-specific */
+#define SHT_HIPROC	  0x7fffffff	/* End of processor-specific */
+#define SHT_LOUSER	  0x80000000	/* Start of application-specific */
+#define SHT_HIUSER	  0x8fffffff	/* End of application-specific */
+
+/* Legal values for sh_flags (section flags).  */
+
+#define SHF_WRITE	     (1 << 0)	/* Writable */
+#define SHF_ALLOC	     (1 << 1)	/* Occupies memory during execution */
+#define SHF_EXECINSTR	     (1 << 2)	/* Executable */
+#define SHF_MERGE	     (1 << 4)	/* Might be merged */
+#define SHF_STRINGS	     (1 << 5)	/* Contains nul-terminated strings */
+#define SHF_INFO_LINK	     (1 << 6)	/* `sh_info' contains SHT index */
+#define SHF_LINK_ORDER	     (1 << 7)	/* Preserve order after combining */
+#define SHF_OS_NONCONFORMING (1 << 8)	/* Non-standard OS specific handling
+					   required */
+#define SHF_GROUP	     (1 << 9)	/* Section is member of a group.  */
+#define SHF_TLS		     (1 << 10)	/* Section hold thread-local data.  */
+#define SHF_MASKOS	     0x0ff00000	/* OS-specific.  */
+#define SHF_MASKPROC	     0xf0000000	/* Processor-specific */
+#define SHF_ORDERED	     (1 << 30)	/* Special ordering requirement
+					   (Solaris).  */
+#define SHF_EXCLUDE	     (1 << 31)	/* Section is excluded unless
+					   referenced or allocated (Solaris).*/
+
+/* Section group handling.  */
+#define GRP_COMDAT	0x1		/* Mark group as COMDAT.  */
+
+/* Symbol table entry.  */
+
+typedef struct
+{
+  Elf32_Word	st_name;		/* Symbol name (string tbl index) */
+  Elf32_Addr	st_value;		/* Symbol value */
+  Elf32_Word	st_size;		/* Symbol size */
+  unsigned char	st_info;		/* Symbol type and binding */
+  unsigned char	st_other;		/* Symbol visibility */
+  Elf32_Section	st_shndx;		/* Section index */
+} Elf32_Sym;
+
+typedef struct
+{
+  Elf64_Word	st_name;		/* Symbol name (string tbl index) */
+  unsigned char	st_info;		/* Symbol type and binding */
+  unsigned char st_other;		/* Symbol visibility */
+  Elf64_Section	st_shndx;		/* Section index */
+  Elf64_Addr	st_value;		/* Symbol value */
+  Elf64_Xword	st_size;		/* Symbol size */
+} Elf64_Sym;
+
+/* The syminfo section if available contains additional information about
+   every dynamic symbol.  */
+
+typedef struct
+{
+  Elf32_Half si_boundto;		/* Direct bindings, symbol bound to */
+  Elf32_Half si_flags;			/* Per symbol flags */
+} Elf32_Syminfo;
+
+typedef struct
+{
+  Elf64_Half si_boundto;		/* Direct bindings, symbol bound to */
+  Elf64_Half si_flags;			/* Per symbol flags */
+} Elf64_Syminfo;
+
+/* Possible values for si_boundto.  */
+#define SYMINFO_BT_SELF		0xffff	/* Symbol bound to self */
+#define SYMINFO_BT_PARENT	0xfffe	/* Symbol bound to parent */
+#define SYMINFO_BT_LOWRESERVE	0xff00	/* Beginning of reserved entries */
+
+/* Possible bitmasks for si_flags.  */
+#define SYMINFO_FLG_DIRECT	0x0001	/* Direct bound symbol */
+#define SYMINFO_FLG_PASSTHRU	0x0002	/* Pass-thru symbol for translator */
+#define SYMINFO_FLG_COPY	0x0004	/* Symbol is a copy-reloc */
+#define SYMINFO_FLG_LAZYLOAD	0x0008	/* Symbol bound to object to be lazy
+					   loaded */
+/* Syminfo version values.  */
+#define SYMINFO_NONE		0
+#define SYMINFO_CURRENT		1
+#define SYMINFO_NUM		2
+
+
+/* How to extract and insert information held in the st_info field.  */
+
+#define ELF32_ST_BIND(val)		(((unsigned char) (val)) >> 4)
+#define ELF32_ST_TYPE(val)		((val) & 0xf)
+#define ELF32_ST_INFO(bind, type)	(((bind) << 4) + ((type) & 0xf))
+
+/* Both Elf32_Sym and Elf64_Sym use the same one-byte st_info field.  */
+#define ELF64_ST_BIND(val)		ELF32_ST_BIND (val)
+#define ELF64_ST_TYPE(val)		ELF32_ST_TYPE (val)
+#define ELF64_ST_INFO(bind, type)	ELF32_ST_INFO ((bind), (type))
+
+/* Legal values for ST_BIND subfield of st_info (symbol binding).  */
+
+#define STB_LOCAL	0		/* Local symbol */
+#define STB_GLOBAL	1		/* Global symbol */
+#define STB_WEAK	2		/* Weak symbol */
+#define	STB_NUM		3		/* Number of defined types.  */
+#define STB_LOOS	10		/* Start of OS-specific */
+#define STB_HIOS	12		/* End of OS-specific */
+#define STB_LOPROC	13		/* Start of processor-specific */
+#define STB_HIPROC	15		/* End of processor-specific */
+
+/* Legal values for ST_TYPE subfield of st_info (symbol type).  */
+
+#define STT_NOTYPE	0		/* Symbol type is unspecified */
+#define STT_OBJECT	1		/* Symbol is a data object */
+#define STT_FUNC	2		/* Symbol is a code object */
+#define STT_SECTION	3		/* Symbol associated with a section */
+#define STT_FILE	4		/* Symbol's name is file name */
+#define STT_COMMON	5		/* Symbol is a common data object */
+#define STT_TLS		6		/* Symbol is thread-local data object*/
+#define	STT_NUM		7		/* Number of defined types.  */
+#define STT_LOOS	10		/* Start of OS-specific */
+#define STT_HIOS	12		/* End of OS-specific */
+#define STT_LOPROC	13		/* Start of processor-specific */
+#define STT_HIPROC	15		/* End of processor-specific */
+
+
+/* Symbol table indices are found in the hash buckets and chain table
+   of a symbol hash table section.  This special index value indicates
+   the end of a chain, meaning no further symbols are found in that bucket.  */
+
+#define STN_UNDEF	0		/* End of a chain.  */
+
+
+/* How to extract and insert information held in the st_other field.  */
+
+#define ELF32_ST_VISIBILITY(o)	((o) & 0x03)
+
+/* For ELF64 the definitions are the same.  */
+#define ELF64_ST_VISIBILITY(o)	ELF32_ST_VISIBILITY (o)
+
+/* Symbol visibility specification encoded in the st_other field.  */
+#define STV_DEFAULT	0		/* Default symbol visibility rules */
+#define STV_INTERNAL	1		/* Processor specific hidden class */
+#define STV_HIDDEN	2		/* Sym unavailable in other modules */
+#define STV_PROTECTED	3		/* Not preemptible, not exported */
+
+
+/* Relocation table entry without addend (in section of type SHT_REL).  */
+
+typedef struct
+{
+  Elf32_Addr	r_offset;		/* Address */
+  Elf32_Word	r_info;			/* Relocation type and symbol index */
+} Elf32_Rel;
+
+/* I have seen two different definitions of the Elf64_Rel and
+   Elf64_Rela structures, so we'll leave them out until Novell (or
+   whoever) gets their act together.  */
+/* The following, at least, is used on Sparc v9, MIPS, and Alpha.  */
+
+typedef struct
+{
+  Elf64_Addr	r_offset;		/* Address */
+  Elf64_Xword	r_info;			/* Relocation type and symbol index */
+} Elf64_Rel;
+
+/* Relocation table entry with addend (in section of type SHT_RELA).  */
+
+typedef struct
+{
+  Elf32_Addr	r_offset;		/* Address */
+  Elf32_Word	r_info;			/* Relocation type and symbol index */
+  Elf32_Sword	r_addend;		/* Addend */
+} Elf32_Rela;
+
+typedef struct
+{
+  Elf64_Addr	r_offset;		/* Address */
+  Elf64_Xword	r_info;			/* Relocation type and symbol index */
+  Elf64_Sxword	r_addend;		/* Addend */
+} Elf64_Rela;
+
+/* How to extract and insert information held in the r_info field.  */
+
+#define ELF32_R_SYM(val)		((val) >> 8)
+#define ELF32_R_TYPE(val)		((val) & 0xff)
+#define ELF32_R_INFO(sym, type)		(((sym) << 8) + ((type) & 0xff))
+
+#define ELF64_R_SYM(i)			((i) >> 32)
+#define ELF64_R_TYPE(i)			((i) & 0xffffffff)
+#define ELF64_R_INFO(sym,type)		((((Elf64_Xword) (sym)) << 32) + (type))
+
+/* Program segment header.  */
+
+typedef struct
+{
+  Elf32_Word	p_type;			/* Segment type */
+  Elf32_Off	p_offset;		/* Segment file offset */
+  Elf32_Addr	p_vaddr;		/* Segment virtual address */
+  Elf32_Addr	p_paddr;		/* Segment physical address */
+  Elf32_Word	p_filesz;		/* Segment size in file */
+  Elf32_Word	p_memsz;		/* Segment size in memory */
+  Elf32_Word	p_flags;		/* Segment flags */
+  Elf32_Word	p_align;		/* Segment alignment */
+} Elf32_Phdr;
+
+typedef struct
+{
+  Elf64_Word	p_type;			/* Segment type */
+  Elf64_Word	p_flags;		/* Segment flags */
+  Elf64_Off	p_offset;		/* Segment file offset */
+  Elf64_Addr	p_vaddr;		/* Segment virtual address */
+  Elf64_Addr	p_paddr;		/* Segment physical address */
+  Elf64_Xword	p_filesz;		/* Segment size in file */
+  Elf64_Xword	p_memsz;		/* Segment size in memory */
+  Elf64_Xword	p_align;		/* Segment alignment */
+} Elf64_Phdr;
+
+/* Legal values for p_type (segment type).  */
+
+#define	PT_NULL		0		/* Program header table entry unused */
+#define PT_LOAD		1		/* Loadable program segment */
+#define PT_DYNAMIC	2		/* Dynamic linking information */
+#define PT_INTERP	3		/* Program interpreter */
+#define PT_NOTE		4		/* Auxiliary information */
+#define PT_SHLIB	5		/* Reserved */
+#define PT_PHDR		6		/* Entry for header table itself */
+#define PT_TLS		7		/* Thread-local storage segment */
+#define	PT_NUM		8		/* Number of defined types */
+#define PT_LOOS		0x60000000	/* Start of OS-specific */
+#define PT_GNU_EH_FRAME	0x6474e550	/* GCC .eh_frame_hdr segment */
+#define PT_GNU_STACK	0x6474e551	/* Indicates stack executability */
+#define PT_GNU_RELRO	0x6474e552	/* Read-only after relocation */
+#define PT_LOSUNW	0x6ffffffa
+#define PT_SUNWBSS	0x6ffffffa	/* Sun Specific segment */
+#define PT_SUNWSTACK	0x6ffffffb	/* Stack segment */
+#define PT_HISUNW	0x6fffffff
+#define PT_HIOS		0x6fffffff	/* End of OS-specific */
+#define PT_LOPROC	0x70000000	/* Start of processor-specific */
+#define PT_HIPROC	0x7fffffff	/* End of processor-specific */
+
+/* Legal values for p_flags (segment flags).  */
+
+#define PF_X		(1 << 0)	/* Segment is executable */
+#define PF_W		(1 << 1)	/* Segment is writable */
+#define PF_R		(1 << 2)	/* Segment is readable */
+#define PF_MASKOS	0x0ff00000	/* OS-specific */
+#define PF_MASKPROC	0xf0000000	/* Processor-specific */
+
+/* Legal values for note segment descriptor types for core files. */
+
+#define NT_PRSTATUS	1		/* Contains copy of prstatus struct */
+#define NT_FPREGSET	2		/* Contains copy of fpregset struct */
+#define NT_PRPSINFO	3		/* Contains copy of prpsinfo struct */
+#define NT_PRXREG	4		/* Contains copy of prxregset struct */
+#define NT_TASKSTRUCT	4		/* Contains copy of task structure */
+#define NT_PLATFORM	5		/* String from sysinfo(SI_PLATFORM) */
+#define NT_AUXV		6		/* Contains copy of auxv array */
+#define NT_GWINDOWS	7		/* Contains copy of gwindows struct */
+#define NT_ASRS		8		/* Contains copy of asrset struct */
+#define NT_PSTATUS	10		/* Contains copy of pstatus struct */
+#define NT_PSINFO	13		/* Contains copy of psinfo struct */
+#define NT_PRCRED	14		/* Contains copy of prcred struct */
+#define NT_UTSNAME	15		/* Contains copy of utsname struct */
+#define NT_LWPSTATUS	16		/* Contains copy of lwpstatus struct */
+#define NT_LWPSINFO	17		/* Contains copy of lwpinfo struct */
+#define NT_PRFPXREG	20		/* Contains copy of fprxregset struct */
+#define NT_PRXFPREG	0x46e62b7f	/* Contains copy of user_fxsr_struct */
+
+/* Legal values for the note segment descriptor types for object files.  */
+
+#define NT_VERSION	1		/* Contains a version string.  */
+
+
+/* Dynamic section entry.  */
+
+typedef struct
+{
+  Elf32_Sword	d_tag;			/* Dynamic entry type */
+  union
+    {
+      Elf32_Word d_val;			/* Integer value */
+      Elf32_Addr d_ptr;			/* Address value */
+    } d_un;
+} Elf32_Dyn;
+
+typedef struct
+{
+  Elf64_Sxword	d_tag;			/* Dynamic entry type */
+  union
+    {
+      Elf64_Xword d_val;		/* Integer value */
+      Elf64_Addr d_ptr;			/* Address value */
+    } d_un;
+} Elf64_Dyn;
+
+/* Legal values for d_tag (dynamic entry type).  */
+
+#define DT_NULL		0		/* Marks end of dynamic section */
+#define DT_NEEDED	1		/* Name of needed library */
+#define DT_PLTRELSZ	2		/* Size in bytes of PLT relocs */
+#define DT_PLTGOT	3		/* Processor defined value */
+#define DT_HASH		4		/* Address of symbol hash table */
+#define DT_STRTAB	5		/* Address of string table */
+#define DT_SYMTAB	6		/* Address of symbol table */
+#define DT_RELA		7		/* Address of Rela relocs */
+#define DT_RELASZ	8		/* Total size of Rela relocs */
+#define DT_RELAENT	9		/* Size of one Rela reloc */
+#define DT_STRSZ	10		/* Size of string table */
+#define DT_SYMENT	11		/* Size of one symbol table entry */
+#define DT_INIT		12		/* Address of init function */
+#define DT_FINI		13		/* Address of termination function */
+#define DT_SONAME	14		/* Name of shared object */
+#define DT_RPATH	15		/* Library search path (deprecated) */
+#define DT_SYMBOLIC	16		/* Start symbol search here */
+#define DT_REL		17		/* Address of Rel relocs */
+#define DT_RELSZ	18		/* Total size of Rel relocs */
+#define DT_RELENT	19		/* Size of one Rel reloc */
+#define DT_PLTREL	20		/* Type of reloc in PLT */
+#define DT_DEBUG	21		/* For debugging; unspecified */
+#define DT_TEXTREL	22		/* Reloc might modify .text */
+#define DT_JMPREL	23		/* Address of PLT relocs */
+#define	DT_BIND_NOW	24		/* Process relocations of object */
+#define	DT_INIT_ARRAY	25		/* Array with addresses of init fct */
+#define	DT_FINI_ARRAY	26		/* Array with addresses of fini fct */
+#define	DT_INIT_ARRAYSZ	27		/* Size in bytes of DT_INIT_ARRAY */
+#define	DT_FINI_ARRAYSZ	28		/* Size in bytes of DT_FINI_ARRAY */
+#define DT_RUNPATH	29		/* Library search path */
+#define DT_FLAGS	30		/* Flags for the object being loaded */
+#define DT_ENCODING	32		/* Start of encoded range */
+#define DT_PREINIT_ARRAY 32		/* Array with addresses of preinit fct*/
+#define DT_PREINIT_ARRAYSZ 33		/* size in bytes of DT_PREINIT_ARRAY */
+#define	DT_NUM		34		/* Number used */
+#define DT_LOOS		0x6000000d	/* Start of OS-specific */
+#define DT_HIOS		0x6ffff000	/* End of OS-specific */
+#define DT_LOPROC	0x70000000	/* Start of processor-specific */
+#define DT_HIPROC	0x7fffffff	/* End of processor-specific */
+#define	DT_PROCNUM	DT_MIPS_NUM	/* Most used by any processor */
+
+/* DT_* entries which fall between DT_VALRNGHI & DT_VALRNGLO use the
+   Dyn.d_un.d_val field of the Elf*_Dyn structure.  This follows Sun's
+   approach.  */
+#define DT_VALRNGLO	0x6ffffd00
+#define DT_GNU_PRELINKED 0x6ffffdf5	/* Prelinking timestamp */
+#define DT_GNU_CONFLICTSZ 0x6ffffdf6	/* Size of conflict section */
+#define DT_GNU_LIBLISTSZ 0x6ffffdf7	/* Size of library list */
+#define DT_CHECKSUM	0x6ffffdf8
+#define DT_PLTPADSZ	0x6ffffdf9
+#define DT_MOVEENT	0x6ffffdfa
+#define DT_MOVESZ	0x6ffffdfb
+#define DT_FEATURE_1	0x6ffffdfc	/* Feature selection (DTF_*).  */
+#define DT_POSFLAG_1	0x6ffffdfd	/* Flags for DT_* entries, effecting
+					   the following DT_* entry.  */
+#define DT_SYMINSZ	0x6ffffdfe	/* Size of syminfo table (in bytes) */
+#define DT_SYMINENT	0x6ffffdff	/* Entry size of syminfo */
+#define DT_VALRNGHI	0x6ffffdff
+#define DT_VALTAGIDX(tag)	(DT_VALRNGHI - (tag))	/* Reverse order! */
+#define DT_VALNUM 12
+
+/* DT_* entries which fall between DT_ADDRRNGHI & DT_ADDRRNGLO use the
+   Dyn.d_un.d_ptr field of the Elf*_Dyn structure.
+
+   If any adjustment is made to the ELF object after it has been
+   built these entries will need to be adjusted.  */
+#define DT_ADDRRNGLO	0x6ffffe00
+#define DT_GNU_HASH	0x6ffffef5	/* GNU-style hash table.  */
+#define DT_TLSDESC_PLT	0x6ffffef6
+#define DT_TLSDESC_GOT	0x6ffffef7
+#define DT_GNU_CONFLICT	0x6ffffef8	/* Start of conflict section */
+#define DT_GNU_LIBLIST	0x6ffffef9	/* Library list */
+#define DT_CONFIG	0x6ffffefa	/* Configuration information.  */
+#define DT_DEPAUDIT	0x6ffffefb	/* Dependency auditing.  */
+#define DT_AUDIT	0x6ffffefc	/* Object auditing.  */
+#define	DT_PLTPAD	0x6ffffefd	/* PLT padding.  */
+#define	DT_MOVETAB	0x6ffffefe	/* Move table.  */
+#define DT_SYMINFO	0x6ffffeff	/* Syminfo table.  */
+#define DT_ADDRRNGHI	0x6ffffeff
+#define DT_ADDRTAGIDX(tag)	(DT_ADDRRNGHI - (tag))	/* Reverse order! */
+#define DT_ADDRNUM 11
+
+/* The versioning entry types.  The next are defined as part of the
+   GNU extension.  */
+#define DT_VERSYM	0x6ffffff0
+
+#define DT_RELACOUNT	0x6ffffff9
+#define DT_RELCOUNT	0x6ffffffa
+
+/* These were chosen by Sun.  */
+#define DT_FLAGS_1	0x6ffffffb	/* State flags, see DF_1_* below.  */
+#define	DT_VERDEF	0x6ffffffc	/* Address of version definition
+					   table */
+#define	DT_VERDEFNUM	0x6ffffffd	/* Number of version definitions */
+#define	DT_VERNEED	0x6ffffffe	/* Address of table with needed
+					   versions */
+#define	DT_VERNEEDNUM	0x6fffffff	/* Number of needed versions */
+#define DT_VERSIONTAGIDX(tag)	(DT_VERNEEDNUM - (tag))	/* Reverse order! */
+#define DT_VERSIONTAGNUM 16
+
+/* Sun added these machine-independent extensions in the "processor-specific"
+   range.  Be compatible.  */
+#define DT_AUXILIARY    0x7ffffffd      /* Shared object to load before self */
+#define DT_FILTER       0x7fffffff      /* Shared object to get values from */
+#define DT_EXTRATAGIDX(tag)	((Elf32_Word)-((Elf32_Sword) (tag) <<1>>1)-1)
+#define DT_EXTRANUM	3
+
+/* Values of `d_un.d_val' in the DT_FLAGS entry.  */
+#define DF_ORIGIN	0x00000001	/* Object may use DF_ORIGIN */
+#define DF_SYMBOLIC	0x00000002	/* Symbol resolutions starts here */
+#define DF_TEXTREL	0x00000004	/* Object contains text relocations */
+#define DF_BIND_NOW	0x00000008	/* No lazy binding for this object */
+#define DF_STATIC_TLS	0x00000010	/* Module uses the static TLS model */
+
+/* State flags selectable in the `d_un.d_val' element of the DT_FLAGS_1
+   entry in the dynamic section.  */
+#define DF_1_NOW	0x00000001	/* Set RTLD_NOW for this object.  */
+#define DF_1_GLOBAL	0x00000002	/* Set RTLD_GLOBAL for this object.  */
+#define DF_1_GROUP	0x00000004	/* Set RTLD_GROUP for this object.  */
+#define DF_1_NODELETE	0x00000008	/* Set RTLD_NODELETE for this object.*/
+#define DF_1_LOADFLTR	0x00000010	/* Trigger filtee loading at runtime.*/
+#define DF_1_INITFIRST	0x00000020	/* Set RTLD_INITFIRST for this object*/
+#define DF_1_NOOPEN	0x00000040	/* Set RTLD_NOOPEN for this object.  */
+#define DF_1_ORIGIN	0x00000080	/* $ORIGIN must be handled.  */
+#define DF_1_DIRECT	0x00000100	/* Direct binding enabled.  */
+#define DF_1_TRANS	0x00000200
+#define DF_1_INTERPOSE	0x00000400	/* Object is used to interpose.  */
+#define DF_1_NODEFLIB	0x00000800	/* Ignore default lib search path.  */
+#define DF_1_NODUMP	0x00001000	/* Object can't be dldump'ed.  */
+#define DF_1_CONFALT	0x00002000	/* Configuration alternative created.*/
+#define DF_1_ENDFILTEE	0x00004000	/* Filtee terminates filters search. */
+#define	DF_1_DISPRELDNE	0x00008000	/* Disp reloc applied at build time. */
+#define	DF_1_DISPRELPND	0x00010000	/* Disp reloc applied at run-time.  */
+
+/* Flags for the feature selection in DT_FEATURE_1.  */
+#define DTF_1_PARINIT	0x00000001
+#define DTF_1_CONFEXP	0x00000002
+
+/* Flags in the DT_POSFLAG_1 entry effecting only the next DT_* entry.  */
+#define DF_P1_LAZYLOAD	0x00000001	/* Lazyload following object.  */
+#define DF_P1_GROUPPERM	0x00000002	/* Symbols from next object are not
+					   generally available.  */
+
+/* Version definition sections.  */
+
+typedef struct
+{
+  Elf32_Half	vd_version;		/* Version revision */
+  Elf32_Half	vd_flags;		/* Version information */
+  Elf32_Half	vd_ndx;			/* Version Index */
+  Elf32_Half	vd_cnt;			/* Number of associated aux entries */
+  Elf32_Word	vd_hash;		/* Version name hash value */
+  Elf32_Word	vd_aux;			/* Offset in bytes to verdaux array */
+  Elf32_Word	vd_next;		/* Offset in bytes to next verdef
+					   entry */
+} Elf32_Verdef;
+
+typedef struct
+{
+  Elf64_Half	vd_version;		/* Version revision */
+  Elf64_Half	vd_flags;		/* Version information */
+  Elf64_Half	vd_ndx;			/* Version Index */
+  Elf64_Half	vd_cnt;			/* Number of associated aux entries */
+  Elf64_Word	vd_hash;		/* Version name hash value */
+  Elf64_Word	vd_aux;			/* Offset in bytes to verdaux array */
+  Elf64_Word	vd_next;		/* Offset in bytes to next verdef
+					   entry */
+} Elf64_Verdef;
+
+
+/* Legal values for vd_version (version revision).  */
+#define VER_DEF_NONE	0		/* No version */
+#define VER_DEF_CURRENT	1		/* Current version */
+#define VER_DEF_NUM	2		/* Given version number */
+
+/* Legal values for vd_flags (version information flags).  */
+#define VER_FLG_BASE	0x1		/* Version definition of file itself */
+#define VER_FLG_WEAK	0x2		/* Weak version identifier */
+
+/* Versym symbol index values.  */
+#define	VER_NDX_LOCAL		0	/* Symbol is local.  */
+#define	VER_NDX_GLOBAL		1	/* Symbol is global.  */
+#define	VER_NDX_LORESERVE	0xff00	/* Beginning of reserved entries.  */
+#define	VER_NDX_ELIMINATE	0xff01	/* Symbol is to be eliminated.  */
+
+/* Auxialiary version information.  */
+
+typedef struct
+{
+  Elf32_Word	vda_name;		/* Version or dependency names */
+  Elf32_Word	vda_next;		/* Offset in bytes to next verdaux
+					   entry */
+} Elf32_Verdaux;
+
+typedef struct
+{
+  Elf64_Word	vda_name;		/* Version or dependency names */
+  Elf64_Word	vda_next;		/* Offset in bytes to next verdaux
+					   entry */
+} Elf64_Verdaux;
+
+
+/* Version dependency section.  */
+
+typedef struct
+{
+  Elf32_Half	vn_version;		/* Version of structure */
+  Elf32_Half	vn_cnt;			/* Number of associated aux entries */
+  Elf32_Word	vn_file;		/* Offset of filename for this
+					   dependency */
+  Elf32_Word	vn_aux;			/* Offset in bytes to vernaux array */
+  Elf32_Word	vn_next;		/* Offset in bytes to next verneed
+					   entry */
+} Elf32_Verneed;
+
+typedef struct
+{
+  Elf64_Half	vn_version;		/* Version of structure */
+  Elf64_Half	vn_cnt;			/* Number of associated aux entries */
+  Elf64_Word	vn_file;		/* Offset of filename for this
+					   dependency */
+  Elf64_Word	vn_aux;			/* Offset in bytes to vernaux array */
+  Elf64_Word	vn_next;		/* Offset in bytes to next verneed
+					   entry */
+} Elf64_Verneed;
+
+
+/* Legal values for vn_version (version revision).  */
+#define VER_NEED_NONE	 0		/* No version */
+#define VER_NEED_CURRENT 1		/* Current version */
+#define VER_NEED_NUM	 2		/* Given version number */
+
+/* Auxiliary needed version information.  */
+
+typedef struct
+{
+  Elf32_Word	vna_hash;		/* Hash value of dependency name */
+  Elf32_Half	vna_flags;		/* Dependency specific information */
+  Elf32_Half	vna_other;		/* Unused */
+  Elf32_Word	vna_name;		/* Dependency name string offset */
+  Elf32_Word	vna_next;		/* Offset in bytes to next vernaux
+					   entry */
+} Elf32_Vernaux;
+
+typedef struct
+{
+  Elf64_Word	vna_hash;		/* Hash value of dependency name */
+  Elf64_Half	vna_flags;		/* Dependency specific information */
+  Elf64_Half	vna_other;		/* Unused */
+  Elf64_Word	vna_name;		/* Dependency name string offset */
+  Elf64_Word	vna_next;		/* Offset in bytes to next vernaux
+					   entry */
+} Elf64_Vernaux;
+
+
+/* Legal values for vna_flags.  */
+#define VER_FLG_WEAK	0x2		/* Weak version identifier */
+
+
+/* Auxiliary vector.  */
+
+/* This vector is normally only used by the program interpreter.  The
+   usual definition in an ABI supplement uses the name auxv_t.  The
+   vector is not usually defined in a standard <elf.h> file, but it
+   can't hurt.  We rename it to avoid conflicts.  The sizes of these
+   types are an arrangement between the exec server and the program
+   interpreter, so we don't fully specify them here.  */
+
+typedef struct
+{
+  uint32_t a_type;		/* Entry type */
+  union
+    {
+      uint32_t a_val;		/* Integer value */
+      /* We use to have pointer elements added here.  We cannot do that,
+	 though, since it does not work when using 32-bit definitions
+	 on 64-bit platforms and vice versa.  */
+    } a_un;
+} Elf32_auxv_t;
+
+typedef struct
+{
+  uint64_t a_type;		/* Entry type */
+  union
+    {
+      uint64_t a_val;		/* Integer value */
+      /* We use to have pointer elements added here.  We cannot do that,
+	 though, since it does not work when using 32-bit definitions
+	 on 64-bit platforms and vice versa.  */
+    } a_un;
+} Elf64_auxv_t;
+
+/* Legal values for a_type (entry type).  */
+
+#define AT_NULL		0		/* End of vector */
+#define AT_IGNORE	1		/* Entry should be ignored */
+#define AT_EXECFD	2		/* File descriptor of program */
+#define AT_PHDR		3		/* Program headers for program */
+#define AT_PHENT	4		/* Size of program header entry */
+#define AT_PHNUM	5		/* Number of program headers */
+#define AT_PAGESZ	6		/* System page size */
+#define AT_BASE		7		/* Base address of interpreter */
+#define AT_FLAGS	8		/* Flags */
+#define AT_ENTRY	9		/* Entry point of program */
+#define AT_NOTELF	10		/* Program is not ELF */
+#define AT_UID		11		/* Real uid */
+#define AT_EUID		12		/* Effective uid */
+#define AT_GID		13		/* Real gid */
+#define AT_EGID		14		/* Effective gid */
+#define AT_CLKTCK	17		/* Frequency of times() */
+
+/* Some more special a_type values describing the hardware.  */
+#define AT_PLATFORM	15		/* String identifying platform.  */
+#define AT_HWCAP	16		/* Machine dependent hints about
+					   processor capabilities.  */
+
+/* This entry gives some information about the FPU initialization
+   performed by the kernel.  */
+#define AT_FPUCW	18		/* Used FPU control word.  */
+
+/* Cache block sizes.  */
+#define AT_DCACHEBSIZE	19		/* Data cache block size.  */
+#define AT_ICACHEBSIZE	20		/* Instruction cache block size.  */
+#define AT_UCACHEBSIZE	21		/* Unified cache block size.  */
+
+/* A special ignored value for PPC, used by the kernel to control the
+   interpretation of the AUXV. Must be > 16.  */
+#define AT_IGNOREPPC	22		/* Entry should be ignored.  */
+
+#define	AT_SECURE	23		/* Boolean, was exec setuid-like?  */
+
+/* Pointer to the global system page used for system calls and other
+   nice things.  */
+#define AT_SYSINFO	32
+#define AT_SYSINFO_EHDR	33
+
+/* Shapes of the caches.  Bits 0-3 contains associativity; bits 4-7 contains
+   log2 of line size; mask those to get cache size.  */
+#define AT_L1I_CACHESHAPE	34
+#define AT_L1D_CACHESHAPE	35
+#define AT_L2_CACHESHAPE	36
+#define AT_L3_CACHESHAPE	37
+
+/* Note section contents.  Each entry in the note section begins with
+   a header of a fixed form.  */
+
+typedef struct
+{
+  Elf32_Word n_namesz;			/* Length of the note's name.  */
+  Elf32_Word n_descsz;			/* Length of the note's descriptor.  */
+  Elf32_Word n_type;			/* Type of the note.  */
+} Elf32_Nhdr;
+
+typedef struct
+{
+  Elf64_Word n_namesz;			/* Length of the note's name.  */
+  Elf64_Word n_descsz;			/* Length of the note's descriptor.  */
+  Elf64_Word n_type;			/* Type of the note.  */
+} Elf64_Nhdr;
+
+/* Known names of notes.  */
+
+/* Solaris entries in the note section have this name.  */
+#define ELF_NOTE_SOLARIS	"SUNW Solaris"
+
+/* Note entries for GNU systems have this name.  */
+#define ELF_NOTE_GNU		"GNU"
+
+
+/* Defined types of notes for Solaris.  */
+
+/* Value of descriptor (one word) is desired pagesize for the binary.  */
+#define ELF_NOTE_PAGESIZE_HINT	1
+
+
+/* Defined note types for GNU systems.  */
+
+/* ABI information.  The descriptor consists of words:
+   word 0: OS descriptor
+   word 1: major version of the ABI
+   word 2: minor version of the ABI
+   word 3: subminor version of the ABI
+*/
+#define NT_GNU_ABI_TAG	1
+#define ELF_NOTE_ABI	NT_GNU_ABI_TAG /* Old name.  */
+
+/* Known OSes.  These values can appear in word 0 of an
+   NT_GNU_ABI_TAG note section entry.  */
+#define ELF_NOTE_OS_LINUX	0
+#define ELF_NOTE_OS_GNU		1
+#define ELF_NOTE_OS_SOLARIS2	2
+#define ELF_NOTE_OS_FREEBSD	3
+
+/* Synthetic hwcap information.  The descriptor begins with two words:
+   word 0: number of entries
+   word 1: bitmask of enabled entries
+   Then follow variable-length entries, one byte followed by a
+   '\0'-terminated hwcap name string.  The byte gives the bit
+   number to test if enabled, (1U << bit) & bitmask.  */
+#define NT_GNU_HWCAP	2
+
+/* Build ID bits as generated by ld --build-id.
+   The descriptor consists of any nonzero number of bytes.  */
+#define NT_GNU_BUILD_ID	3
+
+
+/* Move records.  */
+typedef struct
+{
+  Elf32_Xword m_value;		/* Symbol value.  */
+  Elf32_Word m_info;		/* Size and index.  */
+  Elf32_Word m_poffset;		/* Symbol offset.  */
+  Elf32_Half m_repeat;		/* Repeat count.  */
+  Elf32_Half m_stride;		/* Stride info.  */
+} Elf32_Move;
+
+typedef struct
+{
+  Elf64_Xword m_value;		/* Symbol value.  */
+  Elf64_Xword m_info;		/* Size and index.  */
+  Elf64_Xword m_poffset;	/* Symbol offset.  */
+  Elf64_Half m_repeat;		/* Repeat count.  */
+  Elf64_Half m_stride;		/* Stride info.  */
+} Elf64_Move;
+
+/* Macro to construct move records.  */
+#define ELF32_M_SYM(info)	((info) >> 8)
+#define ELF32_M_SIZE(info)	((unsigned char) (info))
+#define ELF32_M_INFO(sym, size)	(((sym) << 8) + (unsigned char) (size))
+
+#define ELF64_M_SYM(info)	ELF32_M_SYM (info)
+#define ELF64_M_SIZE(info)	ELF32_M_SIZE (info)
+#define ELF64_M_INFO(sym, size)	ELF32_M_INFO (sym, size)
+
+
+/* Motorola 68k specific definitions.  */
+
+/* Values for Elf32_Ehdr.e_flags.  */
+#define EF_CPU32	0x00810000
+
+/* m68k relocs.  */
+
+#define R_68K_NONE	0		/* No reloc */
+#define R_68K_32	1		/* Direct 32 bit  */
+#define R_68K_16	2		/* Direct 16 bit  */
+#define R_68K_8		3		/* Direct 8 bit  */
+#define R_68K_PC32	4		/* PC relative 32 bit */
+#define R_68K_PC16	5		/* PC relative 16 bit */
+#define R_68K_PC8	6		/* PC relative 8 bit */
+#define R_68K_GOT32	7		/* 32 bit PC relative GOT entry */
+#define R_68K_GOT16	8		/* 16 bit PC relative GOT entry */
+#define R_68K_GOT8	9		/* 8 bit PC relative GOT entry */
+#define R_68K_GOT32O	10		/* 32 bit GOT offset */
+#define R_68K_GOT16O	11		/* 16 bit GOT offset */
+#define R_68K_GOT8O	12		/* 8 bit GOT offset */
+#define R_68K_PLT32	13		/* 32 bit PC relative PLT address */
+#define R_68K_PLT16	14		/* 16 bit PC relative PLT address */
+#define R_68K_PLT8	15		/* 8 bit PC relative PLT address */
+#define R_68K_PLT32O	16		/* 32 bit PLT offset */
+#define R_68K_PLT16O	17		/* 16 bit PLT offset */
+#define R_68K_PLT8O	18		/* 8 bit PLT offset */
+#define R_68K_COPY	19		/* Copy symbol at runtime */
+#define R_68K_GLOB_DAT	20		/* Create GOT entry */
+#define R_68K_JMP_SLOT	21		/* Create PLT entry */
+#define R_68K_RELATIVE	22		/* Adjust by program base */
+/* Keep this the last entry.  */
+#define R_68K_NUM	23
+
+/* Intel 80386 specific definitions.  */
+
+/* i386 relocs.  */
+
+#define R_386_NONE	   0		/* No reloc */
+#define R_386_32	   1		/* Direct 32 bit  */
+#define R_386_PC32	   2		/* PC relative 32 bit */
+#define R_386_GOT32	   3		/* 32 bit GOT entry */
+#define R_386_PLT32	   4		/* 32 bit PLT address */
+#define R_386_COPY	   5		/* Copy symbol at runtime */
+#define R_386_GLOB_DAT	   6		/* Create GOT entry */
+#define R_386_JMP_SLOT	   7		/* Create PLT entry */
+#define R_386_RELATIVE	   8		/* Adjust by program base */
+#define R_386_GOTOFF	   9		/* 32 bit offset to GOT */
+#define R_386_GOTPC	   10		/* 32 bit PC relative offset to GOT */
+#define R_386_32PLT	   11
+#define R_386_TLS_TPOFF	   14		/* Offset in static TLS block */
+#define R_386_TLS_IE	   15		/* Address of GOT entry for static TLS
+					   block offset */
+#define R_386_TLS_GOTIE	   16		/* GOT entry for static TLS block
+					   offset */
+#define R_386_TLS_LE	   17		/* Offset relative to static TLS
+					   block */
+#define R_386_TLS_GD	   18		/* Direct 32 bit for GNU version of
+					   general dynamic thread local data */
+#define R_386_TLS_LDM	   19		/* Direct 32 bit for GNU version of
+					   local dynamic thread local data
+					   in LE code */
+#define R_386_16	   20
+#define R_386_PC16	   21
+#define R_386_8		   22
+#define R_386_PC8	   23
+#define R_386_TLS_GD_32	   24		/* Direct 32 bit for general dynamic
+					   thread local data */
+#define R_386_TLS_GD_PUSH  25		/* Tag for pushl in GD TLS code */
+#define R_386_TLS_GD_CALL  26		/* Relocation for call to
+					   __tls_get_addr() */
+#define R_386_TLS_GD_POP   27		/* Tag for popl in GD TLS code */
+#define R_386_TLS_LDM_32   28		/* Direct 32 bit for local dynamic
+					   thread local data in LE code */
+#define R_386_TLS_LDM_PUSH 29		/* Tag for pushl in LDM TLS code */
+#define R_386_TLS_LDM_CALL 30		/* Relocation for call to
+					   __tls_get_addr() in LDM code */
+#define R_386_TLS_LDM_POP  31		/* Tag for popl in LDM TLS code */
+#define R_386_TLS_LDO_32   32		/* Offset relative to TLS block */
+#define R_386_TLS_IE_32	   33		/* GOT entry for negated static TLS
+					   block offset */
+#define R_386_TLS_LE_32	   34		/* Negated offset relative to static
+					   TLS block */
+#define R_386_TLS_DTPMOD32 35		/* ID of module containing symbol */
+#define R_386_TLS_DTPOFF32 36		/* Offset in TLS block */
+#define R_386_TLS_TPOFF32  37		/* Negated offset in static TLS block */
+/* Keep this the last entry.  */
+#define R_386_NUM	   38
+
+/* AMD64 specific definitions. */
+#define	R_AMD64_NONE		0	/* relocation types */
+#define	R_AMD64_64		1
+#define	R_AMD64_PC32		2
+#define	R_AMD64_GOT32		3
+#define	R_AMD64_PLT32		4
+#define	R_AMD64_COPY		5
+#define	R_AMD64_GLOB_DAT	6
+#define	R_AMD64_JUMP_SLOT	7
+#define	R_AMD64_RELATIVE	8
+#define	R_AMD64_GOTPCREL	9
+#define	R_AMD64_32		10
+#define	R_AMD64_32S		11
+#define	R_AMD64_16		12
+#define	R_AMD64_PC16		13
+#define	R_AMD64_8		14
+#define	R_AMD64_PC8		15
+#define	R_AMD64_DTPMOD64	16
+#define	R_AMD64_DTPOFF64	17
+#define	R_AMD64_TPOFF64		18
+#define	R_AMD64_TLSGD		19
+#define	R_AMD64_TLSLD		20
+#define	R_AMD64_DTPOFF32	21
+#define	R_AMD64_GOTTPOFF	22
+#define	R_AMD64_TPOFF32		23
+#define	R_AMD64_PC64		24
+#define	R_AMD64_GOTOFF64	25
+#define	R_AMD64_GOTPC32		26
+#define	R_AMD64_GOT64		27	/* reserved for future expansion */
+#define	R_AMD64_GOTPCREL64	28	/* reserved for future expansion */
+#define	R_AMD64_GOTPC64		29	/* reserved for future expansion */
+#define	R_AMD64_GOTPLT64	30	/* reserved for future expansion */
+#define	R_AMD64_PLTOFF64	31	/* reserved for future expansion */
+#define	R_AMD64_SIZE32		32
+#define	R_AMD64_SIZE64		33
+#define	R_AMD64_NUM	34
+
+/* SUN SPARC specific definitions.  */
+
+/* Legal values for ST_TYPE subfield of st_info (symbol type).  */
+
+#define STT_SPARC_REGISTER	13	/* Global register reserved to app. */
+
+/* Values for Elf64_Ehdr.e_flags.  */
+
+#define EF_SPARCV9_MM		3
+#define EF_SPARCV9_TSO		0
+#define EF_SPARCV9_PSO		1
+#define EF_SPARCV9_RMO		2
+#define EF_SPARC_LEDATA		0x800000 /* little endian data */
+#define EF_SPARC_EXT_MASK	0xFFFF00
+#define EF_SPARC_32PLUS		0x000100 /* generic V8+ features */
+#define EF_SPARC_SUN_US1	0x000200 /* Sun UltraSPARC1 extensions */
+#define EF_SPARC_HAL_R1		0x000400 /* HAL R1 extensions */
+#define EF_SPARC_SUN_US3	0x000800 /* Sun UltraSPARCIII extensions */
+
+/* SPARC relocs.  */
+
+#define R_SPARC_NONE		0	/* No reloc */
+#define R_SPARC_8		1	/* Direct 8 bit */
+#define R_SPARC_16		2	/* Direct 16 bit */
+#define R_SPARC_32		3	/* Direct 32 bit */
+#define R_SPARC_DISP8		4	/* PC relative 8 bit */
+#define R_SPARC_DISP16		5	/* PC relative 16 bit */
+#define R_SPARC_DISP32		6	/* PC relative 32 bit */
+#define R_SPARC_WDISP30		7	/* PC relative 30 bit shifted */
+#define R_SPARC_WDISP22		8	/* PC relative 22 bit shifted */
+#define R_SPARC_HI22		9	/* High 22 bit */
+#define R_SPARC_22		10	/* Direct 22 bit */
+#define R_SPARC_13		11	/* Direct 13 bit */
+#define R_SPARC_LO10		12	/* Truncated 10 bit */
+#define R_SPARC_GOT10		13	/* Truncated 10 bit GOT entry */
+#define R_SPARC_GOT13		14	/* 13 bit GOT entry */
+#define R_SPARC_GOT22		15	/* 22 bit GOT entry shifted */
+#define R_SPARC_PC10		16	/* PC relative 10 bit truncated */
+#define R_SPARC_PC22		17	/* PC relative 22 bit shifted */
+#define R_SPARC_WPLT30		18	/* 30 bit PC relative PLT address */
+#define R_SPARC_COPY		19	/* Copy symbol at runtime */
+#define R_SPARC_GLOB_DAT	20	/* Create GOT entry */
+#define R_SPARC_JMP_SLOT	21	/* Create PLT entry */
+#define R_SPARC_RELATIVE	22	/* Adjust by program base */
+#define R_SPARC_UA32		23	/* Direct 32 bit unaligned */
+
+/* Additional Sparc64 relocs.  */
+
+#define R_SPARC_PLT32		24	/* Direct 32 bit ref to PLT entry */
+#define R_SPARC_HIPLT22		25	/* High 22 bit PLT entry */
+#define R_SPARC_LOPLT10		26	/* Truncated 10 bit PLT entry */
+#define R_SPARC_PCPLT32		27	/* PC rel 32 bit ref to PLT entry */
+#define R_SPARC_PCPLT22		28	/* PC rel high 22 bit PLT entry */
+#define R_SPARC_PCPLT10		29	/* PC rel trunc 10 bit PLT entry */
+#define R_SPARC_10		30	/* Direct 10 bit */
+#define R_SPARC_11		31	/* Direct 11 bit */
+#define R_SPARC_64		32	/* Direct 64 bit */
+#define R_SPARC_OLO10		33	/* 10bit with secondary 13bit addend */
+#define R_SPARC_HH22		34	/* Top 22 bits of direct 64 bit */
+#define R_SPARC_HM10		35	/* High middle 10 bits of ... */
+#define R_SPARC_LM22		36	/* Low middle 22 bits of ... */
+#define R_SPARC_PC_HH22		37	/* Top 22 bits of pc rel 64 bit */
+#define R_SPARC_PC_HM10		38	/* High middle 10 bit of ... */
+#define R_SPARC_PC_LM22		39	/* Low miggle 22 bits of ... */
+#define R_SPARC_WDISP16		40	/* PC relative 16 bit shifted */
+#define R_SPARC_WDISP19		41	/* PC relative 19 bit shifted */
+#define R_SPARC_7		43	/* Direct 7 bit */
+#define R_SPARC_5		44	/* Direct 5 bit */
+#define R_SPARC_6		45	/* Direct 6 bit */
+#define R_SPARC_DISP64		46	/* PC relative 64 bit */
+#define R_SPARC_PLT64		47	/* Direct 64 bit ref to PLT entry */
+#define R_SPARC_HIX22		48	/* High 22 bit complemented */
+#define R_SPARC_LOX10		49	/* Truncated 11 bit complemented */
+#define R_SPARC_H44		50	/* Direct high 12 of 44 bit */
+#define R_SPARC_M44		51	/* Direct mid 22 of 44 bit */
+#define R_SPARC_L44		52	/* Direct low 10 of 44 bit */
+#define R_SPARC_REGISTER	53	/* Global register usage */
+#define R_SPARC_UA64		54	/* Direct 64 bit unaligned */
+#define R_SPARC_UA16		55	/* Direct 16 bit unaligned */
+#define R_SPARC_TLS_GD_HI22	56
+#define R_SPARC_TLS_GD_LO10	57
+#define R_SPARC_TLS_GD_ADD	58
+#define R_SPARC_TLS_GD_CALL	59
+#define R_SPARC_TLS_LDM_HI22	60
+#define R_SPARC_TLS_LDM_LO10	61
+#define R_SPARC_TLS_LDM_ADD	62
+#define R_SPARC_TLS_LDM_CALL	63
+#define R_SPARC_TLS_LDO_HIX22	64
+#define R_SPARC_TLS_LDO_LOX10	65
+#define R_SPARC_TLS_LDO_ADD	66
+#define R_SPARC_TLS_IE_HI22	67
+#define R_SPARC_TLS_IE_LO10	68
+#define R_SPARC_TLS_IE_LD	69
+#define R_SPARC_TLS_IE_LDX	70
+#define R_SPARC_TLS_IE_ADD	71
+#define R_SPARC_TLS_LE_HIX22	72
+#define R_SPARC_TLS_LE_LOX10	73
+#define R_SPARC_TLS_DTPMOD32	74
+#define R_SPARC_TLS_DTPMOD64	75
+#define R_SPARC_TLS_DTPOFF32	76
+#define R_SPARC_TLS_DTPOFF64	77
+#define R_SPARC_TLS_TPOFF32	78
+#define R_SPARC_TLS_TPOFF64	79
+/* Keep this the last entry.  */
+#define R_SPARC_NUM		80
+
+/* For Sparc64, legal values for d_tag of Elf64_Dyn.  */
+
+#define DT_SPARC_REGISTER 0x70000001
+#define DT_SPARC_NUM	2
+
+/* Bits present in AT_HWCAP on SPARC.  */
+
+#define HWCAP_SPARC_FLUSH	1	/* The CPU supports flush insn.  */
+#define HWCAP_SPARC_STBAR	2
+#define HWCAP_SPARC_SWAP	4
+#define HWCAP_SPARC_MULDIV	8
+#define HWCAP_SPARC_V9		16	/* The CPU is v9, so v8plus is ok.  */
+#define HWCAP_SPARC_ULTRA3	32
+#define HWCAP_SPARC_BLKINIT	64	/* Sun4v with block-init/load-twin.  */
+
+/* MIPS R3000 specific definitions.  */
+
+/* Legal values for e_flags field of Elf32_Ehdr.  */
+
+#define EF_MIPS_NOREORDER   1		/* A .noreorder directive was used */
+#define EF_MIPS_PIC	    2		/* Contains PIC code */
+#define EF_MIPS_CPIC	    4		/* Uses PIC calling sequence */
+#define EF_MIPS_XGOT	    8
+#define EF_MIPS_64BIT_WHIRL 16
+#define EF_MIPS_ABI2	    32
+#define EF_MIPS_ABI_ON32    64
+#define EF_MIPS_ARCH	    0xf0000000	/* MIPS architecture level */
+
+/* Legal values for MIPS architecture level.  */
+
+#define EF_MIPS_ARCH_1	    0x00000000	/* -mips1 code.  */
+#define EF_MIPS_ARCH_2	    0x10000000	/* -mips2 code.  */
+#define EF_MIPS_ARCH_3	    0x20000000	/* -mips3 code.  */
+#define EF_MIPS_ARCH_4	    0x30000000	/* -mips4 code.  */
+#define EF_MIPS_ARCH_5	    0x40000000	/* -mips5 code.  */
+#define EF_MIPS_ARCH_32	    0x60000000	/* MIPS32 code.  */
+#define EF_MIPS_ARCH_64	    0x70000000	/* MIPS64 code.  */
+
+/* The following are non-official names and should not be used.  */
+
+#define E_MIPS_ARCH_1	  0x00000000	/* -mips1 code.  */
+#define E_MIPS_ARCH_2	  0x10000000	/* -mips2 code.  */
+#define E_MIPS_ARCH_3	  0x20000000	/* -mips3 code.  */
+#define E_MIPS_ARCH_4	  0x30000000	/* -mips4 code.  */
+#define E_MIPS_ARCH_5	  0x40000000	/* -mips5 code.  */
+#define E_MIPS_ARCH_32	  0x60000000	/* MIPS32 code.  */
+#define E_MIPS_ARCH_64	  0x70000000	/* MIPS64 code.  */
+
+/* Special section indices.  */
+
+#define SHN_MIPS_ACOMMON    0xff00	/* Allocated common symbols */
+#define SHN_MIPS_TEXT	    0xff01	/* Allocated test symbols.  */
+#define SHN_MIPS_DATA	    0xff02	/* Allocated data symbols.  */
+#define SHN_MIPS_SCOMMON    0xff03	/* Small common symbols */
+#define SHN_MIPS_SUNDEFINED 0xff04	/* Small undefined symbols */
+
+/* Legal values for sh_type field of Elf32_Shdr.  */
+
+#define SHT_MIPS_LIBLIST       0x70000000 /* Shared objects used in link */
+#define SHT_MIPS_MSYM	       0x70000001
+#define SHT_MIPS_CONFLICT      0x70000002 /* Conflicting symbols */
+#define SHT_MIPS_GPTAB	       0x70000003 /* Global data area sizes */
+#define SHT_MIPS_UCODE	       0x70000004 /* Reserved for SGI/MIPS compilers */
+#define SHT_MIPS_DEBUG	       0x70000005 /* MIPS ECOFF debugging information*/
+#define SHT_MIPS_REGINFO       0x70000006 /* Register usage information */
+#define SHT_MIPS_PACKAGE       0x70000007
+#define SHT_MIPS_PACKSYM       0x70000008
+#define SHT_MIPS_RELD	       0x70000009
+#define SHT_MIPS_IFACE         0x7000000b
+#define SHT_MIPS_CONTENT       0x7000000c
+#define SHT_MIPS_OPTIONS       0x7000000d /* Miscellaneous options.  */
+#define SHT_MIPS_SHDR	       0x70000010
+#define SHT_MIPS_FDESC	       0x70000011
+#define SHT_MIPS_EXTSYM	       0x70000012
+#define SHT_MIPS_DENSE	       0x70000013
+#define SHT_MIPS_PDESC	       0x70000014
+#define SHT_MIPS_LOCSYM	       0x70000015
+#define SHT_MIPS_AUXSYM	       0x70000016
+#define SHT_MIPS_OPTSYM	       0x70000017
+#define SHT_MIPS_LOCSTR	       0x70000018
+#define SHT_MIPS_LINE	       0x70000019
+#define SHT_MIPS_RFDESC	       0x7000001a
+#define SHT_MIPS_DELTASYM      0x7000001b
+#define SHT_MIPS_DELTAINST     0x7000001c
+#define SHT_MIPS_DELTACLASS    0x7000001d
+#define SHT_MIPS_DWARF         0x7000001e /* DWARF debugging information.  */
+#define SHT_MIPS_DELTADECL     0x7000001f
+#define SHT_MIPS_SYMBOL_LIB    0x70000020
+#define SHT_MIPS_EVENTS	       0x70000021 /* Event section.  */
+#define SHT_MIPS_TRANSLATE     0x70000022
+#define SHT_MIPS_PIXIE	       0x70000023
+#define SHT_MIPS_XLATE	       0x70000024
+#define SHT_MIPS_XLATE_DEBUG   0x70000025
+#define SHT_MIPS_WHIRL	       0x70000026
+#define SHT_MIPS_EH_REGION     0x70000027
+#define SHT_MIPS_XLATE_OLD     0x70000028
+#define SHT_MIPS_PDR_EXCEPTION 0x70000029
+
+/* Legal values for sh_flags field of Elf32_Shdr.  */
+
+#define SHF_MIPS_GPREL	 0x10000000	/* Must be part of global data area */
+#define SHF_MIPS_MERGE	 0x20000000
+#define SHF_MIPS_ADDR	 0x40000000
+#define SHF_MIPS_STRINGS 0x80000000
+#define SHF_MIPS_NOSTRIP 0x08000000
+#define SHF_MIPS_LOCAL	 0x04000000
+#define SHF_MIPS_NAMES	 0x02000000
+#define SHF_MIPS_NODUPE	 0x01000000
+
+
+/* Symbol tables.  */
+
+/* MIPS specific values for `st_other'.  */
+#define STO_MIPS_DEFAULT		0x0
+#define STO_MIPS_INTERNAL		0x1
+#define STO_MIPS_HIDDEN			0x2
+#define STO_MIPS_PROTECTED		0x3
+#define STO_MIPS_SC_ALIGN_UNUSED	0xff
+
+/* MIPS specific values for `st_info'.  */
+#define STB_MIPS_SPLIT_COMMON		13
+
+/* Entries found in sections of type SHT_MIPS_GPTAB.  */
+
+typedef union
+{
+  struct
+    {
+      Elf32_Word gt_current_g_value;	/* -G value used for compilation */
+      Elf32_Word gt_unused;		/* Not used */
+    } gt_header;			/* First entry in section */
+  struct
+    {
+      Elf32_Word gt_g_value;		/* If this value were used for -G */
+      Elf32_Word gt_bytes;		/* This many bytes would be used */
+    } gt_entry;				/* Subsequent entries in section */
+} Elf32_gptab;
+
+/* Entry found in sections of type SHT_MIPS_REGINFO.  */
+
+typedef struct
+{
+  Elf32_Word	ri_gprmask;		/* General registers used */
+  Elf32_Word	ri_cprmask[4];		/* Coprocessor registers used */
+  Elf32_Sword	ri_gp_value;		/* $gp register value */
+} Elf32_RegInfo;
+
+/* Entries found in sections of type SHT_MIPS_OPTIONS.  */
+
+typedef struct
+{
+  unsigned char kind;		/* Determines interpretation of the
+				   variable part of descriptor.  */
+  unsigned char size;		/* Size of descriptor, including header.  */
+  Elf32_Section section;	/* Section header index of section affected,
+				   0 for global options.  */
+  Elf32_Word info;		/* Kind-specific information.  */
+} Elf_Options;
+
+/* Values for `kind' field in Elf_Options.  */
+
+#define ODK_NULL	0	/* Undefined.  */
+#define ODK_REGINFO	1	/* Register usage information.  */
+#define ODK_EXCEPTIONS	2	/* Exception processing options.  */
+#define ODK_PAD		3	/* Section padding options.  */
+#define ODK_HWPATCH	4	/* Hardware workarounds performed */
+#define ODK_FILL	5	/* record the fill value used by the linker. */
+#define ODK_TAGS	6	/* reserve space for desktop tools to write. */
+#define ODK_HWAND	7	/* HW workarounds.  'AND' bits when merging. */
+#define ODK_HWOR	8	/* HW workarounds.  'OR' bits when merging.  */
+
+/* Values for `info' in Elf_Options for ODK_EXCEPTIONS entries.  */
+
+#define OEX_FPU_MIN	0x1f	/* FPE's which MUST be enabled.  */
+#define OEX_FPU_MAX	0x1f00	/* FPE's which MAY be enabled.  */
+#define OEX_PAGE0	0x10000	/* page zero must be mapped.  */
+#define OEX_SMM		0x20000	/* Force sequential memory mode?  */
+#define OEX_FPDBUG	0x40000	/* Force floating point debug mode?  */
+#define OEX_PRECISEFP	OEX_FPDBUG
+#define OEX_DISMISS	0x80000	/* Dismiss invalid address faults?  */
+
+#define OEX_FPU_INVAL	0x10
+#define OEX_FPU_DIV0	0x08
+#define OEX_FPU_OFLO	0x04
+#define OEX_FPU_UFLO	0x02
+#define OEX_FPU_INEX	0x01
+
+/* Masks for `info' in Elf_Options for an ODK_HWPATCH entry.  */
+
+#define OHW_R4KEOP	0x1	/* R4000 end-of-page patch.  */
+#define OHW_R8KPFETCH	0x2	/* may need R8000 prefetch patch.  */
+#define OHW_R5KEOP	0x4	/* R5000 end-of-page patch.  */
+#define OHW_R5KCVTL	0x8	/* R5000 cvt.[ds].l bug.  clean=1.  */
+
+#define OPAD_PREFIX	0x1
+#define OPAD_POSTFIX	0x2
+#define OPAD_SYMBOL	0x4
+
+/* Entry found in `.options' section.  */
+
+typedef struct
+{
+  Elf32_Word hwp_flags1;	/* Extra flags.  */
+  Elf32_Word hwp_flags2;	/* Extra flags.  */
+} Elf_Options_Hw;
+
+/* Masks for `info' in ElfOptions for ODK_HWAND and ODK_HWOR entries.  */
+
+#define OHWA0_R4KEOP_CHECKED	0x00000001
+#define OHWA1_R4KEOP_CLEAN	0x00000002
+
+/* MIPS relocs.  */
+
+#define R_MIPS_NONE		0	/* No reloc */
+#define R_MIPS_16		1	/* Direct 16 bit */
+#define R_MIPS_32		2	/* Direct 32 bit */
+#define R_MIPS_REL32		3	/* PC relative 32 bit */
+#define R_MIPS_26		4	/* Direct 26 bit shifted */
+#define R_MIPS_HI16		5	/* High 16 bit */
+#define R_MIPS_LO16		6	/* Low 16 bit */
+#define R_MIPS_GPREL16		7	/* GP relative 16 bit */
+#define R_MIPS_LITERAL		8	/* 16 bit literal entry */
+#define R_MIPS_GOT16		9	/* 16 bit GOT entry */
+#define R_MIPS_PC16		10	/* PC relative 16 bit */
+#define R_MIPS_CALL16		11	/* 16 bit GOT entry for function */
+#define R_MIPS_GPREL32		12	/* GP relative 32 bit */
+
+#define R_MIPS_SHIFT5		16
+#define R_MIPS_SHIFT6		17
+#define R_MIPS_64		18
+#define R_MIPS_GOT_DISP		19
+#define R_MIPS_GOT_PAGE		20
+#define R_MIPS_GOT_OFST		21
+#define R_MIPS_GOT_HI16		22
+#define R_MIPS_GOT_LO16		23
+#define R_MIPS_SUB		24
+#define R_MIPS_INSERT_A		25
+#define R_MIPS_INSERT_B		26
+#define R_MIPS_DELETE		27
+#define R_MIPS_HIGHER		28
+#define R_MIPS_HIGHEST		29
+#define R_MIPS_CALL_HI16	30
+#define R_MIPS_CALL_LO16	31
+#define R_MIPS_SCN_DISP		32
+#define R_MIPS_REL16		33
+#define R_MIPS_ADD_IMMEDIATE	34
+#define R_MIPS_PJUMP		35
+#define R_MIPS_RELGOT		36
+#define R_MIPS_JALR		37
+#define R_MIPS_TLS_DTPMOD32	38	/* Module number 32 bit */
+#define R_MIPS_TLS_DTPREL32	39	/* Module-relative offset 32 bit */
+#define R_MIPS_TLS_DTPMOD64	40	/* Module number 64 bit */
+#define R_MIPS_TLS_DTPREL64	41	/* Module-relative offset 64 bit */
+#define R_MIPS_TLS_GD		42	/* 16 bit GOT offset for GD */
+#define R_MIPS_TLS_LDM		43	/* 16 bit GOT offset for LDM */
+#define R_MIPS_TLS_DTPREL_HI16	44	/* Module-relative offset, high 16 bits */
+#define R_MIPS_TLS_DTPREL_LO16	45	/* Module-relative offset, low 16 bits */
+#define R_MIPS_TLS_GOTTPREL	46	/* 16 bit GOT offset for IE */
+#define R_MIPS_TLS_TPREL32	47	/* TP-relative offset, 32 bit */
+#define R_MIPS_TLS_TPREL64	48	/* TP-relative offset, 64 bit */
+#define R_MIPS_TLS_TPREL_HI16	49	/* TP-relative offset, high 16 bits */
+#define R_MIPS_TLS_TPREL_LO16	50	/* TP-relative offset, low 16 bits */
+#define R_MIPS_GLOB_DAT		51
+/* Keep this the last entry.  */
+#define R_MIPS_NUM		52
+
+/* Legal values for p_type field of Elf32_Phdr.  */
+
+#define PT_MIPS_REGINFO	0x70000000	/* Register usage information */
+#define PT_MIPS_RTPROC  0x70000001	/* Runtime procedure table. */
+#define PT_MIPS_OPTIONS 0x70000002
+
+/* Special program header types.  */
+
+#define PF_MIPS_LOCAL	0x10000000
+
+/* Legal values for d_tag field of Elf32_Dyn.  */
+
+#define DT_MIPS_RLD_VERSION  0x70000001	/* Runtime linker interface version */
+#define DT_MIPS_TIME_STAMP   0x70000002	/* Timestamp */
+#define DT_MIPS_ICHECKSUM    0x70000003	/* Checksum */
+#define DT_MIPS_IVERSION     0x70000004	/* Version string (string tbl index) */
+#define DT_MIPS_FLAGS	     0x70000005	/* Flags */
+#define DT_MIPS_BASE_ADDRESS 0x70000006	/* Base address */
+#define DT_MIPS_MSYM	     0x70000007
+#define DT_MIPS_CONFLICT     0x70000008	/* Address of CONFLICT section */
+#define DT_MIPS_LIBLIST	     0x70000009	/* Address of LIBLIST section */
+#define DT_MIPS_LOCAL_GOTNO  0x7000000a	/* Number of local GOT entries */
+#define DT_MIPS_CONFLICTNO   0x7000000b	/* Number of CONFLICT entries */
+#define DT_MIPS_LIBLISTNO    0x70000010	/* Number of LIBLIST entries */
+#define DT_MIPS_SYMTABNO     0x70000011	/* Number of DYNSYM entries */
+#define DT_MIPS_UNREFEXTNO   0x70000012	/* First external DYNSYM */
+#define DT_MIPS_GOTSYM	     0x70000013	/* First GOT entry in DYNSYM */
+#define DT_MIPS_HIPAGENO     0x70000014	/* Number of GOT page table entries */
+#define DT_MIPS_RLD_MAP	     0x70000016	/* Address of run time loader map.  */
+#define DT_MIPS_DELTA_CLASS  0x70000017	/* Delta C++ class definition.  */
+#define DT_MIPS_DELTA_CLASS_NO    0x70000018 /* Number of entries in
+						DT_MIPS_DELTA_CLASS.  */
+#define DT_MIPS_DELTA_INSTANCE    0x70000019 /* Delta C++ class instances.  */
+#define DT_MIPS_DELTA_INSTANCE_NO 0x7000001a /* Number of entries in
+						DT_MIPS_DELTA_INSTANCE.  */
+#define DT_MIPS_DELTA_RELOC  0x7000001b /* Delta relocations.  */
+#define DT_MIPS_DELTA_RELOC_NO 0x7000001c /* Number of entries in
+					     DT_MIPS_DELTA_RELOC.  */
+#define DT_MIPS_DELTA_SYM    0x7000001d /* Delta symbols that Delta
+					   relocations refer to.  */
+#define DT_MIPS_DELTA_SYM_NO 0x7000001e /* Number of entries in
+					   DT_MIPS_DELTA_SYM.  */
+#define DT_MIPS_DELTA_CLASSSYM 0x70000020 /* Delta symbols that hold the
+					     class declaration.  */
+#define DT_MIPS_DELTA_CLASSSYM_NO 0x70000021 /* Number of entries in
+						DT_MIPS_DELTA_CLASSSYM.  */
+#define DT_MIPS_CXX_FLAGS    0x70000022 /* Flags indicating for C++ flavor.  */
+#define DT_MIPS_PIXIE_INIT   0x70000023
+#define DT_MIPS_SYMBOL_LIB   0x70000024
+#define DT_MIPS_LOCALPAGE_GOTIDX 0x70000025
+#define DT_MIPS_LOCAL_GOTIDX 0x70000026
+#define DT_MIPS_HIDDEN_GOTIDX 0x70000027
+#define DT_MIPS_PROTECTED_GOTIDX 0x70000028
+#define DT_MIPS_OPTIONS	     0x70000029 /* Address of .options.  */
+#define DT_MIPS_INTERFACE    0x7000002a /* Address of .interface.  */
+#define DT_MIPS_DYNSTR_ALIGN 0x7000002b
+#define DT_MIPS_INTERFACE_SIZE 0x7000002c /* Size of the .interface section. */
+#define DT_MIPS_RLD_TEXT_RESOLVE_ADDR 0x7000002d /* Address of rld_text_rsolve
+						    function stored in GOT.  */
+#define DT_MIPS_PERF_SUFFIX  0x7000002e /* Default suffix of dso to be added
+					   by rld on dlopen() calls.  */
+#define DT_MIPS_COMPACT_SIZE 0x7000002f /* (O32)Size of compact rel section. */
+#define DT_MIPS_GP_VALUE     0x70000030 /* GP value for aux GOTs.  */
+#define DT_MIPS_AUX_DYNAMIC  0x70000031 /* Address of aux .dynamic.  */
+#define DT_MIPS_NUM	     0x32
+
+/* Legal values for DT_MIPS_FLAGS Elf32_Dyn entry.  */
+
+#define RHF_NONE		   0		/* No flags */
+#define RHF_QUICKSTART		   (1 << 0)	/* Use quickstart */
+#define RHF_NOTPOT		   (1 << 1)	/* Hash size not power of 2 */
+#define RHF_NO_LIBRARY_REPLACEMENT (1 << 2)	/* Ignore LD_LIBRARY_PATH */
+#define RHF_NO_MOVE		   (1 << 3)
+#define RHF_SGI_ONLY		   (1 << 4)
+#define RHF_GUARANTEE_INIT	   (1 << 5)
+#define RHF_DELTA_C_PLUS_PLUS	   (1 << 6)
+#define RHF_GUARANTEE_START_INIT   (1 << 7)
+#define RHF_PIXIE		   (1 << 8)
+#define RHF_DEFAULT_DELAY_LOAD	   (1 << 9)
+#define RHF_REQUICKSTART	   (1 << 10)
+#define RHF_REQUICKSTARTED	   (1 << 11)
+#define RHF_CORD		   (1 << 12)
+#define RHF_NO_UNRES_UNDEF	   (1 << 13)
+#define RHF_RLD_ORDER_SAFE	   (1 << 14)
+
+/* Entries found in sections of type SHT_MIPS_LIBLIST.  */
+
+typedef struct
+{
+  Elf32_Word l_name;		/* Name (string table index) */
+  Elf32_Word l_time_stamp;	/* Timestamp */
+  Elf32_Word l_checksum;	/* Checksum */
+  Elf32_Word l_version;		/* Interface version */
+  Elf32_Word l_flags;		/* Flags */
+} Elf32_Lib;
+
+typedef struct
+{
+  Elf64_Word l_name;		/* Name (string table index) */
+  Elf64_Word l_time_stamp;	/* Timestamp */
+  Elf64_Word l_checksum;	/* Checksum */
+  Elf64_Word l_version;		/* Interface version */
+  Elf64_Word l_flags;		/* Flags */
+} Elf64_Lib;
+
+
+/* Legal values for l_flags.  */
+
+#define LL_NONE		  0
+#define LL_EXACT_MATCH	  (1 << 0)	/* Require exact match */
+#define LL_IGNORE_INT_VER (1 << 1)	/* Ignore interface version */
+#define LL_REQUIRE_MINOR  (1 << 2)
+#define LL_EXPORTS	  (1 << 3)
+#define LL_DELAY_LOAD	  (1 << 4)
+#define LL_DELTA	  (1 << 5)
+
+/* Entries found in sections of type SHT_MIPS_CONFLICT.  */
+
+typedef Elf32_Addr Elf32_Conflict;
+
+
+/* HPPA specific definitions.  */
+
+/* Legal values for e_flags field of Elf32_Ehdr.  */
+
+#define EF_PARISC_TRAPNIL	0x00010000 /* Trap nil pointer dereference.  */
+#define EF_PARISC_EXT		0x00020000 /* Program uses arch. extensions. */
+#define EF_PARISC_LSB		0x00040000 /* Program expects little endian. */
+#define EF_PARISC_WIDE		0x00080000 /* Program expects wide mode.  */
+#define EF_PARISC_NO_KABP	0x00100000 /* No kernel assisted branch
+					      prediction.  */
+#define EF_PARISC_LAZYSWAP	0x00400000 /* Allow lazy swapping.  */
+#define EF_PARISC_ARCH		0x0000ffff /* Architecture version.  */
+
+/* Defined values for `e_flags & EF_PARISC_ARCH' are:  */
+
+#define EFA_PARISC_1_0		    0x020b /* PA-RISC 1.0 big-endian.  */
+#define EFA_PARISC_1_1		    0x0210 /* PA-RISC 1.1 big-endian.  */
+#define EFA_PARISC_2_0		    0x0214 /* PA-RISC 2.0 big-endian.  */
+
+/* Additional section indeces.  */
+
+#define SHN_PARISC_ANSI_COMMON	0xff00	   /* Section for tenatively declared
+					      symbols in ANSI C.  */
+#define SHN_PARISC_HUGE_COMMON	0xff01	   /* Common blocks in huge model.  */
+
+/* Legal values for sh_type field of Elf32_Shdr.  */
+
+#define SHT_PARISC_EXT		0x70000000 /* Contains product specific ext. */
+#define SHT_PARISC_UNWIND	0x70000001 /* Unwind information.  */
+#define SHT_PARISC_DOC		0x70000002 /* Debug info for optimized code. */
+
+/* Legal values for sh_flags field of Elf32_Shdr.  */
+
+#define SHF_PARISC_SHORT	0x20000000 /* Section with short addressing. */
+#define SHF_PARISC_HUGE		0x40000000 /* Section far from gp.  */
+#define SHF_PARISC_SBP		0x80000000 /* Static branch prediction code. */
+
+/* Legal values for ST_TYPE subfield of st_info (symbol type).  */
+
+#define STT_PARISC_MILLICODE	13	/* Millicode function entry point.  */
+
+#define STT_HP_OPAQUE		(STT_LOOS + 0x1)
+#define STT_HP_STUB		(STT_LOOS + 0x2)
+
+/* HPPA relocs.  */
+
+#define R_PARISC_NONE		0	/* No reloc.  */
+#define R_PARISC_DIR32		1	/* Direct 32-bit reference.  */
+#define R_PARISC_DIR21L		2	/* Left 21 bits of eff. address.  */
+#define R_PARISC_DIR17R		3	/* Right 17 bits of eff. address.  */
+#define R_PARISC_DIR17F		4	/* 17 bits of eff. address.  */
+#define R_PARISC_DIR14R		6	/* Right 14 bits of eff. address.  */
+#define R_PARISC_PCREL32	9	/* 32-bit rel. address.  */
+#define R_PARISC_PCREL21L	10	/* Left 21 bits of rel. address.  */
+#define R_PARISC_PCREL17R	11	/* Right 17 bits of rel. address.  */
+#define R_PARISC_PCREL17F	12	/* 17 bits of rel. address.  */
+#define R_PARISC_PCREL14R	14	/* Right 14 bits of rel. address.  */
+#define R_PARISC_DPREL21L	18	/* Left 21 bits of rel. address.  */
+#define R_PARISC_DPREL14R	22	/* Right 14 bits of rel. address.  */
+#define R_PARISC_GPREL21L	26	/* GP-relative, left 21 bits.  */
+#define R_PARISC_GPREL14R	30	/* GP-relative, right 14 bits.  */
+#define R_PARISC_LTOFF21L	34	/* LT-relative, left 21 bits.  */
+#define R_PARISC_LTOFF14R	38	/* LT-relative, right 14 bits.  */
+#define R_PARISC_SECREL32	41	/* 32 bits section rel. address.  */
+#define R_PARISC_SEGBASE	48	/* No relocation, set segment base.  */
+#define R_PARISC_SEGREL32	49	/* 32 bits segment rel. address.  */
+#define R_PARISC_PLTOFF21L	50	/* PLT rel. address, left 21 bits.  */
+#define R_PARISC_PLTOFF14R	54	/* PLT rel. address, right 14 bits.  */
+#define R_PARISC_LTOFF_FPTR32	57	/* 32 bits LT-rel. function pointer. */
+#define R_PARISC_LTOFF_FPTR21L	58	/* LT-rel. fct ptr, left 21 bits. */
+#define R_PARISC_LTOFF_FPTR14R	62	/* LT-rel. fct ptr, right 14 bits. */
+#define R_PARISC_FPTR64		64	/* 64 bits function address.  */
+#define R_PARISC_PLABEL32	65	/* 32 bits function address.  */
+#define R_PARISC_PLABEL21L	66	/* Left 21 bits of fdesc address.  */
+#define R_PARISC_PLABEL14R	70	/* Right 14 bits of fdesc address.  */
+#define R_PARISC_PCREL64	72	/* 64 bits PC-rel. address.  */
+#define R_PARISC_PCREL22F	74	/* 22 bits PC-rel. address.  */
+#define R_PARISC_PCREL14WR	75	/* PC-rel. address, right 14 bits.  */
+#define R_PARISC_PCREL14DR	76	/* PC rel. address, right 14 bits.  */
+#define R_PARISC_PCREL16F	77	/* 16 bits PC-rel. address.  */
+#define R_PARISC_PCREL16WF	78	/* 16 bits PC-rel. address.  */
+#define R_PARISC_PCREL16DF	79	/* 16 bits PC-rel. address.  */
+#define R_PARISC_DIR64		80	/* 64 bits of eff. address.  */
+#define R_PARISC_DIR14WR	83	/* 14 bits of eff. address.  */
+#define R_PARISC_DIR14DR	84	/* 14 bits of eff. address.  */
+#define R_PARISC_DIR16F		85	/* 16 bits of eff. address.  */
+#define R_PARISC_DIR16WF	86	/* 16 bits of eff. address.  */
+#define R_PARISC_DIR16DF	87	/* 16 bits of eff. address.  */
+#define R_PARISC_GPREL64	88	/* 64 bits of GP-rel. address.  */
+#define R_PARISC_GPREL14WR	91	/* GP-rel. address, right 14 bits.  */
+#define R_PARISC_GPREL14DR	92	/* GP-rel. address, right 14 bits.  */
+#define R_PARISC_GPREL16F	93	/* 16 bits GP-rel. address.  */
+#define R_PARISC_GPREL16WF	94	/* 16 bits GP-rel. address.  */
+#define R_PARISC_GPREL16DF	95	/* 16 bits GP-rel. address.  */
+#define R_PARISC_LTOFF64	96	/* 64 bits LT-rel. address.  */
+#define R_PARISC_LTOFF14WR	99	/* LT-rel. address, right 14 bits.  */
+#define R_PARISC_LTOFF14DR	100	/* LT-rel. address, right 14 bits.  */
+#define R_PARISC_LTOFF16F	101	/* 16 bits LT-rel. address.  */
+#define R_PARISC_LTOFF16WF	102	/* 16 bits LT-rel. address.  */
+#define R_PARISC_LTOFF16DF	103	/* 16 bits LT-rel. address.  */
+#define R_PARISC_SECREL64	104	/* 64 bits section rel. address.  */
+#define R_PARISC_SEGREL64	112	/* 64 bits segment rel. address.  */
+#define R_PARISC_PLTOFF14WR	115	/* PLT-rel. address, right 14 bits.  */
+#define R_PARISC_PLTOFF14DR	116	/* PLT-rel. address, right 14 bits.  */
+#define R_PARISC_PLTOFF16F	117	/* 16 bits LT-rel. address.  */
+#define R_PARISC_PLTOFF16WF	118	/* 16 bits PLT-rel. address.  */
+#define R_PARISC_PLTOFF16DF	119	/* 16 bits PLT-rel. address.  */
+#define R_PARISC_LTOFF_FPTR64	120	/* 64 bits LT-rel. function ptr.  */
+#define R_PARISC_LTOFF_FPTR14WR	123	/* LT-rel. fct. ptr., right 14 bits. */
+#define R_PARISC_LTOFF_FPTR14DR	124	/* LT-rel. fct. ptr., right 14 bits. */
+#define R_PARISC_LTOFF_FPTR16F	125	/* 16 bits LT-rel. function ptr.  */
+#define R_PARISC_LTOFF_FPTR16WF	126	/* 16 bits LT-rel. function ptr.  */
+#define R_PARISC_LTOFF_FPTR16DF	127	/* 16 bits LT-rel. function ptr.  */
+#define R_PARISC_LORESERVE	128
+#define R_PARISC_COPY		128	/* Copy relocation.  */
+#define R_PARISC_IPLT		129	/* Dynamic reloc, imported PLT */
+#define R_PARISC_EPLT		130	/* Dynamic reloc, exported PLT */
+#define R_PARISC_TPREL32	153	/* 32 bits TP-rel. address.  */
+#define R_PARISC_TPREL21L	154	/* TP-rel. address, left 21 bits.  */
+#define R_PARISC_TPREL14R	158	/* TP-rel. address, right 14 bits.  */
+#define R_PARISC_LTOFF_TP21L	162	/* LT-TP-rel. address, left 21 bits. */
+#define R_PARISC_LTOFF_TP14R	166	/* LT-TP-rel. address, right 14 bits.*/
+#define R_PARISC_LTOFF_TP14F	167	/* 14 bits LT-TP-rel. address.  */
+#define R_PARISC_TPREL64	216	/* 64 bits TP-rel. address.  */
+#define R_PARISC_TPREL14WR	219	/* TP-rel. address, right 14 bits.  */
+#define R_PARISC_TPREL14DR	220	/* TP-rel. address, right 14 bits.  */
+#define R_PARISC_TPREL16F	221	/* 16 bits TP-rel. address.  */
+#define R_PARISC_TPREL16WF	222	/* 16 bits TP-rel. address.  */
+#define R_PARISC_TPREL16DF	223	/* 16 bits TP-rel. address.  */
+#define R_PARISC_LTOFF_TP64	224	/* 64 bits LT-TP-rel. address.  */
+#define R_PARISC_LTOFF_TP14WR	227	/* LT-TP-rel. address, right 14 bits.*/
+#define R_PARISC_LTOFF_TP14DR	228	/* LT-TP-rel. address, right 14 bits.*/
+#define R_PARISC_LTOFF_TP16F	229	/* 16 bits LT-TP-rel. address.  */
+#define R_PARISC_LTOFF_TP16WF	230	/* 16 bits LT-TP-rel. address.  */
+#define R_PARISC_LTOFF_TP16DF	231	/* 16 bits LT-TP-rel. address.  */
+#define R_PARISC_GNU_VTENTRY	232
+#define R_PARISC_GNU_VTINHERIT	233
+#define R_PARISC_TLS_GD21L	234	/* GD 21-bit left.  */
+#define R_PARISC_TLS_GD14R	235	/* GD 14-bit right.  */
+#define R_PARISC_TLS_GDCALL	236	/* GD call to __t_g_a.  */
+#define R_PARISC_TLS_LDM21L	237	/* LD module 21-bit left.  */
+#define R_PARISC_TLS_LDM14R	238	/* LD module 14-bit right.  */
+#define R_PARISC_TLS_LDMCALL	239	/* LD module call to __t_g_a.  */
+#define R_PARISC_TLS_LDO21L	240	/* LD offset 21-bit left.  */
+#define R_PARISC_TLS_LDO14R	241	/* LD offset 14-bit right.  */
+#define R_PARISC_TLS_DTPMOD32	242	/* DTP module 32-bit.  */
+#define R_PARISC_TLS_DTPMOD64	243	/* DTP module 64-bit.  */
+#define R_PARISC_TLS_DTPOFF32	244	/* DTP offset 32-bit.  */
+#define R_PARISC_TLS_DTPOFF64	245	/* DTP offset 32-bit.  */
+#define R_PARISC_TLS_LE21L	R_PARISC_TPREL21L
+#define R_PARISC_TLS_LE14R	R_PARISC_TPREL14R
+#define R_PARISC_TLS_IE21L	R_PARISC_LTOFF_TP21L
+#define R_PARISC_TLS_IE14R	R_PARISC_LTOFF_TP14R
+#define R_PARISC_TLS_TPREL32	R_PARISC_TPREL32
+#define R_PARISC_TLS_TPREL64	R_PARISC_TPREL64
+#define R_PARISC_HIRESERVE	255
+
+/* Legal values for p_type field of Elf32_Phdr/Elf64_Phdr.  */
+
+#define PT_HP_TLS		(PT_LOOS + 0x0)
+#define PT_HP_CORE_NONE		(PT_LOOS + 0x1)
+#define PT_HP_CORE_VERSION	(PT_LOOS + 0x2)
+#define PT_HP_CORE_KERNEL	(PT_LOOS + 0x3)
+#define PT_HP_CORE_COMM		(PT_LOOS + 0x4)
+#define PT_HP_CORE_PROC		(PT_LOOS + 0x5)
+#define PT_HP_CORE_LOADABLE	(PT_LOOS + 0x6)
+#define PT_HP_CORE_STACK	(PT_LOOS + 0x7)
+#define PT_HP_CORE_SHM		(PT_LOOS + 0x8)
+#define PT_HP_CORE_MMF		(PT_LOOS + 0x9)
+#define PT_HP_PARALLEL		(PT_LOOS + 0x10)
+#define PT_HP_FASTBIND		(PT_LOOS + 0x11)
+#define PT_HP_OPT_ANNOT		(PT_LOOS + 0x12)
+#define PT_HP_HSL_ANNOT		(PT_LOOS + 0x13)
+#define PT_HP_STACK		(PT_LOOS + 0x14)
+
+#define PT_PARISC_ARCHEXT	0x70000000
+#define PT_PARISC_UNWIND	0x70000001
+
+/* Legal values for p_flags field of Elf32_Phdr/Elf64_Phdr.  */
+
+#define PF_PARISC_SBP		0x08000000
+
+#define PF_HP_PAGE_SIZE		0x00100000
+#define PF_HP_FAR_SHARED	0x00200000
+#define PF_HP_NEAR_SHARED	0x00400000
+#define PF_HP_CODE		0x01000000
+#define PF_HP_MODIFY		0x02000000
+#define PF_HP_LAZYSWAP		0x04000000
+#define PF_HP_SBP		0x08000000
+
+
+/* Alpha specific definitions.  */
+
+/* Legal values for e_flags field of Elf64_Ehdr.  */
+
+#define EF_ALPHA_32BIT		1	/* All addresses must be < 2GB.  */
+#define EF_ALPHA_CANRELAX	2	/* Relocations for relaxing exist.  */
+
+/* Legal values for sh_type field of Elf64_Shdr.  */
+
+/* These two are primerily concerned with ECOFF debugging info.  */
+#define SHT_ALPHA_DEBUG		0x70000001
+#define SHT_ALPHA_REGINFO	0x70000002
+
+/* Legal values for sh_flags field of Elf64_Shdr.  */
+
+#define SHF_ALPHA_GPREL		0x10000000
+
+/* Legal values for st_other field of Elf64_Sym.  */
+#define STO_ALPHA_NOPV		0x80	/* No PV required.  */
+#define STO_ALPHA_STD_GPLOAD	0x88	/* PV only used for initial ldgp.  */
+
+/* Alpha relocs.  */
+
+#define R_ALPHA_NONE		0	/* No reloc */
+#define R_ALPHA_REFLONG		1	/* Direct 32 bit */
+#define R_ALPHA_REFQUAD		2	/* Direct 64 bit */
+#define R_ALPHA_GPREL32		3	/* GP relative 32 bit */
+#define R_ALPHA_LITERAL		4	/* GP relative 16 bit w/optimization */
+#define R_ALPHA_LITUSE		5	/* Optimization hint for LITERAL */
+#define R_ALPHA_GPDISP		6	/* Add displacement to GP */
+#define R_ALPHA_BRADDR		7	/* PC+4 relative 23 bit shifted */
+#define R_ALPHA_HINT		8	/* PC+4 relative 16 bit shifted */
+#define R_ALPHA_SREL16		9	/* PC relative 16 bit */
+#define R_ALPHA_SREL32		10	/* PC relative 32 bit */
+#define R_ALPHA_SREL64		11	/* PC relative 64 bit */
+#define R_ALPHA_GPRELHIGH	17	/* GP relative 32 bit, high 16 bits */
+#define R_ALPHA_GPRELLOW	18	/* GP relative 32 bit, low 16 bits */
+#define R_ALPHA_GPREL16		19	/* GP relative 16 bit */
+#define R_ALPHA_COPY		24	/* Copy symbol at runtime */
+#define R_ALPHA_GLOB_DAT	25	/* Create GOT entry */
+#define R_ALPHA_JMP_SLOT	26	/* Create PLT entry */
+#define R_ALPHA_RELATIVE	27	/* Adjust by program base */
+#define R_ALPHA_TLS_GD_HI	28
+#define R_ALPHA_TLSGD		29
+#define R_ALPHA_TLS_LDM		30
+#define R_ALPHA_DTPMOD64	31
+#define R_ALPHA_GOTDTPREL	32
+#define R_ALPHA_DTPREL64	33
+#define R_ALPHA_DTPRELHI	34
+#define R_ALPHA_DTPRELLO	35
+#define R_ALPHA_DTPREL16	36
+#define R_ALPHA_GOTTPREL	37
+#define R_ALPHA_TPREL64		38
+#define R_ALPHA_TPRELHI		39
+#define R_ALPHA_TPRELLO		40
+#define R_ALPHA_TPREL16		41
+/* Keep this the last entry.  */
+#define R_ALPHA_NUM		46
+
+/* Magic values of the LITUSE relocation addend.  */
+#define LITUSE_ALPHA_ADDR	0
+#define LITUSE_ALPHA_BASE	1
+#define LITUSE_ALPHA_BYTOFF	2
+#define LITUSE_ALPHA_JSR	3
+#define LITUSE_ALPHA_TLS_GD	4
+#define LITUSE_ALPHA_TLS_LDM	5
+
+/* Legal values for d_tag of Elf64_Dyn.  */
+#define DT_ALPHA_PLTRO		(DT_LOPROC + 0)
+#define DT_ALPHA_NUM		1
+
+/* PowerPC specific declarations */
+
+/* Values for Elf32/64_Ehdr.e_flags.  */
+#define EF_PPC_EMB		0x80000000	/* PowerPC embedded flag */
+
+/* Cygnus local bits below */
+#define EF_PPC_RELOCATABLE	0x00010000	/* PowerPC -mrelocatable flag*/
+#define EF_PPC_RELOCATABLE_LIB	0x00008000	/* PowerPC -mrelocatable-lib
+						   flag */
+
+/* PowerPC relocations defined by the ABIs */
+#define R_PPC_NONE		0
+#define R_PPC_ADDR32		1	/* 32bit absolute address */
+#define R_PPC_ADDR24		2	/* 26bit address, 2 bits ignored.  */
+#define R_PPC_ADDR16		3	/* 16bit absolute address */
+#define R_PPC_ADDR16_LO		4	/* lower 16bit of absolute address */
+#define R_PPC_ADDR16_HI		5	/* high 16bit of absolute address */
+#define R_PPC_ADDR16_HA		6	/* adjusted high 16bit */
+#define R_PPC_ADDR14		7	/* 16bit address, 2 bits ignored */
+#define R_PPC_ADDR14_BRTAKEN	8
+#define R_PPC_ADDR14_BRNTAKEN	9
+#define R_PPC_REL24		10	/* PC relative 26 bit */
+#define R_PPC_REL14		11	/* PC relative 16 bit */
+#define R_PPC_REL14_BRTAKEN	12
+#define R_PPC_REL14_BRNTAKEN	13
+#define R_PPC_GOT16		14
+#define R_PPC_GOT16_LO		15
+#define R_PPC_GOT16_HI		16
+#define R_PPC_GOT16_HA		17
+#define R_PPC_PLTREL24		18
+#define R_PPC_COPY		19
+#define R_PPC_GLOB_DAT		20
+#define R_PPC_JMP_SLOT		21
+#define R_PPC_RELATIVE		22
+#define R_PPC_LOCAL24PC		23
+#define R_PPC_UADDR32		24
+#define R_PPC_UADDR16		25
+#define R_PPC_REL32		26
+#define R_PPC_PLT32		27
+#define R_PPC_PLTREL32		28
+#define R_PPC_PLT16_LO		29
+#define R_PPC_PLT16_HI		30
+#define R_PPC_PLT16_HA		31
+#define R_PPC_SDAREL16		32
+#define R_PPC_SECTOFF		33
+#define R_PPC_SECTOFF_LO	34
+#define R_PPC_SECTOFF_HI	35
+#define R_PPC_SECTOFF_HA	36
+
+/* PowerPC relocations defined for the TLS access ABI.  */
+#define R_PPC_TLS		67 /* none	(sym+add)@tls */
+#define R_PPC_DTPMOD32		68 /* word32	(sym+add)@dtpmod */
+#define R_PPC_TPREL16		69 /* half16*	(sym+add)@tprel */
+#define R_PPC_TPREL16_LO	70 /* half16	(sym+add)@tprel@l */
+#define R_PPC_TPREL16_HI	71 /* half16	(sym+add)@tprel@h */
+#define R_PPC_TPREL16_HA	72 /* half16	(sym+add)@tprel@ha */
+#define R_PPC_TPREL32		73 /* word32	(sym+add)@tprel */
+#define R_PPC_DTPREL16		74 /* half16*	(sym+add)@dtprel */
+#define R_PPC_DTPREL16_LO	75 /* half16	(sym+add)@dtprel@l */
+#define R_PPC_DTPREL16_HI	76 /* half16	(sym+add)@dtprel@h */
+#define R_PPC_DTPREL16_HA	77 /* half16	(sym+add)@dtprel@ha */
+#define R_PPC_DTPREL32		78 /* word32	(sym+add)@dtprel */
+#define R_PPC_GOT_TLSGD16	79 /* half16*	(sym+add)@got@tlsgd */
+#define R_PPC_GOT_TLSGD16_LO	80 /* half16	(sym+add)@got@tlsgd@l */
+#define R_PPC_GOT_TLSGD16_HI	81 /* half16	(sym+add)@got@tlsgd@h */
+#define R_PPC_GOT_TLSGD16_HA	82 /* half16	(sym+add)@got@tlsgd@ha */
+#define R_PPC_GOT_TLSLD16	83 /* half16*	(sym+add)@got@tlsld */
+#define R_PPC_GOT_TLSLD16_LO	84 /* half16	(sym+add)@got@tlsld@l */
+#define R_PPC_GOT_TLSLD16_HI	85 /* half16	(sym+add)@got@tlsld@h */
+#define R_PPC_GOT_TLSLD16_HA	86 /* half16	(sym+add)@got@tlsld@ha */
+#define R_PPC_GOT_TPREL16	87 /* half16*	(sym+add)@got@tprel */
+#define R_PPC_GOT_TPREL16_LO	88 /* half16	(sym+add)@got@tprel@l */
+#define R_PPC_GOT_TPREL16_HI	89 /* half16	(sym+add)@got@tprel@h */
+#define R_PPC_GOT_TPREL16_HA	90 /* half16	(sym+add)@got@tprel@ha */
+#define R_PPC_GOT_DTPREL16	91 /* half16*	(sym+add)@got@dtprel */
+#define R_PPC_GOT_DTPREL16_LO	92 /* half16*	(sym+add)@got@dtprel@l */
+#define R_PPC_GOT_DTPREL16_HI	93 /* half16*	(sym+add)@got@dtprel@h */
+#define R_PPC_GOT_DTPREL16_HA	94 /* half16*	(sym+add)@got@dtprel@ha */
+
+/* Keep this the last entry.  */
+#define R_PPC_NUM		95
+
+/* The remaining relocs are from the Embedded ELF ABI, and are not
+   in the SVR4 ELF ABI.  */
+#define R_PPC_EMB_NADDR32	101
+#define R_PPC_EMB_NADDR16	102
+#define R_PPC_EMB_NADDR16_LO	103
+#define R_PPC_EMB_NADDR16_HI	104
+#define R_PPC_EMB_NADDR16_HA	105
+#define R_PPC_EMB_SDAI16	106
+#define R_PPC_EMB_SDA2I16	107
+#define R_PPC_EMB_SDA2REL	108
+#define R_PPC_EMB_SDA21		109	/* 16 bit offset in SDA */
+#define R_PPC_EMB_MRKREF	110
+#define R_PPC_EMB_RELSEC16	111
+#define R_PPC_EMB_RELST_LO	112
+#define R_PPC_EMB_RELST_HI	113
+#define R_PPC_EMB_RELST_HA	114
+#define R_PPC_EMB_BIT_FLD	115
+#define R_PPC_EMB_RELSDA	116	/* 16 bit relative offset in SDA */
+
+/* Diab tool relocations.  */
+#define R_PPC_DIAB_SDA21_LO	180	/* like EMB_SDA21, but lower 16 bit */
+#define R_PPC_DIAB_SDA21_HI	181	/* like EMB_SDA21, but high 16 bit */
+#define R_PPC_DIAB_SDA21_HA	182	/* like EMB_SDA21, adjusted high 16 */
+#define R_PPC_DIAB_RELSDA_LO	183	/* like EMB_RELSDA, but lower 16 bit */
+#define R_PPC_DIAB_RELSDA_HI	184	/* like EMB_RELSDA, but high 16 bit */
+#define R_PPC_DIAB_RELSDA_HA	185	/* like EMB_RELSDA, adjusted high 16 */
+
+/* GNU relocs used in PIC code sequences.  */
+#define R_PPC_REL16		249	/* word32   (sym-.) */
+#define R_PPC_REL16_LO		250	/* half16   (sym-.)@l */
+#define R_PPC_REL16_HI		251	/* half16   (sym-.)@h */
+#define R_PPC_REL16_HA		252	/* half16   (sym-.)@ha */
+
+/* This is a phony reloc to handle any old fashioned TOC16 references
+   that may still be in object files.  */
+#define R_PPC_TOC16		255
+
+/* PowerPC specific values for the Dyn d_tag field.  */
+#define DT_PPC_GOT		(DT_LOPROC + 0)
+#define DT_PPC_NUM		1
+
+/* PowerPC64 relocations defined by the ABIs */
+#define R_PPC64_NONE		R_PPC_NONE
+#define R_PPC64_ADDR32		R_PPC_ADDR32 /* 32bit absolute address */
+#define R_PPC64_ADDR24		R_PPC_ADDR24 /* 26bit address, word aligned */
+#define R_PPC64_ADDR16		R_PPC_ADDR16 /* 16bit absolute address */
+#define R_PPC64_ADDR16_LO	R_PPC_ADDR16_LO	/* lower 16bits of address */
+#define R_PPC64_ADDR16_HI	R_PPC_ADDR16_HI	/* high 16bits of address. */
+#define R_PPC64_ADDR16_HA	R_PPC_ADDR16_HA /* adjusted high 16bits.  */
+#define R_PPC64_ADDR14		R_PPC_ADDR14 /* 16bit address, word aligned */
+#define R_PPC64_ADDR14_BRTAKEN	R_PPC_ADDR14_BRTAKEN
+#define R_PPC64_ADDR14_BRNTAKEN	R_PPC_ADDR14_BRNTAKEN
+#define R_PPC64_REL24		R_PPC_REL24 /* PC-rel. 26 bit, word aligned */
+#define R_PPC64_REL14		R_PPC_REL14 /* PC relative 16 bit */
+#define R_PPC64_REL14_BRTAKEN	R_PPC_REL14_BRTAKEN
+#define R_PPC64_REL14_BRNTAKEN	R_PPC_REL14_BRNTAKEN
+#define R_PPC64_GOT16		R_PPC_GOT16
+#define R_PPC64_GOT16_LO	R_PPC_GOT16_LO
+#define R_PPC64_GOT16_HI	R_PPC_GOT16_HI
+#define R_PPC64_GOT16_HA	R_PPC_GOT16_HA
+
+#define R_PPC64_COPY		R_PPC_COPY
+#define R_PPC64_GLOB_DAT	R_PPC_GLOB_DAT
+#define R_PPC64_JMP_SLOT	R_PPC_JMP_SLOT
+#define R_PPC64_RELATIVE	R_PPC_RELATIVE
+
+#define R_PPC64_UADDR32		R_PPC_UADDR32
+#define R_PPC64_UADDR16		R_PPC_UADDR16
+#define R_PPC64_REL32		R_PPC_REL32
+#define R_PPC64_PLT32		R_PPC_PLT32
+#define R_PPC64_PLTREL32	R_PPC_PLTREL32
+#define R_PPC64_PLT16_LO	R_PPC_PLT16_LO
+#define R_PPC64_PLT16_HI	R_PPC_PLT16_HI
+#define R_PPC64_PLT16_HA	R_PPC_PLT16_HA
+
+#define R_PPC64_SECTOFF		R_PPC_SECTOFF
+#define R_PPC64_SECTOFF_LO	R_PPC_SECTOFF_LO
+#define R_PPC64_SECTOFF_HI	R_PPC_SECTOFF_HI
+#define R_PPC64_SECTOFF_HA	R_PPC_SECTOFF_HA
+#define R_PPC64_ADDR30		37 /* word30 (S + A - P) >> 2 */
+#define R_PPC64_ADDR64		38 /* doubleword64 S + A */
+#define R_PPC64_ADDR16_HIGHER	39 /* half16 #higher(S + A) */
+#define R_PPC64_ADDR16_HIGHERA	40 /* half16 #highera(S + A) */
+#define R_PPC64_ADDR16_HIGHEST	41 /* half16 #highest(S + A) */
+#define R_PPC64_ADDR16_HIGHESTA	42 /* half16 #highesta(S + A) */
+#define R_PPC64_UADDR64		43 /* doubleword64 S + A */
+#define R_PPC64_REL64		44 /* doubleword64 S + A - P */
+#define R_PPC64_PLT64		45 /* doubleword64 L + A */
+#define R_PPC64_PLTREL64	46 /* doubleword64 L + A - P */
+#define R_PPC64_TOC16		47 /* half16* S + A - .TOC */
+#define R_PPC64_TOC16_LO	48 /* half16 #lo(S + A - .TOC.) */
+#define R_PPC64_TOC16_HI	49 /* half16 #hi(S + A - .TOC.) */
+#define R_PPC64_TOC16_HA	50 /* half16 #ha(S + A - .TOC.) */
+#define R_PPC64_TOC		51 /* doubleword64 .TOC */
+#define R_PPC64_PLTGOT16	52 /* half16* M + A */
+#define R_PPC64_PLTGOT16_LO	53 /* half16 #lo(M + A) */
+#define R_PPC64_PLTGOT16_HI	54 /* half16 #hi(M + A) */
+#define R_PPC64_PLTGOT16_HA	55 /* half16 #ha(M + A) */
+
+#define R_PPC64_ADDR16_DS	56 /* half16ds* (S + A) >> 2 */
+#define R_PPC64_ADDR16_LO_DS	57 /* half16ds  #lo(S + A) >> 2 */
+#define R_PPC64_GOT16_DS	58 /* half16ds* (G + A) >> 2 */
+#define R_PPC64_GOT16_LO_DS	59 /* half16ds  #lo(G + A) >> 2 */
+#define R_PPC64_PLT16_LO_DS	60 /* half16ds  #lo(L + A) >> 2 */
+#define R_PPC64_SECTOFF_DS	61 /* half16ds* (R + A) >> 2 */
+#define R_PPC64_SECTOFF_LO_DS	62 /* half16ds  #lo(R + A) >> 2 */
+#define R_PPC64_TOC16_DS	63 /* half16ds* (S + A - .TOC.) >> 2 */
+#define R_PPC64_TOC16_LO_DS	64 /* half16ds  #lo(S + A - .TOC.) >> 2 */
+#define R_PPC64_PLTGOT16_DS	65 /* half16ds* (M + A) >> 2 */
+#define R_PPC64_PLTGOT16_LO_DS	66 /* half16ds  #lo(M + A) >> 2 */
+
+/* PowerPC64 relocations defined for the TLS access ABI.  */
+#define R_PPC64_TLS		67 /* none	(sym+add)@tls */
+#define R_PPC64_DTPMOD64	68 /* doubleword64 (sym+add)@dtpmod */
+#define R_PPC64_TPREL16		69 /* half16*	(sym+add)@tprel */
+#define R_PPC64_TPREL16_LO	70 /* half16	(sym+add)@tprel@l */
+#define R_PPC64_TPREL16_HI	71 /* half16	(sym+add)@tprel@h */
+#define R_PPC64_TPREL16_HA	72 /* half16	(sym+add)@tprel@ha */
+#define R_PPC64_TPREL64		73 /* doubleword64 (sym+add)@tprel */
+#define R_PPC64_DTPREL16	74 /* half16*	(sym+add)@dtprel */
+#define R_PPC64_DTPREL16_LO	75 /* half16	(sym+add)@dtprel@l */
+#define R_PPC64_DTPREL16_HI	76 /* half16	(sym+add)@dtprel@h */
+#define R_PPC64_DTPREL16_HA	77 /* half16	(sym+add)@dtprel@ha */
+#define R_PPC64_DTPREL64	78 /* doubleword64 (sym+add)@dtprel */
+#define R_PPC64_GOT_TLSGD16	79 /* half16*	(sym+add)@got@tlsgd */
+#define R_PPC64_GOT_TLSGD16_LO	80 /* half16	(sym+add)@got@tlsgd@l */
+#define R_PPC64_GOT_TLSGD16_HI	81 /* half16	(sym+add)@got@tlsgd@h */
+#define R_PPC64_GOT_TLSGD16_HA	82 /* half16	(sym+add)@got@tlsgd@ha */
+#define R_PPC64_GOT_TLSLD16	83 /* half16*	(sym+add)@got@tlsld */
+#define R_PPC64_GOT_TLSLD16_LO	84 /* half16	(sym+add)@got@tlsld@l */
+#define R_PPC64_GOT_TLSLD16_HI	85 /* half16	(sym+add)@got@tlsld@h */
+#define R_PPC64_GOT_TLSLD16_HA	86 /* half16	(sym+add)@got@tlsld@ha */
+#define R_PPC64_GOT_TPREL16_DS	87 /* half16ds*	(sym+add)@got@tprel */
+#define R_PPC64_GOT_TPREL16_LO_DS 88 /* half16ds (sym+add)@got@tprel@l */
+#define R_PPC64_GOT_TPREL16_HI	89 /* half16	(sym+add)@got@tprel@h */
+#define R_PPC64_GOT_TPREL16_HA	90 /* half16	(sym+add)@got@tprel@ha */
+#define R_PPC64_GOT_DTPREL16_DS	91 /* half16ds*	(sym+add)@got@dtprel */
+#define R_PPC64_GOT_DTPREL16_LO_DS 92 /* half16ds (sym+add)@got@dtprel@l */
+#define R_PPC64_GOT_DTPREL16_HI	93 /* half16	(sym+add)@got@dtprel@h */
+#define R_PPC64_GOT_DTPREL16_HA	94 /* half16	(sym+add)@got@dtprel@ha */
+#define R_PPC64_TPREL16_DS	95 /* half16ds*	(sym+add)@tprel */
+#define R_PPC64_TPREL16_LO_DS	96 /* half16ds	(sym+add)@tprel@l */
+#define R_PPC64_TPREL16_HIGHER	97 /* half16	(sym+add)@tprel@higher */
+#define R_PPC64_TPREL16_HIGHERA	98 /* half16	(sym+add)@tprel@highera */
+#define R_PPC64_TPREL16_HIGHEST	99 /* half16	(sym+add)@tprel@highest */
+#define R_PPC64_TPREL16_HIGHESTA 100 /* half16	(sym+add)@tprel@highesta */
+#define R_PPC64_DTPREL16_DS	101 /* half16ds* (sym+add)@dtprel */
+#define R_PPC64_DTPREL16_LO_DS	102 /* half16ds	(sym+add)@dtprel@l */
+#define R_PPC64_DTPREL16_HIGHER	103 /* half16	(sym+add)@dtprel@higher */
+#define R_PPC64_DTPREL16_HIGHERA 104 /* half16	(sym+add)@dtprel@highera */
+#define R_PPC64_DTPREL16_HIGHEST 105 /* half16	(sym+add)@dtprel@highest */
+#define R_PPC64_DTPREL16_HIGHESTA 106 /* half16	(sym+add)@dtprel@highesta */
+
+/* Keep this the last entry.  */
+#define R_PPC64_NUM		107
+
+/* PowerPC64 specific values for the Dyn d_tag field.  */
+#define DT_PPC64_GLINK  (DT_LOPROC + 0)
+#define DT_PPC64_OPD	(DT_LOPROC + 1)
+#define DT_PPC64_OPDSZ	(DT_LOPROC + 2)
+#define DT_PPC64_NUM    3
+
+
+/* ARM specific declarations */
+
+/* Processor specific flags for the ELF header e_flags field.  */
+#define EF_ARM_RELEXEC     0x01
+#define EF_ARM_HASENTRY    0x02
+#define EF_ARM_INTERWORK   0x04
+#define EF_ARM_APCS_26     0x08
+#define EF_ARM_APCS_FLOAT  0x10
+#define EF_ARM_PIC         0x20
+#define EF_ARM_ALIGN8      0x40		/* 8-bit structure alignment is in use */
+#define EF_ARM_NEW_ABI     0x80
+#define EF_ARM_OLD_ABI     0x100
+
+/* Other constants defined in the ARM ELF spec. version B-01.  */
+/* NB. These conflict with values defined above.  */
+#define EF_ARM_SYMSARESORTED	0x04
+#define EF_ARM_DYNSYMSUSESEGIDX 0x08
+#define EF_ARM_MAPSYMSFIRST	0x10
+#define EF_ARM_EABIMASK		0XFF000000
+
+#define EF_ARM_EABI_VERSION(flags) ((flags) & EF_ARM_EABIMASK)
+#define EF_ARM_EABI_UNKNOWN  0x00000000
+#define EF_ARM_EABI_VER1     0x01000000
+#define EF_ARM_EABI_VER2     0x02000000
+
+/* Additional symbol types for Thumb */
+#define STT_ARM_TFUNC      0xd
+
+/* ARM-specific values for sh_flags */
+#define SHF_ARM_ENTRYSECT  0x10000000   /* Section contains an entry point */
+#define SHF_ARM_COMDEF     0x80000000   /* Section may be multiply defined
+					   in the input to a link step */
+
+/* ARM-specific program header flags */
+#define PF_ARM_SB          0x10000000   /* Segment contains the location
+					   addressed by the static base */
+
+/* Processor specific values for the Phdr p_type field.  */
+#define PT_ARM_EXIDX	0x70000001	/* .ARM.exidx segment */
+
+/* ARM relocs.  */
+
+#define R_ARM_NONE		0	/* No reloc */
+#define R_ARM_PC24		1	/* PC relative 26 bit branch */
+#define R_ARM_ABS32		2	/* Direct 32 bit  */
+#define R_ARM_REL32		3	/* PC relative 32 bit */
+#define R_ARM_PC13		4
+#define R_ARM_ABS16		5	/* Direct 16 bit */
+#define R_ARM_ABS12		6	/* Direct 12 bit */
+#define R_ARM_THM_ABS5		7
+#define R_ARM_ABS8		8	/* Direct 8 bit */
+#define R_ARM_SBREL32		9
+#define R_ARM_THM_PC22		10
+#define R_ARM_THM_PC8		11
+#define R_ARM_AMP_VCALL9	12
+#define R_ARM_SWI24		13
+#define R_ARM_THM_SWI8		14
+#define R_ARM_XPC25		15
+#define R_ARM_THM_XPC22		16
+#define R_ARM_TLS_DTPMOD32	17	/* ID of module containing symbol */
+#define R_ARM_TLS_DTPOFF32	18	/* Offset in TLS block */
+#define R_ARM_TLS_TPOFF32	19	/* Offset in static TLS block */
+#define R_ARM_COPY		20	/* Copy symbol at runtime */
+#define R_ARM_GLOB_DAT		21	/* Create GOT entry */
+#define R_ARM_JUMP_SLOT		22	/* Create PLT entry */
+#define R_ARM_RELATIVE		23	/* Adjust by program base */
+#define R_ARM_GOTOFF		24	/* 32 bit offset to GOT */
+#define R_ARM_GOTPC		25	/* 32 bit PC relative offset to GOT */
+#define R_ARM_GOT32		26	/* 32 bit GOT entry */
+#define R_ARM_PLT32		27	/* 32 bit PLT address */
+#define R_ARM_CALL              28
+#define R_ARM_JUMP24            29
+#define R_ARM_THM_JUMP24	30
+#define R_ARM_ALU_PCREL_7_0	32
+#define R_ARM_ALU_PCREL_15_8	33
+#define R_ARM_ALU_PCREL_23_15	34
+#define R_ARM_LDR_SBREL_11_0	35
+#define R_ARM_ALU_SBREL_19_12	36
+#define R_ARM_ALU_SBREL_27_20	37
+#define R_ARM_V4BX              40
+#define R_ARM_GNU_VTENTRY	100
+#define R_ARM_GNU_VTINHERIT	101
+#define R_ARM_THM_PC11		102	/* thumb unconditional branch */
+#define R_ARM_THM_PC9		103	/* thumb conditional branch */
+#define R_ARM_TLS_GD32		104	/* PC-rel 32 bit for global dynamic
+					   thread local data */
+#define R_ARM_TLS_LDM32		105	/* PC-rel 32 bit for local dynamic
+					   thread local data */
+#define R_ARM_TLS_LDO32		106	/* 32 bit offset relative to TLS
+					   block */
+#define R_ARM_TLS_IE32		107	/* PC-rel 32 bit for GOT entry of
+					   static TLS block offset */
+#define R_ARM_TLS_LE32		108	/* 32 bit offset relative to static
+					   TLS block */
+#define R_ARM_RXPC25		249
+#define R_ARM_RSBREL32		250
+#define R_ARM_THM_RPC22		251
+#define R_ARM_RREL32		252
+#define R_ARM_RABS22		253
+#define R_ARM_RPC24		254
+#define R_ARM_RBASE		255
+/* Keep this the last entry.  */
+#define R_ARM_NUM		256
+
+/* AARCH64 Relocs */
+#define R_AARCH64_ABS64			257
+#define R_AARCH64_ABS32			258
+#define R_AARCH64_ABS16			259
+#define R_AARCH64_PREL64		260
+#define R_AARCH64_PREL32		261
+#define R_AARCH64_PREL16		262
+#define R_AARCH64_MOVW_UABS_G0		263
+#define R_AARCH64_MOVW_UABS_G0_NC	264
+#define R_AARCH64_MOVW_UABS_G1		265
+#define R_AARCH64_MOVW_UABS_G1_NC	266
+#define R_AARCH64_MOVW_UABS_G2		267
+#define R_AARCH64_MOVW_UABS_G2_NC	268
+#define R_AARCH64_MOVW_UABS_G3		269
+#define R_AARCH64_MOVW_SABS_G0		270
+#define R_AARCH64_MOVW_SABS_G1		271
+#define R_AARCH64_MOVW_SABS_G2		272
+#define R_AARCH64_LD_PREL_LO19		273
+#define R_AARCH64_ADR_PREL_LO21		274
+#define R_AARCH64_ADR_PREL_PG_HI21	275
+#define R_AARCH64_ADR_PREL_PG_HI21_NC	276
+#define R_AARCH64_ADD_ABS_LO12_NC	277
+#define R_AARCH64_LDST8_ABS_LO12_NC	278
+#define R_AARCH64_TSTBR14		279
+#define R_AARCH64_CONDBR19		280
+#define R_AARCH64_JUMP26		282
+#define R_AARCH64_CALL26		283
+#define R_AARCH64_LDST16_ABS_LO12_NC	284
+#define R_AARCH64_LDST32_ABS_LO12_NC	285
+#define R_AARCH64_LDST64_ABS_LO12_NC	286
+#define R_AARCH64_MOVW_PREL_G0		287
+#define R_AARCH64_MOVW_PREL_G0_NC	288
+#define R_AARCH64_MOVW_PREL_G1		289
+#define R_AARCH64_MOVW_PREL_G1_NC	290
+#define R_AARCH64_MOVW_PREL_G2		291
+#define R_AARCH64_MOVW_PREL_G2_NC	292
+#define R_AARCH64_MOVW_PREL_G3		293
+#define R_AARCH64_LDST128_ABS_LO12_NC	299
+#define R_AARCH64_MOVW_GOTOFF_G0	300
+#define R_AARCH64_MOVW_GOTOFF_G0_NC	301
+#define R_AARCH64_MOVW_GOTOFF_G1	302
+#define R_AARCH64_MOVW_GOTOFF_G1_NC	303
+#define R_AARCH64_MOVW_GOTOFF_G2	304
+#define R_AARCH64_MOVW_GOTOFF_G2_NC	305
+#define R_AARCH64_MOVW_GOTOFF_G3	306
+#define R_AARCH64_GOTREL64		307
+#define R_AARCH64_GOTREL32		308
+#define R_AARCH64_GOT_LD_PREL19		309
+#define R_AARCH64_LD64_GOTOFF_LO15	310
+#define R_AARCH64_ADR_GOT_PAGE		311
+#define R_AARCH64_LD64_GOT_LO12_NC	312
+#define R_AARCH64_LD64_GOTPAGE_LO15	313
+
+/* IA-64 specific declarations.  */
+
+/* Processor specific flags for the Ehdr e_flags field.  */
+#define EF_IA_64_MASKOS		0x0000000f	/* os-specific flags */
+#define EF_IA_64_ABI64		0x00000010	/* 64-bit ABI */
+#define EF_IA_64_ARCH		0xff000000	/* arch. version mask */
+
+/* Processor specific values for the Phdr p_type field.  */
+#define PT_IA_64_ARCHEXT	(PT_LOPROC + 0)	/* arch extension bits */
+#define PT_IA_64_UNWIND		(PT_LOPROC + 1)	/* ia64 unwind bits */
+#define PT_IA_64_HP_OPT_ANOT	(PT_LOOS + 0x12)
+#define PT_IA_64_HP_HSL_ANOT	(PT_LOOS + 0x13)
+#define PT_IA_64_HP_STACK	(PT_LOOS + 0x14)
+
+/* Processor specific flags for the Phdr p_flags field.  */
+#define PF_IA_64_NORECOV	0x80000000	/* spec insns w/o recovery */
+
+/* Processor specific values for the Shdr sh_type field.  */
+#define SHT_IA_64_EXT		(SHT_LOPROC + 0) /* extension bits */
+#define SHT_IA_64_UNWIND	(SHT_LOPROC + 1) /* unwind bits */
+
+/* Processor specific flags for the Shdr sh_flags field.  */
+#define SHF_IA_64_SHORT		0x10000000	/* section near gp */
+#define SHF_IA_64_NORECOV	0x20000000	/* spec insns w/o recovery */
+
+/* Processor specific values for the Dyn d_tag field.  */
+#define DT_IA_64_PLT_RESERVE	(DT_LOPROC + 0)
+#define DT_IA_64_NUM		1
+
+/* IA-64 relocations.  */
+#define R_IA64_NONE		0x00	/* none */
+#define R_IA64_IMM14		0x21	/* symbol + addend, add imm14 */
+#define R_IA64_IMM22		0x22	/* symbol + addend, add imm22 */
+#define R_IA64_IMM64		0x23	/* symbol + addend, mov imm64 */
+#define R_IA64_DIR32MSB		0x24	/* symbol + addend, data4 MSB */
+#define R_IA64_DIR32LSB		0x25	/* symbol + addend, data4 LSB */
+#define R_IA64_DIR64MSB		0x26	/* symbol + addend, data8 MSB */
+#define R_IA64_DIR64LSB		0x27	/* symbol + addend, data8 LSB */
+#define R_IA64_GPREL22		0x2a	/* @gprel(sym + add), add imm22 */
+#define R_IA64_GPREL64I		0x2b	/* @gprel(sym + add), mov imm64 */
+#define R_IA64_GPREL32MSB	0x2c	/* @gprel(sym + add), data4 MSB */
+#define R_IA64_GPREL32LSB	0x2d	/* @gprel(sym + add), data4 LSB */
+#define R_IA64_GPREL64MSB	0x2e	/* @gprel(sym + add), data8 MSB */
+#define R_IA64_GPREL64LSB	0x2f	/* @gprel(sym + add), data8 LSB */
+#define R_IA64_LTOFF22		0x32	/* @ltoff(sym + add), add imm22 */
+#define R_IA64_LTOFF64I		0x33	/* @ltoff(sym + add), mov imm64 */
+#define R_IA64_PLTOFF22		0x3a	/* @pltoff(sym + add), add imm22 */
+#define R_IA64_PLTOFF64I	0x3b	/* @pltoff(sym + add), mov imm64 */
+#define R_IA64_PLTOFF64MSB	0x3e	/* @pltoff(sym + add), data8 MSB */
+#define R_IA64_PLTOFF64LSB	0x3f	/* @pltoff(sym + add), data8 LSB */
+#define R_IA64_FPTR64I		0x43	/* @fptr(sym + add), mov imm64 */
+#define R_IA64_FPTR32MSB	0x44	/* @fptr(sym + add), data4 MSB */
+#define R_IA64_FPTR32LSB	0x45	/* @fptr(sym + add), data4 LSB */
+#define R_IA64_FPTR64MSB	0x46	/* @fptr(sym + add), data8 MSB */
+#define R_IA64_FPTR64LSB	0x47	/* @fptr(sym + add), data8 LSB */
+#define R_IA64_PCREL60B		0x48	/* @pcrel(sym + add), brl */
+#define R_IA64_PCREL21B		0x49	/* @pcrel(sym + add), ptb, call */
+#define R_IA64_PCREL21M		0x4a	/* @pcrel(sym + add), chk.s */
+#define R_IA64_PCREL21F		0x4b	/* @pcrel(sym + add), fchkf */
+#define R_IA64_PCREL32MSB	0x4c	/* @pcrel(sym + add), data4 MSB */
+#define R_IA64_PCREL32LSB	0x4d	/* @pcrel(sym + add), data4 LSB */
+#define R_IA64_PCREL64MSB	0x4e	/* @pcrel(sym + add), data8 MSB */
+#define R_IA64_PCREL64LSB	0x4f	/* @pcrel(sym + add), data8 LSB */
+#define R_IA64_LTOFF_FPTR22	0x52	/* @ltoff(@fptr(s+a)), imm22 */
+#define R_IA64_LTOFF_FPTR64I	0x53	/* @ltoff(@fptr(s+a)), imm64 */
+#define R_IA64_LTOFF_FPTR32MSB	0x54	/* @ltoff(@fptr(s+a)), data4 MSB */
+#define R_IA64_LTOFF_FPTR32LSB	0x55	/* @ltoff(@fptr(s+a)), data4 LSB */
+#define R_IA64_LTOFF_FPTR64MSB	0x56	/* @ltoff(@fptr(s+a)), data8 MSB */
+#define R_IA64_LTOFF_FPTR64LSB	0x57	/* @ltoff(@fptr(s+a)), data8 LSB */
+#define R_IA64_SEGREL32MSB	0x5c	/* @segrel(sym + add), data4 MSB */
+#define R_IA64_SEGREL32LSB	0x5d	/* @segrel(sym + add), data4 LSB */
+#define R_IA64_SEGREL64MSB	0x5e	/* @segrel(sym + add), data8 MSB */
+#define R_IA64_SEGREL64LSB	0x5f	/* @segrel(sym + add), data8 LSB */
+#define R_IA64_SECREL32MSB	0x64	/* @secrel(sym + add), data4 MSB */
+#define R_IA64_SECREL32LSB	0x65	/* @secrel(sym + add), data4 LSB */
+#define R_IA64_SECREL64MSB	0x66	/* @secrel(sym + add), data8 MSB */
+#define R_IA64_SECREL64LSB	0x67	/* @secrel(sym + add), data8 LSB */
+#define R_IA64_REL32MSB		0x6c	/* data 4 + REL */
+#define R_IA64_REL32LSB		0x6d	/* data 4 + REL */
+#define R_IA64_REL64MSB		0x6e	/* data 8 + REL */
+#define R_IA64_REL64LSB		0x6f	/* data 8 + REL */
+#define R_IA64_LTV32MSB		0x74	/* symbol + addend, data4 MSB */
+#define R_IA64_LTV32LSB		0x75	/* symbol + addend, data4 LSB */
+#define R_IA64_LTV64MSB		0x76	/* symbol + addend, data8 MSB */
+#define R_IA64_LTV64LSB		0x77	/* symbol + addend, data8 LSB */
+#define R_IA64_PCREL21BI	0x79	/* @pcrel(sym + add), 21bit inst */
+#define R_IA64_PCREL22		0x7a	/* @pcrel(sym + add), 22bit inst */
+#define R_IA64_PCREL64I		0x7b	/* @pcrel(sym + add), 64bit inst */
+#define R_IA64_IPLTMSB		0x80	/* dynamic reloc, imported PLT, MSB */
+#define R_IA64_IPLTLSB		0x81	/* dynamic reloc, imported PLT, LSB */
+#define R_IA64_COPY		0x84	/* copy relocation */
+#define R_IA64_SUB		0x85	/* Addend and symbol difference */
+#define R_IA64_LTOFF22X		0x86	/* LTOFF22, relaxable.  */
+#define R_IA64_LDXMOV		0x87	/* Use of LTOFF22X.  */
+#define R_IA64_TPREL14		0x91	/* @tprel(sym + add), imm14 */
+#define R_IA64_TPREL22		0x92	/* @tprel(sym + add), imm22 */
+#define R_IA64_TPREL64I		0x93	/* @tprel(sym + add), imm64 */
+#define R_IA64_TPREL64MSB	0x96	/* @tprel(sym + add), data8 MSB */
+#define R_IA64_TPREL64LSB	0x97	/* @tprel(sym + add), data8 LSB */
+#define R_IA64_LTOFF_TPREL22	0x9a	/* @ltoff(@tprel(s+a)), imm2 */
+#define R_IA64_DTPMOD64MSB	0xa6	/* @dtpmod(sym + add), data8 MSB */
+#define R_IA64_DTPMOD64LSB	0xa7	/* @dtpmod(sym + add), data8 LSB */
+#define R_IA64_LTOFF_DTPMOD22	0xaa	/* @ltoff(@dtpmod(sym + add)), imm22 */
+#define R_IA64_DTPREL14		0xb1	/* @dtprel(sym + add), imm14 */
+#define R_IA64_DTPREL22		0xb2	/* @dtprel(sym + add), imm22 */
+#define R_IA64_DTPREL64I	0xb3	/* @dtprel(sym + add), imm64 */
+#define R_IA64_DTPREL32MSB	0xb4	/* @dtprel(sym + add), data4 MSB */
+#define R_IA64_DTPREL32LSB	0xb5	/* @dtprel(sym + add), data4 LSB */
+#define R_IA64_DTPREL64MSB	0xb6	/* @dtprel(sym + add), data8 MSB */
+#define R_IA64_DTPREL64LSB	0xb7	/* @dtprel(sym + add), data8 LSB */
+#define R_IA64_LTOFF_DTPREL22	0xba	/* @ltoff(@dtprel(s+a)), imm22 */
+
+/* SH specific declarations */
+
+/* SH relocs.  */
+#define	R_SH_NONE		0
+#define	R_SH_DIR32		1
+#define	R_SH_REL32		2
+#define	R_SH_DIR8WPN		3
+#define	R_SH_IND12W		4
+#define	R_SH_DIR8WPL		5
+#define	R_SH_DIR8WPZ		6
+#define	R_SH_DIR8BP		7
+#define	R_SH_DIR8W		8
+#define	R_SH_DIR8L		9
+#define	R_SH_SWITCH16		25
+#define	R_SH_SWITCH32		26
+#define	R_SH_USES		27
+#define	R_SH_COUNT		28
+#define	R_SH_ALIGN		29
+#define	R_SH_CODE		30
+#define	R_SH_DATA		31
+#define	R_SH_LABEL		32
+#define	R_SH_SWITCH8		33
+#define	R_SH_GNU_VTINHERIT	34
+#define	R_SH_GNU_VTENTRY	35
+#define	R_SH_TLS_GD_32		144
+#define	R_SH_TLS_LD_32		145
+#define	R_SH_TLS_LDO_32		146
+#define	R_SH_TLS_IE_32		147
+#define	R_SH_TLS_LE_32		148
+#define	R_SH_TLS_DTPMOD32	149
+#define	R_SH_TLS_DTPOFF32	150
+#define	R_SH_TLS_TPOFF32	151
+#define	R_SH_GOT32		160
+#define	R_SH_PLT32		161
+#define	R_SH_COPY		162
+#define	R_SH_GLOB_DAT		163
+#define	R_SH_JMP_SLOT		164
+#define	R_SH_RELATIVE		165
+#define	R_SH_GOTOFF		166
+#define	R_SH_GOTPC		167
+/* Keep this the last entry.  */
+#define	R_SH_NUM		256
+
+/* Additional s390 relocs */
+
+#define R_390_NONE		0	/* No reloc.  */
+#define R_390_8			1	/* Direct 8 bit.  */
+#define R_390_12		2	/* Direct 12 bit.  */
+#define R_390_16		3	/* Direct 16 bit.  */
+#define R_390_32		4	/* Direct 32 bit.  */
+#define R_390_PC32		5	/* PC relative 32 bit.	*/
+#define R_390_GOT12		6	/* 12 bit GOT offset.  */
+#define R_390_GOT32		7	/* 32 bit GOT offset.  */
+#define R_390_PLT32		8	/* 32 bit PC relative PLT address.  */
+#define R_390_COPY		9	/* Copy symbol at runtime.  */
+#define R_390_GLOB_DAT		10	/* Create GOT entry.  */
+#define R_390_JMP_SLOT		11	/* Create PLT entry.  */
+#define R_390_RELATIVE		12	/* Adjust by program base.  */
+#define R_390_GOTOFF32		13	/* 32 bit offset to GOT.	 */
+#define R_390_GOTPC		14	/* 32 bit PC relative offset to GOT.  */
+#define R_390_GOT16		15	/* 16 bit GOT offset.  */
+#define R_390_PC16		16	/* PC relative 16 bit.	*/
+#define R_390_PC16DBL		17	/* PC relative 16 bit shifted by 1.  */
+#define R_390_PLT16DBL		18	/* 16 bit PC rel. PLT shifted by 1.  */
+#define R_390_PC32DBL		19	/* PC relative 32 bit shifted by 1.  */
+#define R_390_PLT32DBL		20	/* 32 bit PC rel. PLT shifted by 1.  */
+#define R_390_GOTPCDBL		21	/* 32 bit PC rel. GOT shifted by 1.  */
+#define R_390_64		22	/* Direct 64 bit.  */
+#define R_390_PC64		23	/* PC relative 64 bit.	*/
+#define R_390_GOT64		24	/* 64 bit GOT offset.  */
+#define R_390_PLT64		25	/* 64 bit PC relative PLT address.  */
+#define R_390_GOTENT		26	/* 32 bit PC rel. to GOT entry >> 1. */
+#define R_390_GOTOFF16		27	/* 16 bit offset to GOT. */
+#define R_390_GOTOFF64		28	/* 64 bit offset to GOT. */
+#define R_390_GOTPLT12		29	/* 12 bit offset to jump slot.	*/
+#define R_390_GOTPLT16		30	/* 16 bit offset to jump slot.	*/
+#define R_390_GOTPLT32		31	/* 32 bit offset to jump slot.	*/
+#define R_390_GOTPLT64		32	/* 64 bit offset to jump slot.	*/
+#define R_390_GOTPLTENT		33	/* 32 bit rel. offset to jump slot.  */
+#define R_390_PLTOFF16		34	/* 16 bit offset from GOT to PLT. */
+#define R_390_PLTOFF32		35	/* 32 bit offset from GOT to PLT. */
+#define R_390_PLTOFF64		36	/* 16 bit offset from GOT to PLT. */
+#define R_390_TLS_LOAD		37	/* Tag for load insn in TLS code.  */
+#define R_390_TLS_GDCALL	38	/* Tag for function call in general
+					   dynamic TLS code. */
+#define R_390_TLS_LDCALL	39	/* Tag for function call in local
+					   dynamic TLS code. */
+#define R_390_TLS_GD32		40	/* Direct 32 bit for general dynamic
+					   thread local data.  */
+#define R_390_TLS_GD64		41	/* Direct 64 bit for general dynamic
+					  thread local data.  */
+#define R_390_TLS_GOTIE12	42	/* 12 bit GOT offset for static TLS
+					   block offset.  */
+#define R_390_TLS_GOTIE32	43	/* 32 bit GOT offset for static TLS
+					   block offset.  */
+#define R_390_TLS_GOTIE64	44	/* 64 bit GOT offset for static TLS
+					   block offset. */
+#define R_390_TLS_LDM32		45	/* Direct 32 bit for local dynamic
+					   thread local data in LE code.  */
+#define R_390_TLS_LDM64		46	/* Direct 64 bit for local dynamic
+					   thread local data in LE code.  */
+#define R_390_TLS_IE32		47	/* 32 bit address of GOT entry for
+					   negated static TLS block offset.  */
+#define R_390_TLS_IE64		48	/* 64 bit address of GOT entry for
+					   negated static TLS block offset.  */
+#define R_390_TLS_IEENT		49	/* 32 bit rel. offset to GOT entry for
+					   negated static TLS block offset.  */
+#define R_390_TLS_LE32		50	/* 32 bit negated offset relative to
+					   static TLS block.  */
+#define R_390_TLS_LE64		51	/* 64 bit negated offset relative to
+					   static TLS block.  */
+#define R_390_TLS_LDO32		52	/* 32 bit offset relative to TLS
+					   block.  */
+#define R_390_TLS_LDO64		53	/* 64 bit offset relative to TLS
+					   block.  */
+#define R_390_TLS_DTPMOD	54	/* ID of module containing symbol.  */
+#define R_390_TLS_DTPOFF	55	/* Offset in TLS block.	 */
+#define R_390_TLS_TPOFF		56	/* Negated offset in static TLS
+					   block.  */
+#define R_390_20		57	/* Direct 20 bit.  */
+#define R_390_GOT20		58	/* 20 bit GOT offset.  */
+#define R_390_GOTPLT20		59	/* 20 bit offset to jump slot.  */
+#define R_390_TLS_GOTIE20	60	/* 20 bit GOT offset for static TLS
+					   block offset.  */
+/* Keep this the last entry.  */
+#define R_390_NUM		61
+
+
+/* CRIS relocations.  */
+#define R_CRIS_NONE		0
+#define R_CRIS_8		1
+#define R_CRIS_16		2
+#define R_CRIS_32		3
+#define R_CRIS_8_PCREL		4
+#define R_CRIS_16_PCREL		5
+#define R_CRIS_32_PCREL		6
+#define R_CRIS_GNU_VTINHERIT	7
+#define R_CRIS_GNU_VTENTRY	8
+#define R_CRIS_COPY		9
+#define R_CRIS_GLOB_DAT		10
+#define R_CRIS_JUMP_SLOT	11
+#define R_CRIS_RELATIVE		12
+#define R_CRIS_16_GOT		13
+#define R_CRIS_32_GOT		14
+#define R_CRIS_16_GOTPLT	15
+#define R_CRIS_32_GOTPLT	16
+#define R_CRIS_32_GOTREL	17
+#define R_CRIS_32_PLT_GOTREL	18
+#define R_CRIS_32_PLT_PCREL	19
+
+#define R_CRIS_NUM		20
+
+
+/* AMD x86-64 relocations.  */
+#define R_X86_64_NONE		0	/* No reloc */
+#define R_X86_64_64		1	/* Direct 64 bit  */
+#define R_X86_64_PC32		2	/* PC relative 32 bit signed */
+#define R_X86_64_GOT32		3	/* 32 bit GOT entry */
+#define R_X86_64_PLT32		4	/* 32 bit PLT address */
+#define R_X86_64_COPY		5	/* Copy symbol at runtime */
+#define R_X86_64_GLOB_DAT	6	/* Create GOT entry */
+#define R_X86_64_JUMP_SLOT	7	/* Create PLT entry */
+#define R_X86_64_RELATIVE	8	/* Adjust by program base */
+#define R_X86_64_GOTPCREL	9	/* 32 bit signed PC relative
+					   offset to GOT */
+#define R_X86_64_32		10	/* Direct 32 bit zero extended */
+#define R_X86_64_32S		11	/* Direct 32 bit sign extended */
+#define R_X86_64_16		12	/* Direct 16 bit zero extended */
+#define R_X86_64_PC16		13	/* 16 bit sign extended pc relative */
+#define R_X86_64_8		14	/* Direct 8 bit sign extended  */
+#define R_X86_64_PC8		15	/* 8 bit sign extended pc relative */
+#define R_X86_64_DTPMOD64	16	/* ID of module containing symbol */
+#define R_X86_64_DTPOFF64	17	/* Offset in module's TLS block */
+#define R_X86_64_TPOFF64	18	/* Offset in initial TLS block */
+#define R_X86_64_TLSGD		19	/* 32 bit signed PC relative offset
+					   to two GOT entries for GD symbol */
+#define R_X86_64_TLSLD		20	/* 32 bit signed PC relative offset
+					   to two GOT entries for LD symbol */
+#define R_X86_64_DTPOFF32	21	/* Offset in TLS block */
+#define R_X86_64_GOTTPOFF	22	/* 32 bit signed PC relative offset
+					   to GOT entry for IE symbol */
+#define R_X86_64_TPOFF32	23	/* Offset in initial TLS block */
+
+#define R_X86_64_NUM		24
+
+
+/* AM33 relocations.  */
+#define R_MN10300_NONE		0	/* No reloc.  */
+#define R_MN10300_32		1	/* Direct 32 bit.  */
+#define R_MN10300_16		2	/* Direct 16 bit.  */
+#define R_MN10300_8		3	/* Direct 8 bit.  */
+#define R_MN10300_PCREL32	4	/* PC-relative 32-bit.  */
+#define R_MN10300_PCREL16	5	/* PC-relative 16-bit signed.  */
+#define R_MN10300_PCREL8	6	/* PC-relative 8-bit signed.  */
+#define R_MN10300_GNU_VTINHERIT	7	/* Ancient C++ vtable garbage... */
+#define R_MN10300_GNU_VTENTRY	8	/* ... collection annotation.  */
+#define R_MN10300_24		9	/* Direct 24 bit.  */
+#define R_MN10300_GOTPC32	10	/* 32-bit PCrel offset to GOT.  */
+#define R_MN10300_GOTPC16	11	/* 16-bit PCrel offset to GOT.  */
+#define R_MN10300_GOTOFF32	12	/* 32-bit offset from GOT.  */
+#define R_MN10300_GOTOFF24	13	/* 24-bit offset from GOT.  */
+#define R_MN10300_GOTOFF16	14	/* 16-bit offset from GOT.  */
+#define R_MN10300_PLT32		15	/* 32-bit PCrel to PLT entry.  */
+#define R_MN10300_PLT16		16	/* 16-bit PCrel to PLT entry.  */
+#define R_MN10300_GOT32		17	/* 32-bit offset to GOT entry.  */
+#define R_MN10300_GOT24		18	/* 24-bit offset to GOT entry.  */
+#define R_MN10300_GOT16		19	/* 16-bit offset to GOT entry.  */
+#define R_MN10300_COPY		20	/* Copy symbol at runtime.  */
+#define R_MN10300_GLOB_DAT	21	/* Create GOT entry.  */
+#define R_MN10300_JMP_SLOT	22	/* Create PLT entry.  */
+#define R_MN10300_RELATIVE	23	/* Adjust by program base.  */
+
+#define R_MN10300_NUM		24
+
+
+/* M32R relocs.  */
+#define R_M32R_NONE		0	/* No reloc. */
+#define R_M32R_16		1	/* Direct 16 bit. */
+#define R_M32R_32		2	/* Direct 32 bit. */
+#define R_M32R_24		3	/* Direct 24 bit. */
+#define R_M32R_10_PCREL		4	/* PC relative 10 bit shifted. */
+#define R_M32R_18_PCREL		5	/* PC relative 18 bit shifted. */
+#define R_M32R_26_PCREL		6	/* PC relative 26 bit shifted. */
+#define R_M32R_HI16_ULO		7	/* High 16 bit with unsigned low. */
+#define R_M32R_HI16_SLO		8	/* High 16 bit with signed low. */
+#define R_M32R_LO16		9	/* Low 16 bit. */
+#define R_M32R_SDA16		10	/* 16 bit offset in SDA. */
+#define R_M32R_GNU_VTINHERIT	11
+#define R_M32R_GNU_VTENTRY	12
+/* M32R relocs use SHT_RELA.  */
+#define R_M32R_16_RELA		33	/* Direct 16 bit. */
+#define R_M32R_32_RELA		34	/* Direct 32 bit. */
+#define R_M32R_24_RELA		35	/* Direct 24 bit. */
+#define R_M32R_10_PCREL_RELA	36	/* PC relative 10 bit shifted. */
+#define R_M32R_18_PCREL_RELA	37	/* PC relative 18 bit shifted. */
+#define R_M32R_26_PCREL_RELA	38	/* PC relative 26 bit shifted. */
+#define R_M32R_HI16_ULO_RELA	39	/* High 16 bit with unsigned low */
+#define R_M32R_HI16_SLO_RELA	40	/* High 16 bit with signed low */
+#define R_M32R_LO16_RELA	41	/* Low 16 bit */
+#define R_M32R_SDA16_RELA	42	/* 16 bit offset in SDA */
+#define R_M32R_RELA_GNU_VTINHERIT	43
+#define R_M32R_RELA_GNU_VTENTRY	44
+#define R_M32R_REL32		45	/* PC relative 32 bit.  */
+
+#define R_M32R_GOT24		48	/* 24 bit GOT entry */
+#define R_M32R_26_PLTREL	49	/* 26 bit PC relative to PLT shifted */
+#define R_M32R_COPY		50	/* Copy symbol at runtime */
+#define R_M32R_GLOB_DAT		51	/* Create GOT entry */
+#define R_M32R_JMP_SLOT		52	/* Create PLT entry */
+#define R_M32R_RELATIVE		53	/* Adjust by program base */
+#define R_M32R_GOTOFF		54	/* 24 bit offset to GOT */
+#define R_M32R_GOTPC24		55	/* 24 bit PC relative offset to GOT */
+#define R_M32R_GOT16_HI_ULO	56	/* High 16 bit GOT entry with unsigned
+					   low */
+#define R_M32R_GOT16_HI_SLO	57	/* High 16 bit GOT entry with signed
+					   low */
+#define R_M32R_GOT16_LO		58	/* Low 16 bit GOT entry */
+#define R_M32R_GOTPC_HI_ULO	59	/* High 16 bit PC relative offset to
+					   GOT with unsigned low */
+#define R_M32R_GOTPC_HI_SLO	60	/* High 16 bit PC relative offset to
+					   GOT with signed low */
+#define R_M32R_GOTPC_LO		61	/* Low 16 bit PC relative offset to
+					   GOT */
+#define R_M32R_GOTOFF_HI_ULO	62	/* High 16 bit offset to GOT
+					   with unsigned low */
+#define R_M32R_GOTOFF_HI_SLO	63	/* High 16 bit offset to GOT
+					   with signed low */
+#define R_M32R_GOTOFF_LO	64	/* Low 16 bit offset to GOT */
+#define R_M32R_NUM		256	/* Keep this the last entry. */
+
+
+/* RISC-V relocation types */
+#define R_RISCV_NONE		0
+#define R_RISCV_32		2
+#define R_RISCV_REL32		3
+#define R_RISCV_JAL		4
+#define R_RISCV_HI20		5
+#define R_RISCV_LO12_I		6
+#define R_RISCV_LO12_S		7
+#define R_RISCV_PCREL_LO12_I	8
+#define R_RISCV_PCREL_LO12_S	9
+#define R_RISCV_BRANCH		10
+#define R_RISCV_CALL		11
+#define R_RISCV_PCREL_HI20	12
+#define R_RISCV_CALL_PLT	13
+#define R_RISCV_64		18
+#define R_RISCV_GOT_HI20	22
+#define R_RISCV_GOT_LO12	23
+#define R_RISCV_COPY		24
+#define R_RISCV_JUMP_SLOT	25
+/* TLS relocations */
+#define R_RISCV_TPREL_HI20	30
+#define R_RISCV_TPREL_LO12_I	31
+#define R_RISCV_TPREL_LO12_S	32
+#define R_RISCV_TLS_DTPMOD32	38
+#define R_RISCV_TLS_DTPREL32	39
+#define R_RISCV_TLS_DTPMOD64	40
+#define R_RISCV_TLS_DTPREL64	41
+#define R_RISCV_TLS_GD		42
+#define R_RISCV_TLS_DTPREL_HI16	44
+#define R_RISCV_TLS_DTPREL_LO16	45
+#define R_RISCV_TLS_GOTTPREL	46
+#define R_RISCV_TLS_TPREL32	47
+#define R_RISCV_TLS_TPREL64	48
+#define R_RISCV_TLS_GOT_HI20	51
+#define R_RISCV_TLS_GOT_LO12	52
+#define R_RISCV_TLS_GD_HI20	53
+#define R_RISCV_TLS_GD_LO12	54
+#define R_RISCV_GLOB_DAT	57
+#define R_RISCV_ADD32		58
+#define R_RISCV_ADD64		59
+#define R_RISCV_SUB32		60
+#define R_RISCV_SUB64		61
+
+#define EM_RISCV	0xF3
+
+/* PPC64, a.k.a. Power8 relocation types
+ * N.B. The instruction sets still seem to have their
+ * differences but the ELF types have converged?
+ * TODO: how much of this do we really need in here?
+ * Or is it better just to bring it all in?
+ */
+/* PowerPC64 relocations defined by the ABIs */
+#define R_PPC64_NONE		R_PPC_NONE
+#define R_PPC64_ADDR32		R_PPC_ADDR32 /* 32bit absolute address */
+#define R_PPC64_ADDR24		R_PPC_ADDR24 /* 26bit address, word aligned */
+#define R_PPC64_ADDR16		R_PPC_ADDR16 /* 16bit absolute address */
+#define R_PPC64_ADDR16_LO	R_PPC_ADDR16_LO	/* lower 16bits of address */
+#define R_PPC64_ADDR16_HI	R_PPC_ADDR16_HI	/* high 16bits of address. */
+#define R_PPC64_ADDR16_HA	R_PPC_ADDR16_HA /* adjusted high 16bits.  */
+#define R_PPC64_ADDR14		R_PPC_ADDR14 /* 16bit address, word aligned */
+#define R_PPC64_ADDR14_BRTAKEN	R_PPC_ADDR14_BRTAKEN
+#define R_PPC64_ADDR14_BRNTAKEN	R_PPC_ADDR14_BRNTAKEN
+#define R_PPC64_REL24		R_PPC_REL24 /* PC-rel. 26 bit, word aligned */
+#define R_PPC64_REL14		R_PPC_REL14 /* PC relative 16 bit */
+#define R_PPC64_REL14_BRTAKEN	R_PPC_REL14_BRTAKEN
+#define R_PPC64_REL14_BRNTAKEN	R_PPC_REL14_BRNTAKEN
+#define R_PPC64_GOT16		R_PPC_GOT16
+#define R_PPC64_GOT16_LO	R_PPC_GOT16_LO
+#define R_PPC64_GOT16_HI	R_PPC_GOT16_HI
+#define R_PPC64_GOT16_HA	R_PPC_GOT16_HA
+
+#define R_PPC64_COPY		R_PPC_COPY
+#define R_PPC64_GLOB_DAT	R_PPC_GLOB_DAT
+#define R_PPC64_JMP_SLOT	R_PPC_JMP_SLOT
+#define R_PPC64_RELATIVE	R_PPC_RELATIVE
+
+#define R_PPC64_UADDR32		R_PPC_UADDR32
+#define R_PPC64_UADDR16		R_PPC_UADDR16
+#define R_PPC64_REL32		R_PPC_REL32
+#define R_PPC64_PLT32		R_PPC_PLT32
+#define R_PPC64_PLTREL32	R_PPC_PLTREL32
+#define R_PPC64_PLT16_LO	R_PPC_PLT16_LO
+#define R_PPC64_PLT16_HI	R_PPC_PLT16_HI
+#define R_PPC64_PLT16_HA	R_PPC_PLT16_HA
+
+#define R_PPC64_SECTOFF		R_PPC_SECTOFF
+#define R_PPC64_SECTOFF_LO	R_PPC_SECTOFF_LO
+#define R_PPC64_SECTOFF_HI	R_PPC_SECTOFF_HI
+#define R_PPC64_SECTOFF_HA	R_PPC_SECTOFF_HA
+#define R_PPC64_ADDR30		37 /* word30 (S + A - P) >> 2 */
+#define R_PPC64_ADDR64		38 /* doubleword64 S + A */
+#define R_PPC64_ADDR16_HIGHER	39 /* half16 #higher(S + A) */
+#define R_PPC64_ADDR16_HIGHERA	40 /* half16 #highera(S + A) */
+#define R_PPC64_ADDR16_HIGHEST	41 /* half16 #highest(S + A) */
+#define R_PPC64_ADDR16_HIGHESTA	42 /* half16 #highesta(S + A) */
+#define R_PPC64_UADDR64		43 /* doubleword64 S + A */
+#define R_PPC64_REL64		44 /* doubleword64 S + A - P */
+#define R_PPC64_PLT64		45 /* doubleword64 L + A */
+#define R_PPC64_PLTREL64	46 /* doubleword64 L + A - P */
+#define R_PPC64_TOC16		47 /* half16* S + A - .TOC */
+#define R_PPC64_TOC16_LO	48 /* half16 #lo(S + A - .TOC.) */
+#define R_PPC64_TOC16_HI	49 /* half16 #hi(S + A - .TOC.) */
+#define R_PPC64_TOC16_HA	50 /* half16 #ha(S + A - .TOC.) */
+#define R_PPC64_TOC		51 /* doubleword64 .TOC */
+#define R_PPC64_PLTGOT16	52 /* half16* M + A */
+#define R_PPC64_PLTGOT16_LO	53 /* half16 #lo(M + A) */
+#define R_PPC64_PLTGOT16_HI	54 /* half16 #hi(M + A) */
+#define R_PPC64_PLTGOT16_HA	55 /* half16 #ha(M + A) */
+
+#define R_PPC64_ADDR16_DS	56 /* half16ds* (S + A) >> 2 */
+#define R_PPC64_ADDR16_LO_DS	57 /* half16ds  #lo(S + A) >> 2 */
+#define R_PPC64_GOT16_DS	58 /* half16ds* (G + A) >> 2 */
+#define R_PPC64_GOT16_LO_DS	59 /* half16ds  #lo(G + A) >> 2 */
+#define R_PPC64_PLT16_LO_DS	60 /* half16ds  #lo(L + A) >> 2 */
+#define R_PPC64_SECTOFF_DS	61 /* half16ds* (R + A) >> 2 */
+#define R_PPC64_SECTOFF_LO_DS	62 /* half16ds  #lo(R + A) >> 2 */
+#define R_PPC64_TOC16_DS	63 /* half16ds* (S + A - .TOC.) >> 2 */
+#define R_PPC64_TOC16_LO_DS	64 /* half16ds  #lo(S + A - .TOC.) >> 2 */
+#define R_PPC64_PLTGOT16_DS	65 /* half16ds* (M + A) >> 2 */
+#define R_PPC64_PLTGOT16_LO_DS	66 /* half16ds  #lo(M + A) >> 2 */
+
+/* PowerPC64 relocations defined for the TLS access ABI.  */
+#define R_PPC64_TLS		67 /* none	(sym+add)@tls */
+#define R_PPC64_DTPMOD64	68 /* doubleword64 (sym+add)@dtpmod */
+#define R_PPC64_TPREL16		69 /* half16*	(sym+add)@tprel */
+#define R_PPC64_TPREL16_LO	70 /* half16	(sym+add)@tprel@l */
+#define R_PPC64_TPREL16_HI	71 /* half16	(sym+add)@tprel@h */
+#define R_PPC64_TPREL16_HA	72 /* half16	(sym+add)@tprel@ha */
+#define R_PPC64_TPREL64		73 /* doubleword64 (sym+add)@tprel */
+#define R_PPC64_DTPREL16	74 /* half16*	(sym+add)@dtprel */
+#define R_PPC64_DTPREL16_LO	75 /* half16	(sym+add)@dtprel@l */
+#define R_PPC64_DTPREL16_HI	76 /* half16	(sym+add)@dtprel@h */
+#define R_PPC64_DTPREL16_HA	77 /* half16	(sym+add)@dtprel@ha */
+#define R_PPC64_DTPREL64	78 /* doubleword64 (sym+add)@dtprel */
+#define R_PPC64_GOT_TLSGD16	79 /* half16*	(sym+add)@got@tlsgd */
+#define R_PPC64_GOT_TLSGD16_LO	80 /* half16	(sym+add)@got@tlsgd@l */
+#define R_PPC64_GOT_TLSGD16_HI	81 /* half16	(sym+add)@got@tlsgd@h */
+#define R_PPC64_GOT_TLSGD16_HA	82 /* half16	(sym+add)@got@tlsgd@ha */
+#define R_PPC64_GOT_TLSLD16	83 /* half16*	(sym+add)@got@tlsld */
+#define R_PPC64_GOT_TLSLD16_LO	84 /* half16	(sym+add)@got@tlsld@l */
+#define R_PPC64_GOT_TLSLD16_HI	85 /* half16	(sym+add)@got@tlsld@h */
+#define R_PPC64_GOT_TLSLD16_HA	86 /* half16	(sym+add)@got@tlsld@ha */
+#define R_PPC64_GOT_TPREL16_DS	87 /* half16ds*	(sym+add)@got@tprel */
+#define R_PPC64_GOT_TPREL16_LO_DS 88 /* half16ds (sym+add)@got@tprel@l */
+#define R_PPC64_GOT_TPREL16_HI	89 /* half16	(sym+add)@got@tprel@h */
+#define R_PPC64_GOT_TPREL16_HA	90 /* half16	(sym+add)@got@tprel@ha */
+#define R_PPC64_GOT_DTPREL16_DS	91 /* half16ds*	(sym+add)@got@dtprel */
+#define R_PPC64_GOT_DTPREL16_LO_DS 92 /* half16ds (sym+add)@got@dtprel@l */
+#define R_PPC64_GOT_DTPREL16_HI	93 /* half16	(sym+add)@got@dtprel@h */
+#define R_PPC64_GOT_DTPREL16_HA	94 /* half16	(sym+add)@got@dtprel@ha */
+#define R_PPC64_TPREL16_DS	95 /* half16ds*	(sym+add)@tprel */
+#define R_PPC64_TPREL16_LO_DS	96 /* half16ds	(sym+add)@tprel@l */
+#define R_PPC64_TPREL16_HIGHER	97 /* half16	(sym+add)@tprel@higher */
+#define R_PPC64_TPREL16_HIGHERA	98 /* half16	(sym+add)@tprel@highera */
+#define R_PPC64_TPREL16_HIGHEST	99 /* half16	(sym+add)@tprel@highest */
+#define R_PPC64_TPREL16_HIGHESTA 100 /* half16	(sym+add)@tprel@highesta */
+#define R_PPC64_DTPREL16_DS	101 /* half16ds* (sym+add)@dtprel */
+#define R_PPC64_DTPREL16_LO_DS	102 /* half16ds	(sym+add)@dtprel@l */
+#define R_PPC64_DTPREL16_HIGHER	103 /* half16	(sym+add)@dtprel@higher */
+#define R_PPC64_DTPREL16_HIGHERA 104 /* half16	(sym+add)@dtprel@highera */
+#define R_PPC64_DTPREL16_HIGHEST 105 /* half16	(sym+add)@dtprel@highest */
+#define R_PPC64_DTPREL16_HIGHESTA 106 /* half16	(sym+add)@dtprel@highesta */
+#define R_PPC64_TLSGD		107 /* none	(sym+add)@tlsgd */
+#define R_PPC64_TLSLD		108 /* none	(sym+add)@tlsld */
+#define R_PPC64_TOCSAVE		109 /* none */
+
+/* Added when HA and HI relocs were changed to report overflows.  */
+#define R_PPC64_ADDR16_HIGH	110
+#define R_PPC64_ADDR16_HIGHA	111
+#define R_PPC64_TPREL16_HIGH	112
+#define R_PPC64_TPREL16_HIGHA	113
+#define R_PPC64_DTPREL16_HIGH	114
+#define R_PPC64_DTPREL16_HIGHA	115
+
+/* GNU extension to support local ifunc.  */
+#define R_PPC64_JMP_IREL	247
+#define R_PPC64_IRELATIVE	248
+#define R_PPC64_REL16		249	/* half16   (sym+add-.) */
+#define R_PPC64_REL16_LO	250	/* half16   (sym+add-.)@l */
+#define R_PPC64_REL16_HI	251	/* half16   (sym+add-.)@h */
+#define R_PPC64_REL16_HA	252	/* half16   (sym+add-.)@ha */
+
+/* e_flags bits specifying ABI.
+   1 for original function descriptor using ABI,
+   2 for revised ABI without function descriptors,
+   0 for unspecified or not using any features affected by the differences.  */
+#define EF_PPC64_ABI	3
+
+/* PowerPC64 specific values for the Dyn d_tag field.  */
+#define DT_PPC64_GLINK  (DT_LOPROC + 0)
+#define DT_PPC64_OPD	(DT_LOPROC + 1)
+#define DT_PPC64_OPDSZ	(DT_LOPROC + 2)
+#define DT_PPC64_OPT	(DT_LOPROC + 3)
+#define DT_PPC64_NUM    3
+
+/* PowerPC64 specific values for the DT_PPC64_OPT Dyn entry.  */
+#define PPC64_OPT_TLS		1
+#define PPC64_OPT_MULTI_TOC	2
+
+/* PowerPC64 specific values for the Elf64_Sym st_other field.  */
+#define STO_PPC64_LOCAL_BIT	5
+#define STO_PPC64_LOCAL_MASK	(7 << STO_PPC64_LOCAL_BIT)
+#define PPC64_LOCAL_ENTRY_OFFSET(other)				\
+(((1 << (((other) & STO_PPC64_LOCAL_MASK) >> STO_PPC64_LOCAL_BIT)) >> 2) << 2)
+
+#define EM_PPC64	21		/* PowerPC 64-bit */
+
+#endif	/* elf.h */
diff --git a/tools/cbfstool/elfheaders.c b/tools/cbfstool/elfheaders.c
new file mode 100644
index 0000000000..676a635b8a
--- /dev/null
+++ b/tools/cbfstool/elfheaders.c
@@ -0,0 +1,1470 @@
+/*
+ * elf header parsing.
+ *
+ * Copyright (C) 2013 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#include "elfparsing.h"
+#include "common.h"
+#include "cbfs.h"
+
+/*
+ * Short form: this is complicated, but we've tried making it simple
+ * and we keep hitting problems with our ELF parsing.
+ *
+ * The ELF parsing situation has always been a bit tricky.  In fact,
+ * we (and most others) have been getting it wrong in small ways for
+ * years. Recently this has caused real trouble for the ARM V8 build.
+ * In this file we attempt to finally get it right for all variations
+ * of endian-ness and word size and target architectures and
+ * architectures we might get run on. Phew!. To do this we borrow a
+ * page from the FreeBSD NFS xdr model (see elf_ehdr and elf_phdr),
+ * the Plan 9 endianness functions (see xdr.c), and Go interfaces (see
+ * how we use buffer structs in this file). This ends up being a bit
+ * wordy at the lowest level, but greatly simplifies the elf parsing
+ * code and removes a common source of bugs, namely, forgetting to
+ * flip type endianness when referencing a struct member.
+ *
+ * ELF files can have four combinations of data layout: 32/64, and
+ * big/little endian.  Further, to add to the fun, depending on the
+ * word size, the size of the ELF structs varies. The coreboot SELF
+ * format is simpler in theory: it's supposed to be always BE, and the
+ * various struct members allow room for growth: the entry point is
+ * always 64 bits, for example, so the size of a SELF struct is
+ * constant, regardless of target architecture word size.  Hence, we
+ * need to do some transformation of the ELF files.
+ *
+ * A given architecture, realistically, only supports one of the four
+ * combinations at a time as the 'native' format. Hence, our code has
+ * been sprinkled with every variation of [nh]to[hn][sll] over the
+ * years. We've never quite gotten it all right, however, and a quick
+ * pass over this code revealed another bug.  It's all worked because,
+ * until now, all the working platforms that had CBFS were 32 LE. Even then,
+ * however, bugs crept in: we recently realized that we're not
+ * transforming the entry point to big format when we store into the
+ * SELF image.
+ *
+ * The problem is essentially an XDR operation:
+ * we have something in a foreign format and need to transform it.
+ * It's most like XDR because:
+ * 1) the byte order can be wrong
+ * 2) the word size can be wrong
+ * 3) the size of elements in the stream depends on the value
+ *    of other elements in the stream
+ * it's not like XDR because:
+ * 1) the byte order can be right
+ * 2) the word size can be right
+ * 3) the struct members are all on a natural alignment
+ *
+ * Hence, this new approach.  To cover word size issues, we *always*
+ * transform the two structs we care about, the file header and
+ * program header, into a native struct in the 64 bit format:
+ *
+ * [32,little] -> [Elf64_Ehdr, Elf64_Phdr]
+ * [64,little] -> [Elf64_Ehdr, Elf64_Phdr]
+ * [32,big] -> [Elf64_Ehdr, Elf64_Phdr]
+ * [64,big] -> [Elf64_Ehdr, Elf64_Phdr]
+ * Then we just use those structs, and all the need for inline ntoh* goes away,
+ * as well as all the chances for error.
+ * This works because all the SELF structs have fields large enough for
+ * the largest ELF 64 struct members, and all the Elf64 struct members
+ * are at least large enough for all ELF 32 struct members.
+ * We end up with one function to do all our ELF parsing, and two functions
+ * to transform the headers. For the put case, we also have
+ * XDR functions, and hopefully we'll never again spend 5 years with the
+ * wrong endian-ness on an output value :-)
+ * This should work for all word sizes and endianness we hope to target.
+ * I *really* don't want to be here for 128 bit addresses.
+ *
+ * The parse functions are called with a pointer to an input buffer
+ * struct. One might ask: are there enough bytes in the input buffer?
+ * We know there need to be at *least* sizeof(Elf32_Ehdr) +
+ * sizeof(Elf32_Phdr) bytes. Realistically, there has to be some data
+ * too.  If we start to worry, though we have not in the past, we
+ * might apply the simple test: the input buffer needs to be at least
+ * sizeof(Elf64_Ehdr) + sizeof(Elf64_Phdr) bytes because, even if it's
+ * ELF 32, there's got to be *some* data! This is not theoretically
+ * accurate but it is actually good enough in practice. It allows the
+ * header transformation code to ignore the possibility of underrun.
+ *
+ * We also must accommodate different ELF files, and hence formats,
+ * in the same cbfs invocation. We might load a 64-bit payload
+ * on a 32-bit machine; we might even have a mixed armv7/armv8
+ * SOC or even a system with an x86/ARM!
+ *
+ * A possibly problematic (though unlikely to be so) assumption
+ * is that we expect the BIOS to remain in the lowest 32 bits
+ * of the physical address space. Since ARMV8 has standardized
+ * on that, and x86_64 also has, this seems a safe assumption.
+ *
+ * To repeat, ELF structs are different sizes because ELF struct
+ * members are different sizes, depending on values in the ELF file
+ * header. For this we use the functions defined in xdr.c, which
+ * consume bytes, convert the endianness, and advance the data pointer
+ * in the buffer struct.
+ */
+
+
+static int iself(const void *input)
+{
+	const Elf32_Ehdr *ehdr = input;
+	return !memcmp(ehdr->e_ident, ELFMAG, 4);
+}
+
+/* Get the ident array, so we can figure out
+ * endian-ness, word size, and in future other useful
+ * parameters
+ */
+static void
+elf_eident(struct buffer *input, Elf64_Ehdr *ehdr)
+{
+	bgets(input, ehdr->e_ident, sizeof(ehdr->e_ident));
+}
+
+
+static int
+check_size(const struct buffer *b, size_t offset, size_t size, const char *desc)
+{
+	if (size == 0)
+		return 0;
+
+	if (offset >= buffer_size(b) || (offset + size) > buffer_size(b)) {
+		ERROR("The file is not large enough for the '%s'. "
+		      "%zu bytes @ offset %zu, input %zu bytes.\n",
+		      desc, size, offset, buffer_size(b));
+		return -1;
+	}
+	return 0;
+}
+
+static void
+elf_ehdr(struct buffer *input, Elf64_Ehdr *ehdr, struct xdr *xdr, int bit64)
+{
+	ehdr->e_type = xdr->get16(input);
+	ehdr->e_machine = xdr->get16(input);
+	ehdr->e_version = xdr->get32(input);
+	if (bit64){
+		ehdr->e_entry = xdr->get64(input);
+		ehdr->e_phoff = xdr->get64(input);
+		ehdr->e_shoff = xdr->get64(input);
+	} else {
+		ehdr->e_entry = xdr->get32(input);
+		ehdr->e_phoff = xdr->get32(input);
+		ehdr->e_shoff = xdr->get32(input);
+	}
+	ehdr->e_flags = xdr->get32(input);
+	ehdr->e_ehsize = xdr->get16(input);
+	ehdr->e_phentsize = xdr->get16(input);
+	ehdr->e_phnum = xdr->get16(input);
+	ehdr->e_shentsize = xdr->get16(input);
+	ehdr->e_shnum = xdr->get16(input);
+	ehdr->e_shstrndx = xdr->get16(input);
+}
+
+static void
+elf_phdr(struct buffer *pinput, Elf64_Phdr *phdr,
+	 int entsize, struct xdr *xdr, int bit64)
+{
+	/*
+	 * The entsize need not be sizeof(*phdr).
+	 * Hence, it is easier to keep a copy of the input,
+	 * as the xdr functions may not advance the input
+	 * pointer the full entsize; rather than get tricky
+	 * we just advance it below.
+	 */
+	struct buffer input;
+	buffer_clone(&input, pinput);
+	if (bit64){
+		phdr->p_type = xdr->get32(&input);
+		phdr->p_flags = xdr->get32(&input);
+		phdr->p_offset = xdr->get64(&input);
+		phdr->p_vaddr = xdr->get64(&input);
+		phdr->p_paddr = xdr->get64(&input);
+		phdr->p_filesz = xdr->get64(&input);
+		phdr->p_memsz = xdr->get64(&input);
+		phdr->p_align = xdr->get64(&input);
+	} else {
+		phdr->p_type = xdr->get32(&input);
+		phdr->p_offset = xdr->get32(&input);
+		phdr->p_vaddr = xdr->get32(&input);
+		phdr->p_paddr = xdr->get32(&input);
+		phdr->p_filesz = xdr->get32(&input);
+		phdr->p_memsz = xdr->get32(&input);
+		phdr->p_flags = xdr->get32(&input);
+		phdr->p_align = xdr->get32(&input);
+	}
+	buffer_seek(pinput, entsize);
+}
+
+static void
+elf_shdr(struct buffer *pinput, Elf64_Shdr *shdr,
+	 int entsize, struct xdr *xdr, int bit64)
+{
+	/*
+	 * The entsize need not be sizeof(*shdr).
+	 * Hence, it is easier to keep a copy of the input,
+	 * as the xdr functions may not advance the input
+	 * pointer the full entsize; rather than get tricky
+	 * we just advance it below.
+	 */
+	struct buffer input = *pinput;
+	if (bit64){
+		shdr->sh_name = xdr->get32(&input);
+		shdr->sh_type = xdr->get32(&input);
+		shdr->sh_flags = xdr->get64(&input);
+		shdr->sh_addr = xdr->get64(&input);
+		shdr->sh_offset = xdr->get64(&input);
+		shdr->sh_size= xdr->get64(&input);
+		shdr->sh_link = xdr->get32(&input);
+		shdr->sh_info = xdr->get32(&input);
+		shdr->sh_addralign = xdr->get64(&input);
+		shdr->sh_entsize = xdr->get64(&input);
+	} else {
+		shdr->sh_name = xdr->get32(&input);
+		shdr->sh_type = xdr->get32(&input);
+		shdr->sh_flags = xdr->get32(&input);
+		shdr->sh_addr = xdr->get32(&input);
+		shdr->sh_offset = xdr->get32(&input);
+		shdr->sh_size = xdr->get32(&input);
+		shdr->sh_link = xdr->get32(&input);
+		shdr->sh_info = xdr->get32(&input);
+		shdr->sh_addralign = xdr->get32(&input);
+		shdr->sh_entsize = xdr->get32(&input);
+	}
+	buffer_seek(pinput, entsize);
+}
+
+static int
+phdr_read(const struct buffer *in, struct parsed_elf *pelf,
+          struct xdr *xdr, int bit64)
+{
+	struct buffer b;
+	Elf64_Phdr *phdr;
+	Elf64_Ehdr *ehdr;
+	int i;
+
+	ehdr = &pelf->ehdr;
+	/* cons up an input buffer for the headers.
+	 * Note that the program headers can be anywhere,
+	 * per the ELF spec, You'd be surprised how many ELF
+	 * readers miss this little detail.
+	 */
+	buffer_splice(&b, in, ehdr->e_phoff,
+		      (uint32_t)ehdr->e_phentsize * ehdr->e_phnum);
+	if (check_size(in, ehdr->e_phoff, buffer_size(&b), "program headers"))
+		return -1;
+
+	/* gather up all the phdrs.
+	 * We do them all at once because there is more
+	 * than one loop over all the phdrs.
+	 */
+	phdr = calloc(ehdr->e_phnum, sizeof(*phdr));
+	for (i = 0; i < ehdr->e_phnum; i++) {
+		DEBUG("Parsing segment %d\n", i);
+		elf_phdr(&b, &phdr[i], ehdr->e_phentsize, xdr, bit64);
+
+		/* Ensure the contents are valid within the elf file. */
+		if (check_size(in, phdr[i].p_offset, phdr[i].p_filesz,
+	                  "segment contents")) {
+			free(phdr);
+			return -1;
+		}
+	}
+
+	pelf->phdr = phdr;
+
+	return 0;
+}
+
+static int
+shdr_read(const struct buffer *in, struct parsed_elf *pelf,
+          struct xdr *xdr, int bit64)
+{
+	struct buffer b;
+	Elf64_Shdr *shdr;
+	Elf64_Ehdr *ehdr;
+	int i;
+
+	ehdr = &pelf->ehdr;
+
+	/* cons up an input buffer for the section headers.
+	 * Note that the section headers can be anywhere,
+	 * per the ELF spec, You'd be surprised how many ELF
+	 * readers miss this little detail.
+	 */
+	buffer_splice(&b, in, ehdr->e_shoff,
+		      (uint32_t)ehdr->e_shentsize * ehdr->e_shnum);
+	if (check_size(in, ehdr->e_shoff, buffer_size(&b), "section headers"))
+		return -1;
+
+	/* gather up all the shdrs. */
+	shdr = calloc(ehdr->e_shnum, sizeof(*shdr));
+	for (i = 0; i < ehdr->e_shnum; i++) {
+		DEBUG("Parsing section %d\n", i);
+		elf_shdr(&b, &shdr[i], ehdr->e_shentsize, xdr, bit64);
+	}
+
+	pelf->shdr = shdr;
+
+	return 0;
+}
+
+static int
+reloc_read(const struct buffer *in, struct parsed_elf *pelf,
+           struct xdr *xdr, int bit64)
+{
+	struct buffer b;
+	Elf64_Word i;
+	Elf64_Ehdr *ehdr;
+
+	ehdr = &pelf->ehdr;
+	pelf->relocs = calloc(ehdr->e_shnum, sizeof(Elf64_Rela *));
+
+	/* Allocate array for each section that contains relocation entries. */
+	for (i = 0; i < ehdr->e_shnum; i++) {
+		Elf64_Shdr *shdr;
+		Elf64_Rela *rela;
+		Elf64_Xword j;
+		Elf64_Xword nrelocs;
+		int is_rela;
+
+		shdr = &pelf->shdr[i];
+
+		/* Only process REL and RELA sections. */
+		if (shdr->sh_type != SHT_REL && shdr->sh_type != SHT_RELA)
+			continue;
+
+		DEBUG("Checking relocation section %u\n", i);
+
+		/* Ensure the section that relocations apply is a valid. */
+		if (shdr->sh_info >= ehdr->e_shnum ||
+		    shdr->sh_info == SHN_UNDEF) {
+			ERROR("Relocations apply to an invalid section: %u\n",
+			      shdr[i].sh_info);
+			return -1;
+		}
+
+		is_rela = shdr->sh_type == SHT_RELA;
+
+		/* Determine the number relocations in this section. */
+		nrelocs = shdr->sh_size / shdr->sh_entsize;
+
+		pelf->relocs[i] = calloc(nrelocs, sizeof(Elf64_Rela));
+
+		buffer_splice(&b, in, shdr->sh_offset, shdr->sh_size);
+		if (check_size(in, shdr->sh_offset, buffer_size(&b),
+		               "relocation section")) {
+			ERROR("Relocation section %u failed.\n", i);
+			return -1;
+		}
+
+		rela = pelf->relocs[i];
+		for (j = 0; j < nrelocs; j++) {
+			if (bit64) {
+				rela->r_offset = xdr->get64(&b);
+				rela->r_info = xdr->get64(&b);
+				if (is_rela)
+					rela->r_addend = xdr->get64(&b);
+			} else {
+				uint32_t r_info;
+
+				rela->r_offset = xdr->get32(&b);
+				r_info = xdr->get32(&b);
+				rela->r_info = ELF64_R_INFO(ELF32_R_SYM(r_info),
+				                          ELF32_R_TYPE(r_info));
+				if (is_rela)
+					rela->r_addend = xdr->get32(&b);
+			}
+			rela++;
+		}
+	}
+
+	return 0;
+}
+
+static int strtab_read(const struct buffer *in, struct parsed_elf *pelf)
+{
+	Elf64_Ehdr *ehdr;
+	Elf64_Word i;
+
+	ehdr = &pelf->ehdr;
+
+	if (ehdr->e_shstrndx >= ehdr->e_shnum) {
+		ERROR("Section header string table index out of range: %d\n",
+		      ehdr->e_shstrndx);
+		return -1;
+	}
+
+	/* For each section of type SHT_STRTAB create a symtab buffer. */
+	pelf->strtabs = calloc(ehdr->e_shnum, sizeof(struct buffer *));
+
+	for (i = 0; i < ehdr->e_shnum; i++) {
+		struct buffer *b;
+		Elf64_Shdr *shdr = &pelf->shdr[i];
+
+		if (shdr->sh_type != SHT_STRTAB)
+			continue;
+
+		b = calloc(1, sizeof(*b));
+		buffer_splice(b, in, shdr->sh_offset, shdr->sh_size);
+		if (check_size(in, shdr->sh_offset, buffer_size(b), "strtab")) {
+			ERROR("STRTAB section not within bounds: %d\n", i);
+			free(b);
+			return -1;
+		}
+		pelf->strtabs[i] = b;
+	}
+
+	return 0;
+}
+
+static int
+symtab_read(const struct buffer *in, struct parsed_elf *pelf,
+            struct xdr *xdr, int bit64)
+{
+	Elf64_Ehdr *ehdr;
+	Elf64_Shdr *shdr;
+	Elf64_Half shnum;
+	Elf64_Xword i;
+	Elf64_Xword nsyms;
+	Elf64_Sym *sym;
+	struct buffer b;
+
+	ehdr = &pelf->ehdr;
+
+	shdr = NULL;
+	for (shnum = 0; shnum < ehdr->e_shnum; shnum++) {
+		if (pelf->shdr[shnum].sh_type != SHT_SYMTAB)
+			continue;
+
+		if (shdr != NULL) {
+			ERROR("Multiple symbol sections found. %u and %u\n",
+			      (unsigned int)(shdr - pelf->shdr), shnum);
+			return -1;
+		}
+
+		shdr = &pelf->shdr[shnum];
+	}
+
+	if (shdr == NULL) {
+		ERROR("No symbol table found.\n");
+		return -1;
+	}
+
+	buffer_splice(&b, in, shdr->sh_offset, shdr->sh_size);
+	if (check_size(in, shdr->sh_offset, buffer_size(&b), "symtab"))
+		return -1;
+
+	nsyms = shdr->sh_size / shdr->sh_entsize;
+
+	pelf->syms = calloc(nsyms, sizeof(Elf64_Sym));
+
+	for (i = 0; i < nsyms; i++) {
+		sym = &pelf->syms[i];
+
+		if (bit64) {
+			sym->st_name = xdr->get32(&b);
+			sym->st_info = xdr->get8(&b);
+			sym->st_other = xdr->get8(&b);
+			sym->st_shndx = xdr->get16(&b);
+			sym->st_value = xdr->get64(&b);
+			sym->st_size = xdr->get64(&b);
+		} else {
+			sym->st_name = xdr->get32(&b);
+			sym->st_value = xdr->get32(&b);
+			sym->st_size = xdr->get32(&b);
+			sym->st_info = xdr->get8(&b);
+			sym->st_other = xdr->get8(&b);
+			sym->st_shndx = xdr->get16(&b);
+		}
+	}
+
+	return 0;
+}
+
+int parse_elf(const struct buffer *pinput, struct parsed_elf *pelf, int flags)
+{
+	struct xdr *xdr = &xdr_le;
+	int bit64 = 0;
+	struct buffer input;
+	Elf64_Ehdr *ehdr;
+
+	/* Zero out the parsed elf structure. */
+	memset(pelf, 0, sizeof(*pelf));
+
+	if (!iself(buffer_get(pinput))) {
+		DEBUG("The stage file is not in ELF format!\n");
+		return -1;
+	}
+
+	buffer_clone(&input, pinput);
+	ehdr = &pelf->ehdr;
+	elf_eident(&input, ehdr);
+	bit64 = ehdr->e_ident[EI_CLASS] == ELFCLASS64;
+	/* Assume LE unless we are sure otherwise.
+	 * We're not going to take on the task of
+	 * fully validating the ELF file. That way
+	 * lies madness.
+	 */
+	if (ehdr->e_ident[EI_DATA] == ELFDATA2MSB)
+		xdr = &xdr_be;
+
+	elf_ehdr(&input, ehdr, xdr, bit64);
+
+	/* Relocation processing requires section header parsing. */
+	if (flags & ELF_PARSE_RELOC)
+		flags |= ELF_PARSE_SHDR;
+
+	/* String table processing requires section header parsing. */
+	if (flags & ELF_PARSE_STRTAB)
+		flags |= ELF_PARSE_SHDR;
+
+	/* Symbole table processing requires section header parsing. */
+	if (flags & ELF_PARSE_SYMTAB)
+		flags |= ELF_PARSE_SHDR;
+
+	if ((flags & ELF_PARSE_PHDR) && phdr_read(pinput, pelf, xdr, bit64))
+		goto fail;
+
+	if ((flags & ELF_PARSE_SHDR) && shdr_read(pinput, pelf, xdr, bit64))
+		goto fail;
+
+	if ((flags & ELF_PARSE_RELOC) && reloc_read(pinput, pelf, xdr, bit64))
+		goto fail;
+
+	if ((flags & ELF_PARSE_STRTAB) && strtab_read(pinput, pelf))
+		goto fail;
+
+	if ((flags & ELF_PARSE_SYMTAB) && symtab_read(pinput, pelf, xdr, bit64))
+		goto fail;
+
+	return 0;
+
+fail:
+	parsed_elf_destroy(pelf);
+	return -1;
+}
+
+void parsed_elf_destroy(struct parsed_elf *pelf)
+{
+	Elf64_Half i;
+
+	free(pelf->phdr);
+	free(pelf->shdr);
+	if (pelf->relocs != NULL) {
+		for (i = 0; i < pelf->ehdr.e_shnum; i++)
+			free(pelf->relocs[i]);
+	}
+	free(pelf->relocs);
+
+	if (pelf->strtabs != NULL) {
+		for (i = 0; i < pelf->ehdr.e_shnum; i++)
+			free(pelf->strtabs[i]);
+	}
+	free(pelf->strtabs);
+	free(pelf->syms);
+}
+
+/* Get the headers from the buffer.
+ * Return -1 in the event of an error.
+ * The section headers are optional; if NULL
+ * is passed in for pshdr they won't be parsed.
+ * We don't (yet) make payload parsing optional
+ * because we've never seen a use case.
+ */
+int
+elf_headers(const struct buffer *pinput,
+	    Elf64_Ehdr *ehdr,
+	    Elf64_Phdr **pphdr,
+	    Elf64_Shdr **pshdr)
+{
+	struct parsed_elf pelf;
+	int flags;
+
+	flags = ELF_PARSE_PHDR;
+
+	if (pshdr != NULL)
+		flags |= ELF_PARSE_SHDR;
+
+	if (parse_elf(pinput, &pelf, flags))
+		return -1;
+
+	/* Copy out the parsed elf header. */
+	memcpy(ehdr, &pelf.ehdr, sizeof(*ehdr));
+
+	*pphdr = calloc(ehdr->e_phnum, sizeof(Elf64_Phdr));
+	memcpy(*pphdr, pelf.phdr, ehdr->e_phnum * sizeof(Elf64_Phdr));
+
+	if (pshdr != NULL) {
+		*pshdr = calloc(ehdr->e_shnum, sizeof(Elf64_Shdr));
+		memcpy(*pshdr, pelf.shdr, ehdr->e_shnum * sizeof(Elf64_Shdr));
+	}
+
+	parsed_elf_destroy(&pelf);
+
+	return 0;
+}
+
+/* ELF Writing  Support
+ *
+ * The ELF file is written according to the following layout:
+ * +------------------+
+ * |    ELF Header    |
+ * +------------------+
+ * | Section  Headers |
+ * +------------------+
+ * | Program  Headers |
+ * +------------------+
+ * |   String table   |
+ * +------------------+ <- 4KiB Aligned
+ * |     Code/Data    |
+ * +------------------+
+ */
+
+void elf_init_eheader(Elf64_Ehdr *ehdr, int machine, int nbits, int endian)
+{
+	memset(ehdr, 0, sizeof(*ehdr));
+	ehdr->e_ident[EI_MAG0] = ELFMAG0;
+	ehdr->e_ident[EI_MAG1] = ELFMAG1;
+	ehdr->e_ident[EI_MAG2] = ELFMAG2;
+	ehdr->e_ident[EI_MAG3] = ELFMAG3;
+	ehdr->e_ident[EI_CLASS] = nbits;
+	ehdr->e_ident[EI_DATA] = endian;
+	ehdr->e_ident[EI_VERSION] = EV_CURRENT;
+	ehdr->e_type = ET_EXEC;
+	ehdr->e_machine = machine;
+	ehdr->e_version = EV_CURRENT;
+	if (nbits == ELFCLASS64) {
+		ehdr->e_ehsize = sizeof(Elf64_Ehdr);
+		ehdr->e_phentsize = sizeof(Elf64_Phdr);
+		ehdr->e_shentsize = sizeof(Elf64_Shdr);
+	} else {
+		ehdr->e_ehsize = sizeof(Elf32_Ehdr);
+		ehdr->e_phentsize = sizeof(Elf32_Phdr);
+		ehdr->e_shentsize = sizeof(Elf32_Shdr);
+	}
+}
+
+/* Arbitray maximum number of sections. */
+#define MAX_SECTIONS 16
+struct elf_writer_section {
+	Elf64_Shdr shdr;
+	struct buffer content;
+	const char *name;
+};
+
+struct elf_writer_string_table {
+	size_t next_offset;
+	size_t max_size;
+	char *buffer;
+};
+
+struct elf_writer_sym_table {
+	size_t max_entries;
+	size_t num_entries;
+	Elf64_Sym *syms;
+};
+
+#define MAX_REL_NAME 32
+struct elf_writer_rel {
+	size_t num_entries;
+	size_t max_entries;
+	Elf64_Rel *rels;
+	struct elf_writer_section *sec;
+	char name[MAX_REL_NAME];
+};
+
+struct elf_writer
+{
+	Elf64_Ehdr ehdr;
+	struct xdr *xdr;
+	size_t num_secs;
+	struct elf_writer_section sections[MAX_SECTIONS];
+	struct elf_writer_rel rel_sections[MAX_SECTIONS];
+	Elf64_Phdr *phdrs;
+	struct elf_writer_section *shstrtab_sec;
+	struct elf_writer_section *strtab_sec;
+	struct elf_writer_section *symtab_sec;
+	struct elf_writer_string_table strtab;
+	struct elf_writer_sym_table symtab;
+	int bit64;
+};
+
+static size_t section_index(struct elf_writer *ew,
+					struct elf_writer_section *sec)
+{
+	return sec - &ew->sections[0];
+}
+
+static struct elf_writer_section *last_section(struct elf_writer *ew)
+{
+	return &ew->sections[ew->num_secs - 1];
+}
+
+static void strtab_init(struct elf_writer *ew, size_t size)
+{
+	struct buffer b;
+	Elf64_Shdr shdr;
+
+	/* Start adding strings after the initial NUL entry. */
+	ew->strtab.next_offset = 1;
+	ew->strtab.max_size = size;
+	ew->strtab.buffer = calloc(1, ew->strtab.max_size);
+
+	buffer_init(&b, NULL, ew->strtab.buffer, ew->strtab.max_size);
+	memset(&shdr, 0, sizeof(shdr));
+	shdr.sh_type = SHT_STRTAB;
+	shdr.sh_addralign = 1;
+	shdr.sh_size = ew->strtab.max_size;
+	elf_writer_add_section(ew, &shdr, &b, ".strtab");
+	ew->strtab_sec = last_section(ew);
+}
+
+static void symtab_init(struct elf_writer *ew, size_t max_entries)
+{
+	struct buffer b;
+	Elf64_Shdr shdr;
+
+	memset(&shdr, 0, sizeof(shdr));
+	shdr.sh_type = SHT_SYMTAB;
+
+	if (ew->bit64) {
+		shdr.sh_entsize = sizeof(Elf64_Sym);
+		shdr.sh_addralign = sizeof(Elf64_Addr);
+	} else {
+		shdr.sh_entsize = sizeof(Elf32_Sym);
+		shdr.sh_addralign = sizeof(Elf32_Addr);
+	}
+
+	shdr.sh_size = shdr.sh_entsize * max_entries;
+
+	ew->symtab.syms = calloc(max_entries, sizeof(Elf64_Sym));
+	ew->symtab.num_entries = 1;
+	ew->symtab.max_entries = max_entries;
+
+	buffer_init(&b, NULL, ew->symtab.syms, shdr.sh_size);
+
+	elf_writer_add_section(ew, &shdr, &b, ".symtab");
+	ew->symtab_sec = last_section(ew);
+}
+
+struct elf_writer *elf_writer_init(const Elf64_Ehdr *ehdr)
+{
+	struct elf_writer *ew;
+	Elf64_Shdr shdr;
+	struct buffer empty_buffer;
+
+	if (!iself(ehdr))
+		return NULL;
+
+	ew = calloc(1, sizeof(*ew));
+
+	memcpy(&ew->ehdr, ehdr, sizeof(ew->ehdr));
+
+	ew->bit64 = ew->ehdr.e_ident[EI_CLASS] == ELFCLASS64;
+
+	/* Set the endinan ops. */
+	if (ew->ehdr.e_ident[EI_DATA] == ELFDATA2MSB)
+		ew->xdr = &xdr_be;
+	else
+		ew->xdr = &xdr_le;
+
+	/* Reset count and offsets */
+	ew->ehdr.e_phoff = 0;
+	ew->ehdr.e_shoff = 0;
+	ew->ehdr.e_shnum = 0;
+	ew->ehdr.e_phnum = 0;
+
+	memset(&empty_buffer, 0, sizeof(empty_buffer));
+	memset(&shdr, 0, sizeof(shdr));
+
+	/* Add SHT_NULL section header. */
+	shdr.sh_type = SHT_NULL;
+	elf_writer_add_section(ew, &shdr, &empty_buffer, NULL);
+
+	/* Add section header string table and maintain reference to it.  */
+	shdr.sh_type = SHT_STRTAB;
+	elf_writer_add_section(ew, &shdr, &empty_buffer, ".shstrtab");
+	ew->shstrtab_sec = last_section(ew);
+	ew->ehdr.e_shstrndx = section_index(ew, ew->shstrtab_sec);
+
+	/* Add a small string table and symbol table. */
+	strtab_init(ew, 4096);
+	symtab_init(ew, 100);
+
+	return ew;
+}
+
+/*
+ * Clean up any internal state represented by ew. Aftewards the elf_writer
+ * is invalid.
+ * It is safe to call elf_writer_destroy with ew as NULL. It returns without
+ * performing any action.
+ */
+void elf_writer_destroy(struct elf_writer *ew)
+{
+	int i;
+	if (ew == NULL)
+		return;
+	if (ew->phdrs != NULL)
+		free(ew->phdrs);
+	free(ew->strtab.buffer);
+	free(ew->symtab.syms);
+	for (i = 0; i < MAX_SECTIONS; i++)
+		free(ew->rel_sections[i].rels);
+	free(ew);
+}
+
+/*
+ * Add a section to the ELF file. Section type, flags, and memsize are
+ * maintained from the passed in Elf64_Shdr. The buffer represents the
+ * content of the section while the name is the name of section itself.
+ * Returns < 0 on error, 0 on success.
+ */
+int elf_writer_add_section(struct elf_writer *ew, const Elf64_Shdr *shdr,
+                           struct buffer *contents, const char *name)
+{
+	struct elf_writer_section *newsh;
+
+	if (ew->num_secs == MAX_SECTIONS)
+		return -1;
+
+	newsh = &ew->sections[ew->num_secs];
+	ew->num_secs++;
+
+	memcpy(&newsh->shdr, shdr, sizeof(newsh->shdr));
+	newsh->shdr.sh_offset = 0;
+
+	newsh->name = name;
+	if (contents != NULL)
+		buffer_clone(&newsh->content, contents);
+
+	return 0;
+}
+
+static void ehdr_write(struct elf_writer *ew, struct buffer *m)
+{
+	int i;
+
+	for (i = 0; i < EI_NIDENT; i++)
+		ew->xdr->put8(m, ew->ehdr.e_ident[i]);
+	ew->xdr->put16(m, ew->ehdr.e_type);
+	ew->xdr->put16(m, ew->ehdr.e_machine);
+	ew->xdr->put32(m, ew->ehdr.e_version);
+	if (ew->bit64) {
+		ew->xdr->put64(m, ew->ehdr.e_entry);
+		ew->xdr->put64(m, ew->ehdr.e_phoff);
+		ew->xdr->put64(m, ew->ehdr.e_shoff);
+	} else {
+		ew->xdr->put32(m, ew->ehdr.e_entry);
+		ew->xdr->put32(m, ew->ehdr.e_phoff);
+		ew->xdr->put32(m, ew->ehdr.e_shoff);
+	}
+	ew->xdr->put32(m, ew->ehdr.e_flags);
+	ew->xdr->put16(m, ew->ehdr.e_ehsize);
+	ew->xdr->put16(m, ew->ehdr.e_phentsize);
+	ew->xdr->put16(m, ew->ehdr.e_phnum);
+	ew->xdr->put16(m, ew->ehdr.e_shentsize);
+	ew->xdr->put16(m, ew->ehdr.e_shnum);
+	ew->xdr->put16(m, ew->ehdr.e_shstrndx);
+}
+
+static void shdr_write(struct elf_writer *ew, size_t n, struct buffer *m)
+{
+	struct xdr *xdr = ew->xdr;
+	int bit64 = ew->bit64;
+	struct elf_writer_section *sec = &ew->sections[n];
+	Elf64_Shdr *shdr = &sec->shdr;
+
+	xdr->put32(m, shdr->sh_name);
+	xdr->put32(m, shdr->sh_type);
+	if (bit64) {
+		xdr->put64(m, shdr->sh_flags);
+		xdr->put64(m, shdr->sh_addr);
+		xdr->put64(m, shdr->sh_offset);
+		xdr->put64(m, shdr->sh_size);
+		xdr->put32(m, shdr->sh_link);
+		xdr->put32(m, shdr->sh_info);
+		xdr->put64(m, shdr->sh_addralign);
+		xdr->put64(m, shdr->sh_entsize);
+	} else {
+		xdr->put32(m, shdr->sh_flags);
+		xdr->put32(m, shdr->sh_addr);
+		xdr->put32(m, shdr->sh_offset);
+		xdr->put32(m, shdr->sh_size);
+		xdr->put32(m, shdr->sh_link);
+		xdr->put32(m, shdr->sh_info);
+		xdr->put32(m, shdr->sh_addralign);
+		xdr->put32(m, shdr->sh_entsize);
+	}
+}
+
+static void
+phdr_write(struct elf_writer *ew, struct buffer *m, Elf64_Phdr *phdr)
+{
+	if (ew->bit64) {
+		ew->xdr->put32(m, phdr->p_type);
+		ew->xdr->put32(m, phdr->p_flags);
+		ew->xdr->put64(m, phdr->p_offset);
+		ew->xdr->put64(m, phdr->p_vaddr);
+		ew->xdr->put64(m, phdr->p_paddr);
+		ew->xdr->put64(m, phdr->p_filesz);
+		ew->xdr->put64(m, phdr->p_memsz);
+		ew->xdr->put64(m, phdr->p_align);
+	} else {
+		ew->xdr->put32(m, phdr->p_type);
+		ew->xdr->put32(m, phdr->p_offset);
+		ew->xdr->put32(m, phdr->p_vaddr);
+		ew->xdr->put32(m, phdr->p_paddr);
+		ew->xdr->put32(m, phdr->p_filesz);
+		ew->xdr->put32(m, phdr->p_memsz);
+		ew->xdr->put32(m, phdr->p_flags);
+		ew->xdr->put32(m, phdr->p_align);
+	}
+
+}
+
+static int section_consecutive(struct elf_writer *ew, Elf64_Half secidx)
+{
+	Elf64_Half i;
+	struct elf_writer_section *prev_alloc = NULL;
+
+	if (secidx == 0)
+		return 0;
+
+	for (i = 0; i < secidx; i++) {
+		if (ew->sections[i].shdr.sh_flags & SHF_ALLOC)
+			prev_alloc = &ew->sections[i];
+	}
+
+	if (prev_alloc == NULL)
+		return 0;
+
+	if (prev_alloc->shdr.sh_addr + prev_alloc->shdr.sh_size ==
+	    ew->sections[secidx].shdr.sh_addr)
+		return 1;
+
+	return 0;
+}
+
+static void write_phdrs(struct elf_writer *ew, struct buffer *phdrs)
+{
+	Elf64_Half i;
+	Elf64_Phdr phdr;
+	size_t num_written = 0;
+	size_t num_needs_write = 0;
+
+	for (i = 0; i < ew->num_secs; i++) {
+		struct elf_writer_section *sec = &ew->sections[i];
+
+		if (!(sec->shdr.sh_flags & SHF_ALLOC))
+			continue;
+
+		if (!section_consecutive(ew, i)) {
+			/* Write out previously set phdr. */
+			if (num_needs_write != num_written) {
+				phdr_write(ew, phdrs, &phdr);
+				num_written++;
+			}
+			phdr.p_type = PT_LOAD;
+			phdr.p_offset = sec->shdr.sh_offset;
+			phdr.p_vaddr = sec->shdr.sh_addr;
+			phdr.p_paddr = sec->shdr.sh_addr;
+			phdr.p_filesz = buffer_size(&sec->content);
+			phdr.p_memsz = sec->shdr.sh_size;
+			phdr.p_flags = 0;
+			if (sec->shdr.sh_flags & SHF_EXECINSTR)
+				phdr.p_flags |= PF_X | PF_R;
+			if (sec->shdr.sh_flags & SHF_WRITE)
+				phdr.p_flags |= PF_W;
+			phdr.p_align = sec->shdr.sh_addralign;
+			num_needs_write++;
+
+		} else {
+			/* Accumulate file size and memsize. The assumption
+			 * is that each section is either NOBITS or full
+			 * (sh_size == file size). This is standard in that
+			 * an ELF section doesn't have a file size component. */
+			if (sec->shdr.sh_flags & SHF_EXECINSTR)
+				phdr.p_flags |= PF_X | PF_R;
+			if (sec->shdr.sh_flags & SHF_WRITE)
+				phdr.p_flags |= PF_W;
+			phdr.p_filesz += buffer_size(&sec->content);
+			phdr.p_memsz += sec->shdr.sh_size;
+		}
+	}
+
+	/* Write out the last phdr. */
+	if (num_needs_write != num_written) {
+		phdr_write(ew, phdrs, &phdr);
+		num_written++;
+	}
+	assert(num_written == ew->ehdr.e_phnum);
+}
+
+static void fixup_symbol_table(struct elf_writer *ew)
+{
+	struct elf_writer_section *sec = ew->symtab_sec;
+
+	/* If there is only the NULL section, mark section as inactive. */
+	if (ew->symtab.num_entries == 1) {
+		sec->shdr.sh_type = SHT_NULL;
+		sec->shdr.sh_size = 0;
+	} else {
+		size_t i;
+		struct buffer wr;
+
+		buffer_clone(&wr, &sec->content);
+		/* To appease xdr. */
+		buffer_set_size(&wr, 0);
+		for (i = 0; i < ew->symtab.num_entries; i++) {
+			/* Create local copy as were over-writing backing
+			 * store of the symbol. */
+			Elf64_Sym sym = ew->symtab.syms[i];
+			if (ew->bit64) {
+				ew->xdr->put32(&wr, sym.st_name);
+				ew->xdr->put8(&wr, sym.st_info);
+				ew->xdr->put8(&wr, sym.st_other);
+				ew->xdr->put16(&wr, sym.st_shndx);
+				ew->xdr->put64(&wr, sym.st_value);
+				ew->xdr->put64(&wr, sym.st_size);
+			} else {
+				ew->xdr->put32(&wr, sym.st_name);
+				ew->xdr->put32(&wr, sym.st_value);
+				ew->xdr->put32(&wr, sym.st_size);
+				ew->xdr->put8(&wr, sym.st_info);
+				ew->xdr->put8(&wr, sym.st_other);
+				ew->xdr->put16(&wr, sym.st_shndx);
+			}
+		}
+
+		/* Update section size. */
+		sec->shdr.sh_size = sec->shdr.sh_entsize;
+		sec->shdr.sh_size *= ew->symtab.num_entries;
+
+		/* Fix up sh_link to point to string table. */
+		sec->shdr.sh_link = section_index(ew, ew->strtab_sec);
+		/* sh_info is supposed to be 1 greater than symbol table
+		 * index of last local binding. Just use max symbols. */
+		sec->shdr.sh_info = ew->symtab.num_entries;
+	}
+
+	buffer_set_size(&sec->content, sec->shdr.sh_size);
+}
+
+static void fixup_relocations(struct elf_writer *ew)
+{
+	int i;
+	Elf64_Xword type;
+
+	switch (ew->ehdr.e_machine) {
+	case EM_386:
+		type = R_386_32;
+		break;
+	case EM_X86_64:
+		type =  R_AMD64_64;
+		break;
+	case EM_ARM:
+		type = R_ARM_ABS32;
+		break;
+	case EM_AARCH64:
+		type = R_AARCH64_ABS64;
+		break;
+	case EM_MIPS:
+		type = R_MIPS_32;
+		break;
+	case EM_RISCV:
+		type = R_RISCV_32;
+		break;
+	case EM_PPC64:
+		type = R_PPC64_ADDR32;
+		break;
+	default:
+		ERROR("Unable to handle relocations for e_machine %x\n",
+			ew->ehdr.e_machine);
+		return;
+	}
+
+	for (i = 0; i < MAX_SECTIONS; i++) {
+		struct elf_writer_rel *rel_sec = &ew->rel_sections[i];
+		struct elf_writer_section *sec = rel_sec->sec;
+		struct buffer writer;
+		size_t j;
+
+		if (sec == NULL)
+			continue;
+
+		/* Update section header size as well as content size. */
+		buffer_init(&sec->content, sec->content.name, rel_sec->rels,
+				rel_sec->num_entries * sec->shdr.sh_entsize);
+		sec->shdr.sh_size = buffer_size(&sec->content);
+		buffer_clone(&writer, &sec->content);
+		/* To make xdr happy. */
+		buffer_set_size(&writer, 0);
+
+		for (j = 0; j < ew->rel_sections[i].num_entries; j++) {
+			/* Make copy as we're overwriting backing store. */
+			Elf64_Rel rel = rel_sec->rels[j];
+			rel.r_info = ELF64_R_INFO(ELF64_R_SYM(rel.r_info),
+						  ELF64_R_TYPE(type));
+
+			if (ew->bit64) {
+				ew->xdr->put64(&writer, rel.r_offset);
+				ew->xdr->put64(&writer, rel.r_info);
+			} else {
+				Elf32_Rel rel32;
+				rel32.r_offset = rel.r_offset;
+				rel32.r_info =
+					ELF32_R_INFO(ELF64_R_SYM(rel.r_info),
+						     ELF64_R_TYPE(rel.r_info));
+				ew->xdr->put32(&writer, rel32.r_offset);
+				ew->xdr->put32(&writer, rel32.r_info);
+			}
+		}
+	}
+}
+
+/*
+ * Serialize the ELF file to the output buffer. Return < 0 on error,
+ * 0 on success.
+ */
+int elf_writer_serialize(struct elf_writer *ew, struct buffer *out)
+{
+	Elf64_Half i;
+	Elf64_Xword metadata_size;
+	Elf64_Xword program_size;
+	Elf64_Off shstroffset;
+	size_t shstrlen;
+	struct buffer metadata;
+	struct buffer phdrs;
+	struct buffer data;
+	struct buffer *strtab;
+
+	INFO("Writing %zu sections.\n", ew->num_secs);
+
+	/* Perform any necessary work for special sections. */
+	fixup_symbol_table(ew);
+	fixup_relocations(ew);
+
+	/* Determine size of sections to be written. */
+	program_size = 0;
+	/* Start with 1 byte for first byte of section header string table. */
+	shstrlen = 1;
+	for (i = 0; i < ew->num_secs; i++) {
+		struct elf_writer_section *sec = &ew->sections[i];
+
+		if (sec->shdr.sh_flags & SHF_ALLOC) {
+			if (!section_consecutive(ew, i))
+				ew->ehdr.e_phnum++;
+		}
+
+		program_size += buffer_size(&sec->content);
+
+		/* Keep track of the length sections' names. */
+		if (sec->name != NULL) {
+			sec->shdr.sh_name = shstrlen;
+			shstrlen += strlen(sec->name) + 1;
+		}
+	}
+	ew->ehdr.e_shnum = ew->num_secs;
+	metadata_size = 0;
+	metadata_size += ew->ehdr.e_ehsize;
+	metadata_size += (Elf64_Xword)ew->ehdr.e_shnum * ew->ehdr.e_shentsize;
+	metadata_size += (Elf64_Xword)ew->ehdr.e_phnum * ew->ehdr.e_phentsize;
+	shstroffset = metadata_size;
+	/* Align up section header string size and metadata size to 4KiB */
+	metadata_size = ALIGN(metadata_size + shstrlen, 4096);
+
+	if (buffer_create(out, metadata_size + program_size, "elfout")) {
+		ERROR("Could not create output buffer for ELF.\n");
+		return -1;
+	}
+
+	INFO("Created %zu output buffer for ELF file.\n", buffer_size(out));
+
+	/*
+	 * Write out ELF header. Section headers come right after ELF header
+	 * followed by the program headers. Buffers need to be created first
+	 * to do the writing.
+	 */
+	ew->ehdr.e_shoff = ew->ehdr.e_ehsize;
+	ew->ehdr.e_phoff = ew->ehdr.e_shoff +
+			   (Elf64_Off)ew->ehdr.e_shnum * ew->ehdr.e_shentsize;
+
+	buffer_splice(&metadata, out, 0, metadata_size);
+	buffer_splice(&phdrs, out, ew->ehdr.e_phoff,
+		      (uint32_t)ew->ehdr.e_phnum * ew->ehdr.e_phentsize);
+	buffer_splice(&data, out, metadata_size, program_size);
+	/* Set up the section header string table contents. */
+	strtab = &ew->shstrtab_sec->content;
+	buffer_splice(strtab, out, shstroffset, shstrlen);
+	ew->shstrtab_sec->shdr.sh_size = shstrlen;
+
+	/* Reset current locations. */
+	buffer_set_size(&metadata, 0);
+	buffer_set_size(&data, 0);
+	buffer_set_size(&phdrs, 0);
+	buffer_set_size(strtab, 0);
+
+	/* ELF Header */
+	ehdr_write(ew, &metadata);
+
+	/* Write out section headers, section strings, section content, and
+	 * program headers. */
+	ew->xdr->put8(strtab, 0);
+	for (i = 0; i < ew->num_secs; i++) {
+		struct elf_writer_section *sec = &ew->sections[i];
+
+		/* Update section offsets. Be sure to not update SHN_UNDEF. */
+		if (sec == ew->shstrtab_sec)
+			sec->shdr.sh_offset = shstroffset;
+		else if (i != SHN_UNDEF)
+			sec->shdr.sh_offset = buffer_size(&data) +
+			                      metadata_size;
+
+		shdr_write(ew, i, &metadata);
+
+		/* Add section name to string table. */
+		if (sec->name != NULL)
+			bputs(strtab, sec->name, strlen(sec->name) + 1);
+
+		/* Output section data for all sections but SHN_UNDEF and
+		 * section header string table. */
+		if (i != SHN_UNDEF && sec != ew->shstrtab_sec)
+			bputs(&data, buffer_get(&sec->content),
+			      buffer_size(&sec->content));
+	}
+
+	write_phdrs(ew, &phdrs);
+
+	return 0;
+}
+
+/* Add a string to the string table returning index on success, < 0 on error. */
+static int elf_writer_add_string(struct elf_writer *ew, const char *new)
+{
+	size_t current_offset;
+	size_t new_len;
+
+	for (current_offset = 0; current_offset < ew->strtab.next_offset; ) {
+		const char *str = ew->strtab.buffer + current_offset;
+		size_t len = strlen(str) + 1;
+
+		if (!strcmp(str, new))
+			return current_offset;
+		current_offset += len;
+	}
+
+	new_len = strlen(new) + 1;
+
+	if (current_offset + new_len > ew->strtab.max_size) {
+		ERROR("No space for string in .strtab.\n");
+		return -1;
+	}
+
+	memcpy(ew->strtab.buffer + current_offset, new, new_len);
+	ew->strtab.next_offset = current_offset + new_len;
+
+	return current_offset;
+}
+
+static int elf_writer_section_index(struct elf_writer *ew, const char *name)
+{
+	size_t i;
+
+	for (i = 0; i < ew->num_secs; i++) {
+		if (ew->sections[i].name == NULL)
+			continue;
+		if (!strcmp(ew->sections[i].name, name))
+			return i;
+	}
+
+	ERROR("ELF Section not found: %s\n", name);
+
+	return -1;
+}
+
+int elf_writer_add_symbol(struct elf_writer *ew, const char *name,
+				const char *section_name,
+				Elf64_Addr value, Elf64_Word size,
+				int binding, int type)
+{
+	int i;
+	Elf64_Sym sym = {
+		.st_value = value,
+		.st_size = size,
+		.st_info = ELF64_ST_INFO(binding, type),
+	};
+
+	if (ew->symtab.max_entries == ew->symtab.num_entries) {
+		ERROR("No more symbol entries left.\n");
+		return -1;
+	}
+
+	i = elf_writer_add_string(ew, name);
+	if (i < 0)
+		return -1;
+	sym.st_name = i;
+
+	i = elf_writer_section_index(ew, section_name);
+	if (i < 0)
+		return -1;
+	sym.st_shndx = i;
+
+	ew->symtab.syms[ew->symtab.num_entries++] = sym;
+
+	return 0;
+}
+
+static int elf_sym_index(struct elf_writer *ew, const char *sym)
+{
+	int j;
+	size_t i;
+	Elf64_Word st_name;
+
+	/* Determine index of symbol in the string table. */
+	j = elf_writer_add_string(ew, sym);
+	if (j < 0)
+		return -1;
+
+	st_name = j;
+
+	for (i = 0; i < ew->symtab.num_entries; i++)
+		if (ew->symtab.syms[i].st_name == st_name)
+			return i;
+
+	return -1;
+}
+
+static struct elf_writer_rel *rel_section(struct elf_writer *ew,
+						const Elf64_Rel *r)
+{
+	Elf64_Sym *sym;
+	struct elf_writer_rel *rel;
+	Elf64_Shdr shdr;
+	struct buffer b;
+
+	sym = &ew->symtab.syms[ELF64_R_SYM(r->r_info)];
+
+	/* Determine if section has been initialized yet. */
+	rel = &ew->rel_sections[sym->st_shndx];
+	if (rel->sec != NULL)
+		return rel;
+
+	memset(&shdr, 0, sizeof(shdr));
+	shdr.sh_type = SHT_REL;
+	shdr.sh_link = section_index(ew, ew->symtab_sec);
+	shdr.sh_info = sym->st_shndx;
+
+	if (ew->bit64) {
+		shdr.sh_addralign = sizeof(Elf64_Addr);
+		shdr.sh_entsize = sizeof(Elf64_Rel);
+	} else {
+		shdr.sh_addralign = sizeof(Elf32_Addr);
+		shdr.sh_entsize = sizeof(Elf32_Rel);
+	}
+
+	if ((strlen(".rel") + strlen(ew->sections[sym->st_shndx].name) + 1) >
+	    MAX_REL_NAME) {
+		ERROR("Rel Section name won't fit\n");
+		return NULL;
+	}
+
+	strcat(rel->name, ".rel");
+	strcat(rel->name, ew->sections[sym->st_shndx].name);
+	buffer_init(&b, rel->name, NULL, 0);
+
+	elf_writer_add_section(ew, &shdr, &b, rel->name);
+	rel->sec = last_section(ew);
+
+	return rel;
+}
+
+static int add_rel(struct elf_writer_rel *rel_sec, const Elf64_Rel *rel)
+{
+	if (rel_sec->num_entries == rel_sec->max_entries) {
+		size_t num = rel_sec->max_entries * 2;
+		Elf64_Rel *old_rels;
+
+		if (num == 0)
+			num = 128;
+
+		old_rels = rel_sec->rels;
+		rel_sec->rels = calloc(num, sizeof(Elf64_Rel));
+
+		memcpy(rel_sec->rels, old_rels,
+			rel_sec->num_entries * sizeof(Elf64_Rel));
+		free(old_rels);
+
+		rel_sec->max_entries = num;
+	}
+
+	rel_sec->rels[rel_sec->num_entries] = *rel;
+	rel_sec->num_entries++;
+
+	return 0;
+}
+
+int elf_writer_add_rel(struct elf_writer *ew, const char *sym, Elf64_Addr addr)
+{
+	Elf64_Rel rel;
+	Elf64_Xword sym_info;
+	int sym_index;
+	struct elf_writer_rel *rel_sec;
+
+	sym_index = elf_sym_index(ew, sym);
+
+	if (sym_index < 0) {
+		ERROR("Unable to locate symbol: %s\n", sym);
+		return -1;
+	}
+
+	sym_info = sym_index;
+
+	/* The relocation type will get fixed prior to serialization. */
+	rel.r_offset = addr;
+	rel.r_info = ELF64_R_INFO(sym_info, 0);
+
+	rel_sec = rel_section(ew, &rel);
+
+	if (rel_sec == NULL)
+		return -1;
+
+	return add_rel(rel_sec, &rel);
+}
+
+int elf_program_file_size(const struct buffer *input, size_t *file_size)
+{
+	Elf64_Ehdr ehdr;
+	Elf64_Phdr *phdr;
+	int i;
+	size_t loadable_file_size = 0;
+
+	if (elf_headers(input, &ehdr, &phdr, NULL))
+		return -1;
+
+	for (i = 0; i < ehdr.e_phnum; i++) {
+		if (phdr[i].p_type != PT_LOAD)
+			continue;
+		loadable_file_size += phdr[i].p_filesz;
+	}
+
+	*file_size = loadable_file_size;
+
+	free(phdr);
+
+	return 0;
+}
diff --git a/tools/cbfstool/elfparsing.h b/tools/cbfstool/elfparsing.h
new file mode 100644
index 0000000000..8b08c135af
--- /dev/null
+++ b/tools/cbfstool/elfparsing.h
@@ -0,0 +1,133 @@
+/*
+ * Copyright (C) 2014 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef ELFPARSING_H
+#define ELFPARSING_H
+
+#include "elf.h"
+#include "common.h"
+
+struct parsed_elf {
+	Elf64_Ehdr ehdr;
+	Elf64_Phdr *phdr;
+	Elf64_Shdr *shdr;
+	/*
+	 * The relocs array contains pointers to arrays of relocation
+	 * structures.  Each index into the relocs array corresponds to its
+	 * corresponding section index. i.e. if a section i is of type SHT_REL
+	 * or SHT_RELA then the corresponding index into the relocs array will
+	 * contain the associated relocations. Otherwise thee entry will be
+	 * NULL.
+	 */
+	Elf64_Rela **relocs;
+	/*
+	 * Similarly to the relocs array the strtabs array consists of an
+	 * array of pointers where each entry represents a potential struct
+	 * buffer pointer. Only setions of type SHT_STRTAB will have a non-NULL
+	 * entry.
+	 */
+	struct buffer **strtabs;
+	/* Parsed symbols. */
+	Elf64_Sym *syms;
+};
+
+#define ELF_PARSE_PHDR		(1 << 0)
+#define ELF_PARSE_SHDR		(1 << 1)
+#define ELF_PARSE_RELOC		(1 << 2)
+#define ELF_PARSE_STRTAB	(1 << 3)
+#define ELF_PARSE_SYMTAB	(1 << 4)
+
+#define ELF_PARSE_ALL		(-1)
+
+/*
+ * Parse an ELF file contained within provide struct buffer. The ELF header
+ * is always parsed while the flags value containing the ELF_PARSE_* values
+ * determine if other parts of the ELF file will be parsed as well.
+ * Returns 0 on success, < 0 error.
+ */
+int parse_elf(const struct buffer *pinput, struct parsed_elf *pelf, int flags);
+
+/*
+ * Clean up memory associated with parsed_elf.
+ */
+void parsed_elf_destroy(struct parsed_elf *pelf);
+
+
+int
+elf_headers(const struct buffer *pinput,
+	    Elf64_Ehdr *ehdr,
+	    Elf64_Phdr **pphdr,
+	    Elf64_Shdr **pshdr);
+
+/* ELF writing support. */
+struct elf_writer;
+
+/*
+ * Initialize a 64-bit ELF header provided the inputs. While the structure
+ * is a 64-bit header one can specify a 32-bit machine. The 64-bit version
+ * is just used as a common structure. If one wants to specify the entry
+ * point, for example, the caller can set it after filling in the common
+ * bits. The machine, nbits, and endian values should be from the ELF
+ * definitions (e.g. EM_386, ELFCLASS32, and ELFDATA2LSB) found in elf.h
+ * with no endian conversion required.
+ */
+void elf_init_eheader(Elf64_Ehdr *ehdr, int machine, int nbits, int endian);
+
+/*
+ * Initialize a new ELF writer. Default machine type, endianness, etc is
+ * copied from the passed in Elf64_Ehdr. Returns NULL on failure, valid
+ * pointer on success.
+ */
+struct elf_writer *elf_writer_init(const Elf64_Ehdr *ehdr);
+
+/*
+ * Clean up any internal state represented by ew. Aftewards the elf_writer
+ * is invalid.
+ * It is safe to call elf_writer_destroy with ew as NULL. It returns without
+ * performing any action.
+ */
+void elf_writer_destroy(struct elf_writer *ew);
+
+/*
+ * Add a section to the ELF file. Section type, flags, and memsize are
+ * maintained from the passed in Elf64_Shdr. The buffer represents the
+ * content of the section while the name is the name of section itself.
+ * Returns < 0 on error, 0 on success.
+ */
+int elf_writer_add_section(struct elf_writer *ew, const Elf64_Shdr *shdr,
+                           struct buffer *contents, const char *name);
+
+/* Add an absolute symbol to the ELF file returning < 0 on error, index of
+ * symbol otherwise. */
+int elf_writer_add_symbol(struct elf_writer *ew, const char *name,
+				const char *section_name,
+				Elf64_Addr value, Elf64_Word size,
+				int binding, int type);
+
+/* Add an absolute relocation referencing the provided symbol name. Returns < 0
+ * on error, 0 on success. */
+int elf_writer_add_rel(struct elf_writer *ew, const char *sym, Elf64_Addr addr);
+
+/*
+ * Serialize the ELF file to the output buffer. Return < 0 on error,
+ * 0 on success.
+ */
+int elf_writer_serialize(struct elf_writer *ew, struct buffer *out);
+
+/*
+ * Calculate the loadable program's file size footprint. Returns < 0 on error,
+ * 0 on success.
+ */
+int elf_program_file_size(const struct buffer *input, size_t *file_size);
+
+#endif /* ELFPARSING_H */
diff --git a/tools/cbfstool/fdt.h b/tools/cbfstool/fdt.h
new file mode 100644
index 0000000000..387cd328ed
--- /dev/null
+++ b/tools/cbfstool/fdt.h
@@ -0,0 +1,34 @@
+/*
+ * Copyright 2013 Google Inc.
+ * Copyright 2018-present Facebook, Inc.
+ *
+ * Taken from depthcharge: src/base/device_tree.h
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but without any warranty; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+struct fdt_header {
+	uint32_t magic;
+	uint32_t totalsize;
+	uint32_t structure_offset;
+	uint32_t strings_offset;
+	uint32_t reserve_map_offset;
+
+	uint32_t version;
+	uint32_t last_compatible_version;
+
+	uint32_t boot_cpuid_phys;
+
+	uint32_t strings_size;
+	uint32_t structure_size;
+};
+
+#define FDT_HEADER_MAGIC	0xd00dfeed
diff --git a/tools/cbfstool/flashmap/fmap.h b/tools/cbfstool/flashmap/fmap.h
new file mode 100644
index 0000000000..8cec7bc0f1
--- /dev/null
+++ b/tools/cbfstool/flashmap/fmap.h
@@ -0,0 +1,175 @@
+/*
+ * Copyright 2015, Google Inc.
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *    * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *    * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *    * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * Alternatively, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") version 2 as published by the Free
+ * Software Foundation.
+ */
+
+#ifndef FLASHMAP_LIB_FMAP_H__
+#define FLASHMAP_LIB_FMAP_H__
+
+#include <inttypes.h>
+#include <valstr.h>
+
+#define FMAP_SIGNATURE		"__FMAP__"
+#define FMAP_VER_MAJOR		1	/* this header's FMAP minor version */
+#define FMAP_VER_MINOR		1	/* this header's FMAP minor version */
+#define FMAP_STRLEN		32	/* maximum length for strings, */
+					/* including null-terminator */
+extern const struct valstr flag_lut[16];
+enum fmap_flags {
+	FMAP_AREA_STATIC	= 1 << 0,
+	FMAP_AREA_COMPRESSED	= 1 << 1,
+	FMAP_AREA_RO		= 1 << 2,
+	FMAP_AREA_PRESERVE	= 1 << 3,
+};
+
+/* Mapping of volatile and static regions in firmware binary */
+struct fmap_area {
+	uint32_t offset;		/* offset relative to base */
+	uint32_t size;			/* size in bytes */
+	uint8_t  name[FMAP_STRLEN];	/* descriptive name */
+	uint16_t flags;			/* flags for this area */
+}  __attribute__((packed));
+
+struct fmap {
+	uint8_t  signature[8];		/* "__FMAP__" (0x5F5F464D41505F5F) */
+	uint8_t  ver_major;		/* major version */
+	uint8_t  ver_minor;		/* minor version */
+	uint64_t base;			/* address of the firmware binary */
+	uint32_t size;			/* size of firmware binary in bytes */
+	uint8_t  name[FMAP_STRLEN];	/* name of this firmware binary */
+	uint16_t nareas;		/* number of areas described by
+					   fmap_areas[] below */
+	struct fmap_area areas[];
+} __attribute__((packed));
+
+/*
+ * fmap_find - find FMAP signature in a binary image
+ *
+ * @image:	binary image
+ * @len:	length of binary image
+ *
+ * This function does no error checking. The caller is responsible for
+ * verifying that the contents are sane.
+ *
+ * returns offset of FMAP signature to indicate success
+ * returns <0 to indicate failure
+ */
+extern long int fmap_find(const uint8_t *image, unsigned int len);
+
+/*
+ * fmap_print - Print contents of flash map data structure
+ *
+ * @map:	raw map data
+ *
+ * returns 0 to indiciate success
+ * returns <0 to indicate failure
+ */
+extern int fmap_print(const struct fmap *map);
+
+/*
+ * fmap_flags_to_string - convert raw flags field into user-friendly string
+ *
+ * @flags:	raw flags
+ *
+ * This function returns a user-friendly comma-separated list of fmap area
+ * flags. If there are no flags (flags == 0), the string will contain only
+ * a terminating character ('\0')
+ *
+ * This function allocates memory which the caller must free.
+ *
+ * returns pointer to an allocated string if successful
+ * returns NULL to indicate failure
+ */
+char *fmap_flags_to_string(uint16_t flags);
+
+/*
+ * fmap_create - allocate and initialize a new fmap structure
+ *
+ * @base:	base address of firmware within address space
+ * @size:	size of the firmware (bytes)
+ * @name:	name of firmware
+ *
+ * This function will allocate a flashmap header. Members of the structure
+ * which are not passed in are automatically initialized.
+ *
+ * returns pointer to newly allocated flashmap header if successful
+ * returns NULL to indicate failure
+ */
+extern struct fmap *fmap_create(uint64_t base,
+				uint32_t size, uint8_t *name);
+
+/* free memory used by an fmap structure */
+extern void fmap_destroy(struct fmap *fmap);
+
+/*
+ * fmap_size - returns size of fmap data structure (including areas)
+ *
+ * @fmap:	fmap
+ *
+ * returns size of fmap structure if successful
+ * returns <0 to indicate failure
+ */
+extern int fmap_size(const struct fmap *fmap);
+
+/*
+ * fmap_append_area - realloc an existing flashmap and append an area
+ *
+ * @fmap:	double pointer to existing flashmap
+ * @offset:	offset of area
+ * @size:	size of area
+ * @name:	name of area
+ * @flags:	area flags
+ *
+ * returns total size of reallocated flashmap structure if successful
+ * returns <0 to indicate failure
+ */
+extern int fmap_append_area(struct fmap **fmap,
+			    uint32_t offset, uint32_t size,
+			    const uint8_t *name, uint16_t flags);
+
+/*
+ * fmap_find_area - find an fmap_area entry (by name) and return pointer to it
+ *
+ * @fmap:	fmap structure to parse
+ * @name:	name of area to find
+ *
+ * returns a pointer to the entry in the fmap structure if successful
+ * returns NULL to indicate failure or if no matching area entry is found
+ */
+extern const struct fmap_area *fmap_find_area(const struct fmap *fmap,
+							const char *name);
+
+/* unit testing stuff */
+extern int fmap_test(void);
+
+#endif	/* FLASHMAP_LIB_FMAP_H__*/
diff --git a/tools/cbfstool/flashmap/valstr.h b/tools/cbfstool/flashmap/valstr.h
new file mode 100644
index 0000000000..9b57d58cfd
--- /dev/null
+++ b/tools/cbfstool/flashmap/valstr.h
@@ -0,0 +1,78 @@
+/*
+ * Copyright 2010, Google Inc.
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *     * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef FLASHMAP_LIB_VALSTR_H__
+#define FLASHMAP_LIB_VALSTR_H__
+
+#include <inttypes.h>
+
+/* value + string structure for common conversions */
+struct valstr {
+	uint32_t val;		/* field value */
+	const char *str;	/* field description */
+};
+
+/*
+ * val2str_default  -  convert value to string
+ *
+ * @val:	value to convert
+ * @vs:		value-string data
+ * @def_str:	default string to return if no matching value found
+ *
+ * returns pointer to string
+ * returns def_str if no matching value found
+ */
+const char *val2str_default(uint32_t val, const struct valstr *vs,
+			    const char *def_str);
+
+/*
+ * val2str  -  convert value to string
+ *
+ * @val:	value to convert
+ * @vs:		value-string data
+ *
+ * returns pointer to string
+ * returns pointer to "unknown" static string if not found
+ */
+const char *val2str(uint32_t val, const struct valstr *vs);
+
+/*
+ * str2val  -  convert string to value
+ *
+ * @str:	string to convert
+ * @vs:		value-string data
+ *
+ * returns value for string
+ * returns value for last entry in value-string data if not found
+ */
+uint32_t str2val(const char *str, const struct valstr *vs);
+
+#endif	/* FLASHMAP_LIB_VALSTR_H__ */
diff --git a/tools/cbfstool/fmap.c b/tools/cbfstool/fmap.c
new file mode 100644
index 0000000000..6255fc5633
--- /dev/null
+++ b/tools/cbfstool/fmap.c
@@ -0,0 +1,684 @@
+/* Copyright 2015, Google Inc.
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *    * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *    * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *    * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * Alternatively, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") version 2 as published by the Free
+ * Software Foundation.
+ */
+
+#define _XOPEN_SOURCE 700
+
+#include <ctype.h>
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+#include <fcntl.h>
+#include <unistd.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/mman.h>
+#include <errno.h>
+#include <inttypes.h>
+#include <limits.h>
+#include <assert.h>
+
+#include "fmap.h"
+#include "kv_pair.h"
+#include "valstr.h"
+
+#define ARRAY_SIZE(arr) (sizeof(arr) / sizeof((arr)[0]))
+
+const struct valstr flag_lut[] = {
+	{ FMAP_AREA_STATIC, "static" },
+	{ FMAP_AREA_COMPRESSED, "compressed" },
+	{ FMAP_AREA_RO, "ro" },
+	{ FMAP_AREA_PRESERVE, "preserve" },
+};
+
+/* returns size of fmap data structure if successful, <0 to indicate error */
+int fmap_size(const struct fmap *fmap)
+{
+	if (!fmap)
+		return -1;
+
+	return sizeof(*fmap) + (fmap->nareas * sizeof(struct fmap_area));
+}
+
+/* Make a best-effort assessment if the given fmap is real */
+static int is_valid_fmap(const struct fmap *fmap)
+{
+	if (memcmp(fmap, FMAP_SIGNATURE, strlen(FMAP_SIGNATURE)) != 0)
+		return 0;
+	/* strings containing the magic tend to fail here */
+	if (fmap->ver_major != FMAP_VER_MAJOR)
+		return 0;
+	/* a basic consistency check: flash should be larger than fmap */
+	if (fmap->size <
+		sizeof(*fmap) + fmap->nareas * sizeof(struct fmap_area))
+		return 0;
+
+	/* fmap-alikes along binary data tend to fail on having a valid,
+	 * null-terminated string in the name field.*/
+	int i = 0;
+	while (i < FMAP_STRLEN) {
+		if (fmap->name[i] == 0)
+			break;
+		if (!isgraph(fmap->name[i]))
+			return 0;
+		if (i == FMAP_STRLEN - 1) {
+			/* name is specified to be null terminated single-word string
+			 * without spaces. We did not break in the 0 test, we know it
+			 * is a printable spaceless string but we're seeing FMAP_STRLEN
+			 * symbols, which is one too many.
+			 */
+			 return 0;
+		}
+		i++;
+	}
+	return 1;
+
+}
+
+/* brute force linear search */
+static long int fmap_lsearch(const uint8_t *image, size_t len)
+{
+	unsigned long int offset;
+	int fmap_found = 0;
+
+	for (offset = 0; offset < len - strlen(FMAP_SIGNATURE); offset++) {
+		if (is_valid_fmap((const struct fmap *)&image[offset])) {
+			fmap_found = 1;
+			break;
+		}
+	}
+
+	if (!fmap_found)
+		return -1;
+
+	if (offset + fmap_size((const struct fmap *)&image[offset]) > len)
+		return -1;
+
+	return offset;
+}
+
+/* if image length is a power of 2, use binary search */
+static long int fmap_bsearch(const uint8_t *image, size_t len)
+{
+	unsigned long int offset = -1;
+	int fmap_found = 0, stride;
+
+	/*
+	 * For efficient operation, we start with the largest stride possible
+	 * and then decrease the stride on each iteration. Also, check for a
+	 * remainder when modding the offset with the previous stride. This
+	 * makes it so that each offset is only checked once.
+	 */
+	for (stride = len / 2; stride >= 16; stride /= 2) {
+		if (fmap_found)
+			break;
+
+		for (offset = 0;
+		     offset < len - strlen(FMAP_SIGNATURE);
+		     offset += stride) {
+			if ((offset % (stride * 2) == 0) && (offset != 0))
+					continue;
+			if (is_valid_fmap(
+				(const struct fmap *)&image[offset])) {
+				fmap_found = 1;
+				break;
+			}
+		}
+	}
+
+	if (!fmap_found)
+		return -1;
+
+	if (offset + fmap_size((const struct fmap *)&image[offset]) > len)
+		return -1;
+
+	return offset;
+}
+
+static int popcnt(unsigned int u)
+{
+	int count;
+
+	/* K&R method */
+	for (count = 0; u; count++)
+		u &= (u - 1);
+
+	return count;
+}
+
+long int fmap_find(const uint8_t *image, unsigned int image_len)
+{
+	long int ret = -1;
+
+	if ((image == NULL) || (image_len == 0))
+		return -1;
+
+	if (popcnt(image_len) == 1)
+		ret = fmap_bsearch(image, image_len);
+	else
+		ret = fmap_lsearch(image, image_len);
+
+	return ret;
+}
+
+int fmap_print(const struct fmap *fmap)
+{
+	int i;
+	struct kv_pair *kv = NULL;
+	const uint8_t *tmp;
+
+	kv = kv_pair_new();
+	if (!kv)
+		return -1;
+
+	tmp = fmap->signature;
+	kv_pair_fmt(kv, "fmap_signature",
+			"0x%02x%02x%02x%02x%02x%02x%02x%02x",
+			tmp[0], tmp[1], tmp[2], tmp[3],
+			tmp[4], tmp[5], tmp[6], tmp[7]);
+	kv_pair_fmt(kv, "fmap_ver_major", "%d", fmap->ver_major);
+	kv_pair_fmt(kv, "fmap_ver_minor","%d", fmap->ver_minor);
+	kv_pair_fmt(kv, "fmap_base", "0x%016llx",
+		    (unsigned long long)fmap->base);
+	kv_pair_fmt(kv, "fmap_size", "0x%04x", fmap->size);
+	kv_pair_fmt(kv, "fmap_name", "%s", fmap->name);
+	kv_pair_fmt(kv, "fmap_nareas", "%d", fmap->nareas);
+	kv_pair_print(kv);
+	kv_pair_free(kv);
+
+	for (i = 0; i < fmap->nareas; i++) {
+		struct kv_pair *pair;
+		uint16_t flags;
+		char *str;
+
+		pair = kv_pair_new();
+		if (!pair)
+			return -1;
+
+		kv_pair_fmt(pair, "area_offset", "0x%08x",
+				fmap->areas[i].offset);
+		kv_pair_fmt(pair, "area_size", "0x%08x",
+				fmap->areas[i].size);
+		kv_pair_fmt(pair, "area_name", "%s",
+				fmap->areas[i].name);
+		kv_pair_fmt(pair, "area_flags_raw", "0x%02x",
+				fmap->areas[i].flags);
+
+		/* Print descriptive strings for flags rather than the field */
+		flags = fmap->areas[i].flags;
+		str = fmap_flags_to_string(flags);
+		if (str == NULL) {
+			kv_pair_free(pair);
+			return -1;
+		}
+		kv_pair_fmt(pair, "area_flags", "%s", str);
+		free(str);
+
+		kv_pair_print(pair);
+		kv_pair_free(pair);
+	}
+
+	return 0;
+}
+
+/* convert raw flags field to user-friendly string */
+char *fmap_flags_to_string(uint16_t flags)
+{
+	char *str = NULL;
+	unsigned int i, total_size;
+
+	str = malloc(1);
+	str[0] = '\0';
+	total_size = 1;
+
+	for (i = 0; i < sizeof(flags) * CHAR_BIT; i++) {
+		if (!flags)
+			break;
+
+		if (flags & (1 << i)) {
+			const char *tmp = val2str(1 << i, flag_lut);
+
+			total_size += strlen(tmp);
+			str = realloc(str, total_size);
+			strcat(str, tmp);
+
+			flags &= ~(1 << i);
+			if (flags) {
+				total_size++;
+				str = realloc(str, total_size);
+				strcat(str, ",");
+			}
+		}
+	}
+
+	return str;
+}
+
+/* allocate and initialize a new fmap structure */
+struct fmap *fmap_create(uint64_t base, uint32_t size, uint8_t *name)
+{
+	struct fmap *fmap;
+
+	fmap = malloc(sizeof(*fmap));
+	if (!fmap)
+		return NULL;
+
+	memset(fmap, 0, sizeof(*fmap));
+	memcpy(&fmap->signature, FMAP_SIGNATURE, strlen(FMAP_SIGNATURE));
+	fmap->ver_major = FMAP_VER_MAJOR;
+	fmap->ver_minor = FMAP_VER_MINOR;
+	fmap->base = base;
+	fmap->size = size;
+	memccpy(&fmap->name, name, '\0', FMAP_STRLEN);
+
+	return fmap;
+}
+
+/* free memory used by an fmap structure */
+void fmap_destroy(struct fmap *fmap) {
+	free(fmap);
+}
+
+/* append area to existing structure, return new total size if successful */
+int fmap_append_area(struct fmap **fmap,
+		     uint32_t offset, uint32_t size,
+		     const uint8_t *name, uint16_t flags)
+{
+	struct fmap_area *area;
+	int orig_size, new_size;
+
+	if ((fmap == NULL || *fmap == NULL) || (name == NULL))
+		return -1;
+
+	/* too many areas */
+	if ((*fmap)->nareas >= 0xffff)
+		return -1;
+
+	orig_size = fmap_size(*fmap);
+	new_size = orig_size + sizeof(*area);
+
+	*fmap = realloc(*fmap, new_size);
+	if (*fmap == NULL)
+		return -1;
+
+	area = (struct fmap_area *)((uint8_t *)*fmap + orig_size);
+	memset(area, 0, sizeof(*area));
+	memcpy(&area->offset, &offset, sizeof(area->offset));
+	memcpy(&area->size, &size, sizeof(area->size));
+	memccpy(&area->name, name, '\0', FMAP_STRLEN);
+	memcpy(&area->flags, &flags, sizeof(area->flags));
+
+	(*fmap)->nareas++;
+	return new_size;
+}
+
+const struct fmap_area *fmap_find_area(const struct fmap *fmap,
+							const char *name)
+{
+	int i;
+	const struct fmap_area *area = NULL;
+
+	if (!fmap || !name)
+		return NULL;
+
+	for (i = 0; i < fmap->nareas; i++) {
+		if (!strcmp((const char *)fmap->areas[i].name, name)) {
+			area = &fmap->areas[i];
+			break;
+		}
+	}
+
+	return area;
+}
+
+/*
+ * LCOV_EXCL_START
+ * Unit testing stuff done here so we do not need to expose static functions.
+ */
+static enum test_status { pass = EXIT_SUCCESS, fail = EXIT_FAILURE } status;
+static struct fmap *fmap_create_test(void)
+{
+	struct fmap *fmap;
+	uint64_t base = 0;
+	uint32_t size = 0x100000;
+	char name[] = "test_fmap";
+
+	status = fail;
+
+	fmap = fmap_create(base, size, (uint8_t *)name);
+	if (!fmap)
+		return NULL;
+
+	if (memcmp(&fmap->signature, FMAP_SIGNATURE, strlen(FMAP_SIGNATURE))) {
+		printf("FAILURE: signature is incorrect\n");
+		goto fmap_create_test_exit;
+	}
+
+	if ((fmap->ver_major != FMAP_VER_MAJOR) ||
+	    (fmap->ver_minor != FMAP_VER_MINOR)) {
+		printf("FAILURE: version is incorrect\n");
+		goto fmap_create_test_exit;
+	}
+
+	if (fmap->base != base) {
+		printf("FAILURE: base is incorrect\n");
+		goto fmap_create_test_exit;
+	}
+
+	if (fmap->size != 0x100000) {
+		printf("FAILURE: size is incorrect\n");
+		goto fmap_create_test_exit;
+	}
+
+	if (strcmp((char *)fmap->name, "test_fmap")) {
+		printf("FAILURE: name is incorrect\n");
+		goto fmap_create_test_exit;
+	}
+
+	if (fmap->nareas != 0) {
+		printf("FAILURE: number of areas is incorrect\n");
+		goto fmap_create_test_exit;
+	}
+
+	status = pass;
+fmap_create_test_exit:
+	/* preserve fmap if all went well */
+	if (status == fail) {
+		fmap_destroy(fmap);
+		fmap = NULL;
+	}
+	return fmap;
+}
+
+static int fmap_print_test(struct fmap *fmap)
+{
+	return fmap_print(fmap);
+}
+
+static int fmap_size_test(void)
+{
+	status = fail;
+
+	if (fmap_size(NULL) >= 0) {
+		printf("FAILURE: failed to abort on NULL pointer input\n");
+		goto fmap_size_test_exit;
+	}
+
+	status = pass;
+fmap_size_test_exit:
+	return status;
+}
+
+/* this test re-allocates the fmap, so it gets a double-pointer */
+static int fmap_append_area_test(struct fmap **fmap)
+{
+	int total_size;
+	uint16_t nareas_orig;
+	/* test_area will be used by fmap_csum_test and find_area_test */
+	struct fmap_area test_area = {
+		.offset = 0x400,
+		.size = 0x10000,
+		.name = "test_area_1",
+		.flags = FMAP_AREA_STATIC,
+	};
+
+	status = fail;
+
+	if ((fmap_append_area(NULL, 0, 0, test_area.name, 0) >= 0) ||
+	    (fmap_append_area(fmap, 0, 0, NULL, 0) >= 0)) {
+		printf("FAILURE: failed to abort on NULL pointer input\n");
+		goto fmap_append_area_test_exit;
+	}
+
+	nareas_orig = (*fmap)->nareas;
+	(*fmap)->nareas = ~(0);
+	if (fmap_append_area(fmap, 0, 0, (const uint8_t *)"foo", 0) >= 0) {
+		printf("FAILURE: failed to abort with too many areas\n");
+		goto fmap_append_area_test_exit;
+	}
+	(*fmap)->nareas = nareas_orig;
+
+	total_size = sizeof(**fmap) + sizeof(test_area);
+	if (fmap_append_area(fmap,
+			     test_area.offset,
+			     test_area.size,
+			     test_area.name,
+			     test_area.flags
+			     ) != total_size) {
+		printf("failed to append area\n");
+		goto fmap_append_area_test_exit;
+	}
+
+	if ((*fmap)->nareas != 1) {
+		printf("FAILURE: failed to increment number of areas\n");
+		goto fmap_append_area_test_exit;
+	}
+
+	status = pass;
+fmap_append_area_test_exit:
+	return status;
+}
+
+static int fmap_find_area_test(struct fmap *fmap)
+{
+	status = fail;
+	char area_name[] = "test_area_1";
+
+	if (fmap_find_area(NULL, area_name) ||
+	    fmap_find_area(fmap, NULL)) {
+		printf("FAILURE: failed to abort on NULL pointer input\n");
+		goto fmap_find_area_test_exit;
+	}
+
+	if (fmap_find_area(fmap, area_name) == NULL) {
+		printf("FAILURE: failed to find \"%s\"\n", area_name);
+		goto fmap_find_area_test_exit;
+	}
+
+	status = pass;
+fmap_find_area_test_exit:
+	return status;
+}
+
+static int fmap_flags_to_string_test(void)
+{
+	char *str = NULL;
+	char *my_str = NULL;
+	unsigned int i;
+	uint16_t flags;
+
+	status = fail;
+
+	/* no area flag */
+	str = fmap_flags_to_string(0);
+	if (!str || strcmp(str, "")) {
+		printf("FAILURE: failed to return empty string when no flag"
+		       "are set");
+		goto fmap_flags_to_string_test_exit;
+	}
+	free(str);
+
+	/* single area flags */
+	for (i = 0; i < ARRAY_SIZE(flag_lut); i++) {
+		if (!flag_lut[i].str)
+			continue;
+
+		if ((str = fmap_flags_to_string(flag_lut[i].val)) == NULL) {
+			printf("FAILURE: failed to translate flag to string");
+			goto fmap_flags_to_string_test_exit;
+		}
+		free(str);
+	}
+
+	/* construct our own flags field and string using all available flags
+	 * and compare output with fmap_flags_to_string() */
+	my_str = calloc(256, 1);
+	flags = 0;
+	for (i = 0; i < ARRAY_SIZE(flag_lut); i++) {
+		if (!flag_lut[i].str)
+			continue;
+		else if (i > 0)
+			strcat(my_str, ",");
+
+		flags |= flag_lut[i].val;
+		strcat(my_str, flag_lut[i].str);
+	}
+
+	str = fmap_flags_to_string(flags);
+	if (strcmp(str, my_str)) {
+		printf("FAILURE: bad result from fmap_flags_to_string\n");
+		goto fmap_flags_to_string_test_exit;
+	}
+
+	status = pass;
+fmap_flags_to_string_test_exit:
+	free(str);
+	free(my_str);
+	return status;
+
+}
+
+static int fmap_find_test(struct fmap *fmap)
+{
+	uint8_t *buf;
+	size_t total_size, offset;
+
+	status = fail;
+
+	/*
+	 * Note: In these tests, we'll use fmap_find() and control usage of
+	 * lsearch and bsearch by using a power-of-2 total_size. For lsearch,
+	 * use total_size - 1. For bsearch, use total_size.
+	 */
+
+	total_size = 0x100000;
+	buf = calloc(total_size, 1);
+
+	/* test if image length is zero */
+	if (fmap_find(buf, 0) >= 0) {
+		printf("FAILURE: failed to abort on zero-length image\n");
+		goto fmap_find_test_exit;
+	}
+
+	/* test if no fmap exists */
+	if (fmap_find(buf, total_size - 1) >= 0) {
+		printf("FAILURE: lsearch returned false positive\n");
+		goto fmap_find_test_exit;
+	}
+	if (fmap_find(buf, total_size) >= 0) {
+		printf("FAILURE: bsearch returned false positive\n");
+		goto fmap_find_test_exit;
+	}
+
+	/* simple test case: fmap at (total_size / 2) + 1 */
+	offset = (total_size / 2) + 1;
+	memcpy(&buf[offset], fmap, fmap_size(fmap));
+
+	if ((unsigned)fmap_find(buf, total_size - 1) != offset) {
+		printf("FAILURE: lsearch failed to find fmap\n");
+		goto fmap_find_test_exit;
+	}
+	if ((unsigned)fmap_find(buf, total_size) != offset) {
+		printf("FAILURE: bsearch failed to find fmap\n");
+		goto fmap_find_test_exit;
+	}
+
+	/* test bsearch if offset is at 0 */
+	offset = 0;
+	memset(buf, 0, total_size);
+	memcpy(buf, fmap, fmap_size(fmap));
+	if ((unsigned)fmap_find(buf, total_size) != offset) {
+		printf("FAILURE: bsearch failed to find fmap at offset 0\n");
+		goto fmap_find_test_exit;
+	}
+
+	/* test overrun detection */
+	memset(buf, 0, total_size);
+	memcpy(&buf[total_size - fmap_size(fmap) + 1],
+	       fmap,
+	       fmap_size(fmap) + 1);
+	if (fmap_find(buf, total_size - 1) >= 0) {
+		printf("FAILURE: lsearch failed to catch overrun\n");
+		goto fmap_find_test_exit;
+	}
+	if (fmap_find(buf, total_size) >= 0) {
+		printf("FAILURE: bsearch failed to catch overrun\n");
+		goto fmap_find_test_exit;
+	}
+
+	status = pass;
+fmap_find_test_exit:
+	free(buf);
+	return status;
+}
+
+int fmap_test(void)
+{
+	int rc = EXIT_SUCCESS;
+	struct fmap *my_fmap;
+
+	/*
+	 * This test has two parts: Creation of an fmap with one or more
+	 * area(s), and other stuff. Since a valid fmap is required to run
+	 * many tests, we abort if fmap creation fails in any way.
+	 *
+	 * Also, fmap_csum_test() makes some assumptions based on the areas
+	 * appended. See fmap_append_area_test() for details.
+	 */
+	if ((my_fmap = fmap_create_test()) == NULL) {
+		rc = EXIT_FAILURE;
+		goto fmap_test_exit;
+	}
+
+	if (fmap_find_test(my_fmap)) {
+		rc = EXIT_FAILURE;
+		goto fmap_test_exit;
+	}
+
+	if (fmap_append_area_test(&my_fmap)) {
+		rc = EXIT_FAILURE;
+		goto fmap_test_exit;
+	}
+
+	rc |= fmap_find_area_test(my_fmap);
+	rc |= fmap_size_test();
+	rc |= fmap_flags_to_string_test();
+	rc |= fmap_print_test(my_fmap);
+
+fmap_test_exit:
+	fmap_destroy(my_fmap);
+	if (rc)
+		printf("FAILED\n");
+	return rc;
+}
+/* LCOV_EXCL_STOP */
diff --git a/tools/cbfstool/fmd.h b/tools/cbfstool/fmd.h
new file mode 100644
index 0000000000..90e6d6e176
--- /dev/null
+++ b/tools/cbfstool/fmd.h
@@ -0,0 +1,146 @@
+/*
+ * fmd.h, parser frontend and utility functions for flashmap descriptor language
+ *
+ * Copyright (C) 2015 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef FMD_H_
+#define FMD_H_
+
+#include <limits.h>
+#include <stdbool.h>
+#include <stddef.h>
+#include <stdio.h>
+
+#define FMD_NOTFOUND UINT_MAX
+
+/**
+ * Flags used by flashmap_descriptor.
+ * These flags can be set by adding (NAME) after description name.
+ * For example, declaring a CBFS section named as COREBOOT for 16k:
+ *   COREBOOT(CBFS) 16k
+ */
+union flashmap_flags {
+	struct {
+		int cbfs: 1;  /* The section contains a CBFS area. */
+		int preserve: 1;  /* Preserve the section before update. */
+	} f;
+	int v;
+};
+
+struct flashmap_descriptor {
+	char *name;
+	bool offset_known;
+	/**
+	 * Offset relative to that of the parent node.
+	 * Exception: for the root node in the descriptor tree, it is optional.
+	 * In this case, if absent, it indicates that the flash chip will not be
+	 * memory mapped at runtime; otherwise, its value indicates the base
+	 * address of the flash chip in the virtual address space rather than
+	 * representing an offset into the flash image itself.
+	 * It is an error to read this field unless offset_known is set.
+	 */
+	unsigned offset;
+	bool size_known;
+	/** It is an error to read this field unless size_known is set. */
+	unsigned size;
+	size_t list_len;
+	union flashmap_flags flags;
+	/** It is an error to dereference this array if list_len is 0. */
+	struct flashmap_descriptor **list;
+};
+
+/**
+ * **Client-defined** callback for flag "CBFS".
+ * This call is used to notify client code that the user has requested the given
+ * section node to be flagged with "CBFS". Implementations of this function
+ * should use their return type to tell the compiler whether the flag can be
+ * applied and can perform whatever actions are necessary.
+ * It's worth reiterating that this is only called on section nodes, and will
+ * never be called with the final, complete flashmap_descriptor because
+ * it is impossible to set flags for the image as a whole.
+ *
+ * @param flashmap_descriptor The section node with flag set
+ * @return                    Whether this flag can be applied
+ */
+bool fmd_process_flag_cbfs(const struct flashmap_descriptor *node);
+
+/**
+ * Parse and validate a flashmap descriptor from the specified stream.
+ * As part of this process, any fields that were omitted in the input are
+ * inferred from whatever information is known, if possible. The result is a
+ * tree with all its offset and size fields filled, except possibly the former
+ * part of the root node in the case of non--memory mapped flash. If a syntax
+ * error causes the parser to fail, or if there is not enough information given
+ * in the input file to determine any single missing value, the specific error
+ * is reported to standard error and this function returns NULL.
+ *
+ * @param stream File from which to read the (partial) flashmap descriptor
+ * @return       Populated flashmap descriptor tree, or NULL on failure
+ */
+struct flashmap_descriptor *fmd_create(FILE *stream);
+
+/** @param victim Valid descriptor tree to be cleaned up, or NULL for no-op */
+void fmd_cleanup(struct flashmap_descriptor *victim);
+
+/**
+ * @param tree Must be non-NULL
+ * @return     The number of nodes in the tree, including the root
+ */
+size_t fmd_count_nodes(const struct flashmap_descriptor *tree);
+
+/**
+ * @param root The flashmap descriptor to search
+ * @param name The name of the sought-after section
+ * @return     The desired section node, or NULL if none was found
+ */
+const struct flashmap_descriptor *fmd_find_node(
+		const struct flashmap_descriptor *root, const char *name);
+
+/**
+ * @param root Parent node to whose start the "absolute" offset will be relative
+ * @param name The name of the node whose offset to determine
+ * @return     The "absolute" offset, or FMD_NOTFOUND if the node wasn't found
+ */
+unsigned fmd_calc_absolute_offset(const struct flashmap_descriptor *root,
+							const char *name);
+
+/** @param tree Must be non-NULL */
+void fmd_print(const struct flashmap_descriptor *tree);
+
+typedef struct flashmap_descriptor **flashmap_descriptor_iterator_t;
+
+/*
+ * Run the subsequent statement once on each descendant of the specified node.
+ *
+ * @param iterator A flashmap_descriptor_iterator_t (automatically declared)
+ * @param parent   The parent node of those over which the loop should iterate
+ */
+#define fmd_foreach_child_iterator(iterator, parent) \
+	for (flashmap_descriptor_iterator_t iterator = parent->list; \
+		iterator < parent->list + parent->list_len; ++iterator)
+
+/*
+ * Run the subsequent statement once on each descendant of the specified node.
+ *
+ * @param child  A struct flashmap_descriptor * (automatically declared)
+ * @param parent The parent node of those over which the loop should iterate
+ */
+#define fmd_foreach_child(child, parent) \
+	for (struct flashmap_descriptor **fmd_foreach_child_iterator_ = \
+						parent->list, *child = NULL; \
+						fmd_foreach_child_iterator_ < \
+					parent->list + parent->list_len && \
+				(child = *fmd_foreach_child_iterator_); \
+						++fmd_foreach_child_iterator_)
+
+#endif
diff --git a/tools/cbfstool/fsp_relocate.c b/tools/cbfstool/fsp_relocate.c
new file mode 100644
index 0000000000..30eadb5eb7
--- /dev/null
+++ b/tools/cbfstool/fsp_relocate.c
@@ -0,0 +1,553 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <console/console.h>
+#include <commonlib/endian.h>
+#include <commonlib/fsp.h>
+/*
+ * Intel's code does not have a handle on changing global packing state.
+ * Therefore, one needs to protect against packing policies that are set
+ * globally for a compilation unit just by including a header file.
+ */
+#pragma pack(push)
+
+/* Default bind FSP 1.1 API to edk2 UEFI 2.4 types. */
+#include <Uefi/uefi_types.h>
+#include <IntelFspPkg/FspInfoHeader.h>
+
+/* Restore original packing policy. */
+#pragma pack(pop)
+
+#include <commonlib/helpers.h>
+#include <stdlib.h>
+#include <stdint.h>
+#include <string.h>
+
+#define FSP_DBG_LVL BIOS_NEVER
+
+/*
+ * UEFI defines everything as little endian. However, this piece of code
+ * can be integrated in a userland tool. That tool could be on a big endian
+ * machine so one needs to access the fields within UEFI structures using
+ * endian-aware accesses.
+ */
+
+/* Return 0 if equal. Non-zero if not equal. */
+static int guid_compare(const EFI_GUID *le_guid, const EFI_GUID *native_guid)
+{
+	if (read_le32(&le_guid->Data1) != native_guid->Data1)
+		return 1;
+	if (read_le16(&le_guid->Data2) != native_guid->Data2)
+		return 1;
+	if (read_le16(&le_guid->Data3) != native_guid->Data3)
+		return 1;
+	return memcmp(le_guid->Data4, native_guid->Data4,
+			ARRAY_SIZE(le_guid->Data4));
+}
+
+static const EFI_GUID ffs2_guid = EFI_FIRMWARE_FILE_SYSTEM2_GUID;
+static const EFI_GUID fih_guid = FSP_INFO_HEADER_GUID;
+
+struct fsp_patch_table {
+	uint32_t signature;
+	uint16_t header_length;
+	uint8_t header_revision;
+	uint8_t reserved;
+	uint32_t patch_entry_num;
+	uint32_t patch_entries[0];
+} __packed;
+
+#define FSPP_SIG 0x50505346
+
+static void *relative_offset(void *base, ssize_t offset)
+{
+	uintptr_t loc;
+
+	loc = (uintptr_t)base;
+	loc += offset;
+
+	return (void *)loc;
+}
+
+static uint32_t *fspp_reloc(void *fsp, size_t fsp_size, uint32_t e)
+{
+	size_t offset;
+
+	/* Offsets live in bits 23:0. */
+	offset = e & 0xffffff;
+
+	/* If bit 31 is set then the offset is considered a negative value
+	 * relative to the end of the image using 16MiB as the offset's
+	 * reference. */
+	if (e & (1 << 31))
+		offset = fsp_size - (16 * MiB - offset);
+
+	/* Determine if offset falls within fsp_size for a 32 bit relocation. */
+	if (offset > fsp_size - sizeof(uint32_t))
+		return NULL;
+
+	return relative_offset(fsp, offset);
+}
+
+static int reloc_type(uint16_t reloc_entry)
+{
+	/* Reloc type in upper 4 bits */
+	return reloc_entry >> 12;
+}
+
+static size_t reloc_offset(uint16_t reloc_entry)
+{
+	/* Offsets are in low 12 bits. */
+	return reloc_entry & ((1 << 12) - 1);
+}
+
+static int te_relocate(uintptr_t new_addr, void *te)
+{
+	EFI_TE_IMAGE_HEADER *teih;
+	EFI_IMAGE_DATA_DIRECTORY *relocd;
+	EFI_IMAGE_BASE_RELOCATION *relocb;
+	uintptr_t image_base;
+	size_t fixup_offset;
+	size_t num_relocs;
+	uint16_t *reloc;
+	size_t relocd_offset;
+	uint8_t *te_base;
+	uint32_t adj;
+
+	teih = te;
+
+	if (read_le16(&teih->Signature) != EFI_TE_IMAGE_HEADER_SIGNATURE) {
+		printk(BIOS_ERR, "TE Signature mismatch: %x vs %x\n",
+			read_le16(&teih->Signature),
+			EFI_TE_IMAGE_HEADER_SIGNATURE);
+		return -1;
+	}
+
+	/*
+	 * A TE image is created by converting a PE file. Because of this
+	 * the offsets within the headers are off. In order to calculate
+	 * the correct releative offets one needs to subtract fixup_offset
+	 * from the encoded offets.  Similarly, the linked address of the
+	 * program is found by adding the fixup_offset to the ImageBase.
+	 */
+	fixup_offset = read_le16(&teih->StrippedSize);
+	fixup_offset -= sizeof(EFI_TE_IMAGE_HEADER);
+	/* Keep track of a base that is correctly adjusted so that offsets
+	 * can be used directly. */
+	te_base = te;
+	te_base -= fixup_offset;
+
+	image_base = read_le64(&teih->ImageBase);
+	adj = new_addr - (image_base + fixup_offset);
+
+	printk(FSP_DBG_LVL, "TE Image %p -> %p adjust value: %x\n",
+		(void *)image_base, (void *)new_addr, adj);
+
+	/* Adjust ImageBase for consistency. */
+	write_le64(&teih->ImageBase, (uint32_t)(image_base + adj));
+
+	relocd = &teih->DataDirectory[EFI_TE_IMAGE_DIRECTORY_ENTRY_BASERELOC];
+
+	relocd_offset = 0;
+	/* Though the field name is VirtualAddress it's actually relative to
+	 * the beginning of the image which is linked at ImageBase. */
+	relocb = relative_offset(te,
+			read_le32(&relocd->VirtualAddress) - fixup_offset);
+	while (relocd_offset < read_le32(&relocd->Size)) {
+		size_t rva_offset = read_le32(&relocb->VirtualAddress);
+
+		printk(FSP_DBG_LVL, "Relocs for RVA offset %zx\n", rva_offset);
+		num_relocs = read_le32(&relocb->SizeOfBlock) - sizeof(*relocb);
+		num_relocs /= sizeof(uint16_t);
+		reloc = relative_offset(relocb, sizeof(*relocb));
+
+		printk(FSP_DBG_LVL, "Num relocs in block: %zx\n", num_relocs);
+
+		while (num_relocs > 0) {
+			uint16_t reloc_val = read_le16(reloc);
+			int type = reloc_type(reloc_val);
+			size_t offset = reloc_offset(reloc_val);
+
+			printk(FSP_DBG_LVL, "reloc type %x offset %zx\n",
+				type, offset);
+
+			if (type == EFI_IMAGE_REL_BASED_HIGHLOW) {
+				uint32_t *reloc_addr;
+				uint32_t val;
+
+				offset += rva_offset;
+				reloc_addr = (void *)&te_base[offset];
+				val = read_le32(reloc_addr);
+
+				printk(FSP_DBG_LVL, "Adjusting %p %x -> %x\n",
+					reloc_addr, val, val + adj);
+				write_le32(reloc_addr, val + adj);
+			} else if (type != EFI_IMAGE_REL_BASED_ABSOLUTE) {
+				printk(BIOS_ERR, "Unknown reloc type: %x\n",
+					type);
+				return -1;
+			}
+			num_relocs--;
+			reloc++;
+		}
+
+		/* Track consumption of relocation directory contents. */
+		relocd_offset += read_le32(&relocb->SizeOfBlock);
+		/* Get next relocation block to process. */
+		relocb = relative_offset(relocb,
+					read_le32(&relocb->SizeOfBlock));
+	}
+
+	return 0;
+}
+
+static size_t csh_size(const EFI_COMMON_SECTION_HEADER *csh)
+{
+	size_t size;
+
+	/* Unpack the array into a type that can be used. */
+	size = 0;
+	size |= read_le8(&csh->Size[0]) << 0;
+	size |= read_le8(&csh->Size[1]) << 8;
+	size |= read_le8(&csh->Size[2]) << 16;
+
+	return size;
+}
+
+static size_t section_data_offset(const EFI_COMMON_SECTION_HEADER *csh)
+{
+	if (csh_size(csh) == 0x00ffffff)
+		return sizeof(EFI_COMMON_SECTION_HEADER2);
+	else
+		return sizeof(EFI_COMMON_SECTION_HEADER);
+}
+
+static size_t section_data_size(const EFI_COMMON_SECTION_HEADER *csh)
+{
+	size_t section_size;
+
+	if (csh_size(csh) == 0x00ffffff)
+		section_size = read_le32(&SECTION2_SIZE(csh));
+	else
+		section_size = csh_size(csh);
+
+	return section_size - section_data_offset(csh);
+}
+
+static size_t file_section_offset(const EFI_FFS_FILE_HEADER *ffsfh)
+{
+	if (IS_FFS_FILE2(ffsfh))
+		return sizeof(EFI_FFS_FILE_HEADER2);
+	else
+		return sizeof(EFI_FFS_FILE_HEADER);
+}
+
+static size_t ffs_file_size(const EFI_FFS_FILE_HEADER *ffsfh)
+{
+	size_t size;
+
+	if (IS_FFS_FILE2(ffsfh)) {
+		/*
+		 * this cast is needed with UEFI 2.6 headers in order
+		 * to read the UINT32 value that FFS_FILE2_SIZE converts
+		 * the return into
+		 */
+		uint32_t file2_size = FFS_FILE2_SIZE(ffsfh);
+		size = read_le32(&file2_size);
+	} else {
+		size = read_le8(&ffsfh->Size[0]) << 0;
+		size |= read_le8(&ffsfh->Size[1]) << 8;
+		size |= read_le8(&ffsfh->Size[2]) << 16;
+	}
+	return size;
+}
+
+static int relocate_patch_table(void *fsp, size_t size, size_t offset,
+				ssize_t adjustment)
+{
+	struct fsp_patch_table *table;
+	size_t num;
+	size_t num_entries;
+
+	table = relative_offset(fsp, offset);
+
+	if ((offset + sizeof(*table) > size) ||
+	    (read_le16(&table->header_length) + offset) > size) {
+		printk(BIOS_ERR, "FSPP not entirely contained in region.\n");
+		return -1;
+	}
+
+	num_entries = read_le32(&table->patch_entry_num);
+	printk(FSP_DBG_LVL, "FSPP relocs: %zx\n", num_entries);
+
+	for (num = 0; num < num_entries; num++) {
+		uint32_t *reloc;
+		uint32_t reloc_val;
+
+		reloc = fspp_reloc(fsp, size,
+				read_le32(&table->patch_entries[num]));
+
+		if (reloc == NULL) {
+			printk(BIOS_ERR, "Ignoring FSPP entry: %x\n",
+				read_le32(&table->patch_entries[num]));
+			continue;
+		}
+
+		reloc_val = read_le32(reloc);
+		printk(FSP_DBG_LVL, "Adjusting %p %x -> %x\n",
+			reloc, reloc_val,
+			(unsigned int)(reloc_val + adjustment));
+
+		write_le32(reloc, reloc_val + adjustment);
+	}
+
+	return 0;
+}
+
+static ssize_t relocate_remaining_items(void *fsp, size_t size,
+					uintptr_t new_addr, size_t fih_offset)
+{
+	EFI_FFS_FILE_HEADER *ffsfh;
+	EFI_COMMON_SECTION_HEADER *csh;
+	FSP_INFO_HEADER *fih;
+	ssize_t adjustment;
+	size_t offset;
+
+	printk(FSP_DBG_LVL, "FSP_INFO_HEADER offset is %zx\n", fih_offset);
+
+	if (fih_offset == 0) {
+		printk(BIOS_ERR, "FSP_INFO_HEADER offset is 0.\n");
+		return -1;
+	}
+
+	/* FSP_INFO_HEADER at first file in FV within first RAW section. */
+	ffsfh = relative_offset(fsp, fih_offset);
+	fih_offset += file_section_offset(ffsfh);
+	csh = relative_offset(fsp, fih_offset);
+	fih_offset += section_data_offset(csh);
+	fih = relative_offset(fsp, fih_offset);
+
+	if (guid_compare(&ffsfh->Name, &fih_guid)) {
+		printk(BIOS_ERR, "Bad FIH GUID.\n");
+		return -1;
+	}
+
+	if (read_le8(&csh->Type) != EFI_SECTION_RAW) {
+		printk(BIOS_ERR, "FIH file should have raw section: %x\n",
+			read_le8(&csh->Type));
+		return -1;
+	}
+
+	if (read_le32(&fih->Signature) != FSP_SIG) {
+		printk(BIOS_ERR, "Unexpected FIH signature: %08x\n",
+			read_le32(&fih->Signature));
+		return -1;
+	}
+
+	adjustment = (intptr_t)new_addr - read_le32(&fih->ImageBase);
+
+	/* Update ImageBase to reflect FSP's new home. */
+	write_le32(&fih->ImageBase, adjustment + read_le32(&fih->ImageBase));
+
+	/* Need to find patch table and adjust each entry. The tables
+	 * following FSP_INFO_HEADER have a 32-bit signature and header
+	 * length. The patch table is denoted as having a 'FSPP' signature;
+	 * the table format doesn't follow the other tables. */
+	offset = fih_offset + read_le32(&fih->HeaderLength);
+	while (offset + 2 * sizeof(uint32_t) <= size) {
+		uint32_t *table_headers;
+
+		table_headers = relative_offset(fsp, offset);
+
+		printk(FSP_DBG_LVL, "Checking offset %zx for 'FSPP'\n",
+			offset);
+
+		if (read_le32(&table_headers[0]) != FSPP_SIG) {
+			offset += read_le32(&table_headers[1]);
+			continue;
+		}
+
+		if (relocate_patch_table(fsp, size, offset, adjustment)) {
+			printk(BIOS_ERR, "FSPP relocation failed.\n");
+			return -1;
+		}
+
+		return fih_offset;
+	}
+
+	printk(BIOS_ERR, "Could not find the FSP patch table.\n");
+	return -1;
+}
+
+static ssize_t relocate_fvh(uintptr_t new_addr, void *fsp, size_t fsp_size,
+				size_t fvh_offset, size_t *fih_offset)
+{
+	EFI_FIRMWARE_VOLUME_HEADER *fvh;
+	EFI_FFS_FILE_HEADER *ffsfh;
+	EFI_COMMON_SECTION_HEADER *csh;
+	size_t offset;
+	size_t file_offset;
+	size_t size;
+	size_t fv_length;
+
+	offset = fvh_offset;
+	fvh = relative_offset(fsp, offset);
+
+	if (read_le32(&fvh->Signature) != EFI_FVH_SIGNATURE)
+		return -1;
+
+	fv_length = read_le64(&fvh->FvLength);
+
+	printk(FSP_DBG_LVL, "FVH length: %zx Offset: %zx Mapping length: %zx\n",
+		fv_length, offset, fsp_size);
+
+	if (fv_length + offset > fsp_size)
+		return -1;
+
+	/* Parse only this FV. However, the algorithm uses offsets into the
+	 * entire FSP region so make size include the starting offset. */
+	size = fv_length + offset;
+
+	if (guid_compare(&fvh->FileSystemGuid, &ffs2_guid)) {
+		printk(BIOS_ERR, "FVH not an FFS2 type.\n");
+		return -1;
+	}
+
+	if (read_le16(&fvh->ExtHeaderOffset) != 0) {
+		EFI_FIRMWARE_VOLUME_EXT_HEADER *fveh;
+
+		offset += read_le16(&fvh->ExtHeaderOffset);
+		fveh = relative_offset(fsp, offset);
+		printk(FSP_DBG_LVL, "Extended Header Offset: %zx Size: %zx\n",
+			(size_t)read_le16(&fvh->ExtHeaderOffset),
+			(size_t)read_le32(&fveh->ExtHeaderSize));
+		offset += read_le32(&fveh->ExtHeaderSize);
+		/* FFS files are 8 byte aligned after extended header. */
+		offset = ALIGN_UP(offset, 8);
+	} else {
+		offset += read_le16(&fvh->HeaderLength);
+	}
+
+	file_offset = offset;
+	while (file_offset + sizeof(*ffsfh) < size) {
+		offset = file_offset;
+		printk(FSP_DBG_LVL, "file offset: %zx\n", file_offset);
+
+		/* First file and section should be FSP info header. */
+		if (fih_offset != NULL && *fih_offset == 0)
+			*fih_offset = file_offset;
+
+		ffsfh = relative_offset(fsp, file_offset);
+
+		printk(FSP_DBG_LVL, "file type = %x\n", read_le8(&ffsfh->Type));
+		printk(FSP_DBG_LVL, "file attribs = %x\n",
+			read_le8(&ffsfh->Attributes));
+
+		/* Exit FV relocation when empty space found */
+		if (read_le8(&ffsfh->Type) == EFI_FV_FILETYPE_FFS_MAX)
+			break;
+
+		/* Next file on 8 byte alignment. */
+		file_offset += ffs_file_size(ffsfh);
+		file_offset = ALIGN_UP(file_offset, 8);
+
+		/* Padding files have no section information. */
+		if (read_le8(&ffsfh->Type) == EFI_FV_FILETYPE_FFS_PAD)
+			continue;
+
+		offset += file_section_offset(ffsfh);
+
+		while (offset + sizeof(*csh) < file_offset) {
+			size_t data_size;
+			size_t data_offset;
+
+			csh = relative_offset(fsp, offset);
+
+			printk(FSP_DBG_LVL, "section offset: %zx\n", offset);
+			printk(FSP_DBG_LVL, "section type: %x\n",
+				read_le8(&csh->Type));
+
+			data_size = section_data_size(csh);
+			data_offset = section_data_offset(csh);
+
+			if (data_size + data_offset + offset > file_offset) {
+				printk(BIOS_ERR, "Section exceeds FV size.\n");
+				return -1;
+			}
+
+			/*
+			 * The entire FSP image can be thought of as one
+			 * program with a single link address even though there
+			 * are multiple TEs linked separately. The reason is
+			 * that each TE is linked for XIP. So in order to
+			 * relocate the TE properly we need to form the
+			 * relocated address based on the TE offset within
+			 * FSP proper.
+			 */
+			if (read_le8(&csh->Type) == EFI_SECTION_TE) {
+				void *te;
+				size_t te_offset = offset + data_offset;
+				uintptr_t te_addr = new_addr + te_offset;
+
+				printk(FSP_DBG_LVL, "TE image at offset %zx\n",
+					te_offset);
+				te = relative_offset(fsp, te_offset);
+				te_relocate(te_addr, te);
+			}
+
+			offset += data_size + data_offset;
+			/* Sections are aligned to 4 bytes. */
+			offset = ALIGN_UP(offset, 4);
+		}
+	}
+
+	/* Return amount of buffer parsed: FV size. */
+	return fv_length;
+}
+
+ssize_t fsp_component_relocate(uintptr_t new_addr, void *fsp, size_t size)
+{
+	size_t offset;
+	size_t fih_offset;
+
+	offset = 0;
+	fih_offset = 0;
+	while (offset < size) {
+		ssize_t nparsed;
+
+		/* Relocate each FV within the FSP region. The FSP_INFO_HEADER
+		 * should only be located in the first FV. */
+		if (offset == 0)
+			nparsed = relocate_fvh(new_addr, fsp, size, offset,
+						&fih_offset);
+		else
+			nparsed = relocate_fvh(new_addr, fsp, size, offset,
+						NULL);
+
+		/* FV should be larger than 0 or failed to parse. */
+		if (nparsed <= 0) {
+			printk(BIOS_ERR, "FV @ offset %zx relocation failed\n",
+				offset);
+			return -1;
+		}
+
+		offset += nparsed;
+	}
+
+	return relocate_remaining_items(fsp, size, new_addr, fih_offset);
+}
+
+ssize_t fsp1_1_relocate(uintptr_t new_addr, void *fsp, size_t size)
+{
+	return fsp_component_relocate(new_addr, fsp, size);
+}
diff --git a/tools/cbfstool/fv.h b/tools/cbfstool/fv.h
new file mode 100644
index 0000000000..04a34e3108
--- /dev/null
+++ b/tools/cbfstool/fv.h
@@ -0,0 +1,47 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * Copyright (C) 2013 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define FV_SIGNATURE 0x4856465f
+typedef struct {
+	uint8_t  padding[16];
+	uint8_t  guid[16];
+	uint64_t fv_length;
+	uint32_t signature;
+	uint32_t attributes;
+	uint16_t header_length;
+	uint16_t checksum;
+	uint16_t ext_header_offs;
+	uint8_t  reserved;
+	uint8_t  revision;
+	/* not used here: block map entries */
+} firmware_volume_header_t;
+
+#define FILETYPE_SEC 0x03
+#define FILETYPE_PAD 0xf0
+typedef struct {
+	uint8_t  name[16];
+	uint16_t integrity;
+	uint8_t  file_type;
+	uint8_t  attributes;
+	uint8_t  size[3];
+	uint8_t  state;
+} ffs_file_header_t;
+
+#define SECTION_PE32 0x10
+#define SECTION_RAW 0x19
+typedef struct {
+	uint8_t size[3];
+	uint8_t section_type;
+} common_section_header_t;
diff --git a/tools/cbfstool/kv_pair.c b/tools/cbfstool/kv_pair.c
new file mode 100644
index 0000000000..89d6169cae
--- /dev/null
+++ b/tools/cbfstool/kv_pair.c
@@ -0,0 +1,221 @@
+/*
+ * Copyright 2010, Google Inc.
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *    * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *    * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *    * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * Alternatively, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") version 2 as published by the Free
+ * Software Foundation.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <stdarg.h>
+
+#include "vboot/kv_pair.h"
+
+/* Internal variable for output style. Use accessors to get/set style. */
+static enum kv_pair_style _style;
+
+void kv_pair_set_style(enum kv_pair_style style)
+{
+	_style = style;
+}
+
+enum kv_pair_style kv_pair_get_style(void)
+{
+	return _style;
+}
+
+struct kv_pair *kv_pair_new(void)
+{
+	struct kv_pair *kv;
+
+	kv = calloc(1, sizeof(*kv));
+	if (!kv)
+		return NULL;
+
+	return kv;
+}
+
+struct kv_pair *kv_pair_add(struct kv_pair *kv_list,
+			    const char *key, const char *value)
+{
+	struct kv_pair *kv_new;
+	struct kv_pair *kv_ptr;
+
+	kv_new = kv_pair_new();
+	if (!kv_new)
+		return NULL;
+
+	/* save key=value strings if provided */
+	if (key) {
+		kv_new->key = strdup(key);
+		if (!kv_new->key)
+			goto kv_pair_add_failed;
+	}
+	if (value) {
+		kv_new->value = strdup(value);
+		if (!kv_new->value)
+			goto kv_pair_add_failed;
+	}
+
+	/* first in the list if no list provided */
+	if (kv_list) {
+		/* find the end of list */
+		for (kv_ptr = kv_list; kv_ptr->next != NULL;
+		     kv_ptr = kv_ptr->next)
+			;
+
+		/* link in the new pair at the end */
+		kv_ptr->next = kv_new;
+	}
+
+	/* return pointer to the new pair */
+	return kv_new;
+
+kv_pair_add_failed:
+	kv_pair_free(kv_new);
+	return NULL;
+}
+
+struct kv_pair *kv_pair_add_bool(struct kv_pair *kv_list,
+				 const char *key, int value)
+{
+	const char *str;
+
+	if (value) {
+		str = "yes";
+	} else {
+		str = "no";
+	}
+	return kv_pair_add(kv_list, key, str);
+}
+
+struct kv_pair *kv_pair_fmt(struct kv_pair *kv_list,
+			    const char *kv_key, const char *format, ...)
+{
+	char kv_value[KV_PAIR_MAX_VALUE_LEN];
+	va_list vptr;
+
+	memset(kv_value, 0, sizeof(kv_value));
+
+	va_start(vptr, format);
+	vsnprintf(kv_value, sizeof(kv_value), format, vptr);
+	va_end(vptr);
+
+	return kv_pair_add(kv_list, kv_key, kv_value);
+}
+
+void kv_pair_free(struct kv_pair *kv_list)
+{
+	struct kv_pair *kv_ptr = kv_list;
+	struct kv_pair *kv_next;
+
+	while (kv_ptr != NULL) {
+		/* free key/value strings */
+		if (kv_ptr->key)
+			free(kv_ptr->key);
+		if (kv_ptr->value)
+			free(kv_ptr->value);
+
+		/* free current pair move to next */
+		kv_next = kv_ptr->next;
+		free(kv_ptr);
+		kv_ptr = kv_next;
+	}
+}
+
+void kv_pair_print_to_file(FILE* fp, struct kv_pair *kv_list,
+			   enum kv_pair_style style)
+{
+	struct kv_pair *kv_ptr;
+
+	switch (style) {
+	case KV_STYLE_PAIR:
+		for (kv_ptr = kv_list; kv_ptr != NULL; kv_ptr = kv_ptr->next) {
+			if (kv_ptr->key && kv_ptr->value) {
+				fprintf(fp, "%s=\"%s\" ",
+					kv_ptr->key, kv_ptr->value);
+			}
+		}
+		break;
+
+	case KV_STYLE_VALUE:
+		for (kv_ptr = kv_list; kv_ptr != NULL; kv_ptr = kv_ptr->next) {
+			if (kv_ptr->value) {
+				fprintf(fp, "%s", kv_ptr->value);
+				if (kv_ptr->next)
+					fprintf(fp, " | ");
+			}
+		}
+		break;
+
+	case KV_STYLE_LONG:
+		for (kv_ptr = kv_list; kv_ptr != NULL; kv_ptr = kv_ptr->next) {
+			if (kv_ptr->key && kv_ptr->value)
+				fprintf(fp, "%-20s | %s\n",
+					kv_ptr->key, kv_ptr->value);
+		}
+		break;
+	}
+
+	fprintf(fp, "\n");
+}
+
+void kv_pair_print(struct kv_pair *kv_list)
+{
+	kv_pair_print_to_file(stdout, kv_list, kv_pair_get_style());
+}
+
+const char *kv_pair_get_value(struct kv_pair *kv_list, const char *kv_key)
+{
+	const char *kv_value = NULL;
+	struct kv_pair *kv_ptr;
+
+	for (kv_ptr = kv_list; kv_ptr != NULL; kv_ptr = kv_ptr->next) {
+		if (kv_ptr->key && strcmp(kv_ptr->key, kv_key) == 0) {
+			kv_value = kv_ptr->value;
+			break;
+		}
+	}
+	return kv_value;
+}
+
+int kv_pair_size(struct kv_pair *kv_list) {
+	struct kv_pair *kv_ptr;
+	int count;
+
+	count = 0;
+	for (kv_ptr = kv_list; kv_ptr != NULL; kv_ptr = kv_ptr->next) {
+		if (kv_ptr->key) {
+			count++;
+		}
+	}
+	return count;
+}
diff --git a/tools/cbfstool/linux.h b/tools/cbfstool/linux.h
new file mode 100644
index 0000000000..4bba6f0d5e
--- /dev/null
+++ b/tools/cbfstool/linux.h
@@ -0,0 +1,190 @@
+/*
+ * This file is part of coreboot..
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+/*
+ * Linux/i386 loader
+ * Supports bzImage, zImage and Image format.
+ *
+ * Based on work by Steve Gehlbach.
+ * Portions are taken from mkelfImage.
+ *
+ * 2003-09 by SONE Takeshi
+ */
+
+#include <stdint.h>
+#include "linux_trampoline.h"
+
+typedef uint8_t u8;
+typedef uint16_t u16;
+typedef uint32_t u32;
+typedef uint64_t u64;
+
+#define E820MAX	32		/* number of entries in E820MAP */
+struct e820entry {
+	u64 addr;		/* start of memory segment */
+	u64 size;		/* size of memory segment */
+	u32 type;		/* type of memory segment */
+#define E820_RAM	1
+#define E820_RESERVED	2
+#define E820_ACPI	3	/* usable as RAM once ACPI tables have been read */
+#define E820_NVS	4
+};
+
+/* The header of Linux/i386 kernel */
+struct linux_header {
+	u8 reserved1[0x1f1];	/* 0x000 */
+	u8 setup_sects;		/* 0x1f1 */
+	u16 root_flags;		/* 0x1f2 */
+	u32 syssize;		/* 0x1f4 (2.04+) */
+	u8 reserved2[2];	/* 0x1f8 */
+	u16 vid_mode;		/* 0x1fa */
+	u16 root_dev;		/* 0x1fc */
+	u16 boot_sector_magic;	/* 0x1fe */
+	/* 2.00+ */
+	u8 reserved3[2];	/* 0x200 */
+	u8 header_magic[4];	/* 0x202 */
+	u16 protocol_version;	/* 0x206 */
+	u32 realmode_swtch;	/* 0x208 */
+	u16 start_sys;		/* 0x20c */
+	u16 kver_addr;		/* 0x20e */
+	u8 type_of_loader;	/* 0x210 */
+	u8 loadflags;		/* 0x211 */
+	u16 setup_move_size;	/* 0x212 */
+	u32 code32_start;	/* 0x214 */
+	u32 ramdisk_image;	/* 0x218 */
+	u32 ramdisk_size;	/* 0x21c */
+	u8 reserved4[4];	/* 0x220 */
+	/* 2.01+ */
+	u16 heap_end_ptr;	/* 0x224 */
+	u8 reserved5[2];	/* 0x226 */
+	/* 2.02+ */
+	u32 cmd_line_ptr;	/* 0x228 */
+	/* 2.03+ */
+	u32 initrd_addr_max;	/* 0x22c */
+	/* 2.05+ */
+	u32 kernel_alignment;	/* 0x230 */
+	u8 relocatable_kernel;	/* 0x234 */
+	u8 min_alignment;	/* 0x235 (2.10+) */
+	u8 reserved6[2];	/* 0x236 */
+	/* 2.06+ */
+	u32 cmdline_size;	/* 0x238 */
+	/* 2.07+ */
+	u32 hardware_subarch;	/* 0x23c */
+	u64 hardware_subarch_data;/* 0x240 */
+	/* 2.08+ */
+	u32 payload_offset;	/* 0x248 */
+	u32 payload_length;	/* 0x24c */
+	/* 2.09+ */
+	u64 setup_data;		/* 0x250 */
+	/* 2.10+ */
+	u64 pref_address;	/* 0x258 */
+	u32 init_size;		/* 0x260 */
+} __packed;
+
+/* Parameters passed to 32-bit part of Linux
+ * This is another view of the structure above.. */
+struct linux_params {
+	u8 orig_x;		/* 0x00 */
+	u8 orig_y;		/* 0x01 */
+	u16 ext_mem_k;		/* 0x02 -- EXT_MEM_K sits here */
+	u16 orig_video_page;	/* 0x04 */
+	u8 orig_video_mode;	/* 0x06 */
+	u8 orig_video_cols;	/* 0x07 */
+	u16 unused2;		/* 0x08 */
+	u16 orig_video_ega_bx;	/* 0x0a */
+	u16 unused3;		/* 0x0c */
+	u8 orig_video_lines;	/* 0x0e */
+	u8 orig_video_isVGA;	/* 0x0f */
+	u16 orig_video_points;	/* 0x10 */
+
+	/* VESA graphic mode -- linear frame buffer */
+	u16 lfb_width;		/* 0x12 */
+	u16 lfb_height;		/* 0x14 */
+	u16 lfb_depth;		/* 0x16 */
+	u32 lfb_base;		/* 0x18 */
+	u32 lfb_size;		/* 0x1c */
+	u16 cl_magic;		/* 0x20 */
+#define CL_MAGIC_VALUE 0xA33F
+	u16 cl_offset;		/* 0x22 */
+	u16 lfb_linelength;	/* 0x24 */
+	u8 red_size;		/* 0x26 */
+	u8 red_pos;		/* 0x27 */
+	u8 green_size;		/* 0x28 */
+	u8 green_pos;		/* 0x29 */
+	u8 blue_size;		/* 0x2a */
+	u8 blue_pos;		/* 0x2b */
+	u8 rsvd_size;		/* 0x2c */
+	u8 rsvd_pos;		/* 0x2d */
+	u16 vesapm_seg;		/* 0x2e */
+	u16 vesapm_off;		/* 0x30 */
+	u16 pages;		/* 0x32 */
+	u8 reserved4[12];	/* 0x34 -- 0x3f reserved for future expansion */
+
+	//struct apm_bios_info apm_bios_info;   /* 0x40 */
+	u8 apm_bios_info[0x40];
+	//struct drive_info_struct drive_info;  /* 0x80 */
+	u8 drive_info[0x20];
+	//struct sys_desc_table sys_desc_table; /* 0xa0 */
+	u8 sys_desc_table[0x140];
+	u32 alt_mem_k;		/* 0x1e0 */
+	u8 reserved5[4];	/* 0x1e4 */
+	u8 e820_map_nr;		/* 0x1e8 */
+	u8 reserved6[8];	/* 0x1e9 */
+				/* This next variable is to show where
+				 * in this struct the Linux setup_hdr
+				 * is located. It does not get filled in.
+				 * We may someday find it useful to use
+				 * its address. */
+	u8 setup_hdr;           /* 0x1f1  */
+	u16 mount_root_rdonly;	/* 0x1f2 */
+	u8 reserved7[4];	/* 0x1f4 */
+	u16 ramdisk_flags;	/* 0x1f8 */
+#define RAMDISK_IMAGE_START_MASK	0x07FF
+#define RAMDISK_PROMPT_FLAG		0x8000
+#define RAMDISK_LOAD_FLAG		0x4000
+	u8 reserved8[2];	/* 0x1fa */
+	u16 orig_root_dev;	/* 0x1fc */
+	u8 reserved9[1];	/* 0x1fe */
+	u8 aux_device_info;	/* 0x1ff */
+	u8 reserved10[2];	/* 0x200 */
+	u8 param_block_signature[4];	/* 0x202 */
+	u16 param_block_version;	/* 0x206 */
+	u8 reserved11[8];	/* 0x208 */
+	u8 loader_type;		/* 0x210 */
+#define LOADER_TYPE_LOADLIN         1
+#define LOADER_TYPE_BOOTSECT_LOADER 2
+#define LOADER_TYPE_SYSLINUX        3
+#define LOADER_TYPE_ETHERBOOT       4
+#define LOADER_TYPE_KERNEL          5
+	u8 loader_flags;	/* 0x211 */
+	u8 reserved12[2];	/* 0x212 */
+	u32 kernel_start;	/* 0x214 */
+	u32 initrd_start;	/* 0x218 */
+	u32 initrd_size;	/* 0x21c */
+	u8 reserved12_5[8];	/* 0x220 */
+	u32 cmd_line_ptr;	/* 0x228 */
+	u32 initrd_addr_max;	/* 0x22c */
+	u32 kernel_alignment;	/* 0x230 */
+	u8 relocatable_kernel;	/* 0x234 */
+	u8 reserved13[0x2b];		/* 0x235 */
+	u32 init_size;          /* 0x260 */
+	u8 reserved14[0x6c];		/* 0x264 */
+	struct e820entry e820_map[E820MAX];	/* 0x2d0 */
+	u8 reserved16[688];	/* 0x550 */
+#define COMMAND_LINE_SIZE 256
+	/* Command line is copied here by 32-bit i386/kernel/head.S.
+	 * So I will follow the boot protocol, rather than putting it
+	 * directly here. --ts1 */
+	u8 command_line[COMMAND_LINE_SIZE];	/* 0x800 */
+	u8 reserved17[1792];	/* 0x900 - 0x1000 */
+};
diff --git a/tools/cbfstool/linux_trampoline.c b/tools/cbfstool/linux_trampoline.c
new file mode 100644
index 0000000000..87f174ceb3
--- /dev/null
+++ b/tools/cbfstool/linux_trampoline.c
@@ -0,0 +1,16 @@
+/* This file is automatically generated. Do not manually change */
+unsigned char trampoline[] = {
+  0xfc, 0x31, 0xd2, 0xb9, 0x00, 0x00, 0x00, 0x00, 0xbb, 0x00, 0x00, 0x01, 0x00, 0x01, 0xcb, 0x8b,
+  0x01, 0x3d, 0x4c, 0x42, 0x49, 0x4f, 0x74, 0x07, 0x83, 0xc1, 0x10, 0x39, 0xcb, 0x75, 0xe9, 0x39,
+  0xcb, 0x0f, 0x84, 0x8a, 0x00, 0x00, 0x00, 0x8b, 0x59, 0x04, 0x01, 0xcb, 0x8b, 0x49, 0x14, 0x83,
+  0x3b, 0x11, 0x75, 0x05, 0x8b, 0x4b, 0x08, 0xeb, 0xcf, 0x83, 0x3b, 0x01, 0x75, 0x33, 0x8b, 0x43,
+  0x04, 0x83, 0xe8, 0x08, 0xc1, 0xe8, 0x02, 0x3d, 0xa0, 0x00, 0x00, 0x00, 0x7e, 0x05, 0xb8, 0xa0,
+  0x00, 0x00, 0x00, 0x89, 0xc6, 0xbf, 0x05, 0x00, 0x00, 0x00, 0xf7, 0xf7, 0xa3, 0xe8, 0x01, 0x09,
+  0x00, 0x89, 0xf0, 0x91, 0x8d, 0x73, 0x08, 0xbf, 0xd0, 0x02, 0x09, 0x00, 0xf3, 0xa5, 0x91, 0xeb,
+  0x05, 0x83, 0x3b, 0x12, 0x75, 0x00, 0x03, 0x5b, 0x04, 0x49, 0x75, 0xb3, 0xb8, 0x00, 0x00, 0x04,
+  0x00, 0xc7, 0x40, 0x10, 0xff, 0xff, 0x00, 0x00, 0xc7, 0x40, 0x14, 0x00, 0x9b, 0xcf, 0x00, 0xc7,
+  0x40, 0x18, 0xff, 0xff, 0x00, 0x00, 0xc7, 0x40, 0x1c, 0x00, 0x93, 0xcf, 0x00, 0xc6, 0x00, 0x2b,
+  0x89, 0x40, 0x02, 0x0f, 0x01, 0x10, 0xbe, 0x00, 0x00, 0x09, 0x00, 0xff, 0x25, 0x14, 0x02, 0x09,
+  0x00, 0xf4, 0xeb, 0xfd
+};
+unsigned int trampoline_len = 180;
diff --git a/tools/cbfstool/linux_trampoline.h b/tools/cbfstool/linux_trampoline.h
new file mode 100644
index 0000000000..7b4fad51c0
--- /dev/null
+++ b/tools/cbfstool/linux_trampoline.h
@@ -0,0 +1,36 @@
+/*
+ * This file is part of coreboot..
+ *
+ * Based on work by Patrick Georgi <patrick@georgi-clan.de>
+ * Copyright 2014 Curt Brune <curt@cumulusnetworks.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+/*
+ * This file contains #define constants used by both the Linux
+ * trampoline C-code and assembly language code.  As such it can only
+ * contain preprocessor macros.  Do not inlucde C language
+ * declarations in this file.
+ */
+
+#ifndef LINUX_TRAMPOLINE_H__
+#define LINUX_TRAMPOLINE_H__
+
+/*
+ * Trampoline entry point
+ * TODO: any better place?
+ */
+#define TRAMPOLINE_ENTRY_LOC 0x40000
+
+#define LINUX_PARAM_LOC 0x90000
+#define COMMAND_LINE_LOC 0x91000
+
+#endif /* LINUX_TRAMPOLINE_H__ */
diff --git a/tools/cbfstool/lz4.c b/tools/cbfstool/lz4.c
new file mode 100644
index 0000000000..beb06e8638
--- /dev/null
+++ b/tools/cbfstool/lz4.c
@@ -0,0 +1,1567 @@
+/*
+   LZ4 - Fast LZ compression algorithm
+   Copyright (C) 2011-2015, Yann Collet.
+
+   BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+
+   Redistribution and use in source and binary forms, with or without
+   modification, are permitted provided that the following conditions are
+   met:
+
+       * Redistributions of source code must retain the above copyright
+   notice, this list of conditions and the following disclaimer.
+       * Redistributions in binary form must reproduce the above
+   copyright notice, this list of conditions and the following disclaimer
+   in the documentation and/or other materials provided with the
+   distribution.
+
+   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+   You can contact the author at :
+   - LZ4 source repository : https://github.com/Cyan4973/lz4
+   - LZ4 public forum : https://groups.google.com/forum/#!forum/lz4c
+*/
+
+
+/**************************************
+*  Tuning parameters
+**************************************/
+/*
+ * HEAPMODE :
+ * Select how default compression functions will allocate memory for their hash table,
+ * in memory stack (0:default, fastest), or in memory heap (1:requires malloc()).
+ */
+#define HEAPMODE 0
+
+/*
+ * ACCELERATION_DEFAULT :
+ * Select "acceleration" for LZ4_compress_fast() when parameter value <= 0
+ */
+#define ACCELERATION_DEFAULT 1
+
+
+/**************************************
+*  CPU Feature Detection
+**************************************/
+/* LZ4_FORCE_MEMORY_ACCESS
+ * By default, access to unaligned memory is controlled by `memcpy()`, which is safe and portable.
+ * Unfortunately, on some target/compiler combinations, the generated assembly is sub-optimal.
+ * The below switch allow to select different access method for improved performance.
+ * Method 0 (default) : use `memcpy()`. Safe and portable.
+ * Method 1 : `__packed` statement. It depends on compiler extension (ie, not portable).
+ *            This method is safe if your compiler supports it, and *generally* as fast or faster than `memcpy`.
+ * Method 2 : direct access. This method is portable but violate C standard.
+ *            It can generate buggy code on targets which generate assembly depending on alignment.
+ *            But in some circumstances, it's the only known way to get the most performance (ie GCC + ARMv6)
+ * See http://fastcompression.blogspot.fr/2015/08/accessing-unaligned-memory.html for details.
+ * Prefer these methods in priority order (0 > 1 > 2)
+ */
+#ifndef LZ4_FORCE_MEMORY_ACCESS   /* can be defined externally, on command line for example */
+#  if defined(__GNUC__) && ( defined(__ARM_ARCH_6__) || defined(__ARM_ARCH_6J__) || defined(__ARM_ARCH_6K__) || defined(__ARM_ARCH_6Z__) || defined(__ARM_ARCH_6ZK__) || defined(__ARM_ARCH_6T2__) )
+#    define LZ4_FORCE_MEMORY_ACCESS 2
+#  elif defined(__INTEL_COMPILER) || \
+  (defined(__GNUC__) && ( defined(__ARM_ARCH_7__) || defined(__ARM_ARCH_7A__) || defined(__ARM_ARCH_7R__) || defined(__ARM_ARCH_7M__) || defined(__ARM_ARCH_7S__) ))
+#    define LZ4_FORCE_MEMORY_ACCESS 1
+#  endif
+#endif
+
+/*
+ * LZ4_FORCE_SW_BITCOUNT
+ * Define this parameter if your target system or compiler does not support hardware bit count
+ */
+#if defined(_MSC_VER) && defined(_WIN32_WCE)   /* Visual Studio for Windows CE does not support Hardware bit count */
+#  define LZ4_FORCE_SW_BITCOUNT
+#endif
+
+
+/**************************************
+*  Includes
+**************************************/
+#include <lz4/lib/lz4.h>
+
+
+/**************************************
+*  Compiler Options
+**************************************/
+#ifdef _MSC_VER    /* Visual Studio */
+#  define FORCE_INLINE static __forceinline
+#  include <intrin.h>
+#  pragma warning(disable : 4127)        /* disable: C4127: conditional expression is constant */
+#  pragma warning(disable : 4293)        /* disable: C4293: too large shift (32-bits) */
+#else
+#  if defined(__STDC_VERSION__) && (__STDC_VERSION__ >= 199901L)   /* C99 */
+#    if defined(__GNUC__) || defined(__clang__)
+#      define FORCE_INLINE static inline __attribute__((always_inline))
+#    else
+#      define FORCE_INLINE static inline
+#    endif
+#  else
+#    define FORCE_INLINE static
+#  endif   /* __STDC_VERSION__ */
+#endif  /* _MSC_VER */
+
+/* LZ4_GCC_VERSION is defined into lz4.h */
+#if (LZ4_GCC_VERSION >= 302) || (__INTEL_COMPILER >= 800) || defined(__clang__)
+#  define expect(expr,value)    (__builtin_expect ((expr),(value)) )
+#else
+#  define expect(expr,value)    (expr)
+#endif
+
+#define likely(expr)     expect((expr) != 0, 1)
+#define unlikely(expr)   expect((expr) != 0, 0)
+
+
+/**************************************
+*  Memory routines
+**************************************/
+#include <stdlib.h>   /* malloc, calloc, free */
+#define ALLOCATOR(n,s) calloc(n,s)
+#define FREEMEM        free
+#include <string.h>   /* memset, memcpy */
+#define MEM_INIT       memset
+
+
+/**************************************
+*  Basic Types
+**************************************/
+#if defined (__STDC_VERSION__) && (__STDC_VERSION__ >= 199901L)   /* C99 */
+# include <stdint.h>
+  typedef  uint8_t BYTE;
+  typedef uint16_t U16;
+  typedef uint32_t U32;
+  typedef  int32_t S32;
+  typedef uint64_t U64;
+#else
+  typedef unsigned char       BYTE;
+  typedef unsigned short      U16;
+  typedef unsigned int        U32;
+  typedef   signed int        S32;
+  typedef unsigned long long  U64;
+#endif
+
+
+/**************************************
+*  Reading and writing into memory
+**************************************/
+#define STEPSIZE sizeof(size_t)
+
+static unsigned LZ4_64bits(void) { return sizeof(void*)==8; }
+
+static unsigned LZ4_isLittleEndian(void)
+{
+    const union { U32 i; BYTE c[4]; } one = { 1 };   // don't use static : performance detrimental
+    return one.c[0];
+}
+
+
+#if defined(LZ4_FORCE_MEMORY_ACCESS) && (LZ4_FORCE_MEMORY_ACCESS==2)
+
+static U16 LZ4_read16(const void* memPtr) { return *(const U16*) memPtr; }
+static U32 LZ4_read32(const void* memPtr) { return *(const U32*) memPtr; }
+static size_t LZ4_read_ARCH(const void* memPtr) { return *(const size_t*) memPtr; }
+
+static void LZ4_write16(void* memPtr, U16 value) { *(U16*)memPtr = value; }
+
+#elif defined(LZ4_FORCE_MEMORY_ACCESS) && (LZ4_FORCE_MEMORY_ACCESS==1)
+
+/* __pack instructions are safer, but compiler specific, hence potentially problematic for some compilers */
+/* currently only defined for gcc and icc */
+typedef union { U16 u16; U32 u32; size_t uArch; } __packed unalign;
+
+static U16 LZ4_read16(const void* ptr) { return ((const unalign*)ptr)->u16; }
+static U32 LZ4_read32(const void* ptr) { return ((const unalign*)ptr)->u32; }
+static size_t LZ4_read_ARCH(const void* ptr) { return ((const unalign*)ptr)->uArch; }
+
+static void LZ4_write16(void* memPtr, U16 value) { ((unalign*)memPtr)->u16 = value; }
+
+#else
+
+static U16 LZ4_read16(const void* memPtr)
+{
+    U16 val; memcpy(&val, memPtr, sizeof(val)); return val;
+}
+
+static U32 LZ4_read32(const void* memPtr)
+{
+    U32 val; memcpy(&val, memPtr, sizeof(val)); return val;
+}
+
+static size_t LZ4_read_ARCH(const void* memPtr)
+{
+    size_t val; memcpy(&val, memPtr, sizeof(val)); return val;
+}
+
+static void LZ4_write16(void* memPtr, U16 value)
+{
+    memcpy(memPtr, &value, sizeof(value));
+}
+
+#endif // LZ4_FORCE_MEMORY_ACCESS
+
+
+static U16 LZ4_readLE16(const void* memPtr)
+{
+    if (LZ4_isLittleEndian())
+    {
+        return LZ4_read16(memPtr);
+    }
+    else
+    {
+        const BYTE* p = (const BYTE*)memPtr;
+        return (U16)((U16)p[0] + (p[1]<<8));
+    }
+}
+
+static void LZ4_writeLE16(void* memPtr, U16 value)
+{
+    if (LZ4_isLittleEndian())
+    {
+        LZ4_write16(memPtr, value);
+    }
+    else
+    {
+        BYTE* p = (BYTE*)memPtr;
+        p[0] = (BYTE) value;
+        p[1] = (BYTE)(value>>8);
+    }
+}
+
+static void LZ4_copy8(void* dst, const void* src)
+{
+    memcpy(dst,src,8);
+}
+
+/* customized variant of memcpy, which can overwrite up to 7 bytes beyond dstEnd */
+static void LZ4_wildCopy(void* dstPtr, const void* srcPtr, void* dstEnd)
+{
+    BYTE* d = (BYTE*)dstPtr;
+    const BYTE* s = (const BYTE*)srcPtr;
+    BYTE* const e = (BYTE*)dstEnd;
+
+#if 0
+    const size_t l2 = 8 - (((size_t)d) & (sizeof(void*)-1));
+    LZ4_copy8(d,s); if (d>e-9) return;
+    d+=l2; s+=l2;
+#endif /* join to align */
+
+    do { LZ4_copy8(d,s); d+=8; s+=8; } while (d<e);
+}
+
+
+/**************************************
+*  Common Constants
+**************************************/
+#define MINMATCH 4
+
+#define WILDCOPYLENGTH 8
+#define LASTLITERALS 5
+#define MFLIMIT (WILDCOPYLENGTH+MINMATCH)
+static const int LZ4_minLength = (MFLIMIT+1);
+
+#define KB *(1 <<10)
+#define MB *(1 <<20)
+#define GB *(1U<<30)
+
+#define MAXD_LOG 16
+#define MAX_DISTANCE ((1 << MAXD_LOG) - 1)
+
+#define ML_BITS  4
+#define ML_MASK  ((1U<<ML_BITS)-1)
+#define RUN_BITS (8-ML_BITS)
+#define RUN_MASK ((1U<<RUN_BITS)-1)
+
+
+/**************************************
+*  Common Utils
+**************************************/
+#define LZ4_STATIC_ASSERT(c)    { enum { LZ4_static_assert = 1/(int)(!!(c)) }; }   /* use only *after* variable declarations */
+
+
+/**************************************
+*  Common functions
+**************************************/
+static unsigned LZ4_NbCommonBytes (register size_t val)
+{
+    if (LZ4_isLittleEndian())
+    {
+        if (LZ4_64bits())
+        {
+#       if defined(_MSC_VER) && defined(_WIN64) && !defined(LZ4_FORCE_SW_BITCOUNT)
+            unsigned long r = 0;
+            _BitScanForward64( &r, (U64)val );
+            return (int)(r>>3);
+#       elif (defined(__clang__) || (LZ4_GCC_VERSION >= 304)) && !defined(LZ4_FORCE_SW_BITCOUNT)
+            return (__builtin_ctzll((U64)val) >> 3);
+#       else
+            static const int DeBruijnBytePos[64] = { 0, 0, 0, 0, 0, 1, 1, 2, 0, 3, 1, 3, 1, 4, 2, 7, 0, 2, 3, 6, 1, 5, 3, 5, 1, 3, 4, 4, 2, 5, 6, 7, 7, 0, 1, 2, 3, 3, 4, 6, 2, 6, 5, 5, 3, 4, 5, 6, 7, 1, 2, 4, 6, 4, 4, 5, 7, 2, 6, 5, 7, 6, 7, 7 };
+            return DeBruijnBytePos[((U64)((val & -(long long)val) * 0x0218A392CDABBD3FULL)) >> 58];
+#       endif
+        }
+        else /* 32 bits */
+        {
+#       if defined(_MSC_VER) && !defined(LZ4_FORCE_SW_BITCOUNT)
+            unsigned long r;
+            _BitScanForward( &r, (U32)val );
+            return (int)(r>>3);
+#       elif (defined(__clang__) || (LZ4_GCC_VERSION >= 304)) && !defined(LZ4_FORCE_SW_BITCOUNT)
+            return (__builtin_ctz((U32)val) >> 3);
+#       else
+            static const int DeBruijnBytePos[32] = { 0, 0, 3, 0, 3, 1, 3, 0, 3, 2, 2, 1, 3, 2, 0, 1, 3, 3, 1, 2, 2, 2, 2, 0, 3, 1, 2, 0, 1, 0, 1, 1 };
+            return DeBruijnBytePos[((U32)((val & -(S32)val) * 0x077CB531U)) >> 27];
+#       endif
+        }
+    }
+    else   /* Big Endian CPU */
+    {
+        if (LZ4_64bits())
+        {
+#       if defined(_MSC_VER) && defined(_WIN64) && !defined(LZ4_FORCE_SW_BITCOUNT)
+            unsigned long r = 0;
+            _BitScanReverse64( &r, val );
+            return (unsigned)(r>>3);
+#       elif (defined(__clang__) || (LZ4_GCC_VERSION >= 304)) && !defined(LZ4_FORCE_SW_BITCOUNT)
+            return (__builtin_clzll((U64)val) >> 3);
+#       else
+            unsigned r;
+            if (!(val>>32)) { r=4; } else { r=0; val>>=32; }
+            if (!(val>>16)) { r+=2; val>>=8; } else { val>>=24; }
+            r += (!val);
+            return r;
+#       endif
+        }
+        else /* 32 bits */
+        {
+#       if defined(_MSC_VER) && !defined(LZ4_FORCE_SW_BITCOUNT)
+            unsigned long r = 0;
+            _BitScanReverse( &r, (unsigned long)val );
+            return (unsigned)(r>>3);
+#       elif (defined(__clang__) || (LZ4_GCC_VERSION >= 304)) && !defined(LZ4_FORCE_SW_BITCOUNT)
+            return (__builtin_clz((U32)val) >> 3);
+#       else
+            unsigned r;
+            if (!(val>>16)) { r=2; val>>=8; } else { r=0; val>>=24; }
+            r += (!val);
+            return r;
+#       endif
+        }
+    }
+}
+
+static unsigned LZ4_count(const BYTE* pIn, const BYTE* pMatch, const BYTE* pInLimit)
+{
+    const BYTE* const pStart = pIn;
+
+    while (likely(pIn<pInLimit-(STEPSIZE-1)))
+    {
+        size_t diff = LZ4_read_ARCH(pMatch) ^ LZ4_read_ARCH(pIn);
+        if (!diff) { pIn+=STEPSIZE; pMatch+=STEPSIZE; continue; }
+        pIn += LZ4_NbCommonBytes(diff);
+        return (unsigned)(pIn - pStart);
+    }
+
+    if (LZ4_64bits()) if ((pIn<(pInLimit-3)) && (LZ4_read32(pMatch) == LZ4_read32(pIn))) { pIn+=4; pMatch+=4; }
+    if ((pIn<(pInLimit-1)) && (LZ4_read16(pMatch) == LZ4_read16(pIn))) { pIn+=2; pMatch+=2; }
+    if ((pIn<pInLimit) && (*pMatch == *pIn)) pIn++;
+    return (unsigned)(pIn - pStart);
+}
+
+
+#ifndef LZ4_COMMONDEFS_ONLY
+/**************************************
+*  Local Constants
+**************************************/
+#define LZ4_HASHLOG   (LZ4_MEMORY_USAGE-2)
+#define HASHTABLESIZE (1 << LZ4_MEMORY_USAGE)
+#define HASH_SIZE_U32 (1 << LZ4_HASHLOG)       /* required as macro for static allocation */
+
+static const int LZ4_64Klimit = ((64 KB) + (MFLIMIT-1));
+static const U32 LZ4_skipTrigger = 6;  /* Increase this value ==> compression run slower on incompressible data */
+
+
+/**************************************
+*  Local Structures and types
+**************************************/
+typedef struct {
+    U32 hashTable[HASH_SIZE_U32];
+    U32 currentOffset;
+    U32 initCheck;
+    const BYTE* dictionary;
+    BYTE* bufferStart;   /* obsolete, used for slideInputBuffer */
+    U32 dictSize;
+} LZ4_stream_t_internal;
+
+typedef enum { notLimited = 0, limitedOutput = 1 } limitedOutput_directive;
+typedef enum { byPtr, byU32, byU16 } tableType_t;
+
+typedef enum { noDict = 0, withPrefix64k, usingExtDict } dict_directive;
+typedef enum { noDictIssue = 0, dictSmall } dictIssue_directive;
+
+typedef enum { endOnOutputSize = 0, endOnInputSize = 1 } endCondition_directive;
+typedef enum { full = 0, partial = 1 } earlyEnd_directive;
+
+
+/**************************************
+*  Local Utils
+**************************************/
+int LZ4_versionNumber (void) { return LZ4_VERSION_NUMBER; }
+int LZ4_compressBound(int isize)  { return LZ4_COMPRESSBOUND(isize); }
+int LZ4_sizeofState() { return LZ4_STREAMSIZE; }
+
+
+
+/********************************
+*  Compression functions
+********************************/
+
+static U32 LZ4_hashSequence(U32 sequence, tableType_t const tableType)
+{
+    if (tableType == byU16)
+        return (((sequence) * 2654435761U) >> ((MINMATCH*8)-(LZ4_HASHLOG+1)));
+    else
+        return (((sequence) * 2654435761U) >> ((MINMATCH*8)-LZ4_HASHLOG));
+}
+
+static const U64 prime5bytes = 889523592379ULL;
+static U32 LZ4_hashSequence64(size_t sequence, tableType_t const tableType)
+{
+    const U32 hashLog = (tableType == byU16) ? LZ4_HASHLOG+1 : LZ4_HASHLOG;
+    const U32 hashMask = (1<<hashLog) - 1;
+    return ((sequence * prime5bytes) >> (40 - hashLog)) & hashMask;
+}
+
+static U32 LZ4_hashSequenceT(size_t sequence, tableType_t const tableType)
+{
+    if (LZ4_64bits())
+        return LZ4_hashSequence64(sequence, tableType);
+    return LZ4_hashSequence((U32)sequence, tableType);
+}
+
+static U32 LZ4_hashPosition(const void* p, tableType_t tableType) { return LZ4_hashSequenceT(LZ4_read_ARCH(p), tableType); }
+
+static void LZ4_putPositionOnHash(const BYTE* p, U32 h, void* tableBase, tableType_t const tableType, const BYTE* srcBase)
+{
+    switch (tableType)
+    {
+    case byPtr: { const BYTE** hashTable = (const BYTE**)tableBase; hashTable[h] = p; return; }
+    case byU32: { U32* hashTable = (U32*) tableBase; hashTable[h] = (U32)(p-srcBase); return; }
+    case byU16: { U16* hashTable = (U16*) tableBase; hashTable[h] = (U16)(p-srcBase); return; }
+    }
+}
+
+static void LZ4_putPosition(const BYTE* p, void* tableBase, tableType_t tableType, const BYTE* srcBase)
+{
+    U32 h = LZ4_hashPosition(p, tableType);
+    LZ4_putPositionOnHash(p, h, tableBase, tableType, srcBase);
+}
+
+static const BYTE* LZ4_getPositionOnHash(U32 h, void* tableBase, tableType_t tableType, const BYTE* srcBase)
+{
+    if (tableType == byPtr) { const BYTE** hashTable = (const BYTE**) tableBase; return hashTable[h]; }
+    if (tableType == byU32) { U32* hashTable = (U32*) tableBase; return hashTable[h] + srcBase; }
+    { U16* hashTable = (U16*) tableBase; return hashTable[h] + srcBase; }   /* default, to ensure a return */
+}
+
+static const BYTE* LZ4_getPosition(const BYTE* p, void* tableBase, tableType_t tableType, const BYTE* srcBase)
+{
+    U32 h = LZ4_hashPosition(p, tableType);
+    return LZ4_getPositionOnHash(h, tableBase, tableType, srcBase);
+}
+
+FORCE_INLINE int LZ4_compress_generic(
+                 void* const ctx,
+                 const char* const source,
+                 char* const dest,
+                 const int inputSize,
+                 const int maxOutputSize,
+                 const limitedOutput_directive outputLimited,
+                 const tableType_t tableType,
+                 const dict_directive dict,
+                 const dictIssue_directive dictIssue,
+                 const U32 acceleration)
+{
+    LZ4_stream_t_internal* const dictPtr = (LZ4_stream_t_internal*)ctx;
+
+    const BYTE* ip = (const BYTE*) source;
+    const BYTE* base;
+    const BYTE* lowLimit;
+    const BYTE* const lowRefLimit = ip - dictPtr->dictSize;
+    const BYTE* const dictionary = dictPtr->dictionary;
+    const BYTE* const dictEnd = dictionary + dictPtr->dictSize;
+    const size_t dictDelta = dictEnd - (const BYTE*)source;
+    const BYTE* anchor = (const BYTE*) source;
+    const BYTE* const iend = ip + inputSize;
+    const BYTE* const mflimit = iend - MFLIMIT;
+    const BYTE* const matchlimit = iend - LASTLITERALS;
+
+    BYTE* op = (BYTE*) dest;
+    BYTE* const olimit = op + maxOutputSize;
+
+    U32 forwardH;
+    size_t refDelta=0;
+
+    /* Init conditions */
+    if ((U32)inputSize > (U32)LZ4_MAX_INPUT_SIZE) return 0;   /* Unsupported input size, too large (or negative) */
+    switch(dict)
+    {
+    case noDict:
+    default:
+        base = (const BYTE*)source;
+        lowLimit = (const BYTE*)source;
+        break;
+    case withPrefix64k:
+        base = (const BYTE*)source - dictPtr->currentOffset;
+        lowLimit = (const BYTE*)source - dictPtr->dictSize;
+        break;
+    case usingExtDict:
+        base = (const BYTE*)source - dictPtr->currentOffset;
+        lowLimit = (const BYTE*)source;
+        break;
+    }
+    if ((tableType == byU16) && (inputSize>=LZ4_64Klimit)) return 0;   /* Size too large (not within 64K limit) */
+    if (inputSize<LZ4_minLength) goto _last_literals;                  /* Input too small, no compression (all literals) */
+
+    /* First Byte */
+    LZ4_putPosition(ip, ctx, tableType, base);
+    ip++; forwardH = LZ4_hashPosition(ip, tableType);
+
+    /* Main Loop */
+    for ( ; ; )
+    {
+        const BYTE* match;
+        BYTE* token;
+        {
+            const BYTE* forwardIp = ip;
+            unsigned step = 1;
+            unsigned searchMatchNb = acceleration << LZ4_skipTrigger;
+
+            /* Find a match */
+            do {
+                U32 h = forwardH;
+                ip = forwardIp;
+                forwardIp += step;
+                step = (searchMatchNb++ >> LZ4_skipTrigger);
+
+                if (unlikely(forwardIp > mflimit)) goto _last_literals;
+
+                match = LZ4_getPositionOnHash(h, ctx, tableType, base);
+                if (dict==usingExtDict)
+                {
+                    if (match<(const BYTE*)source)
+                    {
+                        refDelta = dictDelta;
+                        lowLimit = dictionary;
+                    }
+                    else
+                    {
+                        refDelta = 0;
+                        lowLimit = (const BYTE*)source;
+                    }
+                }
+                forwardH = LZ4_hashPosition(forwardIp, tableType);
+                LZ4_putPositionOnHash(ip, h, ctx, tableType, base);
+
+            } while ( ((dictIssue==dictSmall) ? (match < lowRefLimit) : 0)
+                || ((tableType==byU16) ? 0 : (match + MAX_DISTANCE < ip))
+                || (LZ4_read32(match+refDelta) != LZ4_read32(ip)) );
+        }
+
+        /* Catch up */
+        while ((ip>anchor) && (match+refDelta > lowLimit) && (unlikely(ip[-1]==match[refDelta-1]))) { ip--; match--; }
+
+        {
+            /* Encode Literal length */
+            unsigned litLength = (unsigned)(ip - anchor);
+            token = op++;
+            if ((outputLimited) && (unlikely(op + litLength + (2 + 1 + LASTLITERALS) + (litLength/255) > olimit)))
+                return 0;   /* Check output limit */
+            if (litLength>=RUN_MASK)
+            {
+                int len = (int)litLength-RUN_MASK;
+                *token=(RUN_MASK<<ML_BITS);
+                for(; len >= 255 ; len-=255) *op++ = 255;
+                *op++ = (BYTE)len;
+            }
+            else *token = (BYTE)(litLength<<ML_BITS);
+
+            /* Copy Literals */
+            LZ4_wildCopy(op, anchor, op+litLength);
+            op+=litLength;
+        }
+
+_next_match:
+        /* Encode Offset */
+        LZ4_writeLE16(op, (U16)(ip-match)); op+=2;
+
+        /* Encode MatchLength */
+        {
+            unsigned matchLength;
+
+            if ((dict==usingExtDict) && (lowLimit==dictionary))
+            {
+                const BYTE* limit;
+                match += refDelta;
+                limit = ip + (dictEnd-match);
+                if (limit > matchlimit) limit = matchlimit;
+                matchLength = LZ4_count(ip+MINMATCH, match+MINMATCH, limit);
+                ip += MINMATCH + matchLength;
+                if (ip==limit)
+                {
+                    unsigned more = LZ4_count(ip, (const BYTE*)source, matchlimit);
+                    matchLength += more;
+                    ip += more;
+                }
+            }
+            else
+            {
+                matchLength = LZ4_count(ip+MINMATCH, match+MINMATCH, matchlimit);
+                ip += MINMATCH + matchLength;
+            }
+
+            if ((outputLimited) && (unlikely(op + (1 + LASTLITERALS) + (matchLength>>8) > olimit)))
+                return 0;    /* Check output limit */
+            if (matchLength>=ML_MASK)
+            {
+                *token += ML_MASK;
+                matchLength -= ML_MASK;
+                for (; matchLength >= 510 ; matchLength-=510) { *op++ = 255; *op++ = 255; }
+                if (matchLength >= 255) { matchLength-=255; *op++ = 255; }
+                *op++ = (BYTE)matchLength;
+            }
+            else *token += (BYTE)(matchLength);
+        }
+
+        anchor = ip;
+
+        /* Test end of chunk */
+        if (ip > mflimit) break;
+
+        /* Fill table */
+        LZ4_putPosition(ip-2, ctx, tableType, base);
+
+        /* Test next position */
+        match = LZ4_getPosition(ip, ctx, tableType, base);
+        if (dict==usingExtDict)
+        {
+            if (match<(const BYTE*)source)
+            {
+                refDelta = dictDelta;
+                lowLimit = dictionary;
+            }
+            else
+            {
+                refDelta = 0;
+                lowLimit = (const BYTE*)source;
+            }
+        }
+        LZ4_putPosition(ip, ctx, tableType, base);
+        if ( ((dictIssue==dictSmall) ? (match>=lowRefLimit) : 1)
+            && (match+MAX_DISTANCE>=ip)
+            && (LZ4_read32(match+refDelta)==LZ4_read32(ip)) )
+        { token=op++; *token=0; goto _next_match; }
+
+        /* Prepare next loop */
+        forwardH = LZ4_hashPosition(++ip, tableType);
+    }
+
+_last_literals:
+    /* Encode Last Literals */
+    {
+        const size_t lastRun = (size_t)(iend - anchor);
+        if ((outputLimited) && ((op - (BYTE*)dest) + lastRun + 1 + ((lastRun+255-RUN_MASK)/255) > (U32)maxOutputSize))
+            return 0;   /* Check output limit */
+        if (lastRun >= RUN_MASK)
+        {
+            size_t accumulator = lastRun - RUN_MASK;
+            *op++ = RUN_MASK << ML_BITS;
+            for(; accumulator >= 255 ; accumulator-=255) *op++ = 255;
+            *op++ = (BYTE) accumulator;
+        }
+        else
+        {
+            *op++ = (BYTE)(lastRun<<ML_BITS);
+        }
+        memcpy(op, anchor, lastRun);
+        op += lastRun;
+    }
+
+    /* End */
+    return (int) (((char*)op)-dest);
+}
+
+
+int LZ4_compress_fast_extState(void* state, const char* source, char* dest, int inputSize, int maxOutputSize, int acceleration)
+{
+    LZ4_resetStream((LZ4_stream_t*)state);
+    if (acceleration < 1) acceleration = ACCELERATION_DEFAULT;
+
+    if (maxOutputSize >= LZ4_compressBound(inputSize))
+    {
+        if (inputSize < LZ4_64Klimit)
+            return LZ4_compress_generic(state, source, dest, inputSize, 0, notLimited, byU16,                        noDict, noDictIssue, acceleration);
+        else
+            return LZ4_compress_generic(state, source, dest, inputSize, 0, notLimited, LZ4_64bits() ? byU32 : byPtr, noDict, noDictIssue, acceleration);
+    }
+    else
+    {
+        if (inputSize < LZ4_64Klimit)
+            return LZ4_compress_generic(state, source, dest, inputSize, maxOutputSize, limitedOutput, byU16,                        noDict, noDictIssue, acceleration);
+        else
+            return LZ4_compress_generic(state, source, dest, inputSize, maxOutputSize, limitedOutput, LZ4_64bits() ? byU32 : byPtr, noDict, noDictIssue, acceleration);
+    }
+}
+
+
+int LZ4_compress_fast(const char* source, char* dest, int inputSize, int maxOutputSize, int acceleration)
+{
+#if (HEAPMODE)
+    void* ctxPtr = ALLOCATOR(1, sizeof(LZ4_stream_t));   /* malloc-calloc always properly aligned */
+#else
+    LZ4_stream_t ctx;
+    void* ctxPtr = &ctx;
+#endif
+
+    int result = LZ4_compress_fast_extState(ctxPtr, source, dest, inputSize, maxOutputSize, acceleration);
+
+#if (HEAPMODE)
+    FREEMEM(ctxPtr);
+#endif
+    return result;
+}
+
+
+int LZ4_compress_default(const char* source, char* dest, int inputSize, int maxOutputSize)
+{
+    return LZ4_compress_fast(source, dest, inputSize, maxOutputSize, 1);
+}
+
+
+/* hidden debug function */
+/* strangely enough, gcc generates faster code when this function is uncommented, even if unused */
+int LZ4_compress_fast_force(const char* source, char* dest, int inputSize, int maxOutputSize, int acceleration)
+{
+    LZ4_stream_t ctx;
+
+    LZ4_resetStream(&ctx);
+
+    if (inputSize < LZ4_64Klimit)
+        return LZ4_compress_generic(&ctx, source, dest, inputSize, maxOutputSize, limitedOutput, byU16,                        noDict, noDictIssue, acceleration);
+    else
+        return LZ4_compress_generic(&ctx, source, dest, inputSize, maxOutputSize, limitedOutput, LZ4_64bits() ? byU32 : byPtr, noDict, noDictIssue, acceleration);
+}
+
+
+/********************************
+*  destSize variant
+********************************/
+
+static int LZ4_compress_destSize_generic(
+                       void* const ctx,
+                 const char* const src,
+                       char* const dst,
+                       int*  const srcSizePtr,
+                 const int targetDstSize,
+                 const tableType_t tableType)
+{
+    const BYTE* ip = (const BYTE*) src;
+    const BYTE* base = (const BYTE*) src;
+    const BYTE* lowLimit = (const BYTE*) src;
+    const BYTE* anchor = ip;
+    const BYTE* const iend = ip + *srcSizePtr;
+    const BYTE* const mflimit = iend - MFLIMIT;
+    const BYTE* const matchlimit = iend - LASTLITERALS;
+
+    BYTE* op = (BYTE*) dst;
+    BYTE* const oend = op + targetDstSize;
+    BYTE* const oMaxLit = op + targetDstSize - 2 /* offset */ - 8 /* because 8+MINMATCH==MFLIMIT */ - 1 /* token */;
+    BYTE* const oMaxMatch = op + targetDstSize - (LASTLITERALS + 1 /* token */);
+    BYTE* const oMaxSeq = oMaxLit - 1 /* token */;
+
+    U32 forwardH;
+
+
+    /* Init conditions */
+    if (targetDstSize < 1) return 0;                                     /* Impossible to store anything */
+    if ((U32)*srcSizePtr > (U32)LZ4_MAX_INPUT_SIZE) return 0;            /* Unsupported input size, too large (or negative) */
+    if ((tableType == byU16) && (*srcSizePtr>=LZ4_64Klimit)) return 0;   /* Size too large (not within 64K limit) */
+    if (*srcSizePtr<LZ4_minLength) goto _last_literals;                  /* Input too small, no compression (all literals) */
+
+    /* First Byte */
+    *srcSizePtr = 0;
+    LZ4_putPosition(ip, ctx, tableType, base);
+    ip++; forwardH = LZ4_hashPosition(ip, tableType);
+
+    /* Main Loop */
+    for ( ; ; )
+    {
+        const BYTE* match;
+        BYTE* token;
+        {
+            const BYTE* forwardIp = ip;
+            unsigned step = 1;
+            unsigned searchMatchNb = 1 << LZ4_skipTrigger;
+
+            /* Find a match */
+            do {
+                U32 h = forwardH;
+                ip = forwardIp;
+                forwardIp += step;
+                step = (searchMatchNb++ >> LZ4_skipTrigger);
+
+                if (unlikely(forwardIp > mflimit))
+                    goto _last_literals;
+
+                match = LZ4_getPositionOnHash(h, ctx, tableType, base);
+                forwardH = LZ4_hashPosition(forwardIp, tableType);
+                LZ4_putPositionOnHash(ip, h, ctx, tableType, base);
+
+            } while ( ((tableType==byU16) ? 0 : (match + MAX_DISTANCE < ip))
+                || (LZ4_read32(match) != LZ4_read32(ip)) );
+        }
+
+        /* Catch up */
+        while ((ip>anchor) && (match > lowLimit) && (unlikely(ip[-1]==match[-1]))) { ip--; match--; }
+
+        {
+            /* Encode Literal length */
+            unsigned litLength = (unsigned)(ip - anchor);
+            token = op++;
+            if (op + ((litLength+240)/255) + litLength > oMaxLit)
+            {
+                /* Not enough space for a last match */
+                op--;
+                goto _last_literals;
+            }
+            if (litLength>=RUN_MASK)
+            {
+                unsigned len = litLength - RUN_MASK;
+                *token=(RUN_MASK<<ML_BITS);
+                for(; len >= 255 ; len-=255) *op++ = 255;
+                *op++ = (BYTE)len;
+            }
+            else *token = (BYTE)(litLength<<ML_BITS);
+
+            /* Copy Literals */
+            LZ4_wildCopy(op, anchor, op+litLength);
+            op += litLength;
+        }
+
+_next_match:
+        /* Encode Offset */
+        LZ4_writeLE16(op, (U16)(ip-match)); op+=2;
+
+        /* Encode MatchLength */
+        {
+            size_t matchLength;
+
+            matchLength = LZ4_count(ip+MINMATCH, match+MINMATCH, matchlimit);
+
+            if (op + ((matchLength+240)/255) > oMaxMatch)
+            {
+                /* Match description too long : reduce it */
+                matchLength = (15-1) + (oMaxMatch-op) * 255;
+            }
+            ip += MINMATCH + matchLength;
+
+            if (matchLength>=ML_MASK)
+            {
+                *token += ML_MASK;
+                matchLength -= ML_MASK;
+                while (matchLength >= 255) { matchLength-=255; *op++ = 255; }
+                *op++ = (BYTE)matchLength;
+            }
+            else *token += (BYTE)(matchLength);
+        }
+
+        anchor = ip;
+
+        /* Test end of block */
+        if (ip > mflimit) break;
+        if (op > oMaxSeq) break;
+
+        /* Fill table */
+        LZ4_putPosition(ip-2, ctx, tableType, base);
+
+        /* Test next position */
+        match = LZ4_getPosition(ip, ctx, tableType, base);
+        LZ4_putPosition(ip, ctx, tableType, base);
+        if ( (match+MAX_DISTANCE>=ip)
+            && (LZ4_read32(match)==LZ4_read32(ip)) )
+        { token=op++; *token=0; goto _next_match; }
+
+        /* Prepare next loop */
+        forwardH = LZ4_hashPosition(++ip, tableType);
+    }
+
+_last_literals:
+    /* Encode Last Literals */
+    {
+        size_t lastRunSize = (size_t)(iend - anchor);
+        if (op + 1 /* token */ + ((lastRunSize+240)/255) /* litLength */ + lastRunSize /* literals */ > oend)
+        {
+            /* adapt lastRunSize to fill 'dst' */
+            lastRunSize  = (oend-op) - 1;
+            lastRunSize -= (lastRunSize+240)/255;
+        }
+        ip = anchor + lastRunSize;
+
+        if (lastRunSize >= RUN_MASK)
+        {
+            size_t accumulator = lastRunSize - RUN_MASK;
+            *op++ = RUN_MASK << ML_BITS;
+            for(; accumulator >= 255 ; accumulator-=255) *op++ = 255;
+            *op++ = (BYTE) accumulator;
+        }
+        else
+        {
+            *op++ = (BYTE)(lastRunSize<<ML_BITS);
+        }
+        memcpy(op, anchor, lastRunSize);
+        op += lastRunSize;
+    }
+
+    /* End */
+    *srcSizePtr = (int) (((const char*)ip)-src);
+    return (int) (((char*)op)-dst);
+}
+
+
+static int LZ4_compress_destSize_extState (void* state, const char* src, char* dst, int* srcSizePtr, int targetDstSize)
+{
+    LZ4_resetStream((LZ4_stream_t*)state);
+
+    if (targetDstSize >= LZ4_compressBound(*srcSizePtr))   /* compression success is guaranteed */
+    {
+        return LZ4_compress_fast_extState(state, src, dst, *srcSizePtr, targetDstSize, 1);
+    }
+    else
+    {
+        if (*srcSizePtr < LZ4_64Klimit)
+            return LZ4_compress_destSize_generic(state, src, dst, srcSizePtr, targetDstSize, byU16);
+        else
+            return LZ4_compress_destSize_generic(state, src, dst, srcSizePtr, targetDstSize, LZ4_64bits() ? byU32 : byPtr);
+    }
+}
+
+
+int LZ4_compress_destSize(const char* src, char* dst, int* srcSizePtr, int targetDstSize)
+{
+#if (HEAPMODE)
+    void* ctx = ALLOCATOR(1, sizeof(LZ4_stream_t));   /* malloc-calloc always properly aligned */
+#else
+    LZ4_stream_t ctxBody;
+    void* ctx = &ctxBody;
+#endif
+
+    int result = LZ4_compress_destSize_extState(ctx, src, dst, srcSizePtr, targetDstSize);
+
+#if (HEAPMODE)
+    FREEMEM(ctx);
+#endif
+    return result;
+}
+
+
+
+/********************************
+*  Streaming functions
+********************************/
+
+LZ4_stream_t* LZ4_createStream(void)
+{
+    LZ4_stream_t* lz4s = (LZ4_stream_t*)ALLOCATOR(8, LZ4_STREAMSIZE_U64);
+    LZ4_STATIC_ASSERT(LZ4_STREAMSIZE >= sizeof(LZ4_stream_t_internal));    /* A compilation error here means LZ4_STREAMSIZE is not large enough */
+    LZ4_resetStream(lz4s);
+    return lz4s;
+}
+
+void LZ4_resetStream (LZ4_stream_t* LZ4_stream)
+{
+    MEM_INIT(LZ4_stream, 0, sizeof(LZ4_stream_t));
+}
+
+int LZ4_freeStream (LZ4_stream_t* LZ4_stream)
+{
+    FREEMEM(LZ4_stream);
+    return (0);
+}
+
+
+#define HASH_UNIT sizeof(size_t)
+int LZ4_loadDict (LZ4_stream_t* LZ4_dict, const char* dictionary, int dictSize)
+{
+    LZ4_stream_t_internal* dict = (LZ4_stream_t_internal*) LZ4_dict;
+    const BYTE* p = (const BYTE*)dictionary;
+    const BYTE* const dictEnd = p + dictSize;
+    const BYTE* base;
+
+    if ((dict->initCheck) || (dict->currentOffset > 1 GB))  /* Uninitialized structure, or reuse overflow */
+        LZ4_resetStream(LZ4_dict);
+
+    if (dictSize < (int)HASH_UNIT)
+    {
+        dict->dictionary = NULL;
+        dict->dictSize = 0;
+        return 0;
+    }
+
+    if ((dictEnd - p) > 64 KB) p = dictEnd - 64 KB;
+    dict->currentOffset += 64 KB;
+    base = p - dict->currentOffset;
+    dict->dictionary = p;
+    dict->dictSize = (U32)(dictEnd - p);
+    dict->currentOffset += dict->dictSize;
+
+    while (p <= dictEnd-HASH_UNIT)
+    {
+        LZ4_putPosition(p, dict->hashTable, byU32, base);
+        p+=3;
+    }
+
+    return dict->dictSize;
+}
+
+
+static void LZ4_renormDictT(LZ4_stream_t_internal* LZ4_dict, const BYTE* src)
+{
+    if ((LZ4_dict->currentOffset > 0x80000000) ||
+        ((size_t)LZ4_dict->currentOffset > (size_t)src))   /* address space overflow */
+    {
+        /* rescale hash table */
+        U32 delta = LZ4_dict->currentOffset - 64 KB;
+        const BYTE* dictEnd = LZ4_dict->dictionary + LZ4_dict->dictSize;
+        int i;
+        for (i=0; i<HASH_SIZE_U32; i++)
+        {
+            if (LZ4_dict->hashTable[i] < delta) LZ4_dict->hashTable[i]=0;
+            else LZ4_dict->hashTable[i] -= delta;
+        }
+        LZ4_dict->currentOffset = 64 KB;
+        if (LZ4_dict->dictSize > 64 KB) LZ4_dict->dictSize = 64 KB;
+        LZ4_dict->dictionary = dictEnd - LZ4_dict->dictSize;
+    }
+}
+
+
+int LZ4_compress_fast_continue (LZ4_stream_t* LZ4_stream, const char* source, char* dest, int inputSize, int maxOutputSize, int acceleration)
+{
+    LZ4_stream_t_internal* streamPtr = (LZ4_stream_t_internal*)LZ4_stream;
+    const BYTE* const dictEnd = streamPtr->dictionary + streamPtr->dictSize;
+
+    const BYTE* smallest = (const BYTE*) source;
+    if (streamPtr->initCheck) return 0;   /* Uninitialized structure detected */
+    if ((streamPtr->dictSize>0) && (smallest>dictEnd)) smallest = dictEnd;
+    LZ4_renormDictT(streamPtr, smallest);
+    if (acceleration < 1) acceleration = ACCELERATION_DEFAULT;
+
+    /* Check overlapping input/dictionary space */
+    {
+        const BYTE* sourceEnd = (const BYTE*) source + inputSize;
+        if ((sourceEnd > streamPtr->dictionary) && (sourceEnd < dictEnd))
+        {
+            streamPtr->dictSize = (U32)(dictEnd - sourceEnd);
+            if (streamPtr->dictSize > 64 KB) streamPtr->dictSize = 64 KB;
+            if (streamPtr->dictSize < 4) streamPtr->dictSize = 0;
+            streamPtr->dictionary = dictEnd - streamPtr->dictSize;
+        }
+    }
+
+    /* prefix mode : source data follows dictionary */
+    if (dictEnd == (const BYTE*)source)
+    {
+        int result;
+        if ((streamPtr->dictSize < 64 KB) && (streamPtr->dictSize < streamPtr->currentOffset))
+            result = LZ4_compress_generic(LZ4_stream, source, dest, inputSize, maxOutputSize, limitedOutput, byU32, withPrefix64k, dictSmall, acceleration);
+        else
+            result = LZ4_compress_generic(LZ4_stream, source, dest, inputSize, maxOutputSize, limitedOutput, byU32, withPrefix64k, noDictIssue, acceleration);
+        streamPtr->dictSize += (U32)inputSize;
+        streamPtr->currentOffset += (U32)inputSize;
+        return result;
+    }
+
+    /* external dictionary mode */
+    {
+        int result;
+        if ((streamPtr->dictSize < 64 KB) && (streamPtr->dictSize < streamPtr->currentOffset))
+            result = LZ4_compress_generic(LZ4_stream, source, dest, inputSize, maxOutputSize, limitedOutput, byU32, usingExtDict, dictSmall, acceleration);
+        else
+            result = LZ4_compress_generic(LZ4_stream, source, dest, inputSize, maxOutputSize, limitedOutput, byU32, usingExtDict, noDictIssue, acceleration);
+        streamPtr->dictionary = (const BYTE*)source;
+        streamPtr->dictSize = (U32)inputSize;
+        streamPtr->currentOffset += (U32)inputSize;
+        return result;
+    }
+}
+
+
+/* Hidden debug function, to force external dictionary mode */
+int LZ4_compress_forceExtDict (LZ4_stream_t* LZ4_dict, const char* source, char* dest, int inputSize)
+{
+    LZ4_stream_t_internal* streamPtr = (LZ4_stream_t_internal*)LZ4_dict;
+    int result;
+    const BYTE* const dictEnd = streamPtr->dictionary + streamPtr->dictSize;
+
+    const BYTE* smallest = dictEnd;
+    if (smallest > (const BYTE*) source) smallest = (const BYTE*) source;
+    LZ4_renormDictT((LZ4_stream_t_internal*)LZ4_dict, smallest);
+
+    result = LZ4_compress_generic(LZ4_dict, source, dest, inputSize, 0, notLimited, byU32, usingExtDict, noDictIssue, 1);
+
+    streamPtr->dictionary = (const BYTE*)source;
+    streamPtr->dictSize = (U32)inputSize;
+    streamPtr->currentOffset += (U32)inputSize;
+
+    return result;
+}
+
+
+int LZ4_saveDict (LZ4_stream_t* LZ4_dict, char* safeBuffer, int dictSize)
+{
+    LZ4_stream_t_internal* dict = (LZ4_stream_t_internal*) LZ4_dict;
+    const BYTE* previousDictEnd = dict->dictionary + dict->dictSize;
+
+    if ((U32)dictSize > 64 KB) dictSize = 64 KB;   /* useless to define a dictionary > 64 KB */
+    if ((U32)dictSize > dict->dictSize) dictSize = dict->dictSize;
+
+    memmove(safeBuffer, previousDictEnd - dictSize, dictSize);
+
+    dict->dictionary = (const BYTE*)safeBuffer;
+    dict->dictSize = (U32)dictSize;
+
+    return dictSize;
+}
+
+
+
+/*******************************
+*  Decompression functions
+*******************************/
+/*
+ * This generic decompression function cover all use cases.
+ * It shall be instantiated several times, using different sets of directives
+ * Note that it is essential this generic function is really inlined,
+ * in order to remove useless branches during compilation optimization.
+ */
+FORCE_INLINE int LZ4_decompress_generic(
+                 const char* const source,
+                 char* const dest,
+                 int inputSize,
+                 int outputSize,         /* If endOnInput==endOnInputSize, this value is the max size of Output Buffer. */
+
+                 int endOnInput,         /* endOnOutputSize, endOnInputSize */
+                 int partialDecoding,    /* full, partial */
+                 int targetOutputSize,   /* only used if partialDecoding==partial */
+                 int dict,               /* noDict, withPrefix64k, usingExtDict */
+                 const BYTE* const lowPrefix,  /* == dest if dict == noDict */
+                 const BYTE* const dictStart,  /* only if dict==usingExtDict */
+                 const size_t dictSize         /* note : = 0 if noDict */
+                 )
+{
+    /* Local Variables */
+    const BYTE* ip = (const BYTE*) source;
+    const BYTE* const iend = ip + inputSize;
+
+    BYTE* op = (BYTE*) dest;
+    BYTE* const oend = op + outputSize;
+    BYTE* cpy;
+    BYTE* oexit = op + targetOutputSize;
+    const BYTE* const lowLimit = lowPrefix - dictSize;
+
+    const BYTE* const dictEnd = (const BYTE*)dictStart + dictSize;
+    const unsigned dec32table[] = {4, 1, 2, 1, 4, 4, 4, 4};
+    const int dec64table[] = {0, 0, 0, -1, 0, 1, 2, 3};
+
+    const int safeDecode = (endOnInput==endOnInputSize);
+    const int checkOffset = ((safeDecode) && (dictSize < (int)(64 KB)));
+    const int inPlaceDecode = ((ip >= op) && (ip < oend));
+
+
+    /* Special cases */
+    if ((partialDecoding) && (oexit> oend-MFLIMIT)) oexit = oend-MFLIMIT;                         /* targetOutputSize too high => decode everything */
+    if ((endOnInput) && (unlikely(outputSize==0))) return ((inputSize==1) && (*ip==0)) ? 0 : -1;  /* Empty output buffer */
+    if ((!endOnInput) && (unlikely(outputSize==0))) return (*ip==0?1:-1);
+
+
+    /* Main Loop */
+    while (1)
+    {
+        unsigned token;
+        size_t length;
+        const BYTE* match;
+        size_t offset;
+
+        if (unlikely((inPlaceDecode) && (op + WILDCOPYLENGTH > ip))) goto _output_error;   /* output stream ran over input stream */
+
+        /* get literal length */
+        token = *ip++;
+        if ((length=(token>>ML_BITS)) == RUN_MASK)
+        {
+            unsigned s;
+            do
+            {
+                s = *ip++;
+                length += s;
+            }
+            while ( likely(endOnInput ? ip<iend-RUN_MASK : 1) && (s==255) );
+            if ((safeDecode) && unlikely((size_t)(op+length)<(size_t)(op))) goto _output_error;   /* overflow detection */
+            if ((safeDecode) && unlikely((size_t)(ip+length)<(size_t)(ip))) goto _output_error;   /* overflow detection */
+        }
+
+        /* copy literals */
+        cpy = op+length;
+        if (((endOnInput) && ((cpy>(partialDecoding?oexit:oend-MFLIMIT)) || (ip+length>iend-(2+1+LASTLITERALS))) )
+            || ((!endOnInput) && (cpy>oend-WILDCOPYLENGTH)))
+        {
+            if (partialDecoding)
+            {
+                if (cpy > oend) goto _output_error;                           /* Error : write attempt beyond end of output buffer */
+                if ((endOnInput) && (ip+length > iend)) goto _output_error;   /* Error : read attempt beyond end of input buffer */
+            }
+            else
+            {
+                if ((!endOnInput) && (cpy != oend)) goto _output_error;       /* Error : block decoding must stop exactly there */
+                if ((endOnInput) && ((ip+length != iend) || (cpy > oend))) goto _output_error;   /* Error : input must be consumed */
+            }
+            memmove(op, ip, length);
+            ip += length;
+            op += length;
+            break;     /* Necessarily EOF, due to parsing restrictions */
+        }
+        LZ4_wildCopy(op, ip, cpy);
+        ip += length; op = cpy;
+
+        /* get offset */
+        offset = LZ4_readLE16(ip); ip+=2;
+        match = op - offset;
+        if ((checkOffset) && (unlikely(match < lowLimit))) goto _output_error;   /* Error : offset outside buffers */
+
+        /* get matchlength */
+        length = token & ML_MASK;
+        if (length == ML_MASK)
+        {
+            unsigned s;
+            do
+            {
+                if ((endOnInput) && (ip > iend-LASTLITERALS)) goto _output_error;
+                s = *ip++;
+                length += s;
+            } while (s==255);
+            if ((safeDecode) && unlikely((size_t)(op+length)<(size_t)op)) goto _output_error;   /* overflow detection */
+        }
+        length += MINMATCH;
+
+        /* check external dictionary */
+        if ((dict==usingExtDict) && (match < lowPrefix))
+        {
+            if (unlikely(op+length > oend-LASTLITERALS)) goto _output_error;   /* doesn't respect parsing restriction */
+
+            if (length <= (size_t)(lowPrefix-match))
+            {
+                /* match can be copied as a single segment from external dictionary */
+                match = dictEnd - (lowPrefix-match);
+                memmove(op, match, length); op += length;
+            }
+            else
+            {
+                /* match encompass external dictionary and current block */
+                size_t copySize = (size_t)(lowPrefix-match);
+                memcpy(op, dictEnd - copySize, copySize);
+                op += copySize;
+                copySize = length - copySize;
+                if (copySize > (size_t)(op-lowPrefix))   /* overlap copy */
+                {
+                    BYTE* const endOfMatch = op + copySize;
+                    const BYTE* copyFrom = lowPrefix;
+                    while (op < endOfMatch) *op++ = *copyFrom++;
+                }
+                else
+                {
+                    memcpy(op, lowPrefix, copySize);
+                    op += copySize;
+                }
+            }
+            continue;
+        }
+
+        /* copy match within block */
+        cpy = op + length;
+        if (unlikely(offset<8))
+        {
+            const int dec64 = dec64table[offset];
+            op[0] = match[0];
+            op[1] = match[1];
+            op[2] = match[2];
+            op[3] = match[3];
+            match += dec32table[offset];
+            memcpy(op+4, match, 4);
+            match -= dec64;
+        } else { LZ4_copy8(op, match); match+=8; }
+        op += 8;
+
+        if (unlikely(cpy>oend-12))
+        {
+            BYTE* const oCopyLimit = oend-(WILDCOPYLENGTH-1);
+            if (cpy > oend-LASTLITERALS) goto _output_error;    /* Error : last LASTLITERALS bytes must be literals (uncompressed) */
+            if (op < oCopyLimit)
+            {
+                LZ4_wildCopy(op, match, oCopyLimit);
+                match += oCopyLimit - op;
+                op = oCopyLimit;
+            }
+            while (op<cpy) *op++ = *match++;
+        }
+        else
+            LZ4_wildCopy(op, match, cpy);
+        op=cpy;   /* correction */
+    }
+
+    /* end of decoding */
+    if (endOnInput)
+       return (int) (((char*)op)-dest);     /* Nb of output bytes decoded */
+    else
+       return (int) (((const char*)ip)-source);   /* Nb of input bytes read */
+
+    /* Overflow error detected */
+_output_error:
+    return (int) (-(((const char*)ip)-source))-1;
+}
+
+
+int LZ4_decompress_safe(const char* source, char* dest, int compressedSize, int maxDecompressedSize)
+{
+    return LZ4_decompress_generic(source, dest, compressedSize, maxDecompressedSize, endOnInputSize, full, 0, noDict, (BYTE*)dest, NULL, 0);
+}
+
+int LZ4_decompress_safe_partial(const char* source, char* dest, int compressedSize, int targetOutputSize, int maxDecompressedSize)
+{
+    return LZ4_decompress_generic(source, dest, compressedSize, maxDecompressedSize, endOnInputSize, partial, targetOutputSize, noDict, (BYTE*)dest, NULL, 0);
+}
+
+int LZ4_decompress_fast(const char* source, char* dest, int originalSize)
+{
+    return LZ4_decompress_generic(source, dest, 0, originalSize, endOnOutputSize, full, 0, withPrefix64k, (BYTE*)(dest - 64 KB), NULL, 64 KB);
+}
+
+
+/* streaming decompression functions */
+
+typedef struct
+{
+    const BYTE* externalDict;
+    size_t extDictSize;
+    const BYTE* prefixEnd;
+    size_t prefixSize;
+} LZ4_streamDecode_t_internal;
+
+/*
+ * If you prefer dynamic allocation methods,
+ * LZ4_createStreamDecode()
+ * provides a pointer (void*) towards an initialized LZ4_streamDecode_t structure.
+ */
+LZ4_streamDecode_t* LZ4_createStreamDecode(void)
+{
+    LZ4_streamDecode_t* lz4s = (LZ4_streamDecode_t*) ALLOCATOR(1, sizeof(LZ4_streamDecode_t));
+    return lz4s;
+}
+
+int LZ4_freeStreamDecode (LZ4_streamDecode_t* LZ4_stream)
+{
+    FREEMEM(LZ4_stream);
+    return 0;
+}
+
+/*
+ * LZ4_setStreamDecode
+ * Use this function to instruct where to find the dictionary
+ * This function is not necessary if previous data is still available where it was decoded.
+ * Loading a size of 0 is allowed (same effect as no dictionary).
+ * Return : 1 if OK, 0 if error
+ */
+int LZ4_setStreamDecode (LZ4_streamDecode_t* LZ4_streamDecode, const char* dictionary, int dictSize)
+{
+    LZ4_streamDecode_t_internal* lz4sd = (LZ4_streamDecode_t_internal*) LZ4_streamDecode;
+    lz4sd->prefixSize = (size_t) dictSize;
+    lz4sd->prefixEnd = (const BYTE*) dictionary + dictSize;
+    lz4sd->externalDict = NULL;
+    lz4sd->extDictSize  = 0;
+    return 1;
+}
+
+/*
+*_continue() :
+    These decoding functions allow decompression of multiple blocks in "streaming" mode.
+    Previously decoded blocks must still be available at the memory position where they were decoded.
+    If it's not possible, save the relevant part of decoded data into a safe buffer,
+    and indicate where it stands using LZ4_setStreamDecode()
+*/
+int LZ4_decompress_safe_continue (LZ4_streamDecode_t* LZ4_streamDecode, const char* source, char* dest, int compressedSize, int maxOutputSize)
+{
+    LZ4_streamDecode_t_internal* lz4sd = (LZ4_streamDecode_t_internal*) LZ4_streamDecode;
+    int result;
+
+    if (lz4sd->prefixEnd == (BYTE*)dest)
+    {
+        result = LZ4_decompress_generic(source, dest, compressedSize, maxOutputSize,
+                                        endOnInputSize, full, 0,
+                                        usingExtDict, lz4sd->prefixEnd - lz4sd->prefixSize, lz4sd->externalDict, lz4sd->extDictSize);
+        if (result <= 0) return result;
+        lz4sd->prefixSize += result;
+        lz4sd->prefixEnd  += result;
+    }
+    else
+    {
+        lz4sd->extDictSize = lz4sd->prefixSize;
+        lz4sd->externalDict = lz4sd->prefixEnd - lz4sd->extDictSize;
+        result = LZ4_decompress_generic(source, dest, compressedSize, maxOutputSize,
+                                        endOnInputSize, full, 0,
+                                        usingExtDict, (BYTE*)dest, lz4sd->externalDict, lz4sd->extDictSize);
+        if (result <= 0) return result;
+        lz4sd->prefixSize = result;
+        lz4sd->prefixEnd  = (BYTE*)dest + result;
+    }
+
+    return result;
+}
+
+int LZ4_decompress_fast_continue (LZ4_streamDecode_t* LZ4_streamDecode, const char* source, char* dest, int originalSize)
+{
+    LZ4_streamDecode_t_internal* lz4sd = (LZ4_streamDecode_t_internal*) LZ4_streamDecode;
+    int result;
+
+    if (lz4sd->prefixEnd == (BYTE*)dest)
+    {
+        result = LZ4_decompress_generic(source, dest, 0, originalSize,
+                                        endOnOutputSize, full, 0,
+                                        usingExtDict, lz4sd->prefixEnd - lz4sd->prefixSize, lz4sd->externalDict, lz4sd->extDictSize);
+        if (result <= 0) return result;
+        lz4sd->prefixSize += originalSize;
+        lz4sd->prefixEnd  += originalSize;
+    }
+    else
+    {
+        lz4sd->extDictSize = lz4sd->prefixSize;
+        lz4sd->externalDict = (BYTE*)dest - lz4sd->extDictSize;
+        result = LZ4_decompress_generic(source, dest, 0, originalSize,
+                                        endOnOutputSize, full, 0,
+                                        usingExtDict, (BYTE*)dest, lz4sd->externalDict, lz4sd->extDictSize);
+        if (result <= 0) return result;
+        lz4sd->prefixSize = originalSize;
+        lz4sd->prefixEnd  = (BYTE*)dest + originalSize;
+    }
+
+    return result;
+}
+
+
+/*
+Advanced decoding functions :
+*_usingDict() :
+    These decoding functions work the same as "_continue" ones,
+    the dictionary must be explicitly provided within parameters
+*/
+
+FORCE_INLINE int LZ4_decompress_usingDict_generic(const char* source, char* dest, int compressedSize, int maxOutputSize, int safe, const char* dictStart, int dictSize)
+{
+    if (dictSize==0)
+        return LZ4_decompress_generic(source, dest, compressedSize, maxOutputSize, safe, full, 0, noDict, (BYTE*)dest, NULL, 0);
+    if (dictStart+dictSize == dest)
+    {
+        if (dictSize >= (int)(64 KB - 1))
+            return LZ4_decompress_generic(source, dest, compressedSize, maxOutputSize, safe, full, 0, withPrefix64k, (BYTE*)dest-64 KB, NULL, 0);
+        return LZ4_decompress_generic(source, dest, compressedSize, maxOutputSize, safe, full, 0, noDict, (BYTE*)dest-dictSize, NULL, 0);
+    }
+    return LZ4_decompress_generic(source, dest, compressedSize, maxOutputSize, safe, full, 0, usingExtDict, (BYTE*)dest, (const BYTE*)dictStart, dictSize);
+}
+
+int LZ4_decompress_safe_usingDict(const char* source, char* dest, int compressedSize, int maxOutputSize, const char* dictStart, int dictSize)
+{
+    return LZ4_decompress_usingDict_generic(source, dest, compressedSize, maxOutputSize, 1, dictStart, dictSize);
+}
+
+int LZ4_decompress_fast_usingDict(const char* source, char* dest, int originalSize, const char* dictStart, int dictSize)
+{
+    return LZ4_decompress_usingDict_generic(source, dest, 0, originalSize, 0, dictStart, dictSize);
+}
+
+/* debug function */
+int LZ4_decompress_safe_forceExtDict(const char* source, char* dest, int compressedSize, int maxOutputSize, const char* dictStart, int dictSize)
+{
+    return LZ4_decompress_generic(source, dest, compressedSize, maxOutputSize, endOnInputSize, full, 0, usingExtDict, (BYTE*)dest, (const BYTE*)dictStart, dictSize);
+}
+
+
+/***************************************************
+*  Obsolete Functions
+***************************************************/
+/* obsolete compression functions */
+int LZ4_compress_limitedOutput(const char* source, char* dest, int inputSize, int maxOutputSize) { return LZ4_compress_default(source, dest, inputSize, maxOutputSize); }
+int LZ4_compress(const char* source, char* dest, int inputSize) { return LZ4_compress_default(source, dest, inputSize, LZ4_compressBound(inputSize)); }
+int LZ4_compress_limitedOutput_withState (void* state, const char* src, char* dst, int srcSize, int dstSize) { return LZ4_compress_fast_extState(state, src, dst, srcSize, dstSize, 1); }
+int LZ4_compress_withState (void* state, const char* src, char* dst, int srcSize) { return LZ4_compress_fast_extState(state, src, dst, srcSize, LZ4_compressBound(srcSize), 1); }
+int LZ4_compress_limitedOutput_continue (LZ4_stream_t* LZ4_stream, const char* src, char* dst, int srcSize, int maxDstSize) { return LZ4_compress_fast_continue(LZ4_stream, src, dst, srcSize, maxDstSize, 1); }
+int LZ4_compress_continue (LZ4_stream_t* LZ4_stream, const char* source, char* dest, int inputSize) { return LZ4_compress_fast_continue(LZ4_stream, source, dest, inputSize, LZ4_compressBound(inputSize), 1); }
+
+/*
+These function names are deprecated and should no longer be used.
+They are only provided here for compatibility with older user programs.
+- LZ4_uncompress is totally equivalent to LZ4_decompress_fast
+- LZ4_uncompress_unknownOutputSize is totally equivalent to LZ4_decompress_safe
+*/
+int LZ4_uncompress (const char* source, char* dest, int outputSize) { return LZ4_decompress_fast(source, dest, outputSize); }
+int LZ4_uncompress_unknownOutputSize (const char* source, char* dest, int isize, int maxOutputSize) { return LZ4_decompress_safe(source, dest, isize, maxOutputSize); }
+
+
+/* Obsolete Streaming functions */
+
+int LZ4_sizeofStreamState() { return LZ4_STREAMSIZE; }
+
+static void LZ4_init(LZ4_stream_t_internal* lz4ds, BYTE* base)
+{
+    MEM_INIT(lz4ds, 0, LZ4_STREAMSIZE);
+    lz4ds->bufferStart = base;
+}
+
+int LZ4_resetStreamState(void* state, char* inputBuffer)
+{
+    if ((((size_t)state) & 3) != 0) return 1;   /* Error : pointer is not aligned on 4-bytes boundary */
+    LZ4_init((LZ4_stream_t_internal*)state, (BYTE*)inputBuffer);
+    return 0;
+}
+
+void* LZ4_create (char* inputBuffer)
+{
+    void* lz4ds = ALLOCATOR(8, LZ4_STREAMSIZE_U64);
+    LZ4_init ((LZ4_stream_t_internal*)lz4ds, (BYTE*)inputBuffer);
+    return lz4ds;
+}
+
+char* LZ4_slideInputBuffer (void* LZ4_Data)
+{
+    LZ4_stream_t_internal* ctx = (LZ4_stream_t_internal*)LZ4_Data;
+    int dictSize = LZ4_saveDict((LZ4_stream_t*)LZ4_Data, (char*)ctx->bufferStart, 64 KB);
+    return (char*)(ctx->bufferStart + dictSize);
+}
+
+/* Obsolete streaming decompression functions */
+
+int LZ4_decompress_safe_withPrefix64k(const char* source, char* dest, int compressedSize, int maxOutputSize)
+{
+    return LZ4_decompress_generic(source, dest, compressedSize, maxOutputSize, endOnInputSize, full, 0, withPrefix64k, (BYTE*)dest - 64 KB, NULL, 64 KB);
+}
+
+int LZ4_decompress_fast_withPrefix64k(const char* source, char* dest, int originalSize)
+{
+    return LZ4_decompress_generic(source, dest, 0, originalSize, endOnOutputSize, full, 0, withPrefix64k, (BYTE*)dest - 64 KB, NULL, 64 KB);
+}
+
+#endif   /* LZ4_COMMONDEFS_ONLY */
+
diff --git a/tools/cbfstool/lz4.c.inc b/tools/cbfstool/lz4.c.inc
new file mode 100644
index 0000000000..b3be4e5b44
--- /dev/null
+++ b/tools/cbfstool/lz4.c.inc
@@ -0,0 +1,280 @@
+/*
+   LZ4 - Fast LZ compression algorithm
+   Copyright (C) 2011-2015, Yann Collet.
+
+   BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+
+   Redistribution and use in source and binary forms, with or without
+   modification, are permitted provided that the following conditions are
+   met:
+
+       * Redistributions of source code must retain the above copyright
+   notice, this list of conditions and the following disclaimer.
+       * Redistributions in binary form must reproduce the above
+   copyright notice, this list of conditions and the following disclaimer
+   in the documentation and/or other materials provided with the
+   distribution.
+
+   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+   You can contact the author at :
+   - LZ4 source repository : https://github.com/Cyan4973/lz4
+   - LZ4 public forum : https://groups.google.com/forum/#!forum/lz4c
+*/
+
+
+/**************************************
+*  Reading and writing into memory
+**************************************/
+
+/* customized variant of memcpy, which can overwrite up to 7 bytes beyond dstEnd */
+static void LZ4_wildCopy(void* dstPtr, const void* srcPtr, void* dstEnd)
+{
+    BYTE* d = (BYTE*)dstPtr;
+    const BYTE* s = (const BYTE*)srcPtr;
+    BYTE* const e = (BYTE*)dstEnd;
+
+#if 0
+    const size_t l2 = 8 - (((size_t)d) & (sizeof(void*)-1));
+    LZ4_copy8(d,s); if (d>e-9) return;
+    d+=l2; s+=l2;
+#endif /* join to align */
+
+    do { LZ4_copy8(d,s); d+=8; s+=8; } while (d<e);
+}
+
+
+/**************************************
+*  Common Constants
+**************************************/
+#define MINMATCH 4
+
+#define WILDCOPYLENGTH 8
+#define LASTLITERALS 5
+#define MFLIMIT (WILDCOPYLENGTH+MINMATCH)
+static const int LZ4_minLength = (MFLIMIT+1);
+
+#define KB *(1 <<10)
+#define MB *(1 <<20)
+#define GB *(1U<<30)
+
+#define MAXD_LOG 16
+#define MAX_DISTANCE ((1 << MAXD_LOG) - 1)
+
+#define ML_BITS  4
+#define ML_MASK  ((1U<<ML_BITS)-1)
+#define RUN_BITS (8-ML_BITS)
+#define RUN_MASK ((1U<<RUN_BITS)-1)
+
+
+/**************************************
+*  Local Structures and types
+**************************************/
+typedef enum { noDict = 0, withPrefix64k, usingExtDict } dict_directive;
+typedef enum { endOnOutputSize = 0, endOnInputSize = 1 } endCondition_directive;
+typedef enum { full = 0, partial = 1 } earlyEnd_directive;
+
+
+
+/*******************************
+*  Decompression functions
+*******************************/
+/*
+ * This generic decompression function cover all use cases.
+ * It shall be instantiated several times, using different sets of directives
+ * Note that it is essential this generic function is really inlined,
+ * in order to remove useless branches during compilation optimization.
+ */
+FORCE_INLINE int LZ4_decompress_generic(
+                 const char* const source,
+                 char* const dest,
+                 int inputSize,
+                 int outputSize,         /* If endOnInput==endOnInputSize, this value is the max size of Output Buffer. */
+
+                 int endOnInput,         /* endOnOutputSize, endOnInputSize */
+                 int partialDecoding,    /* full, partial */
+                 int targetOutputSize,   /* only used if partialDecoding==partial */
+                 int dict,               /* noDict, withPrefix64k, usingExtDict */
+                 const BYTE* const lowPrefix,  /* == dest if dict == noDict */
+                 const BYTE* const dictStart,  /* only if dict==usingExtDict */
+                 const size_t dictSize         /* note : = 0 if noDict */
+                 )
+{
+    /* Local Variables */
+    const BYTE* ip = (const BYTE*) source;
+    const BYTE* const iend = ip + inputSize;
+
+    BYTE* op = (BYTE*) dest;
+    BYTE* const oend = op + outputSize;
+    BYTE* cpy;
+    BYTE* oexit = op + targetOutputSize;
+    const BYTE* const lowLimit = lowPrefix - dictSize;
+
+    const BYTE* const dictEnd = (const BYTE*)dictStart + dictSize;
+    const unsigned dec32table[] = {4, 1, 2, 1, 4, 4, 4, 4};
+    const int dec64table[] = {0, 0, 0, -1, 0, 1, 2, 3};
+
+    const int safeDecode = (endOnInput==endOnInputSize);
+    const int checkOffset = ((safeDecode) && (dictSize < (int)(64 KB)));
+    const int inPlaceDecode = ((ip >= op) && (ip < oend));
+
+
+    /* Special cases */
+    if ((partialDecoding) && (oexit> oend-MFLIMIT)) oexit = oend-MFLIMIT;                         /* targetOutputSize too high => decode everything */
+    if ((endOnInput) && (unlikely(outputSize==0))) return ((inputSize==1) && (*ip==0)) ? 0 : -1;  /* Empty output buffer */
+    if ((!endOnInput) && (unlikely(outputSize==0))) return (*ip==0?1:-1);
+
+
+    /* Main Loop */
+    while (1)
+    {
+        unsigned token;
+        size_t length;
+        const BYTE* match;
+        size_t offset;
+
+        if (unlikely((inPlaceDecode) && (op + WILDCOPYLENGTH > ip))) goto _output_error;   /* output stream ran over input stream */
+
+        /* get literal length */
+        token = *ip++;
+        if ((length=(token>>ML_BITS)) == RUN_MASK)
+        {
+            unsigned s;
+            do
+            {
+                s = *ip++;
+                length += s;
+            }
+            while ( likely(endOnInput ? ip<iend-RUN_MASK : 1) && (s==255) );
+            if ((safeDecode) && unlikely((size_t)(op+length)<(size_t)(op))) goto _output_error;   /* overflow detection */
+            if ((safeDecode) && unlikely((size_t)(ip+length)<(size_t)(ip))) goto _output_error;   /* overflow detection */
+        }
+
+        /* copy literals */
+        cpy = op+length;
+        if (((endOnInput) && ((cpy>(partialDecoding?oexit:oend-MFLIMIT)) || (ip+length>iend-(2+1+LASTLITERALS))) )
+            || ((!endOnInput) && (cpy>oend-WILDCOPYLENGTH)))
+        {
+            if (partialDecoding)
+            {
+                if (cpy > oend) goto _output_error;                           /* Error : write attempt beyond end of output buffer */
+                if ((endOnInput) && (ip+length > iend)) goto _output_error;   /* Error : read attempt beyond end of input buffer */
+            }
+            else
+            {
+                if ((!endOnInput) && (cpy != oend)) goto _output_error;       /* Error : block decoding must stop exactly there */
+                if ((endOnInput) && ((ip+length != iend) || (cpy > oend))) goto _output_error;   /* Error : input must be consumed */
+            }
+            memmove(op, ip, length);
+            ip += length;
+            op += length;
+            break;     /* Necessarily EOF, due to parsing restrictions */
+        }
+        LZ4_wildCopy(op, ip, cpy);
+        ip += length; op = cpy;
+
+        /* get offset */
+        offset = LZ4_readLE16(ip); ip+=2;
+        match = op - offset;
+        if ((checkOffset) && (unlikely(match < lowLimit))) goto _output_error;   /* Error : offset outside buffers */
+
+        /* get matchlength */
+        length = token & ML_MASK;
+        if (length == ML_MASK)
+        {
+            unsigned s;
+            do
+            {
+                if ((endOnInput) && (ip > iend-LASTLITERALS)) goto _output_error;
+                s = *ip++;
+                length += s;
+            } while (s==255);
+            if ((safeDecode) && unlikely((size_t)(op+length)<(size_t)op)) goto _output_error;   /* overflow detection */
+        }
+        length += MINMATCH;
+
+        /* check external dictionary */
+        if ((dict==usingExtDict) && (match < lowPrefix))
+        {
+            if (unlikely(op+length > oend-LASTLITERALS)) goto _output_error;   /* doesn't respect parsing restriction */
+
+            if (length <= (size_t)(lowPrefix-match))
+            {
+                /* match can be copied as a single segment from external dictionary */
+                match = dictEnd - (lowPrefix-match);
+                memmove(op, match, length); op += length;
+            }
+            else
+            {
+                /* match encompass external dictionary and current block */
+                size_t copySize = (size_t)(lowPrefix-match);
+                memcpy(op, dictEnd - copySize, copySize);
+                op += copySize;
+                copySize = length - copySize;
+                if (copySize > (size_t)(op-lowPrefix))   /* overlap copy */
+                {
+                    BYTE* const endOfMatch = op + copySize;
+                    const BYTE* copyFrom = lowPrefix;
+                    while (op < endOfMatch) *op++ = *copyFrom++;
+                }
+                else
+                {
+                    memcpy(op, lowPrefix, copySize);
+                    op += copySize;
+                }
+            }
+            continue;
+        }
+
+        /* copy match within block */
+        cpy = op + length;
+        if (unlikely(offset<8))
+        {
+            const int dec64 = dec64table[offset];
+            op[0] = match[0];
+            op[1] = match[1];
+            op[2] = match[2];
+            op[3] = match[3];
+            match += dec32table[offset];
+            memcpy(op+4, match, 4);
+            match -= dec64;
+        } else { LZ4_copy8(op, match); match+=8; }
+        op += 8;
+
+        if (unlikely(cpy>oend-12))
+        {
+            BYTE* const oCopyLimit = oend-(WILDCOPYLENGTH-1);
+            if (cpy > oend-LASTLITERALS) goto _output_error;    /* Error : last LASTLITERALS bytes must be literals (uncompressed) */
+            if (op < oCopyLimit)
+            {
+                LZ4_wildCopy(op, match, oCopyLimit);
+                match += oCopyLimit - op;
+                op = oCopyLimit;
+            }
+            while (op<cpy) *op++ = *match++;
+        }
+        else
+            LZ4_wildCopy(op, match, cpy);
+        op=cpy;   /* correction */
+    }
+
+    /* end of decoding */
+    if (endOnInput)
+       return (int) (((char*)op)-dest);     /* Nb of output bytes decoded */
+    else
+       return (int) (((const char*)ip)-source);   /* Nb of input bytes read */
+
+    /* Overflow error detected */
+_output_error:
+    return (int) (-(((const char*)ip)-source))-1;
+}
diff --git a/tools/cbfstool/lz4/lib/lz4.h b/tools/cbfstool/lz4/lib/lz4.h
new file mode 100644
index 0000000000..96e25a6615
--- /dev/null
+++ b/tools/cbfstool/lz4/lib/lz4.h
@@ -0,0 +1,360 @@
+/*
+   LZ4 - Fast LZ compression algorithm
+   Header File
+   Copyright (C) 2011-2015, Yann Collet.
+
+   BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+
+   Redistribution and use in source and binary forms, with or without
+   modification, are permitted provided that the following conditions are
+   met:
+
+       * Redistributions of source code must retain the above copyright
+   notice, this list of conditions and the following disclaimer.
+       * Redistributions in binary form must reproduce the above
+   copyright notice, this list of conditions and the following disclaimer
+   in the documentation and/or other materials provided with the
+   distribution.
+
+   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+   You can contact the author at :
+   - LZ4 source repository : https://github.com/Cyan4973/lz4
+   - LZ4 public forum : https://groups.google.com/forum/#!forum/lz4c
+*/
+#pragma once
+
+#if defined (__cplusplus)
+extern "C" {
+#endif
+
+/*
+ * lz4.h provides block compression functions, and gives full buffer control to programmer.
+ * If you need to generate inter-operable compressed data (respecting LZ4 frame specification),
+ * and can let the library handle its own memory, please use lz4frame.h instead.
+*/
+
+/**************************************
+*  Version
+**************************************/
+#define LZ4_VERSION_MAJOR    1    /* for breaking interface changes  */
+#define LZ4_VERSION_MINOR    7    /* for new (non-breaking) interface capabilities */
+#define LZ4_VERSION_RELEASE  2    /* for tweaks, bug-fixes, or development */
+#define LZ4_VERSION_NUMBER (LZ4_VERSION_MAJOR *100*100 + LZ4_VERSION_MINOR *100 + LZ4_VERSION_RELEASE)
+int LZ4_versionNumber (void);
+
+/**************************************
+*  Tuning parameter
+**************************************/
+/*
+ * LZ4_MEMORY_USAGE :
+ * Memory usage formula : N->2^N Bytes (examples : 10 -> 1KB; 12 -> 4KB ; 16 -> 64KB; 20 -> 1MB; etc.)
+ * Increasing memory usage improves compression ratio
+ * Reduced memory usage can improve speed, due to cache effect
+ * Default value is 14, for 16KB, which nicely fits into Intel x86 L1 cache
+ */
+#define LZ4_MEMORY_USAGE 14
+
+
+/**************************************
+*  Simple Functions
+**************************************/
+
+int LZ4_compress_default(const char* source, char* dest, int sourceSize, int maxDestSize);
+int LZ4_decompress_safe (const char* source, char* dest, int compressedSize, int maxDecompressedSize);
+
+/*
+LZ4_compress_default() :
+    Compresses 'sourceSize' bytes from buffer 'source'
+    into already allocated 'dest' buffer of size 'maxDestSize'.
+    Compression is guaranteed to succeed if 'maxDestSize' >= LZ4_compressBound(sourceSize).
+    It also runs faster, so it's a recommended setting.
+    If the function cannot compress 'source' into a more limited 'dest' budget,
+    compression stops *immediately*, and the function result is zero.
+    As a consequence, 'dest' content is not valid.
+    This function never writes outside 'dest' buffer, nor read outside 'source' buffer.
+        sourceSize  : Max supported value is LZ4_MAX_INPUT_VALUE
+        maxDestSize : full or partial size of buffer 'dest' (which must be already allocated)
+        return : the number of bytes written into buffer 'dest' (necessarily <= maxOutputSize)
+              or 0 if compression fails
+
+LZ4_decompress_safe() :
+    compressedSize : is the precise full size of the compressed block.
+    maxDecompressedSize : is the size of destination buffer, which must be already allocated.
+    return : the number of bytes decompressed into destination buffer (necessarily <= maxDecompressedSize)
+             If destination buffer is not large enough, decoding will stop and output an error code (<0).
+             If the source stream is detected malformed, the function will stop decoding and return a negative result.
+             This function is protected against buffer overflow exploits, including malicious data packets.
+             It never writes outside output buffer, nor reads outside input buffer.
+*/
+
+
+/**************************************
+*  Advanced Functions
+**************************************/
+#define LZ4_MAX_INPUT_SIZE        0x7E000000   /* 2 113 929 216 bytes */
+#define LZ4_COMPRESSBOUND(isize)  ((unsigned)(isize) > (unsigned)LZ4_MAX_INPUT_SIZE ? 0 : (isize) + ((isize)/255) + 16)
+
+/*
+LZ4_compressBound() :
+    Provides the maximum size that LZ4 compression may output in a "worst case" scenario (input data not compressible)
+    This function is primarily useful for memory allocation purposes (destination buffer size).
+    Macro LZ4_COMPRESSBOUND() is also provided for compilation-time evaluation (stack memory allocation for example).
+    Note that LZ4_compress_default() compress faster when dest buffer size is >= LZ4_compressBound(srcSize)
+        inputSize  : max supported value is LZ4_MAX_INPUT_SIZE
+        return : maximum output size in a "worst case" scenario
+              or 0, if input size is too large ( > LZ4_MAX_INPUT_SIZE)
+*/
+int LZ4_compressBound(int inputSize);
+
+/*
+LZ4_compress_fast() :
+    Same as LZ4_compress_default(), but allows to select an "acceleration" factor.
+    The larger the acceleration value, the faster the algorithm, but also the lesser the compression.
+    It's a trade-off. It can be fine tuned, with each successive value providing roughly +~3% to speed.
+    An acceleration value of "1" is the same as regular LZ4_compress_default()
+    Values <= 0 will be replaced by ACCELERATION_DEFAULT (see lz4.c), which is 1.
+*/
+int LZ4_compress_fast (const char* source, char* dest, int sourceSize, int maxDestSize, int acceleration);
+
+
+/*
+LZ4_compress_fast_extState() :
+    Same compression function, just using an externally allocated memory space to store compression state.
+    Use LZ4_sizeofState() to know how much memory must be allocated,
+    and allocate it on 8-bytes boundaries (using malloc() typically).
+    Then, provide it as 'void* state' to compression function.
+*/
+int LZ4_sizeofState(void);
+int LZ4_compress_fast_extState (void* state, const char* source, char* dest, int inputSize, int maxDestSize, int acceleration);
+
+
+/*
+LZ4_compress_destSize() :
+    Reverse the logic, by compressing as much data as possible from 'source' buffer
+    into already allocated buffer 'dest' of size 'targetDestSize'.
+    This function either compresses the entire 'source' content into 'dest' if it's large enough,
+    or fill 'dest' buffer completely with as much data as possible from 'source'.
+        *sourceSizePtr : will be modified to indicate how many bytes where read from 'source' to fill 'dest'.
+                         New value is necessarily <= old value.
+        return : Nb bytes written into 'dest' (necessarily <= targetDestSize)
+              or 0 if compression fails
+*/
+int LZ4_compress_destSize (const char* source, char* dest, int* sourceSizePtr, int targetDestSize);
+
+
+/*
+LZ4_decompress_fast() :
+    originalSize : is the original and therefore uncompressed size
+    return : the number of bytes read from the source buffer (in other words, the compressed size)
+             If the source stream is detected malformed, the function will stop decoding and return a negative result.
+             Destination buffer must be already allocated. Its size must be a minimum of 'originalSize' bytes.
+    note : This function fully respect memory boundaries for properly formed compressed data.
+           It is a bit faster than LZ4_decompress_safe().
+           However, it does not provide any protection against intentionally modified data stream (malicious input).
+           Use this function in trusted environment only (data to decode comes from a trusted source).
+*/
+int LZ4_decompress_fast (const char* source, char* dest, int originalSize);
+
+/*
+LZ4_decompress_safe_partial() :
+    This function decompress a compressed block of size 'compressedSize' at position 'source'
+    into destination buffer 'dest' of size 'maxDecompressedSize'.
+    The function tries to stop decompressing operation as soon as 'targetOutputSize' has been reached,
+    reducing decompression time.
+    return : the number of bytes decoded in the destination buffer (necessarily <= maxDecompressedSize)
+       Note : this number can be < 'targetOutputSize' should the compressed block to decode be smaller.
+             Always control how many bytes were decoded.
+             If the source stream is detected malformed, the function will stop decoding and return a negative result.
+             This function never writes outside of output buffer, and never reads outside of input buffer. It is therefore protected against malicious data packets
+*/
+int LZ4_decompress_safe_partial (const char* source, char* dest, int compressedSize, int targetOutputSize, int maxDecompressedSize);
+
+
+/***********************************************
+*  Streaming Compression Functions
+***********************************************/
+#define LZ4_STREAMSIZE_U64 ((1 << (LZ4_MEMORY_USAGE-3)) + 4)
+#define LZ4_STREAMSIZE     (LZ4_STREAMSIZE_U64 * sizeof(long long))
+/*
+ * LZ4_stream_t
+ * information structure to track an LZ4 stream.
+ * important : init this structure content before first use !
+ * note : only allocated directly the structure if you are statically linking LZ4
+ *        If you are using liblz4 as a DLL, please use below construction methods instead.
+ */
+typedef struct { long long table[LZ4_STREAMSIZE_U64]; } LZ4_stream_t;
+
+/*
+ * LZ4_resetStream
+ * Use this function to init an allocated LZ4_stream_t structure
+ */
+void LZ4_resetStream (LZ4_stream_t* streamPtr);
+
+/*
+ * LZ4_createStream will allocate and initialize an LZ4_stream_t structure
+ * LZ4_freeStream releases its memory.
+ * In the context of a DLL (liblz4), please use these methods rather than the static struct.
+ * They are more future proof, in case of a change of LZ4_stream_t size.
+ */
+LZ4_stream_t* LZ4_createStream(void);
+int           LZ4_freeStream (LZ4_stream_t* streamPtr);
+
+/*
+ * LZ4_loadDict
+ * Use this function to load a static dictionary into LZ4_stream.
+ * Any previous data will be forgotten, only 'dictionary' will remain in memory.
+ * Loading a size of 0 is allowed.
+ * Return : dictionary size, in bytes (necessarily <= 64 KB)
+ */
+int LZ4_loadDict (LZ4_stream_t* streamPtr, const char* dictionary, int dictSize);
+
+/*
+ * LZ4_compress_fast_continue
+ * Compress buffer content 'src', using data from previously compressed blocks as dictionary to improve compression ratio.
+ * Important : Previous data blocks are assumed to still be present and unmodified !
+ * 'dst' buffer must be already allocated.
+ * If maxDstSize >= LZ4_compressBound(srcSize), compression is guaranteed to succeed, and runs faster.
+ * If not, and if compressed data cannot fit into 'dst' buffer size, compression stops, and function returns a zero.
+ */
+int LZ4_compress_fast_continue (LZ4_stream_t* streamPtr, const char* src, char* dst, int srcSize, int maxDstSize, int acceleration);
+
+/*
+ * LZ4_saveDict
+ * If previously compressed data block is not guaranteed to remain available at its memory location
+ * save it into a safer place (char* safeBuffer)
+ * Note : you don't need to call LZ4_loadDict() afterwards,
+ *        dictionary is immediately usable, you can therefore call LZ4_compress_fast_continue()
+ * Return : saved dictionary size in bytes (necessarily <= dictSize), or 0 if error
+ */
+int LZ4_saveDict (LZ4_stream_t* streamPtr, char* safeBuffer, int dictSize);
+
+
+/************************************************
+*  Streaming Decompression Functions
+************************************************/
+
+#define LZ4_STREAMDECODESIZE_U64  4
+#define LZ4_STREAMDECODESIZE     (LZ4_STREAMDECODESIZE_U64 * sizeof(unsigned long long))
+typedef struct { unsigned long long table[LZ4_STREAMDECODESIZE_U64]; } LZ4_streamDecode_t;
+/*
+ * LZ4_streamDecode_t
+ * information structure to track an LZ4 stream.
+ * init this structure content using LZ4_setStreamDecode or memset() before first use !
+ *
+ * In the context of a DLL (liblz4) please prefer usage of construction methods below.
+ * They are more future proof, in case of a change of LZ4_streamDecode_t size in the future.
+ * LZ4_createStreamDecode will allocate and initialize an LZ4_streamDecode_t structure
+ * LZ4_freeStreamDecode releases its memory.
+ */
+LZ4_streamDecode_t* LZ4_createStreamDecode(void);
+int                 LZ4_freeStreamDecode (LZ4_streamDecode_t* LZ4_stream);
+
+/*
+ * LZ4_setStreamDecode
+ * Use this function to instruct where to find the dictionary.
+ * Setting a size of 0 is allowed (same effect as reset).
+ * Return : 1 if OK, 0 if error
+ */
+int LZ4_setStreamDecode (LZ4_streamDecode_t* LZ4_streamDecode, const char* dictionary, int dictSize);
+
+/*
+*_continue() :
+    These decoding functions allow decompression of multiple blocks in "streaming" mode.
+    Previously decoded blocks *must* remain available at the memory position where they were decoded (up to 64 KB)
+    In the case of a ring buffers, decoding buffer must be either :
+    - Exactly same size as encoding buffer, with same update rule (block boundaries at same positions)
+      In which case, the decoding & encoding ring buffer can have any size, including very small ones ( < 64 KB).
+    - Larger than encoding buffer, by a minimum of maxBlockSize more bytes.
+      maxBlockSize is implementation dependent. It's the maximum size you intend to compress into a single block.
+      In which case, encoding and decoding buffers do not need to be synchronized,
+      and encoding ring buffer can have any size, including small ones ( < 64 KB).
+    - _At least_ 64 KB + 8 bytes + maxBlockSize.
+      In which case, encoding and decoding buffers do not need to be synchronized,
+      and encoding ring buffer can have any size, including larger than decoding buffer.
+    Whenever these conditions are not possible, save the last 64KB of decoded data into a safe buffer,
+    and indicate where it is saved using LZ4_setStreamDecode()
+*/
+int LZ4_decompress_safe_continue (LZ4_streamDecode_t* LZ4_streamDecode, const char* source, char* dest, int compressedSize, int maxDecompressedSize);
+int LZ4_decompress_fast_continue (LZ4_streamDecode_t* LZ4_streamDecode, const char* source, char* dest, int originalSize);
+
+
+/*
+Advanced decoding functions :
+*_usingDict() :
+    These decoding functions work the same as
+    a combination of LZ4_setStreamDecode() followed by LZ4_decompress_x_continue()
+    They are stand-alone. They don't need nor update an LZ4_streamDecode_t structure.
+*/
+int LZ4_decompress_safe_usingDict (const char* source, char* dest, int compressedSize, int maxDecompressedSize, const char* dictStart, int dictSize);
+int LZ4_decompress_fast_usingDict (const char* source, char* dest, int originalSize, const char* dictStart, int dictSize);
+
+
+/**************************************
+*  Obsolete Functions
+**************************************/
+/* Deprecate Warnings */
+/* Should these warnings messages be a problem,
+   it is generally possible to disable them,
+   with -Wno-deprecated-declarations for gcc
+   or _CRT_SECURE_NO_WARNINGS in Visual for example.
+   Otherwise, you can also define LZ4_DISABLE_DEPRECATE_WARNINGS */
+#define LZ4_GCC_VERSION (__GNUC__ * 100 + __GNUC_MINOR__)
+#ifdef LZ4_DISABLE_DEPRECATE_WARNINGS
+#  define LZ4_DEPRECATED()   /* disable deprecation warnings */
+#else
+#  if (LZ4_GCC_VERSION >= 405) || defined(__clang__)
+#    define LZ4_DEPRECATED(message) __attribute__((deprecated(message)))
+#  elif (LZ4_GCC_VERSION >= 301)
+#    define LZ4_DEPRECATED(message) __attribute__((deprecated))
+#  elif defined(_MSC_VER)
+#    define LZ4_DEPRECATED(message) __declspec(deprecated(message))
+#  else
+#    pragma message("WARNING: You need to implement LZ4_DEPRECATED for this compiler")
+#    define LZ4_DEPRECATED(message)
+#  endif
+#endif /* LZ4_DISABLE_DEPRECATE_WARNINGS */
+
+/* Obsolete compression functions */
+/* These functions will generate warnings in a future release */
+int LZ4_compress               (const char* source, char* dest, int sourceSize);
+int LZ4_compress_limitedOutput (const char* source, char* dest, int sourceSize, int maxOutputSize);
+int LZ4_compress_withState               (void* state, const char* source, char* dest, int inputSize);
+int LZ4_compress_limitedOutput_withState (void* state, const char* source, char* dest, int inputSize, int maxOutputSize);
+int LZ4_compress_continue                (LZ4_stream_t* LZ4_streamPtr, const char* source, char* dest, int inputSize);
+int LZ4_compress_limitedOutput_continue  (LZ4_stream_t* LZ4_streamPtr, const char* source, char* dest, int inputSize, int maxOutputSize);
+
+/* Obsolete decompression functions */
+/* These function names are completely deprecated and must no longer be used.
+   They are only provided in lz4.c for compatibility with older programs.
+    - LZ4_uncompress is the same as LZ4_decompress_fast
+    - LZ4_uncompress_unknownOutputSize is the same as LZ4_decompress_safe
+   These function prototypes are now disabled; uncomment them only if you really need them.
+   It is highly recommended to stop using these prototypes and migrate to maintained ones */
+/* int LZ4_uncompress (const char* source, char* dest, int outputSize); */
+/* int LZ4_uncompress_unknownOutputSize (const char* source, char* dest, int isize, int maxOutputSize); */
+
+/* Obsolete streaming functions; use new streaming interface whenever possible */
+LZ4_DEPRECATED("use LZ4_createStream() instead") void* LZ4_create (char* inputBuffer);
+LZ4_DEPRECATED("use LZ4_createStream() instead") int   LZ4_sizeofStreamState(void);
+LZ4_DEPRECATED("use LZ4_resetStream() instead")  int   LZ4_resetStreamState(void* state, char* inputBuffer);
+LZ4_DEPRECATED("use LZ4_saveDict() instead")     char* LZ4_slideInputBuffer (void* state);
+
+/* Obsolete streaming decoding functions */
+LZ4_DEPRECATED("use LZ4_decompress_safe_usingDict() instead") int LZ4_decompress_safe_withPrefix64k (const char* src, char* dst, int compressedSize, int maxDstSize);
+LZ4_DEPRECATED("use LZ4_decompress_fast_usingDict() instead") int LZ4_decompress_fast_withPrefix64k (const char* src, char* dst, int originalSize);
+
+
+#if defined (__cplusplus)
+}
+#endif
diff --git a/tools/cbfstool/lz4/lib/lz4frame.h b/tools/cbfstool/lz4/lib/lz4frame.h
new file mode 100644
index 0000000000..c039e5d559
--- /dev/null
+++ b/tools/cbfstool/lz4/lib/lz4frame.h
@@ -0,0 +1,303 @@
+/*
+   LZ4 auto-framing library
+   Header File
+   Copyright (C) 2011-2015, Yann Collet.
+   BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+
+   Redistribution and use in source and binary forms, with or without
+   modification, are permitted provided that the following conditions are
+   met:
+
+       * Redistributions of source code must retain the above copyright
+   notice, this list of conditions and the following disclaimer.
+       * Redistributions in binary form must reproduce the above
+   copyright notice, this list of conditions and the following disclaimer
+   in the documentation and/or other materials provided with the
+   distribution.
+
+   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+   You can contact the author at :
+   - LZ4 source repository : https://github.com/Cyan4973/lz4
+   - LZ4 public forum : https://groups.google.com/forum/#!forum/lz4c
+*/
+
+/* LZ4F is a stand-alone API to create LZ4-compressed frames
+ * conformant with specification v1.5.1.
+ * All related operations, including memory management, are handled internally by the library.
+ * You don't need lz4.h when using lz4frame.h.
+ * */
+
+#pragma once
+
+#if defined (__cplusplus)
+extern "C" {
+#endif
+
+/**************************************
+*  Includes
+**************************************/
+#include <stddef.h>   /* size_t */
+
+
+/**************************************
+*  Error management
+**************************************/
+typedef size_t LZ4F_errorCode_t;
+
+unsigned    LZ4F_isError(LZ4F_errorCode_t code);
+const char* LZ4F_getErrorName(LZ4F_errorCode_t code);   /* return error code string; useful for debugging */
+
+
+/**************************************
+*  Frame compression types
+**************************************/
+//#define LZ4F_DISABLE_OBSOLETE_ENUMS
+#ifndef LZ4F_DISABLE_OBSOLETE_ENUMS
+#  define LZ4F_OBSOLETE_ENUM(x) ,x
+#else
+#  define LZ4F_OBSOLETE_ENUM(x)
+#endif
+
+typedef enum {
+    LZ4F_default=0,
+    LZ4F_max64KB=4,
+    LZ4F_max256KB=5,
+    LZ4F_max1MB=6,
+    LZ4F_max4MB=7
+    LZ4F_OBSOLETE_ENUM(max64KB = LZ4F_max64KB)
+    LZ4F_OBSOLETE_ENUM(max256KB = LZ4F_max256KB)
+    LZ4F_OBSOLETE_ENUM(max1MB = LZ4F_max1MB)
+    LZ4F_OBSOLETE_ENUM(max4MB = LZ4F_max4MB)
+} LZ4F_blockSizeID_t;
+
+typedef enum {
+    LZ4F_blockLinked=0,
+    LZ4F_blockIndependent
+    LZ4F_OBSOLETE_ENUM(blockLinked = LZ4F_blockLinked)
+    LZ4F_OBSOLETE_ENUM(blockIndependent = LZ4F_blockIndependent)
+} LZ4F_blockMode_t;
+
+typedef enum {
+    LZ4F_noContentChecksum=0,
+    LZ4F_contentChecksumEnabled
+    LZ4F_OBSOLETE_ENUM(noContentChecksum = LZ4F_noContentChecksum)
+    LZ4F_OBSOLETE_ENUM(contentChecksumEnabled = LZ4F_contentChecksumEnabled)
+} LZ4F_contentChecksum_t;
+
+typedef enum {
+    LZ4F_frame=0,
+    LZ4F_skippableFrame
+    LZ4F_OBSOLETE_ENUM(skippableFrame = LZ4F_skippableFrame)
+} LZ4F_frameType_t;
+
+#ifndef LZ4F_DISABLE_OBSOLETE_ENUMS
+typedef LZ4F_blockSizeID_t blockSizeID_t;
+typedef LZ4F_blockMode_t blockMode_t;
+typedef LZ4F_frameType_t frameType_t;
+typedef LZ4F_contentChecksum_t contentChecksum_t;
+#endif
+
+typedef struct {
+  LZ4F_blockSizeID_t     blockSizeID;           /* max64KB, max256KB, max1MB, max4MB ; 0 == default */
+  LZ4F_blockMode_t       blockMode;             /* blockLinked, blockIndependent ; 0 == default */
+  LZ4F_contentChecksum_t contentChecksumFlag;   /* noContentChecksum, contentChecksumEnabled ; 0 == default  */
+  LZ4F_frameType_t       frameType;             /* LZ4F_frame, skippableFrame ; 0 == default */
+  unsigned long long     contentSize;           /* Size of uncompressed (original) content ; 0 == unknown */
+  unsigned               reserved[2];           /* must be zero for forward compatibility */
+} LZ4F_frameInfo_t;
+
+typedef struct {
+  LZ4F_frameInfo_t frameInfo;
+  int      compressionLevel;       /* 0 == default (fast mode); values above 16 count as 16; values below 0 count as 0 */
+  unsigned autoFlush;              /* 1 == always flush (reduce need for tmp buffer) */
+  unsigned reserved[4];            /* must be zero for forward compatibility */
+} LZ4F_preferences_t;
+
+
+/***********************************
+*  Simple compression function
+***********************************/
+size_t LZ4F_compressFrameBound(size_t srcSize, const LZ4F_preferences_t* preferencesPtr);
+
+size_t LZ4F_compressFrame(void* dstBuffer, size_t dstMaxSize, const void* srcBuffer, size_t srcSize, const LZ4F_preferences_t* preferencesPtr);
+/* LZ4F_compressFrame()
+ * Compress an entire srcBuffer into a valid LZ4 frame, as defined by specification v1.5.1
+ * The most important rule is that dstBuffer MUST be large enough (dstMaxSize) to ensure compression completion even in worst case.
+ * You can get the minimum value of dstMaxSize by using LZ4F_compressFrameBound()
+ * If this condition is not respected, LZ4F_compressFrame() will fail (result is an errorCode)
+ * The LZ4F_preferences_t structure is optional : you can provide NULL as argument. All preferences will be set to default.
+ * The result of the function is the number of bytes written into dstBuffer.
+ * The function outputs an error code if it fails (can be tested using LZ4F_isError())
+ */
+
+
+
+/**********************************
+*  Advanced compression functions
+**********************************/
+typedef struct LZ4F_cctx_s* LZ4F_compressionContext_t;   /* must be aligned on 8-bytes */
+
+typedef struct {
+  unsigned stableSrc;    /* 1 == src content will remain available on future calls to LZ4F_compress(); avoid saving src content within tmp buffer as future dictionary */
+  unsigned reserved[3];
+} LZ4F_compressOptions_t;
+
+/* Resource Management */
+
+#define LZ4F_VERSION 100
+LZ4F_errorCode_t LZ4F_createCompressionContext(LZ4F_compressionContext_t* cctxPtr, unsigned version);
+LZ4F_errorCode_t LZ4F_freeCompressionContext(LZ4F_compressionContext_t cctx);
+/* LZ4F_createCompressionContext() :
+ * The first thing to do is to create a compressionContext object, which will be used in all compression operations.
+ * This is achieved using LZ4F_createCompressionContext(), which takes as argument a version and an LZ4F_preferences_t structure.
+ * The version provided MUST be LZ4F_VERSION. It is intended to track potential version differences between different binaries.
+ * The function will provide a pointer to a fully allocated LZ4F_compressionContext_t object.
+ * If the result LZ4F_errorCode_t is not zero, there was an error during context creation.
+ * Object can release its memory using LZ4F_freeCompressionContext();
+ */
+
+
+/* Compression */
+
+size_t LZ4F_compressBegin(LZ4F_compressionContext_t cctx, void* dstBuffer, size_t dstMaxSize, const LZ4F_preferences_t* prefsPtr);
+/* LZ4F_compressBegin() :
+ * will write the frame header into dstBuffer.
+ * dstBuffer must be large enough to accommodate a header (dstMaxSize). Maximum header size is 15 bytes.
+ * The LZ4F_preferences_t structure is optional : you can provide NULL as argument, all preferences will then be set to default.
+ * The result of the function is the number of bytes written into dstBuffer for the header
+ * or an error code (can be tested using LZ4F_isError())
+ */
+
+size_t LZ4F_compressBound(size_t srcSize, const LZ4F_preferences_t* prefsPtr);
+/* LZ4F_compressBound() :
+ * Provides the minimum size of Dst buffer given srcSize to handle worst case situations.
+ * Different preferences can produce different results.
+ * prefsPtr is optional : you can provide NULL as argument, all preferences will then be set to cover worst case.
+ * This function includes frame termination cost (4 bytes, or 8 if frame checksum is enabled)
+ */
+
+size_t LZ4F_compressUpdate(LZ4F_compressionContext_t cctx, void* dstBuffer, size_t dstMaxSize, const void* srcBuffer, size_t srcSize, const LZ4F_compressOptions_t* cOptPtr);
+/* LZ4F_compressUpdate()
+ * LZ4F_compressUpdate() can be called repetitively to compress as much data as necessary.
+ * The most important rule is that dstBuffer MUST be large enough (dstMaxSize) to ensure compression completion even in worst case.
+ * You can get the minimum value of dstMaxSize by using LZ4F_compressBound().
+ * If this condition is not respected, LZ4F_compress() will fail (result is an errorCode).
+ * LZ4F_compressUpdate() doesn't guarantee error recovery, so you have to reset compression context when an error occurs.
+ * The LZ4F_compressOptions_t structure is optional : you can provide NULL as argument.
+ * The result of the function is the number of bytes written into dstBuffer : it can be zero, meaning input data was just buffered.
+ * The function outputs an error code if it fails (can be tested using LZ4F_isError())
+ */
+
+size_t LZ4F_flush(LZ4F_compressionContext_t cctx, void* dstBuffer, size_t dstMaxSize, const LZ4F_compressOptions_t* cOptPtr);
+/* LZ4F_flush()
+ * Should you need to generate compressed data immediately, without waiting for the current block to be filled,
+ * you can call LZ4_flush(), which will immediately compress any remaining data buffered within cctx.
+ * Note that dstMaxSize must be large enough to ensure the operation will be successful.
+ * LZ4F_compressOptions_t structure is optional : you can provide NULL as argument.
+ * The result of the function is the number of bytes written into dstBuffer
+ * (it can be zero, this means there was no data left within cctx)
+ * The function outputs an error code if it fails (can be tested using LZ4F_isError())
+ */
+
+size_t LZ4F_compressEnd(LZ4F_compressionContext_t cctx, void* dstBuffer, size_t dstMaxSize, const LZ4F_compressOptions_t* cOptPtr);
+/* LZ4F_compressEnd()
+ * When you want to properly finish the compressed frame, just call LZ4F_compressEnd().
+ * It will flush whatever data remained within compressionContext (like LZ4_flush())
+ * but also properly finalize the frame, with an endMark and a checksum.
+ * The result of the function is the number of bytes written into dstBuffer (necessarily >= 4 (endMark), or 8 if optional frame checksum is enabled)
+ * The function outputs an error code if it fails (can be tested using LZ4F_isError())
+ * The LZ4F_compressOptions_t structure is optional : you can provide NULL as argument.
+ * A successful call to LZ4F_compressEnd() makes cctx available again for next compression task.
+ */
+
+
+/***********************************
+*  Decompression functions
+***********************************/
+
+typedef struct LZ4F_dctx_s* LZ4F_decompressionContext_t;   /* must be aligned on 8-bytes */
+
+typedef struct {
+  unsigned stableDst;       /* guarantee that decompressed data will still be there on next function calls (avoid storage into tmp buffers) */
+  unsigned reserved[3];
+} LZ4F_decompressOptions_t;
+
+
+/* Resource management */
+
+LZ4F_errorCode_t LZ4F_createDecompressionContext(LZ4F_decompressionContext_t* dctxPtr, unsigned version);
+LZ4F_errorCode_t LZ4F_freeDecompressionContext(LZ4F_decompressionContext_t dctx);
+/* LZ4F_createDecompressionContext() :
+ * The first thing to do is to create an LZ4F_decompressionContext_t object, which will be used in all decompression operations.
+ * This is achieved using LZ4F_createDecompressionContext().
+ * The version provided MUST be LZ4F_VERSION. It is intended to track potential breaking differences between different versions.
+ * The function will provide a pointer to a fully allocated and initialized LZ4F_decompressionContext_t object.
+ * The result is an errorCode, which can be tested using LZ4F_isError().
+ * dctx memory can be released using LZ4F_freeDecompressionContext();
+ * The result of LZ4F_freeDecompressionContext() is indicative of the current state of decompressionContext when being released.
+ * That is, it should be == 0 if decompression has been completed fully and correctly.
+ */
+
+
+/* Decompression */
+
+size_t LZ4F_getFrameInfo(LZ4F_decompressionContext_t dctx,
+                         LZ4F_frameInfo_t* frameInfoPtr,
+                         const void* srcBuffer, size_t* srcSizePtr);
+/* LZ4F_getFrameInfo()
+ * This function decodes frame header information (such as max blockSize, frame checksum, etc.).
+ * Its usage is optional. The objective is to extract frame header information, typically for allocation purposes.
+ * A header size is variable and can be from 7 to 15 bytes. It's also possible to input more bytes than that.
+ * The number of bytes read from srcBuffer will be updated within *srcSizePtr (necessarily <= original value).
+ * (note that LZ4F_getFrameInfo() can also be used anytime *after* starting decompression, in this case 0 input byte is enough)
+ * Frame header info is *copied into* an already allocated LZ4F_frameInfo_t structure.
+ * The function result is an hint about how many srcSize bytes LZ4F_decompress() expects for next call,
+ *                        or an error code which can be tested using LZ4F_isError()
+ *                        (typically, when there is not enough src bytes to fully decode the frame header)
+ * Decompression is expected to resume from where it stopped (srcBuffer + *srcSizePtr)
+ */
+
+size_t LZ4F_decompress(LZ4F_decompressionContext_t dctx,
+                       void* dstBuffer, size_t* dstSizePtr,
+                       const void* srcBuffer, size_t* srcSizePtr,
+                       const LZ4F_decompressOptions_t* dOptPtr);
+/* LZ4F_decompress()
+ * Call this function repetitively to regenerate data compressed within srcBuffer.
+ * The function will attempt to decode *srcSizePtr bytes from srcBuffer, into dstBuffer of maximum size *dstSizePtr.
+ *
+ * The number of bytes regenerated into dstBuffer will be provided within *dstSizePtr (necessarily <= original value).
+ *
+ * The number of bytes read from srcBuffer will be provided within *srcSizePtr (necessarily <= original value).
+ * If number of bytes read is < number of bytes provided, then decompression operation is not completed.
+ * It typically happens when dstBuffer is not large enough to contain all decoded data.
+ * LZ4F_decompress() must be called again, starting from where it stopped (srcBuffer + *srcSizePtr)
+ * The function will check this condition, and refuse to continue if it is not respected.
+ *
+ * dstBuffer is supposed to be flushed between each call to the function, since its content will be overwritten.
+ * dst arguments can be changed at will with each consecutive call to the function.
+ *
+ * The function result is an hint of how many srcSize bytes LZ4F_decompress() expects for next call.
+ * Schematically, it's the size of the current (or remaining) compressed block + header of next block.
+ * Respecting the hint provides some boost to performance, since it does skip intermediate buffers.
+ * This is just a hint, you can always provide any srcSize you want.
+ * When a frame is fully decoded, the function result will be 0 (no more data expected).
+ * If decompression failed, function result is an error code, which can be tested using LZ4F_isError().
+ *
+ * After a frame is fully decoded, dctx can be used again to decompress another frame.
+ */
+
+
+#if defined (__cplusplus)
+}
+#endif
diff --git a/tools/cbfstool/lz4/lib/lz4frame_static.h b/tools/cbfstool/lz4/lib/lz4frame_static.h
new file mode 100644
index 0000000000..0d909753b9
--- /dev/null
+++ b/tools/cbfstool/lz4/lib/lz4frame_static.h
@@ -0,0 +1,81 @@
+/*
+   LZ4 auto-framing library
+   Header File for static linking only
+   Copyright (C) 2011-2015, Yann Collet.
+
+   BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+
+   Redistribution and use in source and binary forms, with or without
+   modification, are permitted provided that the following conditions are
+   met:
+
+       * Redistributions of source code must retain the above copyright
+   notice, this list of conditions and the following disclaimer.
+       * Redistributions in binary form must reproduce the above
+   copyright notice, this list of conditions and the following disclaimer
+   in the documentation and/or other materials provided with the
+   distribution.
+
+   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+   You can contact the author at :
+   - LZ4 source repository : https://github.com/Cyan4973/lz4
+   - LZ4 public forum : https://groups.google.com/forum/#!forum/lz4c
+*/
+
+#pragma once
+
+#if defined (__cplusplus)
+extern "C" {
+#endif
+
+/* lz4frame_static.h should be used solely in the context of static linking.
+ * It contains definitions which may still change overtime.
+ * Never use it in the context of DLL linking.
+ * */
+
+
+/**************************************
+*  Includes
+**************************************/
+#include "lz4frame.h"
+
+
+/**************************************
+ * Error management
+ * ************************************/
+#define LZ4F_LIST_ERRORS(ITEM) \
+        ITEM(OK_NoError) ITEM(ERROR_GENERIC) \
+        ITEM(ERROR_maxBlockSize_invalid) ITEM(ERROR_blockMode_invalid) ITEM(ERROR_contentChecksumFlag_invalid) \
+        ITEM(ERROR_compressionLevel_invalid) \
+        ITEM(ERROR_headerVersion_wrong) ITEM(ERROR_blockChecksum_unsupported) ITEM(ERROR_reservedFlag_set) \
+        ITEM(ERROR_allocation_failed) \
+        ITEM(ERROR_srcSize_tooLarge) ITEM(ERROR_dstMaxSize_tooSmall) \
+        ITEM(ERROR_frameHeader_incomplete) ITEM(ERROR_frameType_unknown) ITEM(ERROR_frameSize_wrong) \
+        ITEM(ERROR_srcPtr_wrong) \
+        ITEM(ERROR_decompressionFailed) \
+        ITEM(ERROR_headerChecksum_invalid) ITEM(ERROR_contentChecksum_invalid) \
+        ITEM(ERROR_maxCode)
+
+//#define LZ4F_DISABLE_OLD_ENUMS
+#ifndef LZ4F_DISABLE_OLD_ENUMS
+#define LZ4F_GENERATE_ENUM(ENUM) LZ4F_##ENUM, ENUM = LZ4F_##ENUM,
+#else
+#define LZ4F_GENERATE_ENUM(ENUM) LZ4F_##ENUM,
+#endif
+typedef enum { LZ4F_LIST_ERRORS(LZ4F_GENERATE_ENUM) } LZ4F_errorCodes;  /* enum is exposed, to handle specific errors; compare function result to -enum value */
+
+
+#if defined (__cplusplus)
+}
+#endif
diff --git a/tools/cbfstool/lz4/lib/lz4hc.h b/tools/cbfstool/lz4/lib/lz4hc.h
new file mode 100644
index 0000000000..431f7c87c8
--- /dev/null
+++ b/tools/cbfstool/lz4/lib/lz4hc.h
@@ -0,0 +1,189 @@
+/*
+   LZ4 HC - High Compression Mode of LZ4
+   Header File
+   Copyright (C) 2011-2015, Yann Collet.
+   BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+
+   Redistribution and use in source and binary forms, with or without
+   modification, are permitted provided that the following conditions are
+   met:
+
+       * Redistributions of source code must retain the above copyright
+   notice, this list of conditions and the following disclaimer.
+       * Redistributions in binary form must reproduce the above
+   copyright notice, this list of conditions and the following disclaimer
+   in the documentation and/or other materials provided with the
+   distribution.
+
+   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+   You can contact the author at :
+   - LZ4 source repository : https://github.com/Cyan4973/lz4
+   - LZ4 public forum : https://groups.google.com/forum/#!forum/lz4c
+*/
+#pragma once
+
+
+#if defined (__cplusplus)
+extern "C" {
+#endif
+
+/*****************************
+*  Includes
+*****************************/
+#include <stddef.h>   /* size_t */
+
+
+/**************************************
+*  Block Compression
+**************************************/
+int LZ4_compress_HC (const char* src, char* dst, int srcSize, int maxDstSize, int compressionLevel);
+/*
+LZ4_compress_HC :
+    Destination buffer 'dst' must be already allocated.
+    Compression completion is guaranteed if 'dst' buffer is sized to handle worst circumstances (data not compressible)
+    Worst size evaluation is provided by function LZ4_compressBound() (see "lz4.h")
+      srcSize  : Max supported value is LZ4_MAX_INPUT_SIZE (see "lz4.h")
+      compressionLevel : Recommended values are between 4 and 9, although any value between 0 and 16 will work.
+                         0 means "use default value" (see lz4hc.c).
+                         Values >16 behave the same as 16.
+      return : the number of bytes written into buffer 'dst'
+            or 0 if compression fails.
+*/
+
+
+/* Note :
+   Decompression functions are provided within LZ4 source code (see "lz4.h") (BSD license)
+*/
+
+
+int LZ4_sizeofStateHC(void);
+int LZ4_compress_HC_extStateHC(void* state, const char* src, char* dst, int srcSize, int maxDstSize, int compressionLevel);
+/*
+LZ4_compress_HC_extStateHC() :
+   Use this function if you prefer to manually allocate memory for compression tables.
+   To know how much memory must be allocated for the compression tables, use :
+      int LZ4_sizeofStateHC();
+
+   Allocated memory must be aligned on 8-bytes boundaries (which a normal malloc() will do properly).
+
+   The allocated memory can then be provided to the compression functions using 'void* state' parameter.
+   LZ4_compress_HC_extStateHC() is equivalent to previously described function.
+   It just uses externally allocated memory for stateHC.
+*/
+
+
+/**************************************
+*  Streaming Compression
+**************************************/
+#define LZ4_STREAMHCSIZE        262192
+#define LZ4_STREAMHCSIZE_SIZET (LZ4_STREAMHCSIZE / sizeof(size_t))
+typedef struct { size_t table[LZ4_STREAMHCSIZE_SIZET]; } LZ4_streamHC_t;
+/*
+  LZ4_streamHC_t
+  This structure allows static allocation of LZ4 HC streaming state.
+  State must then be initialized using LZ4_resetStreamHC() before first use.
+
+  Static allocation should only be used in combination with static linking.
+  If you want to use LZ4 as a DLL, please use construction functions below, which are future-proof.
+*/
+
+
+LZ4_streamHC_t* LZ4_createStreamHC(void);
+int             LZ4_freeStreamHC (LZ4_streamHC_t* streamHCPtr);
+/*
+  These functions create and release memory for LZ4 HC streaming state.
+  Newly created states are already initialized.
+  Existing state space can be re-used anytime using LZ4_resetStreamHC().
+  If you use LZ4 as a DLL, use these functions instead of static structure allocation,
+  to avoid size mismatch between different versions.
+*/
+
+void LZ4_resetStreamHC (LZ4_streamHC_t* streamHCPtr, int compressionLevel);
+int  LZ4_loadDictHC (LZ4_streamHC_t* streamHCPtr, const char* dictionary, int dictSize);
+
+int LZ4_compress_HC_continue (LZ4_streamHC_t* streamHCPtr, const char* src, char* dst, int srcSize, int maxDstSize);
+
+int LZ4_saveDictHC (LZ4_streamHC_t* streamHCPtr, char* safeBuffer, int maxDictSize);
+
+/*
+  These functions compress data in successive blocks of any size, using previous blocks as dictionary.
+  One key assumption is that previous blocks (up to 64 KB) remain read-accessible while compressing next blocks.
+  There is an exception for ring buffers, which can be smaller 64 KB.
+  Such case is automatically detected and correctly handled by LZ4_compress_HC_continue().
+
+  Before starting compression, state must be properly initialized, using LZ4_resetStreamHC().
+  A first "fictional block" can then be designated as initial dictionary, using LZ4_loadDictHC() (Optional).
+
+  Then, use LZ4_compress_HC_continue() to compress each successive block.
+  It works like LZ4_compress_HC(), but use previous memory blocks as dictionary to improve compression.
+  Previous memory blocks (including initial dictionary when present) must remain accessible and unmodified during compression.
+  As a reminder, size 'dst' buffer to handle worst cases, using LZ4_compressBound(), to ensure success of compression operation.
+
+  If, for any reason, previous data blocks can't be preserved unmodified in memory during next compression block,
+  you must save it to a safer memory space, using LZ4_saveDictHC().
+  Return value of LZ4_saveDictHC() is the size of dictionary effectively saved into 'safeBuffer'.
+*/
+
+
+
+/**************************************
+*  Deprecated Functions
+**************************************/
+/* Deprecate Warnings */
+/* Should these warnings messages be a problem,
+   it is generally possible to disable them,
+   with -Wno-deprecated-declarations for gcc
+   or _CRT_SECURE_NO_WARNINGS in Visual for example.
+   You can also define LZ4_DEPRECATE_WARNING_DEFBLOCK. */
+#ifndef LZ4_DEPRECATE_WARNING_DEFBLOCK
+#  define LZ4_DEPRECATE_WARNING_DEFBLOCK
+#  define LZ4_GCC_VERSION (__GNUC__ * 100 + __GNUC_MINOR__)
+#  if (LZ4_GCC_VERSION >= 405) || defined(__clang__)
+#    define LZ4_DEPRECATED(message) __attribute__((deprecated(message)))
+#  elif (LZ4_GCC_VERSION >= 301)
+#    define LZ4_DEPRECATED(message) __attribute__((deprecated))
+#  elif defined(_MSC_VER)
+#    define LZ4_DEPRECATED(message) __declspec(deprecated(message))
+#  else
+#    pragma message("WARNING: You need to implement LZ4_DEPRECATED for this compiler")
+#    define LZ4_DEPRECATED(message)
+#  endif
+#endif // LZ4_DEPRECATE_WARNING_DEFBLOCK
+
+/* compression functions */
+/* these functions are planned to trigger warning messages by r131 approximately */
+int LZ4_compressHC                (const char* source, char* dest, int inputSize);
+int LZ4_compressHC_limitedOutput  (const char* source, char* dest, int inputSize, int maxOutputSize);
+int LZ4_compressHC2               (const char* source, char* dest, int inputSize, int compressionLevel);
+int LZ4_compressHC2_limitedOutput (const char* source, char* dest, int inputSize, int maxOutputSize, int compressionLevel);
+int LZ4_compressHC_withStateHC               (void* state, const char* source, char* dest, int inputSize);
+int LZ4_compressHC_limitedOutput_withStateHC (void* state, const char* source, char* dest, int inputSize, int maxOutputSize);
+int LZ4_compressHC2_withStateHC              (void* state, const char* source, char* dest, int inputSize, int compressionLevel);
+int LZ4_compressHC2_limitedOutput_withStateHC(void* state, const char* source, char* dest, int inputSize, int maxOutputSize, int compressionLevel);
+int LZ4_compressHC_continue               (LZ4_streamHC_t* LZ4_streamHCPtr, const char* source, char* dest, int inputSize);
+int LZ4_compressHC_limitedOutput_continue (LZ4_streamHC_t* LZ4_streamHCPtr, const char* source, char* dest, int inputSize, int maxOutputSize);
+
+/* Streaming functions following the older model; should no longer be used */
+LZ4_DEPRECATED("use LZ4_createStreamHC() instead") void* LZ4_createHC (char* inputBuffer);
+LZ4_DEPRECATED("use LZ4_saveDictHC() instead")     char* LZ4_slideInputBufferHC (void* LZ4HC_Data);
+LZ4_DEPRECATED("use LZ4_freeStreamHC() instead")   int   LZ4_freeHC (void* LZ4HC_Data);
+LZ4_DEPRECATED("use LZ4_compress_HC_continue() instead") int   LZ4_compressHC2_continue (void* LZ4HC_Data, const char* source, char* dest, int inputSize, int compressionLevel);
+LZ4_DEPRECATED("use LZ4_compress_HC_continue() instead") int   LZ4_compressHC2_limitedOutput_continue (void* LZ4HC_Data, const char* source, char* dest, int inputSize, int maxOutputSize, int compressionLevel);
+LZ4_DEPRECATED("use LZ4_createStreamHC() instead") int   LZ4_sizeofStreamStateHC(void);
+LZ4_DEPRECATED("use LZ4_resetStreamHC() instead")  int   LZ4_resetStreamStateHC(void* state, char* inputBuffer);
+
+
+#if defined (__cplusplus)
+}
+#endif
diff --git a/tools/cbfstool/lz4/lib/xxhash.h b/tools/cbfstool/lz4/lib/xxhash.h
new file mode 100644
index 0000000000..c60aa61571
--- /dev/null
+++ b/tools/cbfstool/lz4/lib/xxhash.h
@@ -0,0 +1,192 @@
+/*
+   xxHash - Extremely Fast Hash algorithm
+   Header File
+   Copyright (C) 2012-2015, Yann Collet.
+
+   BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+
+   Redistribution and use in source and binary forms, with or without
+   modification, are permitted provided that the following conditions are
+   met:
+
+       * Redistributions of source code must retain the above copyright
+   notice, this list of conditions and the following disclaimer.
+       * Redistributions in binary form must reproduce the above
+   copyright notice, this list of conditions and the following disclaimer
+   in the documentation and/or other materials provided with the
+   distribution.
+
+   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+   You can contact the author at :
+   - xxHash source repository : https://github.com/Cyan4973/xxHash
+*/
+
+/* Notice extracted from xxHash homepage :
+
+xxHash is an extremely fast Hash algorithm, running at RAM speed limits.
+It also successfully passes all tests from the SMHasher suite.
+
+Comparison (single thread, Windows Seven 32 bits, using SMHasher on a Core 2 Duo @3GHz)
+
+Name            Speed       Q.Score   Author
+xxHash          5.4 GB/s     10
+CrapWow         3.2 GB/s      2       Andrew
+MumurHash 3a    2.7 GB/s     10       Austin Appleby
+SpookyHash      2.0 GB/s     10       Bob Jenkins
+SBox            1.4 GB/s      9       Bret Mulvey
+Lookup3         1.2 GB/s      9       Bob Jenkins
+SuperFastHash   1.2 GB/s      1       Paul Hsieh
+CityHash64      1.05 GB/s    10       Pike & Alakuijala
+FNV             0.55 GB/s     5       Fowler, Noll, Vo
+CRC32           0.43 GB/s     9
+MD5-32          0.33 GB/s    10       Ronald L. Rivest
+SHA1-32         0.28 GB/s    10
+
+Q.Score is a measure of quality of the hash function.
+It depends on successfully passing SMHasher test set.
+10 is a perfect score.
+
+A 64-bits version, named XXH64, is available since r35.
+It offers much better speed, but for 64-bits applications only.
+Name     Speed on 64 bits    Speed on 32 bits
+XXH64       13.8 GB/s            1.9 GB/s
+XXH32        6.8 GB/s            6.0 GB/s
+*/
+
+#pragma once
+
+#if defined (__cplusplus)
+extern "C" {
+#endif
+
+
+/*****************************
+*  Definitions
+*****************************/
+#include <stddef.h>   /* size_t */
+typedef enum { XXH_OK=0, XXH_ERROR } XXH_errorcode;
+
+
+/*****************************
+*  Namespace Emulation
+*****************************/
+/* Motivations :
+
+If you need to include xxHash into your library,
+but wish to avoid xxHash symbols to be present on your library interface
+in an effort to avoid potential name collision if another library also includes xxHash,
+
+you can use XXH_NAMESPACE, which will automatically prefix any symbol from xxHash
+with the value of XXH_NAMESPACE (so avoid to keep it NULL, and avoid numeric values).
+
+Note that no change is required within the calling program :
+it can still call xxHash functions using their regular name.
+They will be automatically translated by this header.
+*/
+#ifdef XXH_NAMESPACE
+#  define XXH_CAT(A,B) A##B
+#  define XXH_NAME2(A,B) XXH_CAT(A,B)
+#  define XXH32 XXH_NAME2(XXH_NAMESPACE, XXH32)
+#  define XXH64 XXH_NAME2(XXH_NAMESPACE, XXH64)
+#  define XXH32_createState XXH_NAME2(XXH_NAMESPACE, XXH32_createState)
+#  define XXH64_createState XXH_NAME2(XXH_NAMESPACE, XXH64_createState)
+#  define XXH32_freeState XXH_NAME2(XXH_NAMESPACE, XXH32_freeState)
+#  define XXH64_freeState XXH_NAME2(XXH_NAMESPACE, XXH64_freeState)
+#  define XXH32_reset XXH_NAME2(XXH_NAMESPACE, XXH32_reset)
+#  define XXH64_reset XXH_NAME2(XXH_NAMESPACE, XXH64_reset)
+#  define XXH32_update XXH_NAME2(XXH_NAMESPACE, XXH32_update)
+#  define XXH64_update XXH_NAME2(XXH_NAMESPACE, XXH64_update)
+#  define XXH32_digest XXH_NAME2(XXH_NAMESPACE, XXH32_digest)
+#  define XXH64_digest XXH_NAME2(XXH_NAMESPACE, XXH64_digest)
+#endif
+
+
+/*****************************
+*  Simple Hash Functions
+*****************************/
+
+unsigned int       XXH32 (const void* input, size_t length, unsigned seed);
+unsigned long long XXH64 (const void* input, size_t length, unsigned long long seed);
+
+/*
+XXH32() :
+    Calculate the 32-bits hash of sequence "length" bytes stored at memory address "input".
+    The memory between input & input+length must be valid (allocated and read-accessible).
+    "seed" can be used to alter the result predictably.
+    This function successfully passes all SMHasher tests.
+    Speed on Core 2 Duo @ 3 GHz (single thread, SMHasher benchmark) : 5.4 GB/s
+XXH64() :
+    Calculate the 64-bits hash of sequence of length "len" stored at memory address "input".
+    Faster on 64-bits systems. Slower on 32-bits systems.
+*/
+
+
+
+/*****************************
+*  Advanced Hash Functions
+*****************************/
+typedef struct { long long ll[ 6]; } XXH32_state_t;
+typedef struct { long long ll[11]; } XXH64_state_t;
+
+/*
+These structures allow static allocation of XXH states.
+States must then be initialized using XXHnn_reset() before first use.
+
+If you prefer dynamic allocation, please refer to functions below.
+*/
+
+XXH32_state_t* XXH32_createState(void);
+XXH_errorcode  XXH32_freeState(XXH32_state_t* statePtr);
+
+XXH64_state_t* XXH64_createState(void);
+XXH_errorcode  XXH64_freeState(XXH64_state_t* statePtr);
+
+/*
+These functions create and release memory for XXH state.
+States must then be initialized using XXHnn_reset() before first use.
+*/
+
+
+XXH_errorcode XXH32_reset  (XXH32_state_t* statePtr, unsigned seed);
+XXH_errorcode XXH32_update (XXH32_state_t* statePtr, const void* input, size_t length);
+unsigned int  XXH32_digest (const XXH32_state_t* statePtr);
+
+XXH_errorcode      XXH64_reset  (XXH64_state_t* statePtr, unsigned long long seed);
+XXH_errorcode      XXH64_update (XXH64_state_t* statePtr, const void* input, size_t length);
+unsigned long long XXH64_digest (const XXH64_state_t* statePtr);
+
+/*
+These functions calculate the xxHash of an input provided in multiple smaller packets,
+as opposed to an input provided as a single block.
+
+XXH state space must first be allocated, using either static or dynamic method provided above.
+
+Start a new hash by initializing state with a seed, using XXHnn_reset().
+
+Then, feed the hash state by calling XXHnn_update() as many times as necessary.
+Obviously, input must be valid, meaning allocated and read accessible.
+The function returns an error code, with 0 meaning OK, and any other value meaning there is an error.
+
+Finally, you can produce a hash anytime, by using XXHnn_digest().
+This function returns the final nn-bits hash.
+You can nonetheless continue feeding the hash state with more input,
+and therefore get some new hashes, by calling again XXHnn_digest().
+
+When you are done, don't forget to free XXH state space, using typically XXHnn_freeState().
+*/
+
+
+#if defined (__cplusplus)
+}
+#endif
diff --git a/tools/cbfstool/lz4_wrapper.c b/tools/cbfstool/lz4_wrapper.c
new file mode 100644
index 0000000000..474df642c2
--- /dev/null
+++ b/tools/cbfstool/lz4_wrapper.c
@@ -0,0 +1,201 @@
+/*
+ * Copyright 2015-2016 Google Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. The name of the author may not be used to endorse or promote products
+ *    derived from this software without specific prior written permission.
+ *
+ * Alternatively, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") version 2 as published by the Free
+ * Software Foundation.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ */
+
+#include <commonlib/compression.h>
+#include <commonlib/endian.h>
+#include <commonlib/helpers.h>
+#include <stdint.h>
+#include <string.h>
+
+/* LZ4 comes with its own supposedly portable memory access functions, but they
+ * seem to be very inefficient in practice (at least on ARM64). Since coreboot
+ * knows about endinaness and allows some basic assumptions (such as unaligned
+ * access support), we can easily write the ones we need ourselves. */
+static uint16_t LZ4_readLE16(const void *src)
+{
+	return read_le16(src);
+}
+static void LZ4_copy8(void *dst, const void *src)
+{
+/* ARM32 needs to be a special snowflake to prevent GCC from coalescing the
+ * access into LDRD/STRD (which don't support unaligned accesses). */
+#ifdef __arm__	/* ARMv < 6 doesn't support unaligned accesses at all. */
+	#if defined(__COREBOOT_ARM_ARCH__) && __COREBOOT_ARM_ARCH__ < 6
+		int i;
+		for (i = 0; i < 8; i++)
+			((uint8_t *)dst)[i] = ((uint8_t *)src)[i];
+	#else
+		uint32_t x0, x1;
+		__asm__ ("ldr %[x0], [%[src]]"
+			: [x0]"=r"(x0)
+			: [src]"r"(src), "m"(*(const uint32_t *)src));
+		__asm__ ("ldr %[x1], [%[src], #4]"
+			: [x1]"=r"(x1)
+			: [src]"r"(src), "m"(*(const uint32_t *)(src + 4)));
+		__asm__ ("str %[x0], [%[dst]]"
+			: "=m"(*(uint32_t *)dst)
+			: [x0]"r"(x0), [dst]"r"(dst));
+		__asm__ ("str %[x1], [%[dst], #4]"
+			: "=m"(*(uint32_t *)(dst + 4))
+			: [x1]"r"(x1), [dst]"r"(dst));
+	#endif
+#elif defined(__riscv)
+	/* RISC-V implementations may trap on any unaligned access. */
+	int i;
+	for (i = 0; i < 8; i++)
+		((uint8_t *)dst)[i] = ((uint8_t *)src)[i];
+#else
+	*(uint64_t *)dst = *(const uint64_t *)src;
+#endif
+}
+
+typedef  uint8_t BYTE;
+typedef uint16_t U16;
+typedef uint32_t U32;
+typedef  int32_t S32;
+typedef uint64_t U64;
+
+#define FORCE_INLINE static __always_inline
+#define likely(expr) __builtin_expect((expr) != 0, 1)
+#define unlikely(expr) __builtin_expect((expr) != 0, 0)
+
+/* Unaltered (just removed unrelated code) from github.com/Cyan4973/lz4/dev. */
+#include "lz4.c.inc"	/* #include for inlining, do not link! */
+
+#define LZ4F_MAGICNUMBER 0x184D2204
+
+struct lz4_frame_header {
+	uint32_t magic;
+	union {
+		uint8_t flags;
+		struct {
+			uint8_t reserved0		: 2;
+			uint8_t has_content_checksum	: 1;
+			uint8_t has_content_size	: 1;
+			uint8_t has_block_checksum	: 1;
+			uint8_t independent_blocks	: 1;
+			uint8_t version			: 2;
+		};
+	};
+	union {
+		uint8_t block_descriptor;
+		struct {
+			uint8_t reserved1		: 4;
+			uint8_t max_block_size		: 3;
+			uint8_t reserved2		: 1;
+		};
+	};
+	/* + uint64_t content_size iff has_content_size is set */
+	/* + uint8_t header_checksum */
+} __packed;
+
+struct lz4_block_header {
+	union {
+		uint32_t raw;
+		struct {
+			uint32_t size		: 31;
+			uint32_t not_compressed	: 1;
+		};
+	};
+	/* + size bytes of data */
+	/* + uint32_t block_checksum iff has_block_checksum is set */
+} __packed;
+
+size_t ulz4fn(const void *src, size_t srcn, void *dst, size_t dstn)
+{
+	const void *in = src;
+	void *out = dst;
+	size_t out_size = 0;
+	int has_block_checksum;
+
+	{ /* With in-place decompression the header may become invalid later. */
+		const struct lz4_frame_header *h = in;
+
+		if (srcn < sizeof(*h) + sizeof(uint64_t) + sizeof(uint8_t))
+			return 0;	/* input overrun */
+
+		/* We assume there's always only a single, standard frame. */
+		if (read_le32(&h->magic) != LZ4F_MAGICNUMBER || h->version != 1)
+			return 0;	/* unknown format */
+		if (h->reserved0 || h->reserved1 || h->reserved2)
+			return 0;	/* reserved must be zero */
+		if (!h->independent_blocks)
+			return 0;	/* we don't support block dependency */
+		has_block_checksum = h->has_block_checksum;
+
+		in += sizeof(*h);
+		if (h->has_content_size)
+			in += sizeof(uint64_t);
+		in += sizeof(uint8_t);
+	}
+
+	while (1) {
+		struct lz4_block_header b = { { .raw = read_le32(in) } };
+		in += sizeof(struct lz4_block_header);
+
+		if ((size_t)(in - src) + b.size > srcn)
+			break;			/* input overrun */
+
+		if (!b.size) {
+			out_size = out - dst;
+			break;			/* decompression successful */
+		}
+
+		if (b.not_compressed) {
+			size_t size = MIN((uintptr_t)b.size, (uintptr_t)dst
+				+ dstn - (uintptr_t)out);
+			memcpy(out, in, size);
+			if (size < b.size)
+				break;		/* output overrun */
+			out += size;
+		} else {
+			/* constant folding essential, do not touch params! */
+			int ret = LZ4_decompress_generic(in, out, b.size,
+					dst + dstn - out, endOnInputSize,
+					full, 0, noDict, out, NULL, 0);
+			if (ret < 0)
+				break;		/* decompression error */
+			out += ret;
+		}
+
+		in += b.size;
+		if (has_block_checksum)
+			in += sizeof(uint32_t);
+	}
+
+	return out_size;
+}
+
+size_t ulz4f(const void *src, void *dst)
+{
+	/* LZ4 uses signed size parameters, so can't just use ((u32)-1) here. */
+	return ulz4fn(src, 1*GiB, dst, 1*GiB);
+}
diff --git a/tools/cbfstool/lz4frame.c b/tools/cbfstool/lz4frame.c
new file mode 100644
index 0000000000..db53dc1474
--- /dev/null
+++ b/tools/cbfstool/lz4frame.c
@@ -0,0 +1,1479 @@
+/*
+LZ4 auto-framing library
+Copyright (C) 2011-2015, Yann Collet.
+
+BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+
+* Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+* Redistributions in binary form must reproduce the above
+copyright notice, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+You can contact the author at :
+- LZ4 source repository : https://github.com/Cyan4973/lz4
+- LZ4 public forum : https://groups.google.com/forum/#!forum/lz4c
+*/
+
+/* LZ4F is a stand-alone API to create LZ4-compressed Frames
+*  in full conformance with specification v1.5.0
+*  All related operations, including memory management, are handled by the library.
+* */
+
+
+/**************************************
+*  Compiler Options
+**************************************/
+#ifdef _MSC_VER    /* Visual Studio */
+#  pragma warning(disable : 4127)        /* disable: C4127: conditional expression is constant */
+#endif
+
+
+/**************************************
+*  Memory routines
+**************************************/
+#include <stdlib.h>   /* malloc, calloc, free */
+#define ALLOCATOR(s)   calloc(1,s)
+#define FREEMEM        free
+#include <string.h>   /* memset, memcpy, memmove */
+#define MEM_INIT       memset
+
+
+/**************************************
+*  Includes
+**************************************/
+#include "lz4/lib/lz4frame_static.h"
+#include "lz4/lib/lz4.h"
+#include "lz4/lib/lz4hc.h"
+#include "lz4/lib/xxhash.h"
+
+
+/**************************************
+*  Basic Types
+**************************************/
+#if defined(__STDC_VERSION__) && (__STDC_VERSION__ >= 199901L)   /* C99 */
+# include <stdint.h>
+typedef  uint8_t BYTE;
+typedef uint16_t U16;
+typedef uint32_t U32;
+typedef  int32_t S32;
+typedef uint64_t U64;
+#else
+typedef unsigned char       BYTE;
+typedef unsigned short      U16;
+typedef unsigned int        U32;
+typedef   signed int        S32;
+typedef unsigned long long  U64;
+#endif
+
+
+/**************************************
+*  Constants
+**************************************/
+#define KB *(1<<10)
+#define MB *(1<<20)
+#define GB *(1<<30)
+
+#define _1BIT  0x01
+#define _2BITS 0x03
+#define _3BITS 0x07
+#define _4BITS 0x0F
+#define _8BITS 0xFF
+
+#define LZ4F_MAGIC_SKIPPABLE_START 0x184D2A50U
+#define LZ4F_MAGICNUMBER 0x184D2204U
+#define LZ4F_BLOCKUNCOMPRESSED_FLAG 0x80000000U
+#define LZ4F_BLOCKSIZEID_DEFAULT LZ4F_max64KB
+
+static const size_t minFHSize = 7;
+static const size_t maxFHSize = 15;
+static const size_t BHSize = 4;
+static const int    minHClevel = 3;
+
+
+/**************************************
+*  Structures and local types
+**************************************/
+typedef struct LZ4F_cctx_s
+{
+    LZ4F_preferences_t prefs;
+    U32    version;
+    U32    cStage;
+    size_t maxBlockSize;
+    size_t maxBufferSize;
+    BYTE*  tmpBuff;
+    BYTE*  tmpIn;
+    size_t tmpInSize;
+    U64    totalInSize;
+    XXH32_state_t xxh;
+    void*  lz4CtxPtr;
+    U32    lz4CtxLevel;     /* 0: unallocated;  1: LZ4_stream_t;  3: LZ4_streamHC_t */
+} LZ4F_cctx_t;
+
+typedef struct LZ4F_dctx_s
+{
+    LZ4F_frameInfo_t frameInfo;
+    U32    version;
+    U32    dStage;
+    U64    frameRemainingSize;
+    size_t maxBlockSize;
+    size_t maxBufferSize;
+    const BYTE* srcExpect;
+    BYTE*  tmpIn;
+    size_t tmpInSize;
+    size_t tmpInTarget;
+    BYTE*  tmpOutBuffer;
+    const BYTE*  dict;
+    size_t dictSize;
+    BYTE*  tmpOut;
+    size_t tmpOutSize;
+    size_t tmpOutStart;
+    XXH32_state_t xxh;
+    BYTE   header[16];
+} LZ4F_dctx_t;
+
+
+/**************************************
+*  Error management
+**************************************/
+#define LZ4F_GENERATE_STRING(STRING) #STRING,
+static const char* LZ4F_errorStrings[] = { LZ4F_LIST_ERRORS(LZ4F_GENERATE_STRING) };
+
+
+unsigned LZ4F_isError(LZ4F_errorCode_t code)
+{
+    return (code > (LZ4F_errorCode_t)(-LZ4F_ERROR_maxCode));
+}
+
+const char* LZ4F_getErrorName(LZ4F_errorCode_t code)
+{
+    static const char* codeError = "Unspecified error code";
+    if (LZ4F_isError(code)) return LZ4F_errorStrings[-(int)(code)];
+    return codeError;
+}
+
+
+/**************************************
+*  Private functions
+**************************************/
+static size_t LZ4F_getBlockSize(unsigned blockSizeID)
+{
+    static const size_t blockSizes[4] = { 64 KB, 256 KB, 1 MB, 4 MB };
+
+    if (blockSizeID == 0) blockSizeID = LZ4F_BLOCKSIZEID_DEFAULT;
+    blockSizeID -= 4;
+    if (blockSizeID > 3) return (size_t)-LZ4F_ERROR_maxBlockSize_invalid;
+    return blockSizes[blockSizeID];
+}
+
+
+/* unoptimized version; solves endianness & alignment issues */
+static U32 LZ4F_readLE32 (const BYTE* srcPtr)
+{
+    U32 value32 = srcPtr[0];
+    value32 += (srcPtr[1]<<8);
+    value32 += (srcPtr[2]<<16);
+    value32 += ((U32)srcPtr[3])<<24;
+    return value32;
+}
+
+static void LZ4F_writeLE32 (BYTE* dstPtr, U32 value32)
+{
+    dstPtr[0] = (BYTE)value32;
+    dstPtr[1] = (BYTE)(value32 >> 8);
+    dstPtr[2] = (BYTE)(value32 >> 16);
+    dstPtr[3] = (BYTE)(value32 >> 24);
+}
+
+static U64 LZ4F_readLE64 (const BYTE* srcPtr)
+{
+    U64 value64 = srcPtr[0];
+    value64 += ((U64)srcPtr[1]<<8);
+    value64 += ((U64)srcPtr[2]<<16);
+    value64 += ((U64)srcPtr[3]<<24);
+    value64 += ((U64)srcPtr[4]<<32);
+    value64 += ((U64)srcPtr[5]<<40);
+    value64 += ((U64)srcPtr[6]<<48);
+    value64 += ((U64)srcPtr[7]<<56);
+    return value64;
+}
+
+static void LZ4F_writeLE64 (BYTE* dstPtr, U64 value64)
+{
+    dstPtr[0] = (BYTE)value64;
+    dstPtr[1] = (BYTE)(value64 >> 8);
+    dstPtr[2] = (BYTE)(value64 >> 16);
+    dstPtr[3] = (BYTE)(value64 >> 24);
+    dstPtr[4] = (BYTE)(value64 >> 32);
+    dstPtr[5] = (BYTE)(value64 >> 40);
+    dstPtr[6] = (BYTE)(value64 >> 48);
+    dstPtr[7] = (BYTE)(value64 >> 56);
+}
+
+
+static BYTE LZ4F_headerChecksum (const void* header, size_t length)
+{
+    U32 xxh = XXH32(header, length, 0);
+    return (BYTE)(xxh >> 8);
+}
+
+
+/**************************************
+*  Simple compression functions
+**************************************/
+static LZ4F_blockSizeID_t LZ4F_optimalBSID(const LZ4F_blockSizeID_t requestedBSID, const size_t srcSize)
+{
+    LZ4F_blockSizeID_t proposedBSID = LZ4F_max64KB;
+    size_t maxBlockSize = 64 KB;
+    while (requestedBSID > proposedBSID)
+    {
+        if (srcSize <= maxBlockSize)
+            return proposedBSID;
+        proposedBSID = (LZ4F_blockSizeID_t)((int)proposedBSID + 1);
+        maxBlockSize <<= 2;
+    }
+    return requestedBSID;
+}
+
+
+size_t LZ4F_compressFrameBound(size_t srcSize, const LZ4F_preferences_t* preferencesPtr)
+{
+    LZ4F_preferences_t prefs;
+    size_t headerSize;
+    size_t streamSize;
+
+    if (preferencesPtr!=NULL) prefs = *preferencesPtr;
+    else memset(&prefs, 0, sizeof(prefs));
+
+    prefs.frameInfo.blockSizeID = LZ4F_optimalBSID(prefs.frameInfo.blockSizeID, srcSize);
+    prefs.autoFlush = 1;
+
+    headerSize = maxFHSize;      /* header size, including magic number and frame content size*/
+    streamSize = LZ4F_compressBound(srcSize, &prefs);
+
+    return headerSize + streamSize;
+}
+
+
+/* LZ4F_compressFrame()
+* Compress an entire srcBuffer into a valid LZ4 frame, as defined by specification v1.5.0, in a single step.
+* The most important rule is that dstBuffer MUST be large enough (dstMaxSize) to ensure compression completion even in worst case.
+* You can get the minimum value of dstMaxSize by using LZ4F_compressFrameBound()
+* If this condition is not respected, LZ4F_compressFrame() will fail (result is an errorCode)
+* The LZ4F_preferences_t structure is optional : you can provide NULL as argument. All preferences will then be set to default.
+* The result of the function is the number of bytes written into dstBuffer.
+* The function outputs an error code if it fails (can be tested using LZ4F_isError())
+*/
+size_t LZ4F_compressFrame(void* dstBuffer, size_t dstMaxSize, const void* srcBuffer, size_t srcSize, const LZ4F_preferences_t* preferencesPtr)
+{
+    LZ4F_cctx_t cctxI;
+    LZ4_stream_t lz4ctx;
+    LZ4F_preferences_t prefs;
+    LZ4F_compressOptions_t options;
+    LZ4F_errorCode_t errorCode;
+    BYTE* const dstStart = (BYTE*) dstBuffer;
+    BYTE* dstPtr = dstStart;
+    BYTE* const dstEnd = dstStart + dstMaxSize;
+
+    memset(&cctxI, 0, sizeof(cctxI));   /* works because no allocation */
+    memset(&options, 0, sizeof(options));
+
+    cctxI.version = LZ4F_VERSION;
+    cctxI.maxBufferSize = 5 MB;   /* mess with real buffer size to prevent allocation; works because autoflush==1 & stableSrc==1 */
+
+    if (preferencesPtr!=NULL)
+        prefs = *preferencesPtr;
+    else
+        memset(&prefs, 0, sizeof(prefs));
+    if (prefs.frameInfo.contentSize != 0)
+        prefs.frameInfo.contentSize = (U64)srcSize;   /* auto-correct content size if selected (!=0) */
+
+    if (prefs.compressionLevel < (int)minHClevel)
+    {
+        cctxI.lz4CtxPtr = &lz4ctx;
+        cctxI.lz4CtxLevel = 1;
+    }
+
+    prefs.frameInfo.blockSizeID = LZ4F_optimalBSID(prefs.frameInfo.blockSizeID, srcSize);
+    prefs.autoFlush = 1;
+    if (srcSize <= LZ4F_getBlockSize(prefs.frameInfo.blockSizeID))
+        prefs.frameInfo.blockMode = LZ4F_blockIndependent;   /* no need for linked blocks */
+
+    options.stableSrc = 1;
+
+    if (dstMaxSize < LZ4F_compressFrameBound(srcSize, &prefs))
+        return (size_t)-LZ4F_ERROR_dstMaxSize_tooSmall;
+
+    errorCode = LZ4F_compressBegin(&cctxI, dstBuffer, dstMaxSize, &prefs);  /* write header */
+    if (LZ4F_isError(errorCode)) return errorCode;
+    dstPtr += errorCode;   /* header size */
+
+    errorCode = LZ4F_compressUpdate(&cctxI, dstPtr, dstEnd-dstPtr, srcBuffer, srcSize, &options);
+    if (LZ4F_isError(errorCode)) return errorCode;
+    dstPtr += errorCode;
+
+    errorCode = LZ4F_compressEnd(&cctxI, dstPtr, dstEnd-dstPtr, &options);   /* flush last block, and generate suffix */
+    if (LZ4F_isError(errorCode)) return errorCode;
+    dstPtr += errorCode;
+
+    if (prefs.compressionLevel >= (int)minHClevel)   /* no allocation necessary with lz4 fast */
+        FREEMEM(cctxI.lz4CtxPtr);
+
+    return (dstPtr - dstStart);
+}
+
+
+/***********************************
+*  Advanced compression functions
+***********************************/
+
+/* LZ4F_createCompressionContext() :
+* The first thing to do is to create a compressionContext object, which will be used in all compression operations.
+* This is achieved using LZ4F_createCompressionContext(), which takes as argument a version and an LZ4F_preferences_t structure.
+* The version provided MUST be LZ4F_VERSION. It is intended to track potential version differences between different binaries.
+* The function will provide a pointer to an allocated LZ4F_compressionContext_t object.
+* If the result LZ4F_errorCode_t is not OK_NoError, there was an error during context creation.
+* Object can release its memory using LZ4F_freeCompressionContext();
+*/
+LZ4F_errorCode_t LZ4F_createCompressionContext(LZ4F_compressionContext_t* LZ4F_compressionContextPtr, unsigned version)
+{
+    LZ4F_cctx_t* cctxPtr;
+
+    cctxPtr = (LZ4F_cctx_t*)ALLOCATOR(sizeof(LZ4F_cctx_t));
+    if (cctxPtr==NULL) return (LZ4F_errorCode_t)(-LZ4F_ERROR_allocation_failed);
+
+    cctxPtr->version = version;
+    cctxPtr->cStage = 0;   /* Next stage : write header */
+
+    *LZ4F_compressionContextPtr = (LZ4F_compressionContext_t)cctxPtr;
+
+    return LZ4F_OK_NoError;
+}
+
+
+LZ4F_errorCode_t LZ4F_freeCompressionContext(LZ4F_compressionContext_t LZ4F_compressionContext)
+{
+    LZ4F_cctx_t* cctxPtr = (LZ4F_cctx_t*)LZ4F_compressionContext;
+
+    if (cctxPtr != NULL)   /* null pointers can be safely provided to this function, like free() */
+    {
+       FREEMEM(cctxPtr->lz4CtxPtr);
+       FREEMEM(cctxPtr->tmpBuff);
+       FREEMEM(LZ4F_compressionContext);
+    }
+
+    return LZ4F_OK_NoError;
+}
+
+
+/* LZ4F_compressBegin() :
+* will write the frame header into dstBuffer.
+* dstBuffer must be large enough to accommodate a header (dstMaxSize). Maximum header size is LZ4F_MAXHEADERFRAME_SIZE bytes.
+* The result of the function is the number of bytes written into dstBuffer for the header
+* or an error code (can be tested using LZ4F_isError())
+*/
+size_t LZ4F_compressBegin(LZ4F_compressionContext_t compressionContext, void* dstBuffer, size_t dstMaxSize, const LZ4F_preferences_t* preferencesPtr)
+{
+    LZ4F_preferences_t prefNull;
+    LZ4F_cctx_t* cctxPtr = (LZ4F_cctx_t*)compressionContext;
+    BYTE* const dstStart = (BYTE*)dstBuffer;
+    BYTE* dstPtr = dstStart;
+    BYTE* headerStart;
+    size_t requiredBuffSize;
+
+    if (dstMaxSize < maxFHSize) return (size_t)-LZ4F_ERROR_dstMaxSize_tooSmall;
+    if (cctxPtr->cStage != 0) return (size_t)-LZ4F_ERROR_GENERIC;
+    memset(&prefNull, 0, sizeof(prefNull));
+    if (preferencesPtr == NULL) preferencesPtr = &prefNull;
+    cctxPtr->prefs = *preferencesPtr;
+
+    /* ctx Management */
+    {
+        U32 tableID = (cctxPtr->prefs.compressionLevel < minHClevel) ? 1 : 2;  /* 0:nothing ; 1:LZ4 table ; 2:HC tables */
+        if (cctxPtr->lz4CtxLevel < tableID)
+        {
+            FREEMEM(cctxPtr->lz4CtxPtr);
+            if (cctxPtr->prefs.compressionLevel < minHClevel)
+                cctxPtr->lz4CtxPtr = (void*)LZ4_createStream();
+            else
+                cctxPtr->lz4CtxPtr = (void*)LZ4_createStreamHC();
+            cctxPtr->lz4CtxLevel = tableID;
+        }
+    }
+
+    /* Buffer Management */
+    if (cctxPtr->prefs.frameInfo.blockSizeID == 0) cctxPtr->prefs.frameInfo.blockSizeID = LZ4F_BLOCKSIZEID_DEFAULT;
+    cctxPtr->maxBlockSize = LZ4F_getBlockSize(cctxPtr->prefs.frameInfo.blockSizeID);
+
+    requiredBuffSize = cctxPtr->maxBlockSize + ((cctxPtr->prefs.frameInfo.blockMode == LZ4F_blockLinked) * 128 KB);
+    if (preferencesPtr->autoFlush)
+        requiredBuffSize = (cctxPtr->prefs.frameInfo.blockMode == LZ4F_blockLinked) * 64 KB;   /* just needs dict */
+
+    if (cctxPtr->maxBufferSize < requiredBuffSize)
+    {
+        cctxPtr->maxBufferSize = requiredBuffSize;
+        FREEMEM(cctxPtr->tmpBuff);
+        cctxPtr->tmpBuff = (BYTE*)ALLOCATOR(requiredBuffSize);
+        if (cctxPtr->tmpBuff == NULL) return (size_t)-LZ4F_ERROR_allocation_failed;
+    }
+    cctxPtr->tmpIn = cctxPtr->tmpBuff;
+    cctxPtr->tmpInSize = 0;
+    XXH32_reset(&(cctxPtr->xxh), 0);
+    if (cctxPtr->prefs.compressionLevel < minHClevel)
+        LZ4_resetStream((LZ4_stream_t*)(cctxPtr->lz4CtxPtr));
+    else
+        LZ4_resetStreamHC((LZ4_streamHC_t*)(cctxPtr->lz4CtxPtr), cctxPtr->prefs.compressionLevel);
+
+    /* Magic Number */
+    LZ4F_writeLE32(dstPtr, LZ4F_MAGICNUMBER);
+    dstPtr += 4;
+    headerStart = dstPtr;
+
+    /* FLG Byte */
+    *dstPtr++ = (BYTE)(((1 & _2BITS) << 6)    /* Version('01') */
+        + ((cctxPtr->prefs.frameInfo.blockMode & _1BIT ) << 5)    /* Block mode */
+        + ((cctxPtr->prefs.frameInfo.contentChecksumFlag & _1BIT ) << 2)   /* Frame checksum */
+        + ((cctxPtr->prefs.frameInfo.contentSize > 0) << 3));   /* Frame content size */
+    /* BD Byte */
+    *dstPtr++ = (BYTE)((cctxPtr->prefs.frameInfo.blockSizeID & _3BITS) << 4);
+    /* Optional Frame content size field */
+    if (cctxPtr->prefs.frameInfo.contentSize)
+    {
+        LZ4F_writeLE64(dstPtr, cctxPtr->prefs.frameInfo.contentSize);
+        dstPtr += 8;
+        cctxPtr->totalInSize = 0;
+    }
+    /* CRC Byte */
+    *dstPtr = LZ4F_headerChecksum(headerStart, dstPtr - headerStart);
+    dstPtr++;
+
+    cctxPtr->cStage = 1;   /* header written, now request input data block */
+
+    return (dstPtr - dstStart);
+}
+
+
+/* LZ4F_compressBound() : gives the size of Dst buffer given a srcSize to handle worst case situations.
+*                        The LZ4F_frameInfo_t structure is optional :
+*                        you can provide NULL as argument, preferences will then be set to cover worst case situations.
+* */
+size_t LZ4F_compressBound(size_t srcSize, const LZ4F_preferences_t* preferencesPtr)
+{
+    LZ4F_preferences_t prefsNull;
+    memset(&prefsNull, 0, sizeof(prefsNull));
+    prefsNull.frameInfo.contentChecksumFlag = LZ4F_contentChecksumEnabled;   /* worst case */
+    {
+        const LZ4F_preferences_t* prefsPtr = (preferencesPtr==NULL) ? &prefsNull : preferencesPtr;
+        LZ4F_blockSizeID_t bid = prefsPtr->frameInfo.blockSizeID;
+        size_t blockSize = LZ4F_getBlockSize(bid);
+        unsigned nbBlocks = (unsigned)(srcSize / blockSize) + 1;
+        size_t lastBlockSize = prefsPtr->autoFlush ? srcSize % blockSize : blockSize;
+        size_t blockInfo = 4;   /* default, without block CRC option */
+        size_t frameEnd = 4 + (prefsPtr->frameInfo.contentChecksumFlag*4);
+
+        return (blockInfo * nbBlocks) + (blockSize * (nbBlocks-1)) + lastBlockSize + frameEnd;;
+    }
+}
+
+
+typedef int (*compressFunc_t)(void* ctx, const char* src, char* dst, int srcSize, int dstSize, int level);
+
+static size_t LZ4F_compressBlock(void* dst, const void* src, size_t srcSize, compressFunc_t compress, void* lz4ctx, int level)
+{
+    /* compress one block */
+    BYTE* cSizePtr = (BYTE*)dst;
+    U32 cSize;
+    cSize = (U32)compress(lz4ctx, (const char*)src, (char*)(cSizePtr+4), (int)(srcSize), (int)(srcSize-1), level);
+    LZ4F_writeLE32(cSizePtr, cSize);
+    if (cSize == 0)   /* compression failed */
+    {
+        cSize = (U32)srcSize;
+        LZ4F_writeLE32(cSizePtr, cSize + LZ4F_BLOCKUNCOMPRESSED_FLAG);
+        memcpy(cSizePtr+4, src, srcSize);
+    }
+    return cSize + 4;
+}
+
+
+static int LZ4F_localLZ4_compress_limitedOutput_withState(void* ctx, const char* src, char* dst, int srcSize, int dstSize, int level)
+{
+    (void) level;
+    return LZ4_compress_limitedOutput_withState(ctx, src, dst, srcSize, dstSize);
+}
+
+static int LZ4F_localLZ4_compress_limitedOutput_continue(void* ctx, const char* src, char* dst, int srcSize, int dstSize, int level)
+{
+    (void) level;
+    return LZ4_compress_limitedOutput_continue((LZ4_stream_t*)ctx, src, dst, srcSize, dstSize);
+}
+
+static int LZ4F_localLZ4_compressHC_limitedOutput_continue(void* ctx, const char* src, char* dst, int srcSize, int dstSize, int level)
+{
+    (void) level;
+    return LZ4_compress_HC_continue((LZ4_streamHC_t*)ctx, src, dst, srcSize, dstSize);
+}
+
+static compressFunc_t LZ4F_selectCompression(LZ4F_blockMode_t blockMode, int level)
+{
+    if (level < minHClevel)
+    {
+        if (blockMode == LZ4F_blockIndependent) return LZ4F_localLZ4_compress_limitedOutput_withState;
+        return LZ4F_localLZ4_compress_limitedOutput_continue;
+    }
+    if (blockMode == LZ4F_blockIndependent) return LZ4_compress_HC_extStateHC;
+    return LZ4F_localLZ4_compressHC_limitedOutput_continue;
+}
+
+static int LZ4F_localSaveDict(LZ4F_cctx_t* cctxPtr)
+{
+    if (cctxPtr->prefs.compressionLevel < minHClevel)
+        return LZ4_saveDict ((LZ4_stream_t*)(cctxPtr->lz4CtxPtr), (char*)(cctxPtr->tmpBuff), 64 KB);
+    return LZ4_saveDictHC ((LZ4_streamHC_t*)(cctxPtr->lz4CtxPtr), (char*)(cctxPtr->tmpBuff), 64 KB);
+}
+
+typedef enum { notDone, fromTmpBuffer, fromSrcBuffer } LZ4F_lastBlockStatus;
+
+/* LZ4F_compressUpdate()
+* LZ4F_compressUpdate() can be called repetitively to compress as much data as necessary.
+* The most important rule is that dstBuffer MUST be large enough (dstMaxSize) to ensure compression completion even in worst case.
+* If this condition is not respected, LZ4F_compress() will fail (result is an errorCode)
+* You can get the minimum value of dstMaxSize by using LZ4F_compressBound()
+* The LZ4F_compressOptions_t structure is optional : you can provide NULL as argument.
+* The result of the function is the number of bytes written into dstBuffer : it can be zero, meaning input data was just buffered.
+* The function outputs an error code if it fails (can be tested using LZ4F_isError())
+*/
+size_t LZ4F_compressUpdate(LZ4F_compressionContext_t compressionContext, void* dstBuffer, size_t dstMaxSize, const void* srcBuffer, size_t srcSize, const LZ4F_compressOptions_t* compressOptionsPtr)
+{
+    LZ4F_compressOptions_t cOptionsNull;
+    LZ4F_cctx_t* cctxPtr = (LZ4F_cctx_t*)compressionContext;
+    size_t blockSize = cctxPtr->maxBlockSize;
+    const BYTE* srcPtr = (const BYTE*)srcBuffer;
+    const BYTE* const srcEnd = srcPtr + srcSize;
+    BYTE* const dstStart = (BYTE*)dstBuffer;
+    BYTE* dstPtr = dstStart;
+    LZ4F_lastBlockStatus lastBlockCompressed = notDone;
+    compressFunc_t compress;
+
+
+    if (cctxPtr->cStage != 1) return (size_t)-LZ4F_ERROR_GENERIC;
+    if (dstMaxSize < LZ4F_compressBound(srcSize, &(cctxPtr->prefs))) return (size_t)-LZ4F_ERROR_dstMaxSize_tooSmall;
+    memset(&cOptionsNull, 0, sizeof(cOptionsNull));
+    if (compressOptionsPtr == NULL) compressOptionsPtr = &cOptionsNull;
+
+    /* select compression function */
+    compress = LZ4F_selectCompression(cctxPtr->prefs.frameInfo.blockMode, cctxPtr->prefs.compressionLevel);
+
+    /* complete tmp buffer */
+    if (cctxPtr->tmpInSize > 0)   /* some data already within tmp buffer */
+    {
+        size_t sizeToCopy = blockSize - cctxPtr->tmpInSize;
+        if (sizeToCopy > srcSize)
+        {
+            /* add src to tmpIn buffer */
+            memcpy(cctxPtr->tmpIn + cctxPtr->tmpInSize, srcBuffer, srcSize);
+            srcPtr = srcEnd;
+            cctxPtr->tmpInSize += srcSize;
+            /* still needs some CRC */
+        }
+        else
+        {
+            /* complete tmpIn block and then compress it */
+            lastBlockCompressed = fromTmpBuffer;
+            memcpy(cctxPtr->tmpIn + cctxPtr->tmpInSize, srcBuffer, sizeToCopy);
+            srcPtr += sizeToCopy;
+
+            dstPtr += LZ4F_compressBlock(dstPtr, cctxPtr->tmpIn, blockSize, compress, cctxPtr->lz4CtxPtr, cctxPtr->prefs.compressionLevel);
+
+            if (cctxPtr->prefs.frameInfo.blockMode==LZ4F_blockLinked) cctxPtr->tmpIn += blockSize;
+            cctxPtr->tmpInSize = 0;
+        }
+    }
+
+    while ((size_t)(srcEnd - srcPtr) >= blockSize)
+    {
+        /* compress full block */
+        lastBlockCompressed = fromSrcBuffer;
+        dstPtr += LZ4F_compressBlock(dstPtr, srcPtr, blockSize, compress, cctxPtr->lz4CtxPtr, cctxPtr->prefs.compressionLevel);
+        srcPtr += blockSize;
+    }
+
+    if ((cctxPtr->prefs.autoFlush) && (srcPtr < srcEnd))
+    {
+        /* compress remaining input < blockSize */
+        lastBlockCompressed = fromSrcBuffer;
+        dstPtr += LZ4F_compressBlock(dstPtr, srcPtr, srcEnd - srcPtr, compress, cctxPtr->lz4CtxPtr, cctxPtr->prefs.compressionLevel);
+        srcPtr  = srcEnd;
+    }
+
+    /* preserve dictionary if necessary */
+    if ((cctxPtr->prefs.frameInfo.blockMode==LZ4F_blockLinked) && (lastBlockCompressed==fromSrcBuffer))
+    {
+        if (compressOptionsPtr->stableSrc)
+        {
+            cctxPtr->tmpIn = cctxPtr->tmpBuff;
+        }
+        else
+        {
+            int realDictSize = LZ4F_localSaveDict(cctxPtr);
+            if (realDictSize==0) return (size_t)-LZ4F_ERROR_GENERIC;
+            cctxPtr->tmpIn = cctxPtr->tmpBuff + realDictSize;
+        }
+    }
+
+    /* keep tmpIn within limits */
+    if ((cctxPtr->tmpIn + blockSize) > (cctxPtr->tmpBuff + cctxPtr->maxBufferSize)   /* necessarily LZ4F_blockLinked && lastBlockCompressed==fromTmpBuffer */
+        && !(cctxPtr->prefs.autoFlush))
+    {
+        int realDictSize = LZ4F_localSaveDict(cctxPtr);
+        cctxPtr->tmpIn = cctxPtr->tmpBuff + realDictSize;
+    }
+
+    /* some input data left, necessarily < blockSize */
+    if (srcPtr < srcEnd)
+    {
+        /* fill tmp buffer */
+        size_t sizeToCopy = srcEnd - srcPtr;
+        memcpy(cctxPtr->tmpIn, srcPtr, sizeToCopy);
+        cctxPtr->tmpInSize = sizeToCopy;
+    }
+
+    if (cctxPtr->prefs.frameInfo.contentChecksumFlag == LZ4F_contentChecksumEnabled)
+        XXH32_update(&(cctxPtr->xxh), srcBuffer, srcSize);
+
+    cctxPtr->totalInSize += srcSize;
+    return dstPtr - dstStart;
+}
+
+
+/* LZ4F_flush()
+* Should you need to create compressed data immediately, without waiting for a block to be filled,
+* you can call LZ4_flush(), which will immediately compress any remaining data stored within compressionContext.
+* The result of the function is the number of bytes written into dstBuffer
+* (it can be zero, this means there was no data left within compressionContext)
+* The function outputs an error code if it fails (can be tested using LZ4F_isError())
+* The LZ4F_compressOptions_t structure is optional : you can provide NULL as argument.
+*/
+size_t LZ4F_flush(LZ4F_compressionContext_t compressionContext, void* dstBuffer, size_t dstMaxSize, const LZ4F_compressOptions_t* compressOptionsPtr)
+{
+    LZ4F_cctx_t* cctxPtr = (LZ4F_cctx_t*)compressionContext;
+    BYTE* const dstStart = (BYTE*)dstBuffer;
+    BYTE* dstPtr = dstStart;
+    compressFunc_t compress;
+
+
+    if (cctxPtr->tmpInSize == 0) return 0;   /* nothing to flush */
+    if (cctxPtr->cStage != 1) return (size_t)-LZ4F_ERROR_GENERIC;
+    if (dstMaxSize < (cctxPtr->tmpInSize + 8)) return (size_t)-LZ4F_ERROR_dstMaxSize_tooSmall;   /* +8 : block header(4) + block checksum(4) */
+    (void)compressOptionsPtr;   /* not yet useful */
+
+    /* select compression function */
+    compress = LZ4F_selectCompression(cctxPtr->prefs.frameInfo.blockMode, cctxPtr->prefs.compressionLevel);
+
+    /* compress tmp buffer */
+    dstPtr += LZ4F_compressBlock(dstPtr, cctxPtr->tmpIn, cctxPtr->tmpInSize, compress, cctxPtr->lz4CtxPtr, cctxPtr->prefs.compressionLevel);
+    if (cctxPtr->prefs.frameInfo.blockMode==LZ4F_blockLinked) cctxPtr->tmpIn += cctxPtr->tmpInSize;
+    cctxPtr->tmpInSize = 0;
+
+    /* keep tmpIn within limits */
+    if ((cctxPtr->tmpIn + cctxPtr->maxBlockSize) > (cctxPtr->tmpBuff + cctxPtr->maxBufferSize))   /* necessarily LZ4F_blockLinked */
+    {
+        int realDictSize = LZ4F_localSaveDict(cctxPtr);
+        cctxPtr->tmpIn = cctxPtr->tmpBuff + realDictSize;
+    }
+
+    return dstPtr - dstStart;
+}
+
+
+/* LZ4F_compressEnd()
+* When you want to properly finish the compressed frame, just call LZ4F_compressEnd().
+* It will flush whatever data remained within compressionContext (like LZ4_flush())
+* but also properly finalize the frame, with an endMark and a checksum.
+* The result of the function is the number of bytes written into dstBuffer (necessarily >= 4 (endMark size))
+* The function outputs an error code if it fails (can be tested using LZ4F_isError())
+* The LZ4F_compressOptions_t structure is optional : you can provide NULL as argument.
+* compressionContext can then be used again, starting with LZ4F_compressBegin(). The preferences will remain the same.
+*/
+size_t LZ4F_compressEnd(LZ4F_compressionContext_t compressionContext, void* dstBuffer, size_t dstMaxSize, const LZ4F_compressOptions_t* compressOptionsPtr)
+{
+    LZ4F_cctx_t* cctxPtr = (LZ4F_cctx_t*)compressionContext;
+    BYTE* const dstStart = (BYTE*)dstBuffer;
+    BYTE* dstPtr = dstStart;
+    size_t errorCode;
+
+    errorCode = LZ4F_flush(compressionContext, dstBuffer, dstMaxSize, compressOptionsPtr);
+    if (LZ4F_isError(errorCode)) return errorCode;
+    dstPtr += errorCode;
+
+    LZ4F_writeLE32(dstPtr, 0);
+    dstPtr+=4;   /* endMark */
+
+    if (cctxPtr->prefs.frameInfo.contentChecksumFlag == LZ4F_contentChecksumEnabled)
+    {
+        U32 xxh = XXH32_digest(&(cctxPtr->xxh));
+        LZ4F_writeLE32(dstPtr, xxh);
+        dstPtr+=4;   /* content Checksum */
+    }
+
+    cctxPtr->cStage = 0;   /* state is now re-usable (with identical preferences) */
+
+    if (cctxPtr->prefs.frameInfo.contentSize)
+    {
+        if (cctxPtr->prefs.frameInfo.contentSize != cctxPtr->totalInSize)
+            return (size_t)-LZ4F_ERROR_frameSize_wrong;
+    }
+
+    return dstPtr - dstStart;
+}
+
+
+/**********************************
+*  Decompression functions
+**********************************/
+
+/* Resource management */
+
+/* LZ4F_createDecompressionContext() :
+* The first thing to do is to create a decompressionContext object, which will be used in all decompression operations.
+* This is achieved using LZ4F_createDecompressionContext().
+* The function will provide a pointer to a fully allocated and initialized LZ4F_decompressionContext object.
+* If the result LZ4F_errorCode_t is not zero, there was an error during context creation.
+* Object can release its memory using LZ4F_freeDecompressionContext();
+*/
+LZ4F_errorCode_t LZ4F_createDecompressionContext(LZ4F_decompressionContext_t* LZ4F_decompressionContextPtr, unsigned versionNumber)
+{
+    LZ4F_dctx_t* dctxPtr;
+
+    dctxPtr = (LZ4F_dctx_t*)ALLOCATOR(sizeof(LZ4F_dctx_t));
+    if (dctxPtr==NULL) return (LZ4F_errorCode_t)-LZ4F_ERROR_GENERIC;
+
+    dctxPtr->version = versionNumber;
+    *LZ4F_decompressionContextPtr = (LZ4F_decompressionContext_t)dctxPtr;
+    return LZ4F_OK_NoError;
+}
+
+LZ4F_errorCode_t LZ4F_freeDecompressionContext(LZ4F_decompressionContext_t LZ4F_decompressionContext)
+{
+    LZ4F_errorCode_t result = LZ4F_OK_NoError;
+    LZ4F_dctx_t* dctxPtr = (LZ4F_dctx_t*)LZ4F_decompressionContext;
+    if (dctxPtr != NULL)   /* can accept NULL input, like free() */
+    {
+      result = (LZ4F_errorCode_t)dctxPtr->dStage;
+      FREEMEM(dctxPtr->tmpIn);
+      FREEMEM(dctxPtr->tmpOutBuffer);
+      FREEMEM(dctxPtr);
+    }
+    return result;
+}
+
+
+/* ******************************************************************** */
+/* ********************* Decompression ******************************** */
+/* ******************************************************************** */
+
+typedef enum { dstage_getHeader=0, dstage_storeHeader,
+    dstage_getCBlockSize, dstage_storeCBlockSize,
+    dstage_copyDirect,
+    dstage_getCBlock, dstage_storeCBlock,
+    dstage_decodeCBlock, dstage_decodeCBlock_intoDst,
+    dstage_decodeCBlock_intoTmp, dstage_flushOut,
+    dstage_getSuffix, dstage_storeSuffix,
+    dstage_getSFrameSize, dstage_storeSFrameSize,
+    dstage_skipSkippable
+} dStage_t;
+
+
+/* LZ4F_decodeHeader
+   return : nb Bytes read from srcVoidPtr (necessarily <= srcSize)
+            or an error code (testable with LZ4F_isError())
+   output : set internal values of dctx, such as
+            dctxPtr->frameInfo and dctxPtr->dStage.
+   input  : srcVoidPtr points at the **beginning of the frame**
+*/
+static size_t LZ4F_decodeHeader(LZ4F_dctx_t* dctxPtr, const void* srcVoidPtr, size_t srcSize)
+{
+    BYTE FLG, BD, HC;
+    unsigned version, blockMode, blockChecksumFlag, contentSizeFlag, contentChecksumFlag, blockSizeID;
+    size_t bufferNeeded;
+    size_t frameHeaderSize;
+    const BYTE* srcPtr = (const BYTE*)srcVoidPtr;
+
+    /* need to decode header to get frameInfo */
+    if (srcSize < minFHSize) return (size_t)-LZ4F_ERROR_frameHeader_incomplete;   /* minimal frame header size */
+    memset(&(dctxPtr->frameInfo), 0, sizeof(dctxPtr->frameInfo));
+
+    /* special case : skippable frames */
+    if ((LZ4F_readLE32(srcPtr) & 0xFFFFFFF0U) == LZ4F_MAGIC_SKIPPABLE_START)
+    {
+        dctxPtr->frameInfo.frameType = LZ4F_skippableFrame;
+        if (srcVoidPtr == (void*)(dctxPtr->header))
+        {
+            dctxPtr->tmpInSize = srcSize;
+            dctxPtr->tmpInTarget = 8;
+            dctxPtr->dStage = dstage_storeSFrameSize;
+            return srcSize;
+        }
+        else
+        {
+            dctxPtr->dStage = dstage_getSFrameSize;
+            return 4;
+        }
+    }
+
+    /* control magic number */
+    if (LZ4F_readLE32(srcPtr) != LZ4F_MAGICNUMBER) return (size_t)-LZ4F_ERROR_frameType_unknown;
+    dctxPtr->frameInfo.frameType = LZ4F_frame;
+
+    /* Flags */
+    FLG = srcPtr[4];
+    version = (FLG>>6) & _2BITS;
+    blockMode = (FLG>>5) & _1BIT;
+    blockChecksumFlag = (FLG>>4) & _1BIT;
+    contentSizeFlag = (FLG>>3) & _1BIT;
+    contentChecksumFlag = (FLG>>2) & _1BIT;
+
+    /* Frame Header Size */
+    frameHeaderSize = contentSizeFlag ? maxFHSize : minFHSize;
+
+    if (srcSize < frameHeaderSize)
+    {
+        /* not enough input to fully decode frame header */
+        if (srcPtr != dctxPtr->header)
+            memcpy(dctxPtr->header, srcPtr, srcSize);
+        dctxPtr->tmpInSize = srcSize;
+        dctxPtr->tmpInTarget = frameHeaderSize;
+        dctxPtr->dStage = dstage_storeHeader;
+        return srcSize;
+    }
+
+    BD = srcPtr[5];
+    blockSizeID = (BD>>4) & _3BITS;
+
+    /* validate */
+    if (version != 1) return (size_t)-LZ4F_ERROR_headerVersion_wrong;        /* Version Number, only supported value */
+    if (blockChecksumFlag != 0) return (size_t)-LZ4F_ERROR_blockChecksum_unsupported; /* Not supported for the time being */
+    if (((FLG>>0)&_2BITS) != 0) return (size_t)-LZ4F_ERROR_reservedFlag_set; /* Reserved bits */
+    if (((BD>>7)&_1BIT) != 0) return (size_t)-LZ4F_ERROR_reservedFlag_set;   /* Reserved bit */
+    if (blockSizeID < 4) return (size_t)-LZ4F_ERROR_maxBlockSize_invalid;    /* 4-7 only supported values for the time being */
+    if (((BD>>0)&_4BITS) != 0) return (size_t)-LZ4F_ERROR_reservedFlag_set;  /* Reserved bits */
+
+    /* check */
+    HC = LZ4F_headerChecksum(srcPtr+4, frameHeaderSize-5);
+    if (HC != srcPtr[frameHeaderSize-1]) return (size_t)-LZ4F_ERROR_headerChecksum_invalid;   /* Bad header checksum error */
+
+    /* save */
+    dctxPtr->frameInfo.blockMode = (LZ4F_blockMode_t)blockMode;
+    dctxPtr->frameInfo.contentChecksumFlag = (LZ4F_contentChecksum_t)contentChecksumFlag;
+    dctxPtr->frameInfo.blockSizeID = (LZ4F_blockSizeID_t)blockSizeID;
+    dctxPtr->maxBlockSize = LZ4F_getBlockSize(blockSizeID);
+    if (contentSizeFlag)
+        dctxPtr->frameRemainingSize = dctxPtr->frameInfo.contentSize = LZ4F_readLE64(srcPtr+6);
+
+    /* init */
+    if (contentChecksumFlag) XXH32_reset(&(dctxPtr->xxh), 0);
+
+    /* alloc */
+    bufferNeeded = dctxPtr->maxBlockSize + ((dctxPtr->frameInfo.blockMode==LZ4F_blockLinked) * 128 KB);
+    if (bufferNeeded > dctxPtr->maxBufferSize)   /* tmp buffers too small */
+    {
+        FREEMEM(dctxPtr->tmpIn);
+        FREEMEM(dctxPtr->tmpOutBuffer);
+        dctxPtr->maxBufferSize = bufferNeeded;
+        dctxPtr->tmpIn = (BYTE*)ALLOCATOR(dctxPtr->maxBlockSize);
+        if (dctxPtr->tmpIn == NULL) return (size_t)-LZ4F_ERROR_GENERIC;
+        dctxPtr->tmpOutBuffer= (BYTE*)ALLOCATOR(dctxPtr->maxBufferSize);
+        if (dctxPtr->tmpOutBuffer== NULL) return (size_t)-LZ4F_ERROR_GENERIC;
+    }
+    dctxPtr->tmpInSize = 0;
+    dctxPtr->tmpInTarget = 0;
+    dctxPtr->dict = dctxPtr->tmpOutBuffer;
+    dctxPtr->dictSize = 0;
+    dctxPtr->tmpOut = dctxPtr->tmpOutBuffer;
+    dctxPtr->tmpOutStart = 0;
+    dctxPtr->tmpOutSize = 0;
+
+    dctxPtr->dStage = dstage_getCBlockSize;
+
+    return frameHeaderSize;
+}
+
+
+/* LZ4F_getFrameInfo()
+* This function decodes frame header information, such as blockSize.
+* It is optional : you could start by calling directly LZ4F_decompress() instead.
+* The objective is to extract header information without starting decompression, typically for allocation purposes.
+* LZ4F_getFrameInfo() can also be used *after* starting decompression, on a valid LZ4F_decompressionContext_t.
+* The number of bytes read from srcBuffer will be provided within *srcSizePtr (necessarily <= original value).
+* You are expected to resume decompression from where it stopped (srcBuffer + *srcSizePtr)
+* The function result is an hint of the better srcSize to use for next call to LZ4F_decompress,
+* or an error code which can be tested using LZ4F_isError().
+*/
+LZ4F_errorCode_t LZ4F_getFrameInfo(LZ4F_decompressionContext_t dCtx, LZ4F_frameInfo_t* frameInfoPtr,
+                                   const void* srcBuffer, size_t* srcSizePtr)
+{
+    LZ4F_dctx_t* dctxPtr = (LZ4F_dctx_t*)dCtx;
+
+    if (dctxPtr->dStage > dstage_storeHeader)   /* note : requires dstage_* header related to be at beginning of enum */
+    {
+        size_t o=0, i=0;
+        /* frameInfo already decoded */
+        *srcSizePtr = 0;
+        *frameInfoPtr = dctxPtr->frameInfo;
+        return LZ4F_decompress(dCtx, NULL, &o, NULL, &i, NULL);
+    }
+    else
+    {
+        size_t o=0;
+        size_t nextSrcSize = LZ4F_decompress(dCtx, NULL, &o, srcBuffer, srcSizePtr, NULL);
+        if (dctxPtr->dStage <= dstage_storeHeader)   /* note : requires dstage_* header related to be at beginning of enum */
+            return (size_t)-LZ4F_ERROR_frameHeader_incomplete;
+        *frameInfoPtr = dctxPtr->frameInfo;
+        return nextSrcSize;
+    }
+}
+
+
+/* trivial redirector, for common prototype */
+static int LZ4F_decompress_safe (const char* source, char* dest, int compressedSize, int maxDecompressedSize, const char* dictStart, int dictSize)
+{
+    (void)dictStart; (void)dictSize;
+    return LZ4_decompress_safe (source, dest, compressedSize, maxDecompressedSize);
+}
+
+
+static void LZ4F_updateDict(LZ4F_dctx_t* dctxPtr, const BYTE* dstPtr, size_t dstSize, const BYTE* dstPtr0, unsigned withinTmp)
+{
+    if (dctxPtr->dictSize==0)
+        dctxPtr->dict = (const BYTE*)dstPtr;   /* priority to dictionary continuity */
+
+    if (dctxPtr->dict + dctxPtr->dictSize == dstPtr)   /* dictionary continuity */
+    {
+        dctxPtr->dictSize += dstSize;
+        return;
+    }
+
+    if (dstPtr - dstPtr0 + dstSize >= 64 KB)   /* dstBuffer large enough to become dictionary */
+    {
+        dctxPtr->dict = (const BYTE*)dstPtr0;
+        dctxPtr->dictSize = dstPtr - dstPtr0 + dstSize;
+        return;
+    }
+
+    if ((withinTmp) && (dctxPtr->dict == dctxPtr->tmpOutBuffer))
+    {
+        /* assumption : dctxPtr->dict + dctxPtr->dictSize == dctxPtr->tmpOut + dctxPtr->tmpOutStart */
+        dctxPtr->dictSize += dstSize;
+        return;
+    }
+
+    if (withinTmp) /* copy relevant dict portion in front of tmpOut within tmpOutBuffer */
+    {
+        size_t preserveSize = dctxPtr->tmpOut - dctxPtr->tmpOutBuffer;
+        size_t copySize = 64 KB - dctxPtr->tmpOutSize;
+        const BYTE* oldDictEnd = dctxPtr->dict + dctxPtr->dictSize - dctxPtr->tmpOutStart;
+        if (dctxPtr->tmpOutSize > 64 KB) copySize = 0;
+        if (copySize > preserveSize) copySize = preserveSize;
+
+        memcpy(dctxPtr->tmpOutBuffer + preserveSize - copySize, oldDictEnd - copySize, copySize);
+
+        dctxPtr->dict = dctxPtr->tmpOutBuffer;
+        dctxPtr->dictSize = preserveSize + dctxPtr->tmpOutStart + dstSize;
+        return;
+    }
+
+    if (dctxPtr->dict == dctxPtr->tmpOutBuffer)     /* copy dst into tmp to complete dict */
+    {
+        if (dctxPtr->dictSize + dstSize > dctxPtr->maxBufferSize)   /* tmp buffer not large enough */
+        {
+            size_t preserveSize = 64 KB - dstSize;   /* note : dstSize < 64 KB */
+            memcpy(dctxPtr->tmpOutBuffer, dctxPtr->dict + dctxPtr->dictSize - preserveSize, preserveSize);
+            dctxPtr->dictSize = preserveSize;
+        }
+        memcpy(dctxPtr->tmpOutBuffer + dctxPtr->dictSize, dstPtr, dstSize);
+        dctxPtr->dictSize += dstSize;
+        return;
+    }
+
+    /* join dict & dest into tmp */
+    {
+        size_t preserveSize = 64 KB - dstSize;   /* note : dstSize < 64 KB */
+        if (preserveSize > dctxPtr->dictSize) preserveSize = dctxPtr->dictSize;
+        memcpy(dctxPtr->tmpOutBuffer, dctxPtr->dict + dctxPtr->dictSize - preserveSize, preserveSize);
+        memcpy(dctxPtr->tmpOutBuffer + preserveSize, dstPtr, dstSize);
+        dctxPtr->dict = dctxPtr->tmpOutBuffer;
+        dctxPtr->dictSize = preserveSize + dstSize;
+    }
+}
+
+
+
+/* LZ4F_decompress()
+* Call this function repetitively to regenerate data compressed within srcBuffer.
+* The function will attempt to decode *srcSizePtr from srcBuffer, into dstBuffer of maximum size *dstSizePtr.
+*
+* The number of bytes regenerated into dstBuffer will be provided within *dstSizePtr (necessarily <= original value).
+*
+* The number of bytes effectively read from srcBuffer will be provided within *srcSizePtr (necessarily <= original value).
+* If the number of bytes read is < number of bytes provided, then the decompression operation is not complete.
+* You will have to call it again, continuing from where it stopped.
+*
+* The function result is an hint of the better srcSize to use for next call to LZ4F_decompress.
+* Basically, it's the size of the current (or remaining) compressed block + header of next block.
+* Respecting the hint provides some boost to performance, since it allows less buffer shuffling.
+* Note that this is just a hint, you can always provide any srcSize you want.
+* When a frame is fully decoded, the function result will be 0.
+* If decompression failed, function result is an error code which can be tested using LZ4F_isError().
+*/
+size_t LZ4F_decompress(LZ4F_decompressionContext_t decompressionContext,
+                       void* dstBuffer, size_t* dstSizePtr,
+                       const void* srcBuffer, size_t* srcSizePtr,
+                       const LZ4F_decompressOptions_t* decompressOptionsPtr)
+{
+    LZ4F_dctx_t* dctxPtr = (LZ4F_dctx_t*)decompressionContext;
+    LZ4F_decompressOptions_t optionsNull;
+    const BYTE* const srcStart = (const BYTE*)srcBuffer;
+    const BYTE* const srcEnd = srcStart + *srcSizePtr;
+    const BYTE* srcPtr = srcStart;
+    BYTE* const dstStart = (BYTE*)dstBuffer;
+    BYTE* const dstEnd = dstStart + *dstSizePtr;
+    BYTE* dstPtr = dstStart;
+    const BYTE* selectedIn = NULL;
+    unsigned doAnotherStage = 1;
+    size_t nextSrcSizeHint = 1;
+
+
+    memset(&optionsNull, 0, sizeof(optionsNull));
+    if (decompressOptionsPtr==NULL) decompressOptionsPtr = &optionsNull;
+    *srcSizePtr = 0;
+    *dstSizePtr = 0;
+
+    /* expect to continue decoding src buffer where it left previously */
+    if (dctxPtr->srcExpect != NULL)
+    {
+        if (srcStart != dctxPtr->srcExpect) return (size_t)-LZ4F_ERROR_srcPtr_wrong;
+    }
+
+    /* programmed as a state machine */
+
+    while (doAnotherStage)
+    {
+
+        switch(dctxPtr->dStage)
+        {
+
+        case dstage_getHeader:
+            {
+                if ((size_t)(srcEnd-srcPtr) >= maxFHSize)   /* enough to decode - shortcut */
+                {
+                    LZ4F_errorCode_t errorCode = LZ4F_decodeHeader(dctxPtr, srcPtr, srcEnd-srcPtr);
+                    if (LZ4F_isError(errorCode)) return errorCode;
+                    srcPtr += errorCode;
+                    break;
+                }
+                dctxPtr->tmpInSize = 0;
+                dctxPtr->tmpInTarget = minFHSize;   /* minimum to attempt decode */
+                dctxPtr->dStage = dstage_storeHeader;
+            }
+	    /* Falls through. */
+        case dstage_storeHeader:
+            {
+                size_t sizeToCopy = dctxPtr->tmpInTarget - dctxPtr->tmpInSize;
+                if (sizeToCopy > (size_t)(srcEnd - srcPtr)) sizeToCopy =  srcEnd - srcPtr;
+                memcpy(dctxPtr->header + dctxPtr->tmpInSize, srcPtr, sizeToCopy);
+                dctxPtr->tmpInSize += sizeToCopy;
+                srcPtr += sizeToCopy;
+                if (dctxPtr->tmpInSize < dctxPtr->tmpInTarget)
+                {
+                    nextSrcSizeHint = (dctxPtr->tmpInTarget - dctxPtr->tmpInSize) + BHSize;   /* rest of header + nextBlockHeader */
+                    doAnotherStage = 0;   /* not enough src data, ask for some more */
+                    break;
+                }
+                {
+                    LZ4F_errorCode_t errorCode = LZ4F_decodeHeader(dctxPtr, dctxPtr->header, dctxPtr->tmpInTarget);
+                    if (LZ4F_isError(errorCode)) return errorCode;
+                }
+                break;
+            }
+
+        case dstage_getCBlockSize:
+            {
+                if ((size_t)(srcEnd - srcPtr) >= BHSize)
+                {
+                    selectedIn = srcPtr;
+                    srcPtr += BHSize;
+                }
+                else
+                {
+                /* not enough input to read cBlockSize field */
+                    dctxPtr->tmpInSize = 0;
+                    dctxPtr->dStage = dstage_storeCBlockSize;
+                }
+            }
+
+            if (dctxPtr->dStage == dstage_storeCBlockSize)
+        case dstage_storeCBlockSize:
+            {
+                size_t sizeToCopy = BHSize - dctxPtr->tmpInSize;
+                if (sizeToCopy > (size_t)(srcEnd - srcPtr)) sizeToCopy = srcEnd - srcPtr;
+                memcpy(dctxPtr->tmpIn + dctxPtr->tmpInSize, srcPtr, sizeToCopy);
+                srcPtr += sizeToCopy;
+                dctxPtr->tmpInSize += sizeToCopy;
+                if (dctxPtr->tmpInSize < BHSize) /* not enough input to get full cBlockSize; wait for more */
+                {
+                    nextSrcSizeHint = BHSize - dctxPtr->tmpInSize;
+                    doAnotherStage  = 0;
+                    break;
+                }
+                selectedIn = dctxPtr->tmpIn;
+            }
+
+        /* case dstage_decodeCBlockSize: */   /* no more direct access, to prevent scan-build warning */
+            {
+                size_t nextCBlockSize = LZ4F_readLE32(selectedIn) & 0x7FFFFFFFU;
+                if (nextCBlockSize==0)   /* frameEnd signal, no more CBlock */
+                {
+                    dctxPtr->dStage = dstage_getSuffix;
+                    break;
+                }
+                if (nextCBlockSize > dctxPtr->maxBlockSize) return (size_t)-LZ4F_ERROR_GENERIC;   /* invalid cBlockSize */
+                dctxPtr->tmpInTarget = nextCBlockSize;
+                if (LZ4F_readLE32(selectedIn) & LZ4F_BLOCKUNCOMPRESSED_FLAG)
+                {
+                    dctxPtr->dStage = dstage_copyDirect;
+                    break;
+                }
+                dctxPtr->dStage = dstage_getCBlock;
+                if (dstPtr==dstEnd)
+                {
+                    nextSrcSizeHint = nextCBlockSize + BHSize;
+                    doAnotherStage = 0;
+                }
+                break;
+            }
+
+        case dstage_copyDirect:   /* uncompressed block */
+            {
+                size_t sizeToCopy = dctxPtr->tmpInTarget;
+                if ((size_t)(srcEnd-srcPtr) < sizeToCopy) sizeToCopy = srcEnd - srcPtr;  /* not enough input to read full block */
+                if ((size_t)(dstEnd-dstPtr) < sizeToCopy) sizeToCopy = dstEnd - dstPtr;
+                memcpy(dstPtr, srcPtr, sizeToCopy);
+                if (dctxPtr->frameInfo.contentChecksumFlag) XXH32_update(&(dctxPtr->xxh), srcPtr, sizeToCopy);
+                if (dctxPtr->frameInfo.contentSize) dctxPtr->frameRemainingSize -= sizeToCopy;
+
+                /* dictionary management */
+                if (dctxPtr->frameInfo.blockMode==LZ4F_blockLinked)
+                    LZ4F_updateDict(dctxPtr, dstPtr, sizeToCopy, dstStart, 0);
+
+                srcPtr += sizeToCopy;
+                dstPtr += sizeToCopy;
+                if (sizeToCopy == dctxPtr->tmpInTarget)   /* all copied */
+                {
+                    dctxPtr->dStage = dstage_getCBlockSize;
+                    break;
+                }
+                dctxPtr->tmpInTarget -= sizeToCopy;   /* still need to copy more */
+                nextSrcSizeHint = dctxPtr->tmpInTarget + BHSize;
+                doAnotherStage = 0;
+                break;
+            }
+
+        case dstage_getCBlock:   /* entry from dstage_decodeCBlockSize */
+            {
+                if ((size_t)(srcEnd-srcPtr) < dctxPtr->tmpInTarget)
+                {
+                    dctxPtr->tmpInSize = 0;
+                    dctxPtr->dStage = dstage_storeCBlock;
+                    break;
+                }
+                selectedIn = srcPtr;
+                srcPtr += dctxPtr->tmpInTarget;
+                dctxPtr->dStage = dstage_decodeCBlock;
+                break;
+            }
+
+        case dstage_storeCBlock:
+            {
+                size_t sizeToCopy = dctxPtr->tmpInTarget - dctxPtr->tmpInSize;
+                if (sizeToCopy > (size_t)(srcEnd-srcPtr)) sizeToCopy = srcEnd-srcPtr;
+                memcpy(dctxPtr->tmpIn + dctxPtr->tmpInSize, srcPtr, sizeToCopy);
+                dctxPtr->tmpInSize += sizeToCopy;
+                srcPtr += sizeToCopy;
+                if (dctxPtr->tmpInSize < dctxPtr->tmpInTarget)  /* need more input */
+                {
+                    nextSrcSizeHint = (dctxPtr->tmpInTarget - dctxPtr->tmpInSize) + BHSize;
+                    doAnotherStage=0;
+                    break;
+                }
+                selectedIn = dctxPtr->tmpIn;
+                dctxPtr->dStage = dstage_decodeCBlock;
+                break;
+            }
+
+        case dstage_decodeCBlock:
+            {
+                if ((size_t)(dstEnd-dstPtr) < dctxPtr->maxBlockSize)   /* not enough place into dst : decode into tmpOut */
+                    dctxPtr->dStage = dstage_decodeCBlock_intoTmp;
+                else
+                    dctxPtr->dStage = dstage_decodeCBlock_intoDst;
+                break;
+            }
+
+        case dstage_decodeCBlock_intoDst:
+            {
+                int (*decoder)(const char*, char*, int, int, const char*, int);
+                int decodedSize;
+
+                if (dctxPtr->frameInfo.blockMode == LZ4F_blockLinked)
+                    decoder = LZ4_decompress_safe_usingDict;
+                else
+                    decoder = LZ4F_decompress_safe;
+
+                decodedSize = decoder((const char*)selectedIn, (char*)dstPtr, (int)dctxPtr->tmpInTarget, (int)dctxPtr->maxBlockSize, (const char*)dctxPtr->dict, (int)dctxPtr->dictSize);
+                if (decodedSize < 0) return (size_t)-LZ4F_ERROR_GENERIC;   /* decompression failed */
+                if (dctxPtr->frameInfo.contentChecksumFlag) XXH32_update(&(dctxPtr->xxh), dstPtr, decodedSize);
+                if (dctxPtr->frameInfo.contentSize) dctxPtr->frameRemainingSize -= decodedSize;
+
+                /* dictionary management */
+                if (dctxPtr->frameInfo.blockMode==LZ4F_blockLinked)
+                    LZ4F_updateDict(dctxPtr, dstPtr, decodedSize, dstStart, 0);
+
+                dstPtr += decodedSize;
+                dctxPtr->dStage = dstage_getCBlockSize;
+                break;
+            }
+
+        case dstage_decodeCBlock_intoTmp:
+            {
+                /* not enough place into dst : decode into tmpOut */
+                int (*decoder)(const char*, char*, int, int, const char*, int);
+                int decodedSize;
+
+                if (dctxPtr->frameInfo.blockMode == LZ4F_blockLinked)
+                    decoder = LZ4_decompress_safe_usingDict;
+                else
+                    decoder = LZ4F_decompress_safe;
+
+                /* ensure enough place for tmpOut */
+                if (dctxPtr->frameInfo.blockMode == LZ4F_blockLinked)
+                {
+                    if (dctxPtr->dict == dctxPtr->tmpOutBuffer)
+                    {
+                        if (dctxPtr->dictSize > 128 KB)
+                        {
+                            memcpy(dctxPtr->tmpOutBuffer, dctxPtr->dict + dctxPtr->dictSize - 64 KB, 64 KB);
+                            dctxPtr->dictSize = 64 KB;
+                        }
+                        dctxPtr->tmpOut = dctxPtr->tmpOutBuffer + dctxPtr->dictSize;
+                    }
+                    else   /* dict not within tmp */
+                    {
+                        size_t reservedDictSpace = dctxPtr->dictSize;
+                        if (reservedDictSpace > 64 KB) reservedDictSpace = 64 KB;
+                        dctxPtr->tmpOut = dctxPtr->tmpOutBuffer + reservedDictSpace;
+                    }
+                }
+
+                /* Decode */
+                decodedSize = decoder((const char*)selectedIn, (char*)dctxPtr->tmpOut, (int)dctxPtr->tmpInTarget, (int)dctxPtr->maxBlockSize, (const char*)dctxPtr->dict, (int)dctxPtr->dictSize);
+                if (decodedSize < 0) return (size_t)-LZ4F_ERROR_decompressionFailed;   /* decompression failed */
+                if (dctxPtr->frameInfo.contentChecksumFlag) XXH32_update(&(dctxPtr->xxh), dctxPtr->tmpOut, decodedSize);
+                if (dctxPtr->frameInfo.contentSize) dctxPtr->frameRemainingSize -= decodedSize;
+                dctxPtr->tmpOutSize = decodedSize;
+                dctxPtr->tmpOutStart = 0;
+                dctxPtr->dStage = dstage_flushOut;
+                break;
+            }
+
+        case dstage_flushOut:  /* flush decoded data from tmpOut to dstBuffer */
+            {
+                size_t sizeToCopy = dctxPtr->tmpOutSize - dctxPtr->tmpOutStart;
+                if (sizeToCopy > (size_t)(dstEnd-dstPtr)) sizeToCopy = dstEnd-dstPtr;
+                memcpy(dstPtr, dctxPtr->tmpOut + dctxPtr->tmpOutStart, sizeToCopy);
+
+                /* dictionary management */
+                if (dctxPtr->frameInfo.blockMode==LZ4F_blockLinked)
+                    LZ4F_updateDict(dctxPtr, dstPtr, sizeToCopy, dstStart, 1);
+
+                dctxPtr->tmpOutStart += sizeToCopy;
+                dstPtr += sizeToCopy;
+
+                /* end of flush ? */
+                if (dctxPtr->tmpOutStart == dctxPtr->tmpOutSize)
+                {
+                    dctxPtr->dStage = dstage_getCBlockSize;
+                    break;
+                }
+                nextSrcSizeHint = BHSize;
+                doAnotherStage = 0;   /* still some data to flush */
+                break;
+            }
+
+        case dstage_getSuffix:
+            {
+                size_t suffixSize = dctxPtr->frameInfo.contentChecksumFlag * 4;
+                if (dctxPtr->frameRemainingSize) return (size_t)-LZ4F_ERROR_frameSize_wrong;   /* incorrect frame size decoded */
+                if (suffixSize == 0)   /* frame completed */
+                {
+                    nextSrcSizeHint = 0;
+                    dctxPtr->dStage = dstage_getHeader;
+                    doAnotherStage = 0;
+                    break;
+                }
+                if ((srcEnd - srcPtr) < 4)   /* not enough size for entire CRC */
+                {
+                    dctxPtr->tmpInSize = 0;
+                    dctxPtr->dStage = dstage_storeSuffix;
+                }
+                else
+                {
+                    selectedIn = srcPtr;
+                    srcPtr += 4;
+                }
+            }
+
+            if (dctxPtr->dStage == dstage_storeSuffix)
+        case dstage_storeSuffix:
+            {
+                size_t sizeToCopy = 4 - dctxPtr->tmpInSize;
+                if (sizeToCopy > (size_t)(srcEnd - srcPtr)) sizeToCopy = srcEnd - srcPtr;
+                memcpy(dctxPtr->tmpIn + dctxPtr->tmpInSize, srcPtr, sizeToCopy);
+                srcPtr += sizeToCopy;
+                dctxPtr->tmpInSize += sizeToCopy;
+                if (dctxPtr->tmpInSize < 4)  /* not enough input to read complete suffix */
+                {
+                    nextSrcSizeHint = 4 - dctxPtr->tmpInSize;
+                    doAnotherStage=0;
+                    break;
+                }
+                selectedIn = dctxPtr->tmpIn;
+            }
+
+        /* case dstage_checkSuffix: */   /* no direct call, to avoid scan-build warning */
+            {
+                U32 readCRC = LZ4F_readLE32(selectedIn);
+                U32 resultCRC = XXH32_digest(&(dctxPtr->xxh));
+                if (readCRC != resultCRC) return (size_t)-LZ4F_ERROR_contentChecksum_invalid;
+                nextSrcSizeHint = 0;
+                dctxPtr->dStage = dstage_getHeader;
+                doAnotherStage = 0;
+                break;
+            }
+
+        case dstage_getSFrameSize:
+            {
+                if ((srcEnd - srcPtr) >= 4)
+                {
+                    selectedIn = srcPtr;
+                    srcPtr += 4;
+                }
+                else
+                {
+                /* not enough input to read cBlockSize field */
+                    dctxPtr->tmpInSize = 4;
+                    dctxPtr->tmpInTarget = 8;
+                    dctxPtr->dStage = dstage_storeSFrameSize;
+                }
+            }
+
+            if (dctxPtr->dStage == dstage_storeSFrameSize)
+        case dstage_storeSFrameSize:
+            {
+                size_t sizeToCopy = dctxPtr->tmpInTarget - dctxPtr->tmpInSize;
+                if (sizeToCopy > (size_t)(srcEnd - srcPtr)) sizeToCopy = srcEnd - srcPtr;
+                memcpy(dctxPtr->header + dctxPtr->tmpInSize, srcPtr, sizeToCopy);
+                srcPtr += sizeToCopy;
+                dctxPtr->tmpInSize += sizeToCopy;
+                if (dctxPtr->tmpInSize < dctxPtr->tmpInTarget) /* not enough input to get full sBlockSize; wait for more */
+                {
+                    nextSrcSizeHint = dctxPtr->tmpInTarget - dctxPtr->tmpInSize;
+                    doAnotherStage = 0;
+                    break;
+                }
+                selectedIn = dctxPtr->header + 4;
+            }
+
+        /* case dstage_decodeSFrameSize: */   /* no direct access */
+            {
+                size_t SFrameSize = LZ4F_readLE32(selectedIn);
+                dctxPtr->frameInfo.contentSize = SFrameSize;
+                dctxPtr->tmpInTarget = SFrameSize;
+                dctxPtr->dStage = dstage_skipSkippable;
+                break;
+            }
+
+        case dstage_skipSkippable:
+            {
+                size_t skipSize = dctxPtr->tmpInTarget;
+                if (skipSize > (size_t)(srcEnd-srcPtr)) skipSize = srcEnd-srcPtr;
+                srcPtr += skipSize;
+                dctxPtr->tmpInTarget -= skipSize;
+                doAnotherStage = 0;
+                nextSrcSizeHint = dctxPtr->tmpInTarget;
+                if (nextSrcSizeHint) break;
+                dctxPtr->dStage = dstage_getHeader;
+                break;
+            }
+        }
+    }
+
+    /* preserve dictionary within tmp if necessary */
+    if ( (dctxPtr->frameInfo.blockMode==LZ4F_blockLinked)
+        &&(dctxPtr->dict != dctxPtr->tmpOutBuffer)
+        &&(!decompressOptionsPtr->stableDst)
+        &&((unsigned)(dctxPtr->dStage-1) < (unsigned)(dstage_getSuffix-1))
+        )
+    {
+        if (dctxPtr->dStage == dstage_flushOut)
+        {
+            size_t preserveSize = dctxPtr->tmpOut - dctxPtr->tmpOutBuffer;
+            size_t copySize = 64 KB - dctxPtr->tmpOutSize;
+            const BYTE* oldDictEnd = dctxPtr->dict + dctxPtr->dictSize - dctxPtr->tmpOutStart;
+            if (dctxPtr->tmpOutSize > 64 KB) copySize = 0;
+            if (copySize > preserveSize) copySize = preserveSize;
+
+            memcpy(dctxPtr->tmpOutBuffer + preserveSize - copySize, oldDictEnd - copySize, copySize);
+
+            dctxPtr->dict = dctxPtr->tmpOutBuffer;
+            dctxPtr->dictSize = preserveSize + dctxPtr->tmpOutStart;
+        }
+        else
+        {
+            size_t newDictSize = dctxPtr->dictSize;
+            const BYTE* oldDictEnd = dctxPtr->dict + dctxPtr->dictSize;
+            if ((newDictSize) > 64 KB) newDictSize = 64 KB;
+
+            memcpy(dctxPtr->tmpOutBuffer, oldDictEnd - newDictSize, newDictSize);
+
+            dctxPtr->dict = dctxPtr->tmpOutBuffer;
+            dctxPtr->dictSize = newDictSize;
+            dctxPtr->tmpOut = dctxPtr->tmpOutBuffer + newDictSize;
+        }
+    }
+
+    /* require function to be called again from position where it stopped */
+    if (srcPtr<srcEnd)
+        dctxPtr->srcExpect = srcPtr;
+    else
+        dctxPtr->srcExpect = NULL;
+
+    *srcSizePtr = (srcPtr - srcStart);
+    *dstSizePtr = (dstPtr - dstStart);
+    return nextSrcSizeHint;
+}
diff --git a/tools/cbfstool/lz4hc.c b/tools/cbfstool/lz4hc.c
new file mode 100644
index 0000000000..5bd2421459
--- /dev/null
+++ b/tools/cbfstool/lz4hc.c
@@ -0,0 +1,748 @@
+/*
+    LZ4 HC - High Compression Mode of LZ4
+    Copyright (C) 2011-2015, Yann Collet.
+
+    BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+
+    Redistribution and use in source and binary forms, with or without
+    modification, are permitted provided that the following conditions are
+    met:
+
+    * Redistributions of source code must retain the above copyright
+    notice, this list of conditions and the following disclaimer.
+    * Redistributions in binary form must reproduce the above
+    copyright notice, this list of conditions and the following disclaimer
+    in the documentation and/or other materials provided with the
+    distribution.
+
+    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+    "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+    LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+    A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+    OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+    SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+    LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+    THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+    (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+    OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+    You can contact the author at :
+       - LZ4 source repository : https://github.com/Cyan4973/lz4
+       - LZ4 public forum : https://groups.google.com/forum/#!forum/lz4c
+*/
+
+
+
+/* *************************************
+*  Tuning Parameter
+***************************************/
+static const int LZ4HC_compressionLevel_default = 9;
+
+/*!
+ * HEAPMODE :
+ * Select how default compression function will allocate workplace memory,
+ * in stack (0:fastest), or in heap (1:requires malloc()).
+ * Since workplace is rather large, heap mode is recommended.
+ */
+#define LZ4HC_HEAPMODE 0
+
+
+/* *************************************
+*  Includes
+***************************************/
+#include <lz4/lib/lz4hc.h>
+
+
+/* *************************************
+*  Local Compiler Options
+***************************************/
+#if defined(__GNUC__)
+#  pragma GCC diagnostic ignored "-Wunused-function"
+#endif
+
+#if defined (__clang__)
+#  pragma clang diagnostic ignored "-Wunused-function"
+#endif
+
+
+/* *************************************
+*  Common LZ4 definition
+***************************************/
+#define LZ4_COMMONDEFS_ONLY
+#include "lz4.c"
+
+
+/* *************************************
+*  Local Constants
+***************************************/
+#define DICTIONARY_LOGSIZE 16
+#define MAXD (1<<DICTIONARY_LOGSIZE)
+#define MAXD_MASK (MAXD - 1)
+
+#define HASH_LOG (DICTIONARY_LOGSIZE-1)
+#define HASHTABLESIZE (1 << HASH_LOG)
+#define HASH_MASK (HASHTABLESIZE - 1)
+
+#define OPTIMAL_ML (int)((ML_MASK-1)+MINMATCH)
+
+static const int g_maxCompressionLevel = 16;
+
+
+/**************************************
+*  Local Types
+**************************************/
+typedef struct
+{
+    U32   hashTable[HASHTABLESIZE];
+    U16   chainTable[MAXD];
+    const BYTE* end;        /* next block here to continue on current prefix */
+    const BYTE* base;       /* All index relative to this position */
+    const BYTE* dictBase;   /* alternate base for extDict */
+    BYTE* inputBuffer;      /* deprecated */
+    U32   dictLimit;        /* below that point, need extDict */
+    U32   lowLimit;         /* below that point, no more dict */
+    U32   nextToUpdate;     /* index from which to continue dictionary update */
+    U32   compressionLevel;
+} LZ4HC_Data_Structure;
+
+
+/**************************************
+*  Local Macros
+**************************************/
+#define HASH_FUNCTION(i)       (((i) * 2654435761U) >> ((MINMATCH*8)-HASH_LOG))
+//#define DELTANEXTU16(p)        chainTable[(p) & MAXD_MASK]   /* flexible, MAXD dependent */
+#define DELTANEXTU16(p)        chainTable[(U16)(p)]   /* faster */
+
+static U32 LZ4HC_hashPtr(const void* ptr) { return HASH_FUNCTION(LZ4_read32(ptr)); }
+
+
+
+/**************************************
+*  HC Compression
+**************************************/
+static void LZ4HC_init (LZ4HC_Data_Structure* hc4, const BYTE* start)
+{
+    MEM_INIT((void*)hc4->hashTable, 0, sizeof(hc4->hashTable));
+    MEM_INIT(hc4->chainTable, 0xFF, sizeof(hc4->chainTable));
+    hc4->nextToUpdate = 64 KB;
+    hc4->base = start - 64 KB;
+    hc4->end = start;
+    hc4->dictBase = start - 64 KB;
+    hc4->dictLimit = 64 KB;
+    hc4->lowLimit = 64 KB;
+}
+
+
+/* Update chains up to ip (excluded) */
+FORCE_INLINE void LZ4HC_Insert (LZ4HC_Data_Structure* hc4, const BYTE* ip)
+{
+    U16* chainTable = hc4->chainTable;
+    U32* HashTable  = hc4->hashTable;
+    const BYTE* const base = hc4->base;
+    const U32 target = (U32)(ip - base);
+    U32 idx = hc4->nextToUpdate;
+
+    while(idx < target)
+    {
+        U32 h = LZ4HC_hashPtr(base+idx);
+        size_t delta = idx - HashTable[h];
+        if (delta>MAX_DISTANCE) delta = MAX_DISTANCE;
+        DELTANEXTU16(idx) = (U16)delta;
+        HashTable[h] = idx;
+        idx++;
+    }
+
+    hc4->nextToUpdate = target;
+}
+
+
+FORCE_INLINE int LZ4HC_InsertAndFindBestMatch (LZ4HC_Data_Structure* hc4,   /* Index table will be updated */
+                                               const BYTE* ip, const BYTE* const iLimit,
+                                               const BYTE** matchpos,
+                                               const int maxNbAttempts)
+{
+    U16* const chainTable = hc4->chainTable;
+    U32* const HashTable = hc4->hashTable;
+    const BYTE* const base = hc4->base;
+    const BYTE* const dictBase = hc4->dictBase;
+    const U32 dictLimit = hc4->dictLimit;
+    const U32 lowLimit = (hc4->lowLimit + 64 KB > (U32)(ip-base)) ? hc4->lowLimit : (U32)(ip - base) - (64 KB - 1);
+    U32 matchIndex;
+    const BYTE* match;
+    int nbAttempts=maxNbAttempts;
+    size_t ml=0;
+
+    /* HC4 match finder */
+    LZ4HC_Insert(hc4, ip);
+    matchIndex = HashTable[LZ4HC_hashPtr(ip)];
+
+    while ((matchIndex>=lowLimit) && (nbAttempts))
+    {
+        nbAttempts--;
+        if (matchIndex >= dictLimit)
+        {
+            match = base + matchIndex;
+            if (*(match+ml) == *(ip+ml)
+                && (LZ4_read32(match) == LZ4_read32(ip)))
+            {
+                size_t mlt = LZ4_count(ip+MINMATCH, match+MINMATCH, iLimit) + MINMATCH;
+                if (mlt > ml) { ml = mlt; *matchpos = match; }
+            }
+        }
+        else
+        {
+            match = dictBase + matchIndex;
+            if (LZ4_read32(match) == LZ4_read32(ip))
+            {
+                size_t mlt;
+                const BYTE* vLimit = ip + (dictLimit - matchIndex);
+                if (vLimit > iLimit) vLimit = iLimit;
+                mlt = LZ4_count(ip+MINMATCH, match+MINMATCH, vLimit) + MINMATCH;
+                if ((ip+mlt == vLimit) && (vLimit < iLimit))
+                    mlt += LZ4_count(ip+mlt, base+dictLimit, iLimit);
+                if (mlt > ml) { ml = mlt; *matchpos = base + matchIndex; }   /* virtual matchpos */
+            }
+        }
+        matchIndex -= DELTANEXTU16(matchIndex);
+    }
+
+    return (int)ml;
+}
+
+
+FORCE_INLINE int LZ4HC_InsertAndGetWiderMatch (
+    LZ4HC_Data_Structure* hc4,
+    const BYTE* const ip,
+    const BYTE* const iLowLimit,
+    const BYTE* const iHighLimit,
+    int longest,
+    const BYTE** matchpos,
+    const BYTE** startpos,
+    const int maxNbAttempts)
+{
+    U16* const chainTable = hc4->chainTable;
+    U32* const HashTable = hc4->hashTable;
+    const BYTE* const base = hc4->base;
+    const U32 dictLimit = hc4->dictLimit;
+    const BYTE* const lowPrefixPtr = base + dictLimit;
+    const U32 lowLimit = (hc4->lowLimit + 64 KB > (U32)(ip-base)) ? hc4->lowLimit : (U32)(ip - base) - (64 KB - 1);
+    const BYTE* const dictBase = hc4->dictBase;
+    U32   matchIndex;
+    int nbAttempts = maxNbAttempts;
+    int delta = (int)(ip-iLowLimit);
+
+
+    /* First Match */
+    LZ4HC_Insert(hc4, ip);
+    matchIndex = HashTable[LZ4HC_hashPtr(ip)];
+
+    while ((matchIndex>=lowLimit) && (nbAttempts))
+    {
+        nbAttempts--;
+        if (matchIndex >= dictLimit)
+        {
+            const BYTE* matchPtr = base + matchIndex;
+            if (*(iLowLimit + longest) == *(matchPtr - delta + longest))
+                if (LZ4_read32(matchPtr) == LZ4_read32(ip))
+                {
+                    int mlt = MINMATCH + LZ4_count(ip+MINMATCH, matchPtr+MINMATCH, iHighLimit);
+                    int back = 0;
+
+                    while ((ip+back>iLowLimit)
+                           && (matchPtr+back > lowPrefixPtr)
+                           && (ip[back-1] == matchPtr[back-1]))
+                            back--;
+
+                    mlt -= back;
+
+                    if (mlt > longest)
+                    {
+                        longest = (int)mlt;
+                        *matchpos = matchPtr+back;
+                        *startpos = ip+back;
+                    }
+                }
+        }
+        else
+        {
+            const BYTE* matchPtr = dictBase + matchIndex;
+            if (LZ4_read32(matchPtr) == LZ4_read32(ip))
+            {
+                size_t mlt;
+                int back=0;
+                const BYTE* vLimit = ip + (dictLimit - matchIndex);
+                if (vLimit > iHighLimit) vLimit = iHighLimit;
+                mlt = LZ4_count(ip+MINMATCH, matchPtr+MINMATCH, vLimit) + MINMATCH;
+                if ((ip+mlt == vLimit) && (vLimit < iHighLimit))
+                    mlt += LZ4_count(ip+mlt, base+dictLimit, iHighLimit);
+                while ((ip+back > iLowLimit) && (matchIndex+back > lowLimit) && (ip[back-1] == matchPtr[back-1])) back--;
+                mlt -= back;
+                if ((int)mlt > longest) { longest = (int)mlt; *matchpos = base + matchIndex + back; *startpos = ip+back; }
+            }
+        }
+        matchIndex -= DELTANEXTU16(matchIndex);
+    }
+
+    return longest;
+}
+
+
+typedef enum { noLimit = 0, limitedOutput = 1 } limitedOutput_directive;
+
+#define LZ4HC_DEBUG 0
+#if LZ4HC_DEBUG
+static unsigned debug = 0;
+#endif
+
+FORCE_INLINE int LZ4HC_encodeSequence (
+    const BYTE** ip,
+    BYTE** op,
+    const BYTE** anchor,
+    int matchLength,
+    const BYTE* const match,
+    limitedOutput_directive limitedOutputBuffer,
+    BYTE* oend)
+{
+    int length;
+    BYTE* token;
+
+#if LZ4HC_DEBUG
+    if (debug) printf("literal : %u  --  match : %u  --  offset : %u\n", (U32)(*ip - *anchor), (U32)matchLength, (U32)(*ip-match));
+#endif
+
+    /* Encode Literal length */
+    length = (int)(*ip - *anchor);
+    token = (*op)++;
+    if ((limitedOutputBuffer) && ((*op + (length>>8) + length + (2 + 1 + LASTLITERALS)) > oend)) return 1;   /* Check output limit */
+    if (length>=(int)RUN_MASK) { int len; *token=(RUN_MASK<<ML_BITS); len = length-RUN_MASK; for(; len > 254 ; len-=255) *(*op)++ = 255;  *(*op)++ = (BYTE)len; }
+    else *token = (BYTE)(length<<ML_BITS);
+
+    /* Copy Literals */
+    LZ4_wildCopy(*op, *anchor, (*op) + length);
+    *op += length;
+
+    /* Encode Offset */
+    LZ4_writeLE16(*op, (U16)(*ip-match)); *op += 2;
+
+    /* Encode MatchLength */
+    length = (int)(matchLength-MINMATCH);
+    if ((limitedOutputBuffer) && (*op + (length>>8) + (1 + LASTLITERALS) > oend)) return 1;   /* Check output limit */
+    if (length>=(int)ML_MASK) { *token+=ML_MASK; length-=ML_MASK; for(; length > 509 ; length-=510) { *(*op)++ = 255; *(*op)++ = 255; } if (length > 254) { length-=255; *(*op)++ = 255; } *(*op)++ = (BYTE)length; }
+    else *token += (BYTE)(length);
+
+    /* Prepare next loop */
+    *ip += matchLength;
+    *anchor = *ip;
+
+    return 0;
+}
+
+
+static int LZ4HC_compress_generic (
+    void* ctxvoid,
+    const char* source,
+    char* dest,
+    int inputSize,
+    int maxOutputSize,
+    int compressionLevel,
+    limitedOutput_directive limit
+    )
+{
+    LZ4HC_Data_Structure* ctx = (LZ4HC_Data_Structure*) ctxvoid;
+    const BYTE* ip = (const BYTE*) source;
+    const BYTE* anchor = ip;
+    const BYTE* const iend = ip + inputSize;
+    const BYTE* const mflimit = iend - MFLIMIT;
+    const BYTE* const matchlimit = (iend - LASTLITERALS);
+
+    BYTE* op = (BYTE*) dest;
+    BYTE* const oend = op + maxOutputSize;
+
+    unsigned maxNbAttempts;
+    int   ml, ml2, ml3, ml0;
+    const BYTE* ref=NULL;
+    const BYTE* start2=NULL;
+    const BYTE* ref2=NULL;
+    const BYTE* start3=NULL;
+    const BYTE* ref3=NULL;
+    const BYTE* start0;
+    const BYTE* ref0;
+
+
+    /* init */
+    if (compressionLevel > g_maxCompressionLevel) compressionLevel = g_maxCompressionLevel;
+    if (compressionLevel < 1) compressionLevel = LZ4HC_compressionLevel_default;
+    maxNbAttempts = 1 << (compressionLevel-1);
+    ctx->end += inputSize;
+
+    ip++;
+
+    /* Main Loop */
+    while (ip < mflimit)
+    {
+        ml = LZ4HC_InsertAndFindBestMatch (ctx, ip, matchlimit, (&ref), maxNbAttempts);
+        if (!ml) { ip++; continue; }
+
+        /* saved, in case we would skip too much */
+        start0 = ip;
+        ref0 = ref;
+        ml0 = ml;
+
+_Search2:
+        if (ip+ml < mflimit)
+            ml2 = LZ4HC_InsertAndGetWiderMatch(ctx, ip + ml - 2, ip + 1, matchlimit, ml, &ref2, &start2, maxNbAttempts);
+        else ml2 = ml;
+
+        if (ml2 == ml)  /* No better match */
+        {
+            if (LZ4HC_encodeSequence(&ip, &op, &anchor, ml, ref, limit, oend)) return 0;
+            continue;
+        }
+
+        if (start0 < ip)
+        {
+            if (start2 < ip + ml0)   /* empirical */
+            {
+                ip = start0;
+                ref = ref0;
+                ml = ml0;
+            }
+        }
+
+        /* Here, start0==ip */
+        if ((start2 - ip) < 3)   /* First Match too small : removed */
+        {
+            ml = ml2;
+            ip = start2;
+            ref =ref2;
+            goto _Search2;
+        }
+
+_Search3:
+        /*
+        * Currently we have :
+        * ml2 > ml1, and
+        * ip1+3 <= ip2 (usually < ip1+ml1)
+        */
+        if ((start2 - ip) < OPTIMAL_ML)
+        {
+            int correction;
+            int new_ml = ml;
+            if (new_ml > OPTIMAL_ML) new_ml = OPTIMAL_ML;
+            if (ip+new_ml > start2 + ml2 - MINMATCH) new_ml = (int)(start2 - ip) + ml2 - MINMATCH;
+            correction = new_ml - (int)(start2 - ip);
+            if (correction > 0)
+            {
+                start2 += correction;
+                ref2 += correction;
+                ml2 -= correction;
+            }
+        }
+        /* Now, we have start2 = ip+new_ml, with new_ml = min(ml, OPTIMAL_ML=18) */
+
+        if (start2 + ml2 < mflimit)
+            ml3 = LZ4HC_InsertAndGetWiderMatch(ctx, start2 + ml2 - 3, start2, matchlimit, ml2, &ref3, &start3, maxNbAttempts);
+        else ml3 = ml2;
+
+        if (ml3 == ml2) /* No better match : 2 sequences to encode */
+        {
+            /* ip & ref are known; Now for ml */
+            if (start2 < ip+ml)  ml = (int)(start2 - ip);
+            /* Now, encode 2 sequences */
+            if (LZ4HC_encodeSequence(&ip, &op, &anchor, ml, ref, limit, oend)) return 0;
+            ip = start2;
+            if (LZ4HC_encodeSequence(&ip, &op, &anchor, ml2, ref2, limit, oend)) return 0;
+            continue;
+        }
+
+        if (start3 < ip+ml+3) /* Not enough space for match 2 : remove it */
+        {
+            if (start3 >= (ip+ml)) /* can write Seq1 immediately ==> Seq2 is removed, so Seq3 becomes Seq1 */
+            {
+                if (start2 < ip+ml)
+                {
+                    int correction = (int)(ip+ml - start2);
+                    start2 += correction;
+                    ref2 += correction;
+                    ml2 -= correction;
+                    if (ml2 < MINMATCH)
+                    {
+                        start2 = start3;
+                        ref2 = ref3;
+                        ml2 = ml3;
+                    }
+                }
+
+                if (LZ4HC_encodeSequence(&ip, &op, &anchor, ml, ref, limit, oend)) return 0;
+                ip  = start3;
+                ref = ref3;
+                ml  = ml3;
+
+                start0 = start2;
+                ref0 = ref2;
+                ml0 = ml2;
+                goto _Search2;
+            }
+
+            start2 = start3;
+            ref2 = ref3;
+            ml2 = ml3;
+            goto _Search3;
+        }
+
+        /*
+        * OK, now we have 3 ascending matches; let's write at least the first one
+        * ip & ref are known; Now for ml
+        */
+        if (start2 < ip+ml)
+        {
+            if ((start2 - ip) < (int)ML_MASK)
+            {
+                int correction;
+                if (ml > OPTIMAL_ML) ml = OPTIMAL_ML;
+                if (ip + ml > start2 + ml2 - MINMATCH) ml = (int)(start2 - ip) + ml2 - MINMATCH;
+                correction = ml - (int)(start2 - ip);
+                if (correction > 0)
+                {
+                    start2 += correction;
+                    ref2 += correction;
+                    ml2 -= correction;
+                }
+            }
+            else
+            {
+                ml = (int)(start2 - ip);
+            }
+        }
+        if (LZ4HC_encodeSequence(&ip, &op, &anchor, ml, ref, limit, oend)) return 0;
+
+        ip = start2;
+        ref = ref2;
+        ml = ml2;
+
+        start2 = start3;
+        ref2 = ref3;
+        ml2 = ml3;
+
+        goto _Search3;
+    }
+
+    /* Encode Last Literals */
+    {
+        int lastRun = (int)(iend - anchor);
+        if ((limit) && (((char*)op - dest) + lastRun + 1 + ((lastRun+255-RUN_MASK)/255) > (U32)maxOutputSize)) return 0;  /* Check output limit */
+        if (lastRun>=(int)RUN_MASK) { *op++=(RUN_MASK<<ML_BITS); lastRun-=RUN_MASK; for(; lastRun > 254 ; lastRun-=255) *op++ = 255; *op++ = (BYTE) lastRun; }
+        else *op++ = (BYTE)(lastRun<<ML_BITS);
+        memcpy(op, anchor, iend - anchor);
+        op += iend-anchor;
+    }
+
+    /* End */
+    return (int) (((char*)op)-dest);
+}
+
+
+int LZ4_sizeofStateHC(void) { return sizeof(LZ4HC_Data_Structure); }
+
+int LZ4_compress_HC_extStateHC (void* state, const char* src, char* dst, int srcSize, int maxDstSize, int compressionLevel)
+{
+    if (((size_t)(state)&(sizeof(void*)-1)) != 0) return 0;   /* Error : state is not aligned for pointers (32 or 64 bits) */
+    LZ4HC_init ((LZ4HC_Data_Structure*)state, (const BYTE*)src);
+    if (maxDstSize < LZ4_compressBound(srcSize))
+        return LZ4HC_compress_generic (state, src, dst, srcSize, maxDstSize, compressionLevel, limitedOutput);
+    else
+        return LZ4HC_compress_generic (state, src, dst, srcSize, maxDstSize, compressionLevel, noLimit);
+}
+
+int LZ4_compress_HC(const char* src, char* dst, int srcSize, int maxDstSize, int compressionLevel)
+{
+#if LZ4HC_HEAPMODE==1
+    LZ4HC_Data_Structure* statePtr = malloc(sizeof(LZ4HC_Data_Structure));
+#else
+    LZ4HC_Data_Structure state;
+    LZ4HC_Data_Structure* const statePtr = &state;
+#endif
+    int cSize = LZ4_compress_HC_extStateHC(statePtr, src, dst, srcSize, maxDstSize, compressionLevel);
+#if LZ4HC_HEAPMODE==1
+    free(statePtr);
+#endif
+    return cSize;
+}
+
+
+
+/**************************************
+*  Streaming Functions
+**************************************/
+/* allocation */
+LZ4_streamHC_t* LZ4_createStreamHC(void) { return (LZ4_streamHC_t*)malloc(sizeof(LZ4_streamHC_t)); }
+int             LZ4_freeStreamHC (LZ4_streamHC_t* LZ4_streamHCPtr) { free(LZ4_streamHCPtr); return 0; }
+
+
+/* initialization */
+void LZ4_resetStreamHC (LZ4_streamHC_t* LZ4_streamHCPtr, int compressionLevel)
+{
+    LZ4_STATIC_ASSERT(sizeof(LZ4HC_Data_Structure) <= sizeof(LZ4_streamHC_t));   /* if compilation fails here, LZ4_STREAMHCSIZE must be increased */
+    ((LZ4HC_Data_Structure*)LZ4_streamHCPtr)->base = NULL;
+    ((LZ4HC_Data_Structure*)LZ4_streamHCPtr)->compressionLevel = (unsigned)compressionLevel;
+}
+
+int LZ4_loadDictHC (LZ4_streamHC_t* LZ4_streamHCPtr, const char* dictionary, int dictSize)
+{
+    LZ4HC_Data_Structure* ctxPtr = (LZ4HC_Data_Structure*) LZ4_streamHCPtr;
+    if (dictSize > 64 KB)
+    {
+        dictionary += dictSize - 64 KB;
+        dictSize = 64 KB;
+    }
+    LZ4HC_init (ctxPtr, (const BYTE*)dictionary);
+    if (dictSize >= 4) LZ4HC_Insert (ctxPtr, (const BYTE*)dictionary +(dictSize-3));
+    ctxPtr->end = (const BYTE*)dictionary + dictSize;
+    return dictSize;
+}
+
+
+/* compression */
+
+static void LZ4HC_setExternalDict(LZ4HC_Data_Structure* ctxPtr, const BYTE* newBlock)
+{
+    if (ctxPtr->end >= ctxPtr->base + 4)
+        LZ4HC_Insert (ctxPtr, ctxPtr->end-3);   /* Referencing remaining dictionary content */
+    /* Only one memory segment for extDict, so any previous extDict is lost at this stage */
+    ctxPtr->lowLimit  = ctxPtr->dictLimit;
+    ctxPtr->dictLimit = (U32)(ctxPtr->end - ctxPtr->base);
+    ctxPtr->dictBase  = ctxPtr->base;
+    ctxPtr->base = newBlock - ctxPtr->dictLimit;
+    ctxPtr->end  = newBlock;
+    ctxPtr->nextToUpdate = ctxPtr->dictLimit;   /* match referencing will resume from there */
+}
+
+static int LZ4_compressHC_continue_generic (LZ4HC_Data_Structure* ctxPtr,
+                                            const char* source, char* dest,
+                                            int inputSize, int maxOutputSize, limitedOutput_directive limit)
+{
+    /* auto-init if forgotten */
+    if (ctxPtr->base == NULL)
+        LZ4HC_init (ctxPtr, (const BYTE*) source);
+
+    /* Check overflow */
+    if ((size_t)(ctxPtr->end - ctxPtr->base) > 2 GB)
+    {
+        size_t dictSize = (size_t)(ctxPtr->end - ctxPtr->base) - ctxPtr->dictLimit;
+        if (dictSize > 64 KB) dictSize = 64 KB;
+
+        LZ4_loadDictHC((LZ4_streamHC_t*)ctxPtr, (const char*)(ctxPtr->end) - dictSize, (int)dictSize);
+    }
+
+    /* Check if blocks follow each other */
+    if ((const BYTE*)source != ctxPtr->end)
+        LZ4HC_setExternalDict(ctxPtr, (const BYTE*)source);
+
+    /* Check overlapping input/dictionary space */
+    {
+        const BYTE* sourceEnd = (const BYTE*) source + inputSize;
+        const BYTE* dictBegin = ctxPtr->dictBase + ctxPtr->lowLimit;
+        const BYTE* dictEnd   = ctxPtr->dictBase + ctxPtr->dictLimit;
+        if ((sourceEnd > dictBegin) && ((const BYTE*)source < dictEnd))
+        {
+            if (sourceEnd > dictEnd) sourceEnd = dictEnd;
+            ctxPtr->lowLimit = (U32)(sourceEnd - ctxPtr->dictBase);
+            if (ctxPtr->dictLimit - ctxPtr->lowLimit < 4) ctxPtr->lowLimit = ctxPtr->dictLimit;
+        }
+    }
+
+    return LZ4HC_compress_generic (ctxPtr, source, dest, inputSize, maxOutputSize, ctxPtr->compressionLevel, limit);
+}
+
+int LZ4_compress_HC_continue (LZ4_streamHC_t* LZ4_streamHCPtr, const char* source, char* dest, int inputSize, int maxOutputSize)
+{
+    if (maxOutputSize < LZ4_compressBound(inputSize))
+        return LZ4_compressHC_continue_generic ((LZ4HC_Data_Structure*)LZ4_streamHCPtr, source, dest, inputSize, maxOutputSize, limitedOutput);
+    else
+        return LZ4_compressHC_continue_generic ((LZ4HC_Data_Structure*)LZ4_streamHCPtr, source, dest, inputSize, maxOutputSize, noLimit);
+}
+
+
+/* dictionary saving */
+
+int LZ4_saveDictHC (LZ4_streamHC_t* LZ4_streamHCPtr, char* safeBuffer, int dictSize)
+{
+    LZ4HC_Data_Structure* streamPtr = (LZ4HC_Data_Structure*)LZ4_streamHCPtr;
+    int prefixSize = (int)(streamPtr->end - (streamPtr->base + streamPtr->dictLimit));
+    if (dictSize > 64 KB) dictSize = 64 KB;
+    if (dictSize < 4) dictSize = 0;
+    if (dictSize > prefixSize) dictSize = prefixSize;
+    memmove(safeBuffer, streamPtr->end - dictSize, dictSize);
+    {
+        U32 endIndex = (U32)(streamPtr->end - streamPtr->base);
+        streamPtr->end = (const BYTE*)safeBuffer + dictSize;
+        streamPtr->base = streamPtr->end - endIndex;
+        streamPtr->dictLimit = endIndex - dictSize;
+        streamPtr->lowLimit = endIndex - dictSize;
+        if (streamPtr->nextToUpdate < streamPtr->dictLimit) streamPtr->nextToUpdate = streamPtr->dictLimit;
+    }
+    return dictSize;
+}
+
+
+/***********************************
+*  Deprecated Functions
+***********************************/
+/* Deprecated compression functions */
+/* These functions are planned to start generate warnings by r131 approximately */
+int LZ4_compressHC(const char* src, char* dst, int srcSize) { return LZ4_compress_HC (src, dst, srcSize, LZ4_compressBound(srcSize), 0); }
+int LZ4_compressHC_limitedOutput(const char* src, char* dst, int srcSize, int maxDstSize) { return LZ4_compress_HC(src, dst, srcSize, maxDstSize, 0); }
+int LZ4_compressHC2(const char* src, char* dst, int srcSize, int cLevel) { return LZ4_compress_HC (src, dst, srcSize, LZ4_compressBound(srcSize), cLevel); }
+int LZ4_compressHC2_limitedOutput(const char* src, char* dst, int srcSize, int maxDstSize, int cLevel) { return LZ4_compress_HC(src, dst, srcSize, maxDstSize, cLevel); }
+int LZ4_compressHC_withStateHC (void* state, const char* src, char* dst, int srcSize) { return LZ4_compress_HC_extStateHC (state, src, dst, srcSize, LZ4_compressBound(srcSize), 0); }
+int LZ4_compressHC_limitedOutput_withStateHC (void* state, const char* src, char* dst, int srcSize, int maxDstSize) { return LZ4_compress_HC_extStateHC (state, src, dst, srcSize, maxDstSize, 0); }
+int LZ4_compressHC2_withStateHC (void* state, const char* src, char* dst, int srcSize, int cLevel) { return LZ4_compress_HC_extStateHC(state, src, dst, srcSize, LZ4_compressBound(srcSize), cLevel); }
+int LZ4_compressHC2_limitedOutput_withStateHC (void* state, const char* src, char* dst, int srcSize, int maxDstSize, int cLevel) { return LZ4_compress_HC_extStateHC(state, src, dst, srcSize, maxDstSize, cLevel); }
+int LZ4_compressHC_continue (LZ4_streamHC_t* ctx, const char* src, char* dst, int srcSize) { return LZ4_compress_HC_continue (ctx, src, dst, srcSize, LZ4_compressBound(srcSize)); }
+int LZ4_compressHC_limitedOutput_continue (LZ4_streamHC_t* ctx, const char* src, char* dst, int srcSize, int maxDstSize) { return LZ4_compress_HC_continue (ctx, src, dst, srcSize, maxDstSize); }
+
+
+/* Deprecated streaming functions */
+/* These functions currently generate deprecation warnings */
+int LZ4_sizeofStreamStateHC(void) { return LZ4_STREAMHCSIZE; }
+
+int LZ4_resetStreamStateHC(void* state, char* inputBuffer)
+{
+    if ((((size_t)state) & (sizeof(void*)-1)) != 0) return 1;   /* Error : pointer is not aligned for pointer (32 or 64 bits) */
+    LZ4HC_init((LZ4HC_Data_Structure*)state, (const BYTE*)inputBuffer);
+    ((LZ4HC_Data_Structure*)state)->inputBuffer = (BYTE*)inputBuffer;
+    return 0;
+}
+
+void* LZ4_createHC (char* inputBuffer)
+{
+    void* hc4 = ALLOCATOR(1, sizeof(LZ4HC_Data_Structure));
+    if (hc4 == NULL) return NULL;   /* not enough memory */
+    LZ4HC_init ((LZ4HC_Data_Structure*)hc4, (const BYTE*)inputBuffer);
+    ((LZ4HC_Data_Structure*)hc4)->inputBuffer = (BYTE*)inputBuffer;
+    return hc4;
+}
+
+int LZ4_freeHC (void* LZ4HC_Data)
+{
+    FREEMEM(LZ4HC_Data);
+    return (0);
+}
+
+int LZ4_compressHC2_continue (void* LZ4HC_Data, const char* source, char* dest, int inputSize, int compressionLevel)
+{
+    return LZ4HC_compress_generic (LZ4HC_Data, source, dest, inputSize, 0, compressionLevel, noLimit);
+}
+
+int LZ4_compressHC2_limitedOutput_continue (void* LZ4HC_Data, const char* source, char* dest, int inputSize, int maxOutputSize, int compressionLevel)
+{
+    return LZ4HC_compress_generic (LZ4HC_Data, source, dest, inputSize, maxOutputSize, compressionLevel, limitedOutput);
+}
+
+char* LZ4_slideInputBufferHC(void* LZ4HC_Data)
+{
+    LZ4HC_Data_Structure* hc4 = (LZ4HC_Data_Structure*)LZ4HC_Data;
+    int dictSize = LZ4_saveDictHC((LZ4_streamHC_t*)LZ4HC_Data, (char*)(hc4->inputBuffer), 64 KB);
+    return (char*)(hc4->inputBuffer + dictSize);
+}
diff --git a/tools/cbfstool/lzma.c b/tools/cbfstool/lzma.c
new file mode 100644
index 0000000000..986ebfaa22
--- /dev/null
+++ b/tools/cbfstool/lzma.c
@@ -0,0 +1,192 @@
+#include <stdio.h>
+#include <stdint.h>
+#include <stdlib.h>
+#include <string.h>
+#include "../common.h"
+#include "C/LzmaDec.h"
+#include "C/LzmaEnc.h"
+
+#define L (uint64_t)
+
+static inline uint64_t get_64(const void *p)
+{
+	const unsigned char *data = (const unsigned char *)p;
+	return (L data[0]) | (L data[1] << 8) | (L data[2] << 16) |
+		(L data[3] << 24) | (L data [4] << 32) | (L data[5] << 40) |
+		(L data[6] << 48) | (L data[7] << 56);
+}
+
+static void put_64(void *p, uint64_t value)
+{
+	unsigned char *data = (unsigned char *)p;
+	data[0] = value & 0xff;
+	data[1] = (value >> 8) & 0xff;
+	data[2] = (value >> 16) & 0xff;
+	data[3] = (value >> 24) & 0xff;
+	data[4] = (value >> 32) & 0xff;
+	data[5] = (value >> 40) & 0xff;
+	data[6] = (value >> 48) & 0xff;
+	data[7] = (value >> 56) & 0xff;
+}
+
+/* Memory Allocation API */
+
+static void *SzAlloc(unused void *u, size_t size)
+{
+	return malloc(size);
+}
+
+static void SzFree(unused void *u, void *address)
+{
+	free(address);
+}
+
+static struct ISzAlloc LZMAalloc = { SzAlloc, SzFree };
+
+/* Streaming API */
+
+struct vector_t {
+	char *p;
+	size_t pos;
+	size_t size;
+};
+
+static struct vector_t instream, outstream;
+
+static SRes Read(unused void *u, void *buf, size_t *size)
+{
+	if ((instream.size - instream.pos) < *size)
+		*size = instream.size - instream.pos;
+	memcpy(buf, instream.p + instream.pos, *size);
+	instream.pos += *size;
+	return SZ_OK;
+}
+
+static size_t Write(unused void *u, const void *buf, size_t size)
+{
+	if(outstream.size - outstream.pos < size)
+		size = outstream.size - outstream.pos;
+	memcpy(outstream.p + outstream.pos, buf, size);
+	outstream.pos += size;
+	return size;
+}
+
+static struct ISeqInStream is = { Read };
+static struct ISeqOutStream os = { Write };
+
+/**
+ * Compress a buffer with lzma
+ * Don't copy the result back if it is too large.
+ * @param in a pointer to the buffer
+ * @param in_len the length in bytes
+ * @param out a pointer to a buffer of at least size in_len
+ * @param out_len a pointer to the compressed length of in
+ */
+
+int do_lzma_compress(char *in, int in_len, char *out, int *out_len)
+{
+	if (in_len == 0) {
+		ERROR("LZMA: Input length is zero.\n");
+		return -1;
+	}
+
+	struct CLzmaEncProps props;
+	LzmaEncProps_Init(&props);
+	props.dictSize = in_len;
+	props.pb = 0; /* PosStateBits, default: 2, range: 0..4 */
+	props.lp = 0; /* LiteralPosStateBits, default: 0, range: 0..4 */
+	props.lc = 1; /* LiteralContextBits, default: 3, range: 0..8 */
+	props.fb = 273; /* NumFastBytes */
+	props.mc = 0; /* MatchFinderCycles, default: 0 */
+	props.algo = 1; /* AlgorithmNo, apparently, 0 and 1 are valid values. 0 = fast mode */
+	props.numThreads = 1;
+
+	switch (props.algo) {
+	case 0:	// quick: HC4
+		props.btMode = 0;
+		props.level = 1;
+		break;
+	case 1:	// full: BT4
+	default:
+		props.level = 9;
+		props.btMode = 1;
+		props.numHashBytes = 4;
+		break;
+	}
+
+	CLzmaEncHandle p = LzmaEnc_Create(&LZMAalloc);
+
+	int res = LzmaEnc_SetProps(p, &props);
+	if (res != SZ_OK) {
+		ERROR("LZMA: LzmaEnc_SetProps failed.\n");
+		return -1;
+	}
+
+	unsigned char propsEncoded[LZMA_PROPS_SIZE + 8];
+	size_t propsSize = sizeof propsEncoded;
+	res = LzmaEnc_WriteProperties(p, propsEncoded, &propsSize);
+	if (res != SZ_OK) {
+		ERROR("LZMA: LzmaEnc_WriteProperties failed.\n");
+		return -1;
+	}
+
+	instream.p = in;
+	instream.pos = 0;
+	instream.size = in_len;
+
+	outstream.p = out;
+	outstream.pos = 0;
+	outstream.size = in_len;
+
+	put_64(propsEncoded + LZMA_PROPS_SIZE, in_len);
+	Write(&os, propsEncoded, LZMA_PROPS_SIZE+8);
+
+	res = LzmaEnc_Encode(p, &os, &is, 0, &LZMAalloc, &LZMAalloc);
+	LzmaEnc_Destroy(p, &LZMAalloc, &LZMAalloc);
+	if (res != SZ_OK) {
+		ERROR("LZMA: LzmaEnc_Encode failed %d.\n", res);
+		return -1;
+	}
+
+	*out_len = outstream.pos;
+	return 0;
+}
+
+int do_lzma_uncompress(char *dst, int dst_len, char *src, int src_len,
+			size_t *actual_size)
+{
+	if (src_len <= LZMA_PROPS_SIZE + 8) {
+		ERROR("LZMA: Input length is too small.\n");
+		return -1;
+	}
+
+	uint64_t out_sizemax = get_64(&src[LZMA_PROPS_SIZE]);
+
+	if (out_sizemax > (size_t) dst_len) {
+		ERROR("Not copying %d bytes to %d-byte buffer!\n",
+			(unsigned int)out_sizemax, dst_len);
+		return -1;
+	}
+
+	enum ELzmaStatus status;
+
+	size_t destlen = out_sizemax;
+	size_t srclen = src_len - (LZMA_PROPS_SIZE + 8);
+
+	int res = LzmaDecode((uint8_t *) dst, &destlen,
+			     (uint8_t *) &src[LZMA_PROPS_SIZE + 8], &srclen,
+			     (uint8_t *) &src[0], LZMA_PROPS_SIZE,
+			     LZMA_FINISH_END,
+			     &status,
+			     &LZMAalloc);
+
+	if (res != SZ_OK) {
+		ERROR("Error while decompressing.\n");
+		return -1;
+	}
+
+	if (actual_size != NULL)
+		*actual_size = destlen;
+
+	return 0;
+}
diff --git a/tools/cbfstool/lzma/C/LzFind.h b/tools/cbfstool/lzma/C/LzFind.h
new file mode 100644
index 0000000000..66e1ecdf32
--- /dev/null
+++ b/tools/cbfstool/lzma/C/LzFind.h
@@ -0,0 +1,107 @@
+/* LzFind.h -- Match finder for LZ algorithms
+2009-04-22 : Igor Pavlov : Public domain */
+
+#ifndef __LZ_FIND_H
+#define __LZ_FIND_H
+
+#include "Types.h"
+
+typedef uint32_t CLzRef;
+
+struct CMatchFinder
+{
+  uint8_t *buffer;
+  uint32_t pos;
+  uint32_t posLimit;
+  uint32_t streamPos;
+  uint32_t lenLimit;
+
+  uint32_t cyclicBufferPos;
+  uint32_t cyclicBufferSize; /* it must be = (historySize + 1) */
+
+  uint32_t matchMaxLen;
+  CLzRef *hash;
+  CLzRef *son;
+  uint32_t hashMask;
+  uint32_t cutValue;
+
+  uint8_t *bufferBase;
+  struct ISeqInStream *stream;
+  int streamEndWasReached;
+
+  uint32_t blockSize;
+  uint32_t keepSizeBefore;
+  uint32_t keepSizeAfter;
+
+  uint32_t numHashBytes;
+  int directInput;
+  size_t directInputRem;
+  int btMode;
+  int bigHash;
+  uint32_t historySize;
+  uint32_t fixedHashSize;
+  uint32_t hashSizeSum;
+  uint32_t numSons;
+  SRes result;
+  uint32_t crc[256];
+};
+
+#define Inline_MatchFinder_GetPointerToCurrentPos(p) ((p)->buffer)
+#define Inline_MatchFinder_GetIndexByte(p, index) ((p)->buffer[(int32_t)(index)])
+
+#define Inline_MatchFinder_GetNumAvailableBytes(p) ((p)->streamPos - (p)->pos)
+
+int MatchFinder_NeedMove(struct CMatchFinder *p);
+uint8_t *MatchFinder_GetPointerToCurrentPos(struct CMatchFinder *p);
+void MatchFinder_MoveBlock(struct CMatchFinder *p);
+void MatchFinder_ReadIfRequired(struct CMatchFinder *p);
+
+void MatchFinder_Construct(struct CMatchFinder *p);
+
+/* Conditions:
+     historySize <= 3 GB
+     keepAddBufferBefore + matchMaxLen + keepAddBufferAfter < 511MB
+*/
+int MatchFinder_Create(struct CMatchFinder *p, uint32_t historySize,
+    uint32_t keepAddBufferBefore, uint32_t matchMaxLen, uint32_t keepAddBufferAfter,
+    struct ISzAlloc *alloc);
+void MatchFinder_Free(struct CMatchFinder *p, struct ISzAlloc *alloc);
+void MatchFinder_Normalize3(uint32_t subValue, CLzRef *items, uint32_t numItems);
+void MatchFinder_ReduceOffsets(struct CMatchFinder *p, uint32_t subValue);
+
+uint32_t * GetMatchesSpec1(uint32_t lenLimit, uint32_t curMatch, uint32_t pos, const uint8_t *buffer, CLzRef *son,
+    uint32_t _cyclicBufferPos, uint32_t _cyclicBufferSize, uint32_t _cutValue,
+    uint32_t *distances, uint32_t maxLen);
+
+/*
+Conditions:
+  Mf_GetNumAvailableBytes_Func must be called before each Mf_GetMatchLen_Func.
+  Mf_GetPointerToCurrentPos_Func's result must be used only before any other function
+*/
+
+typedef void (*Mf_Init_Func)(void *object);
+typedef uint8_t (*Mf_GetIndexByte_Func)(void *object, int32_t index);
+typedef uint32_t (*Mf_GetNumAvailableBytes_Func)(void *object);
+typedef const uint8_t * (*Mf_GetPointerToCurrentPos_Func)(void *object);
+typedef uint32_t (*Mf_GetMatches_Func)(void *object, uint32_t *distances);
+typedef void (*Mf_Skip_Func)(void *object, uint32_t);
+
+struct IMatchFinder
+{
+  Mf_Init_Func Init;
+  Mf_GetIndexByte_Func GetIndexByte;
+  Mf_GetNumAvailableBytes_Func GetNumAvailableBytes;
+  Mf_GetPointerToCurrentPos_Func GetPointerToCurrentPos;
+  Mf_GetMatches_Func GetMatches;
+  Mf_Skip_Func Skip;
+};
+
+void MatchFinder_CreateVTable(struct CMatchFinder *p, struct IMatchFinder *vTable);
+
+void MatchFinder_Init(struct CMatchFinder *p);
+uint32_t Bt3Zip_MatchFinder_GetMatches(struct CMatchFinder *p, uint32_t *distances);
+uint32_t Hc3Zip_MatchFinder_GetMatches(struct CMatchFinder *p, uint32_t *distances);
+void Bt3Zip_MatchFinder_Skip(struct CMatchFinder *p, uint32_t num);
+void Hc3Zip_MatchFinder_Skip(struct CMatchFinder *p, uint32_t num);
+
+#endif
diff --git a/tools/cbfstool/lzma/C/LzHash.h b/tools/cbfstool/lzma/C/LzHash.h
new file mode 100644
index 0000000000..cc01a3f937
--- /dev/null
+++ b/tools/cbfstool/lzma/C/LzHash.h
@@ -0,0 +1,54 @@
+/* LzHash.h -- HASH functions for LZ algorithms
+2009-02-07 : Igor Pavlov : Public domain */
+
+#ifndef __LZ_HASH_H
+#define __LZ_HASH_H
+
+#define kHash2Size (1 << 10)
+#define kHash3Size (1 << 16)
+#define kHash4Size (1 << 20)
+
+#define kFix3HashSize (kHash2Size)
+#define kFix4HashSize (kHash2Size + kHash3Size)
+#define kFix5HashSize (kHash2Size + kHash3Size + kHash4Size)
+
+#define HASH2_CALC hashValue = cur[0] | ((uint32_t)cur[1] << 8);
+
+#define HASH3_CALC { \
+  uint32_t temp = p->crc[cur[0]] ^ cur[1]; \
+  hash2Value = temp & (kHash2Size - 1); \
+  hashValue = (temp ^ ((uint32_t)cur[2] << 8)) & p->hashMask; }
+
+#define HASH4_CALC { \
+  uint32_t temp = p->crc[cur[0]] ^ cur[1]; \
+  hash2Value = temp & (kHash2Size - 1); \
+  hash3Value = (temp ^ ((uint32_t)cur[2] << 8)) & (kHash3Size - 1); \
+  hashValue = (temp ^ ((uint32_t)cur[2] << 8) ^ (p->crc[cur[3]] << 5)) & p->hashMask; }
+
+#define HASH5_CALC { \
+  uint32_t temp = p->crc[cur[0]] ^ cur[1]; \
+  hash2Value = temp & (kHash2Size - 1); \
+  hash3Value = (temp ^ ((uint32_t)cur[2] << 8)) & (kHash3Size - 1); \
+  hash4Value = (temp ^ ((uint32_t)cur[2] << 8) ^ (p->crc[cur[3]] << 5)); \
+  hashValue = (hash4Value ^ (p->crc[cur[4]] << 3)) & p->hashMask; \
+  hash4Value &= (kHash4Size - 1); }
+
+/* #define HASH_ZIP_CALC hashValue = ((cur[0] | ((uint32_t)cur[1] << 8)) ^ p->crc[cur[2]]) & 0xFFFF; */
+#define HASH_ZIP_CALC hashValue = ((cur[2] | ((uint32_t)cur[0] << 8)) ^ p->crc[cur[1]]) & 0xFFFF;
+
+
+#define MT_HASH2_CALC \
+  hash2Value = (p->crc[cur[0]] ^ cur[1]) & (kHash2Size - 1);
+
+#define MT_HASH3_CALC { \
+  uint32_t temp = p->crc[cur[0]] ^ cur[1]; \
+  hash2Value = temp & (kHash2Size - 1); \
+  hash3Value = (temp ^ ((uint32_t)cur[2] << 8)) & (kHash3Size - 1); }
+
+#define MT_HASH4_CALC { \
+  uint32_t temp = p->crc[cur[0]] ^ cur[1]; \
+  hash2Value = temp & (kHash2Size - 1); \
+  hash3Value = (temp ^ ((uint32_t)cur[2] << 8)) & (kHash3Size - 1); \
+  hash4Value = (temp ^ ((uint32_t)cur[2] << 8) ^ (p->crc[cur[3]] << 5)) & (kHash4Size - 1); }
+
+#endif
diff --git a/tools/cbfstool/lzma/C/LzmaDec.h b/tools/cbfstool/lzma/C/LzmaDec.h
new file mode 100644
index 0000000000..1addabe55a
--- /dev/null
+++ b/tools/cbfstool/lzma/C/LzmaDec.h
@@ -0,0 +1,214 @@
+/* LzmaDec.h -- LZMA Decoder
+2009-02-07 : Igor Pavlov : Public domain */
+
+#ifndef __LZMA_DEC_H
+#define __LZMA_DEC_H
+
+#include "Types.h"
+
+typedef uint16_t CLzmaProb;
+
+/* ---------- LZMA Properties ---------- */
+
+#define LZMA_PROPS_SIZE 5
+
+struct CLzmaProps
+{
+  unsigned lc, lp, pb;
+  uint32_t dicSize;
+};
+
+/* LzmaProps_Decode - decodes properties
+Returns:
+  SZ_OK
+  SZ_ERROR_UNSUPPORTED - Unsupported properties
+*/
+
+SRes LzmaProps_Decode(struct CLzmaProps *p, const uint8_t *data, unsigned size);
+
+
+/* ---------- LZMA Decoder state ---------- */
+
+/* LZMA_REQUIRED_INPUT_MAX = number of required input bytes for worst case.
+   Num bits = log2((2^11 / 31) ^ 22) + 26 < 134 + 26 = 160; */
+
+#define LZMA_REQUIRED_INPUT_MAX 20
+
+struct CLzmaDec
+{
+	struct CLzmaProps prop;
+  CLzmaProb *probs;
+  uint8_t *dic;
+  const uint8_t *buf;
+  uint32_t range, code;
+  size_t dicPos;
+  size_t dicBufSize;
+  uint32_t processedPos;
+  uint32_t checkDicSize;
+  unsigned state;
+  uint32_t reps[4];
+  unsigned remainLen;
+  int needFlush;
+  int needInitState;
+  uint32_t numProbs;
+  unsigned tempBufSize;
+  uint8_t tempBuf[LZMA_REQUIRED_INPUT_MAX];
+};
+
+#define LzmaDec_Construct(p) { (p)->dic = 0; (p)->probs = 0; }
+
+void LzmaDec_Init(struct CLzmaDec *p);
+
+/* There are two types of LZMA streams:
+     0) Stream with end mark. That end mark adds about 6 bytes to compressed size.
+     1) Stream without end mark. You must know exact uncompressed size to decompress such stream. */
+
+enum ELzmaFinishMode
+{
+  LZMA_FINISH_ANY,   /* finish at any point */
+  LZMA_FINISH_END    /* block must be finished at the end */
+};
+
+/* ELzmaFinishMode has meaning only if the decoding reaches output limit !!!
+
+   You must use LZMA_FINISH_END, when you know that current output buffer
+   covers last bytes of block. In other cases you must use LZMA_FINISH_ANY.
+
+   If LZMA decoder sees end marker before reaching output limit, it returns SZ_OK,
+   and output value of destLen will be less than output buffer size limit.
+   You can check status result also.
+
+   You can use multiple checks to test data integrity after full decompression:
+     1) Check Result and "status" variable.
+     2) Check that output(destLen) = uncompressedSize, if you know real uncompressedSize.
+     3) Check that output(srcLen) = compressedSize, if you know real compressedSize.
+        You must use correct finish mode in that case. */
+
+enum ELzmaStatus
+{
+  LZMA_STATUS_NOT_SPECIFIED,               /* use main error code instead */
+  LZMA_STATUS_FINISHED_WITH_MARK,          /* stream was finished with end mark. */
+  LZMA_STATUS_NOT_FINISHED,                /* stream was not finished */
+  LZMA_STATUS_NEEDS_MORE_INPUT,            /* you must provide more input bytes */
+  LZMA_STATUS_MAYBE_FINISHED_WITHOUT_MARK  /* there is probability that stream was finished without end mark */
+};
+
+/* ELzmaStatus is used only as output value for function call */
+
+
+/* ---------- Interfaces ---------- */
+
+/* There are 3 levels of interfaces:
+     1) Dictionary Interface
+     2) Buffer Interface
+     3) One Call Interface
+   You can select any of these interfaces, but don't mix functions from different
+   groups for same object. */
+
+
+/* There are two variants to allocate state for Dictionary Interface:
+     1) LzmaDec_Allocate / LzmaDec_Free
+     2) LzmaDec_AllocateProbs / LzmaDec_FreeProbs
+   You can use variant 2, if you set dictionary buffer manually.
+   For Buffer Interface you must always use variant 1.
+
+LzmaDec_Allocate* can return:
+  SZ_OK
+  SZ_ERROR_MEM         - Memory allocation error
+  SZ_ERROR_UNSUPPORTED - Unsupported properties
+*/
+
+SRes LzmaDec_AllocateProbs(struct CLzmaDec *p, const uint8_t *props, unsigned propsSize, struct ISzAlloc *alloc);
+void LzmaDec_FreeProbs(struct CLzmaDec *p, struct ISzAlloc *alloc);
+
+SRes LzmaDec_Allocate(struct CLzmaDec *state, const uint8_t *prop, unsigned propsSize, struct ISzAlloc *alloc);
+void LzmaDec_Free(struct CLzmaDec *state, struct ISzAlloc *alloc);
+
+/* ---------- Dictionary Interface ---------- */
+
+/* You can use it, if you want to eliminate the overhead for data copying from
+   dictionary to some other external buffer.
+   You must work with CLzmaDec variables directly in this interface.
+
+   STEPS:
+     LzmaDec_Constr()
+     LzmaDec_Allocate()
+     for (each new stream)
+     {
+       LzmaDec_Init()
+       while (it needs more decompression)
+       {
+         LzmaDec_DecodeToDic()
+         use data from CLzmaDec::dic and update CLzmaDec::dicPos
+       }
+     }
+     LzmaDec_Free()
+*/
+
+/* LzmaDec_DecodeToDic
+
+   The decoding to internal dictionary buffer (CLzmaDec::dic).
+   You must manually update CLzmaDec::dicPos, if it reaches CLzmaDec::dicBufSize !!!
+
+finishMode:
+  It has meaning only if the decoding reaches output limit (dicLimit).
+  LZMA_FINISH_ANY - Decode just dicLimit bytes.
+  LZMA_FINISH_END - Stream must be finished after dicLimit.
+
+Returns:
+  SZ_OK
+    status:
+      LZMA_STATUS_FINISHED_WITH_MARK
+      LZMA_STATUS_NOT_FINISHED
+      LZMA_STATUS_NEEDS_MORE_INPUT
+      LZMA_STATUS_MAYBE_FINISHED_WITHOUT_MARK
+  SZ_ERROR_DATA - Data error
+*/
+
+SRes LzmaDec_DecodeToDic(struct CLzmaDec *p, size_t dicLimit,
+    const uint8_t *src, size_t *srcLen, enum ELzmaFinishMode finishMode, enum ELzmaStatus *status);
+
+
+/* ---------- Buffer Interface ---------- */
+
+/* It's zlib-like interface.
+   See LzmaDec_DecodeToDic description for information about STEPS and return results,
+   but you must use LzmaDec_DecodeToBuf instead of LzmaDec_DecodeToDic and you don't need
+   to work with CLzmaDec variables manually.
+
+finishMode:
+  It has meaning only if the decoding reaches output limit (*destLen).
+  LZMA_FINISH_ANY - Decode just destLen bytes.
+  LZMA_FINISH_END - Stream must be finished after (*destLen).
+*/
+
+SRes LzmaDec_DecodeToBuf(struct CLzmaDec *p, uint8_t *dest, size_t *destLen,
+    const uint8_t *src, size_t *srcLen, enum ELzmaFinishMode finishMode, enum ELzmaStatus *status);
+
+
+/* ---------- One Call Interface ---------- */
+
+/* LzmaDecode
+
+finishMode:
+  It has meaning only if the decoding reaches output limit (*destLen).
+  LZMA_FINISH_ANY - Decode just destLen bytes.
+  LZMA_FINISH_END - Stream must be finished after (*destLen).
+
+Returns:
+  SZ_OK
+    status:
+      LZMA_STATUS_FINISHED_WITH_MARK
+      LZMA_STATUS_NOT_FINISHED
+      LZMA_STATUS_MAYBE_FINISHED_WITHOUT_MARK
+  SZ_ERROR_DATA - Data error
+  SZ_ERROR_MEM  - Memory allocation error
+  SZ_ERROR_UNSUPPORTED - Unsupported properties
+  SZ_ERROR_INPUT_EOF - It needs more bytes in input buffer (src).
+*/
+
+SRes LzmaDecode(uint8_t *dest, size_t *destLen, const uint8_t *src, size_t *srcLen,
+    const uint8_t *propData, unsigned propSize, enum ELzmaFinishMode finishMode,
+    enum ELzmaStatus *status, struct ISzAlloc *alloc);
+
+#endif
diff --git a/tools/cbfstool/lzma/C/LzmaEnc.h b/tools/cbfstool/lzma/C/LzmaEnc.h
new file mode 100644
index 0000000000..c57c3209a0
--- /dev/null
+++ b/tools/cbfstool/lzma/C/LzmaEnc.h
@@ -0,0 +1,72 @@
+/*  LzmaEnc.h -- LZMA Encoder
+2009-02-07 : Igor Pavlov : Public domain */
+
+#ifndef __LZMA_ENC_H
+#define __LZMA_ENC_H
+
+#include "Types.h"
+
+#define LZMA_PROPS_SIZE 5
+
+struct CLzmaEncProps
+{
+  int level;       /*  0 <= level <= 9 */
+  uint32_t dictSize; /* (1 << 12) <= dictSize <= (1 << 27) for 32-bit version
+                      (1 << 12) <= dictSize <= (1 << 30) for 64-bit version
+                       default = (1 << 24) */
+  int lc;          /* 0 <= lc <= 8, default = 3 */
+  int lp;          /* 0 <= lp <= 4, default = 0 */
+  int pb;          /* 0 <= pb <= 4, default = 2 */
+  int algo;        /* 0 - fast, 1 - normal, default = 1 */
+  int fb;          /* 5 <= fb <= 273, default = 32 */
+  int btMode;      /* 0 - hashChain Mode, 1 - binTree mode - normal, default = 1 */
+  int numHashBytes; /* 2, 3 or 4, default = 4 */
+  uint32_t mc;        /* 1 <= mc <= (1 << 30), default = 32 */
+  unsigned writeEndMark;  /* 0 - do not write EOPM, 1 - write EOPM, default = 0 */
+  int numThreads;  /* 1 or 2, default = 2 */
+};
+
+void LzmaEncProps_Init(struct CLzmaEncProps *p);
+void LzmaEncProps_Normalize(struct CLzmaEncProps *p);
+uint32_t LzmaEncProps_GetDictSize(const struct CLzmaEncProps *props2);
+
+
+/* ---------- CLzmaEncHandle Interface ---------- */
+
+/* LzmaEnc_* functions can return the following exit codes:
+Returns:
+  SZ_OK           - OK
+  SZ_ERROR_MEM    - Memory allocation error
+  SZ_ERROR_PARAM  - Incorrect parameter in props
+  SZ_ERROR_WRITE  - Write callback error.
+  SZ_ERROR_PROGRESS - some break from progress callback
+  SZ_ERROR_THREAD - errors in multithreading functions (only for Mt version)
+*/
+
+typedef void * CLzmaEncHandle;
+
+CLzmaEncHandle LzmaEnc_Create(struct ISzAlloc *alloc);
+void LzmaEnc_Destroy(CLzmaEncHandle p, struct ISzAlloc *alloc, struct ISzAlloc *allocBig);
+SRes LzmaEnc_SetProps(CLzmaEncHandle p, const struct CLzmaEncProps *props);
+SRes LzmaEnc_WriteProperties(CLzmaEncHandle p, uint8_t *properties, size_t *size);
+SRes LzmaEnc_Encode(CLzmaEncHandle p, struct ISeqOutStream *outStream, struct ISeqInStream *inStream,
+    struct ICompressProgress *progress, struct ISzAlloc *alloc, struct ISzAlloc *allocBig);
+SRes LzmaEnc_MemEncode(CLzmaEncHandle p, uint8_t *dest, size_t *destLen, const uint8_t *src, size_t srcLen,
+    int writeEndMark, struct ICompressProgress *progress, struct ISzAlloc *alloc, struct ISzAlloc *allocBig);
+
+/* ---------- One Call Interface ---------- */
+
+/* LzmaEncode
+Return code:
+  SZ_OK               - OK
+  SZ_ERROR_MEM        - Memory allocation error
+  SZ_ERROR_PARAM      - Incorrect parameter
+  SZ_ERROR_OUTPUT_EOF - output buffer overflow
+  SZ_ERROR_THREAD     - errors in multithreading functions (only for Mt version)
+*/
+
+SRes LzmaEncode(uint8_t *dest, size_t *destLen, const uint8_t *src, size_t srcLen,
+    const struct CLzmaEncProps *props, uint8_t *propsEncoded, size_t *propsSize, int writeEndMark,
+    struct ICompressProgress *progress, struct ISzAlloc *alloc, struct ISzAlloc *allocBig);
+
+#endif
diff --git a/tools/cbfstool/lzma/C/Types.h b/tools/cbfstool/lzma/C/Types.h
new file mode 100644
index 0000000000..ce98ab5e4f
--- /dev/null
+++ b/tools/cbfstool/lzma/C/Types.h
@@ -0,0 +1,148 @@
+/* Types.h -- Basic types
+2010-03-11 : Igor Pavlov : Public domain */
+
+#ifndef __7Z_TYPES_H
+#define __7Z_TYPES_H
+
+#include <stddef.h>
+#include <stdint.h>
+#include <stdbool.h>
+
+
+#define SZ_OK 0
+
+#define SZ_ERROR_DATA 1
+#define SZ_ERROR_MEM 2
+#define SZ_ERROR_CRC 3
+#define SZ_ERROR_UNSUPPORTED 4
+#define SZ_ERROR_PARAM 5
+#define SZ_ERROR_INPUT_EOF 6
+#define SZ_ERROR_OUTPUT_EOF 7
+#define SZ_ERROR_READ 8
+#define SZ_ERROR_WRITE 9
+#define SZ_ERROR_PROGRESS 10
+#define SZ_ERROR_FAIL 11
+#define SZ_ERROR_THREAD 12
+
+#define SZ_ERROR_ARCHIVE 16
+#define SZ_ERROR_NO_ARCHIVE 17
+
+typedef int SRes;
+typedef int WRes; /* This was DWORD for _WIN32. That's uint32_t */
+
+#ifndef RINOK
+#define RINOK(x) { int __result__ = (x); if (__result__ != 0) return __result__; }
+#endif
+
+/* The following interfaces use first parameter as pointer to structure */
+
+struct IByteIn
+{
+  uint8_t (*Read)(void *p); /* reads one byte, returns 0 in case of EOF or error */
+};
+
+struct IByteOut
+{
+  void (*Write)(void *p, uint8_t b);
+};
+
+struct ISeqInStream
+{
+  SRes (*Read)(void *p, void *buf, size_t *size);
+    /* if (input(*size) != 0 && output(*size) == 0) means end_of_stream.
+       (output(*size) < input(*size)) is allowed */
+};
+
+/* it can return SZ_ERROR_INPUT_EOF */
+SRes SeqInStream_Read(struct ISeqInStream *stream, void *buf, size_t size);
+SRes SeqInStream_Read2(struct ISeqInStream *stream, void *buf, size_t size, SRes errorType);
+SRes SeqInStream_ReadByte(struct ISeqInStream *stream, uint8_t *buf);
+
+struct ISeqOutStream
+{
+  size_t (*Write)(void *p, const void *buf, size_t size);
+    /* Returns: result - the number of actually written bytes.
+       (result < size) means error */
+};
+
+enum ESzSeek
+{
+  SZ_SEEK_SET = 0,
+  SZ_SEEK_CUR = 1,
+  SZ_SEEK_END = 2
+};
+
+struct ISeekInStream
+{
+  SRes (*Read)(void *p, void *buf, size_t *size);  /* same as ISeqInStream::Read */
+  SRes (*Seek)(void *p, int64_t *pos, enum ESzSeek origin);
+};
+
+struct ILookInStream
+{
+  SRes (*Look)(void *p, const void **buf, size_t *size);
+    /* if (input(*size) != 0 && output(*size) == 0) means end_of_stream.
+       (output(*size) > input(*size)) is not allowed
+       (output(*size) < input(*size)) is allowed */
+  SRes (*Skip)(void *p, size_t offset);
+    /* offset must be <= output(*size) of Look */
+
+  SRes (*Read)(void *p, void *buf, size_t *size);
+    /* reads directly (without buffer). It's same as ISeqInStream::Read */
+  SRes (*Seek)(void *p, int64_t *pos, enum ESzSeek origin);
+};
+
+SRes LookInStream_LookRead(struct ILookInStream *stream, void *buf, size_t *size);
+SRes LookInStream_SeekTo(struct ILookInStream *stream, uint64_t offset);
+
+/* reads via ILookInStream::Read */
+SRes LookInStream_Read2(struct ILookInStream *stream, void *buf, size_t size, SRes errorType);
+SRes LookInStream_Read(struct ILookInStream *stream, void *buf, size_t size);
+
+#define LookToRead_BUF_SIZE (1 << 14)
+
+struct CLookToRead
+{
+  struct ILookInStream s;
+  struct ISeekInStream *realStream;
+  size_t pos;
+  size_t size;
+  uint8_t buf[LookToRead_BUF_SIZE];
+};
+
+void LookToRead_CreateVTable(struct CLookToRead *p, int lookahead);
+void LookToRead_Init(struct CLookToRead *p);
+
+struct CSecToLook
+{
+  struct ISeqInStream s;
+  struct ILookInStream *realStream;
+};
+
+void SecToLook_CreateVTable(struct CSecToLook *p);
+
+struct CSecToRead
+{
+  struct ISeqInStream s;
+  struct ILookInStream *realStream;
+};
+
+void SecToRead_CreateVTable(struct CSecToRead *p);
+
+struct ICompressProgress
+{
+  SRes (*Progress)(void *p, uint64_t inSize, uint64_t outSize);
+    /* Returns: result. (result != SZ_OK) means break.
+       Value (uint64_t)(int64_t)-1 for size means unknown value. */
+};
+
+struct ISzAlloc
+{
+  void *(*Alloc)(void *p, size_t size);
+  void (*Free)(void *p, void *address); /* address can be 0 */
+};
+
+#define IAlloc_Alloc(p, size) (p)->Alloc((p), size)
+#define IAlloc_Free(p, a) (p)->Free((p), a)
+
+#endif
diff --git a/tools/cbfstool/mem_pool.c b/tools/cbfstool/mem_pool.c
new file mode 100644
index 0000000000..0aa821b24f
--- /dev/null
+++ b/tools/cbfstool/mem_pool.c
@@ -0,0 +1,45 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <commonlib/helpers.h>
+#include <commonlib/mem_pool.h>
+
+void *mem_pool_alloc(struct mem_pool *mp, size_t sz)
+{
+	void *p;
+
+	/* Make all allocations be at least 8 byte aligned. */
+	sz = ALIGN_UP(sz, 8);
+
+	/* Determine if any space available. */
+	if ((mp->size - mp->free_offset) < sz)
+		return NULL;
+
+	p = &mp->buf[mp->free_offset];
+
+	mp->free_offset += sz;
+	mp->last_alloc = p;
+
+	return p;
+}
+
+void mem_pool_free(struct mem_pool *mp, void *p)
+{
+	/* Determine if p was the most recent allocation. */
+	if (p == NULL || mp->last_alloc != p)
+		return;
+
+	mp->free_offset = mp->last_alloc - mp->buf;
+	/* No way to track allocation before this one. */
+	mp->last_alloc = NULL;
+}
diff --git a/tools/cbfstool/partitioned_file.c b/tools/cbfstool/partitioned_file.c
new file mode 100644
index 0000000000..a2d9ddfee2
--- /dev/null
+++ b/tools/cbfstool/partitioned_file.c
@@ -0,0 +1,368 @@
+/*
+ * partitioned_file.c, read and write binary file "partitions" described by FMAP
+ *
+ * Copyright (C) 2015 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include "partitioned_file.h"
+
+#include "cbfs_sections.h"
+
+#include <assert.h>
+#include <stdlib.h>
+#include <string.h>
+
+struct partitioned_file {
+	struct fmap *fmap;
+	struct buffer buffer;
+	FILE *stream;
+};
+
+static bool fill_ones_through(struct partitioned_file *file)
+{
+	assert(file);
+
+	memset(file->buffer.data, 0xff, file->buffer.size);
+	return partitioned_file_write_region(file, &file->buffer);
+}
+
+static unsigned count_selected_fmap_entries(const struct fmap *fmap,
+		partitioned_file_fmap_selector_t callback, const void *arg)
+{
+	assert(fmap);
+	assert(callback);
+
+	unsigned count = 0;
+	for (unsigned i = 0; i < fmap->nareas; ++i) {
+		if (callback(fmap->areas + i, arg))
+			++count;
+	}
+	return count;
+}
+
+static partitioned_file_t *reopen_flat_file(const char *filename,
+					    bool write_access)
+{
+	assert(filename);
+	struct partitioned_file *file = calloc(1, sizeof(*file));
+	const char *access_mode;
+
+	if (!file) {
+		ERROR("Failed to allocate partitioned file structure\n");
+		return NULL;
+	}
+
+	if (buffer_from_file(&file->buffer, filename)) {
+		free(file);
+		return NULL;
+	}
+
+	access_mode = write_access ?  "rb+" : "rb";
+	file->stream = fopen(filename, access_mode);
+
+	if (!file->stream) {
+		perror(filename);
+		partitioned_file_close(file);
+		return NULL;
+	}
+
+	return file;
+}
+
+partitioned_file_t *partitioned_file_create_flat(const char *filename,
+							size_t image_size)
+{
+	assert(filename);
+
+	struct partitioned_file *file = calloc(1, sizeof(*file));
+	if (!file) {
+		ERROR("Failed to allocate partitioned file structure\n");
+		return NULL;
+	}
+
+	file->stream = fopen(filename, "wb");
+	if (!file->stream) {
+		perror(filename);
+		free(file);
+		return NULL;
+	}
+
+	if (buffer_create(&file->buffer, image_size, filename)) {
+		partitioned_file_close(file);
+		return NULL;
+	}
+
+	if (!fill_ones_through(file)) {
+		partitioned_file_close(file);
+		return NULL;
+	}
+
+	return file;
+}
+
+partitioned_file_t *partitioned_file_create(const char *filename,
+							struct buffer *flashmap)
+{
+	assert(filename);
+	assert(flashmap);
+	assert(flashmap->data);
+
+	if (fmap_find((const uint8_t *)flashmap->data, flashmap->size) != 0) {
+		ERROR("Attempted to create a partitioned image out of something that isn't an FMAP\n");
+		return NULL;
+	}
+	struct fmap *bootstrap_fmap = (struct fmap *)flashmap->data;
+
+	const struct fmap_area *fmap_area =
+			fmap_find_area(bootstrap_fmap, SECTION_NAME_FMAP);
+	if (!fmap_area) {
+		ERROR("Provided FMAP missing '%s' region\n", SECTION_NAME_FMAP);
+		return NULL;
+	}
+
+	if (count_selected_fmap_entries(bootstrap_fmap,
+		partitioned_file_fmap_select_children_of, fmap_area)) {
+		ERROR("Provided FMAP's '%s' region contains other regions\n",
+							SECTION_NAME_FMAP);
+		return NULL;
+	}
+
+	int fmap_len = fmap_size(bootstrap_fmap);
+	if (fmap_len < 0) {
+		ERROR("Unable to determine size of provided FMAP\n");
+		return NULL;
+	}
+	assert((size_t)fmap_len <= flashmap->size);
+	if ((uint32_t)fmap_len > fmap_area->size) {
+		ERROR("Provided FMAP's '%s' region needs to be at least %d bytes\n",
+						SECTION_NAME_FMAP, fmap_len);
+		return NULL;
+	}
+
+	partitioned_file_t *file = partitioned_file_create_flat(filename,
+							bootstrap_fmap->size);
+	if (!file)
+		return NULL;
+
+	struct buffer fmap_region;
+	buffer_splice(&fmap_region, &file->buffer, fmap_area->offset, fmap_area->size);
+	memcpy(fmap_region.data, bootstrap_fmap, fmap_len);
+	if (!partitioned_file_write_region(file, &fmap_region)) {
+		partitioned_file_close(file);
+		return NULL;
+	}
+	file->fmap = (struct fmap *)(file->buffer.data + fmap_area->offset);
+
+	return file;
+}
+
+partitioned_file_t *partitioned_file_reopen(const char *filename,
+					    bool write_access)
+{
+	assert(filename);
+
+	partitioned_file_t *file = reopen_flat_file(filename, write_access);
+	if (!file)
+		return NULL;
+
+	long fmap_region_offset = fmap_find((const uint8_t *)file->buffer.data,
+							file->buffer.size);
+	if (fmap_region_offset < 0) {
+		INFO("Opening image as a flat file because it doesn't contain any FMAP\n");
+		return file;
+	}
+	file->fmap = (struct fmap *)(file->buffer.data + fmap_region_offset);
+
+	if (file->fmap->size > file->buffer.size) {
+		int fmap_region_size = fmap_size(file->fmap);
+		ERROR("FMAP records image size as %u, but file is only %zu bytes%s\n",
+					file->fmap->size, file->buffer.size,
+						fmap_region_offset == 0 &&
+				(signed)file->buffer.size == fmap_region_size ?
+				" (is it really an image, or *just* an FMAP?)" :
+					" (did something truncate this file?)");
+		partitioned_file_close(file);
+		return NULL;
+	}
+
+	const struct fmap_area *fmap_fmap_entry =
+				fmap_find_area(file->fmap, SECTION_NAME_FMAP);
+
+	if (!fmap_fmap_entry) {
+		partitioned_file_close(file);
+		return NULL;
+	}
+
+	if ((long)fmap_fmap_entry->offset != fmap_region_offset) {
+		ERROR("FMAP's '%s' section doesn't point back to FMAP start (did something corrupt this file?)\n",
+							SECTION_NAME_FMAP);
+		partitioned_file_close(file);
+		return NULL;
+	}
+
+	return file;
+}
+
+bool partitioned_file_write_region(partitioned_file_t *file,
+						const struct buffer *buffer)
+{
+	assert(file);
+	assert(file->stream);
+	assert(buffer);
+	assert(buffer->data);
+
+	if (buffer->data - buffer->offset != file->buffer.data) {
+		ERROR("Attempted to write a partition buffer back to a different file than it came from\n");
+		return false;
+	}
+	if (buffer->offset + buffer->size > file->buffer.size) {
+		ERROR("Attempted to write data off the end of image file\n");
+		return false;
+	}
+
+	if (fseek(file->stream, buffer->offset, SEEK_SET)) {
+		ERROR("Failed to seek within image file\n");
+		return false;
+	}
+	if (!fwrite(buffer->data, buffer->size, 1, file->stream)) {
+		ERROR("Failed to write to image file\n");
+		return false;
+	}
+	return true;
+}
+
+bool partitioned_file_read_region(struct buffer *dest,
+			const partitioned_file_t *file, const char *region)
+{
+	assert(dest);
+	assert(file);
+	assert(file->buffer.data);
+	assert(region);
+
+	if (file->fmap) {
+		const struct fmap_area *area = fmap_find_area(file->fmap,
+									region);
+		if (!area) {
+			ERROR("Image is missing '%s' region\n", region);
+			return false;
+		}
+		if (area->offset + area->size > file->buffer.size) {
+			ERROR("Region '%s' runs off the end of the image file\n",
+									region);
+			return false;
+		}
+		buffer_splice(dest, &file->buffer, area->offset, area->size);
+	} else {
+		if (strcmp(region, SECTION_NAME_PRIMARY_CBFS) != 0) {
+			ERROR("This is a legacy image that contains only a CBFS\n");
+			return false;
+		}
+		buffer_clone(dest, &file->buffer);
+	}
+
+	return true;
+}
+
+void partitioned_file_close(partitioned_file_t *file)
+{
+	if (!file)
+		return;
+
+	file->fmap = NULL;
+	buffer_delete(&file->buffer);
+	if (file->stream) {
+		fclose(file->stream);
+		file->stream = NULL;
+	}
+	free(file);
+}
+
+bool partitioned_file_is_partitioned(const partitioned_file_t *file)
+{
+	return partitioned_file_get_fmap(file) != NULL;
+}
+
+size_t partitioned_file_total_size(const partitioned_file_t *file)
+{
+	assert(file);
+
+	return file->buffer.size;
+}
+
+bool partitioned_file_region_check_magic(const partitioned_file_t *file,
+			const char *region, const char *magic, size_t magic_len)
+{
+	struct buffer area;
+	return partitioned_file_read_region(&area, file, region) &&
+				buffer_check_magic(&area, magic, magic_len);
+}
+
+bool partitioned_file_region_contains_nested(const partitioned_file_t *file,
+							const char *region)
+{
+	assert(file);
+	assert(region);
+
+	if (!file->fmap)
+		return false;
+	const struct fmap_area *area = fmap_find_area(file->fmap, region);
+	return area && partitioned_file_fmap_count(file,
+			partitioned_file_fmap_select_children_of, area);
+}
+
+const struct fmap *partitioned_file_get_fmap(const partitioned_file_t *file)
+{
+	assert(file);
+
+	return file->fmap;
+}
+
+unsigned partitioned_file_fmap_count(const partitioned_file_t *file,
+		partitioned_file_fmap_selector_t callback, const void *arg)
+{
+	assert(file);
+	assert(callback);
+
+	if (!file->fmap)
+		return 0;
+	return count_selected_fmap_entries(file->fmap, callback, arg);
+}
+
+static bool select_all(unused const struct fmap_area *area,
+							unused const void *arg)
+{
+	return true;
+}
+const partitioned_file_fmap_selector_t partitioned_file_fmap_select_all =
+								select_all;
+
+static bool select_children_of(const struct fmap_area *child, const void *arg)
+{
+	assert(child);
+	assert(arg);
+
+	const struct fmap_area *parent = (const struct fmap_area *)arg;
+	if (child == arg || (child->offset == parent->offset &&
+						child->size == parent->size))
+		return false;
+	return child->offset >= parent->offset &&
+		child->offset + child->size <= parent->offset + parent->size;
+}
+const partitioned_file_fmap_selector_t
+		partitioned_file_fmap_select_children_of = select_children_of;
+
+static bool select_parents_of(const struct fmap_area *parent, const void *arg)
+{
+	return select_children_of((const struct fmap_area *)arg, parent);
+}
+const partitioned_file_fmap_selector_t partitioned_file_fmap_select_parents_of =
+							select_parents_of;
diff --git a/tools/cbfstool/partitioned_file.h b/tools/cbfstool/partitioned_file.h
new file mode 100644
index 0000000000..5a8f4dd5af
--- /dev/null
+++ b/tools/cbfstool/partitioned_file.h
@@ -0,0 +1,161 @@
+/*
+ * partitioned_file.h, read and write binary file "partitions" described by FMAP
+ *
+ * Copyright (C) 2015 Google, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef PARITITONED_FILE_H_
+#define PARITITONED_FILE_H_
+
+#include "common.h"
+#include "flashmap/fmap.h"
+
+#include <stdbool.h>
+#include <stddef.h>
+
+typedef struct partitioned_file partitioned_file_t;
+
+/**
+ * Create a new filesystem-backed flat buffer.
+ * This backwards-compatibility function creates a new in-memory buffer and
+ * backing binary file of the specified size. Although the file won't actually
+ * have multiple regions, it'll still be possible to access and manipulate it
+ * using this module; this is accomplished by requesting the special region
+ * whose name matches SECTION_NAME_PRIMARY_CBFS, which maps to the whole file.
+ * Note that the caller will be responsible for calling partitioned_file_close()
+ * on the returned object, and that this function will overwrite any existing
+ * file with the given name without warning.
+ *
+ * @param filename   Name of the backing file
+ * @param image_size Size of the image
+ * @return           Caller-owned partitioned file, or NULL on error
+ */
+partitioned_file_t *partitioned_file_create_flat(const char *filename,
+							size_t image_size);
+
+/**
+ * Create a new filesystem-backed partitioned buffer.
+ * This creates a new in-memory buffer and backing binary file. Both are
+ * segmented into regions according to the provided flashmap's sections, and the
+ * flashmap itself is automatically copied into the region named
+ * SECTION_NAME_FMAP: a section with this name must already exist in the FMAP.
+ * After calling this function, it is safe for the caller to clean up flashmap
+ * at any time. The partitioned_file_t returned from this function is separately
+ * owned by the caller, and must later be passed to partitioned_file_close().
+ * Note that this function will overwrite any existing file with the given name
+ * without warning.
+ *
+ * @param filename Name of the backing file
+ * @param flashmap Buffer containing an FMAP file layout
+ * @return         Caller-owned partitioned file, or NULL on error
+ */
+partitioned_file_t *partitioned_file_create(const char *filename,
+						struct buffer *flashmap);
+
+/**
+ * Read a file back in from the disk.
+ * An in-memory buffer is created and populated with the file's
+ * contents. If the image contains an FMAP, it will be opened as a
+ * full partitioned file; otherwise, it will be opened as a flat file as
+ * if it had been created by partitioned_file_create_flat().
+ * The partitioned_file_t returned from this function is separately owned by the
+ * caller, and must later be passed to partitioned_file_close();
+ *
+ * @param filename      Name of the file to read in
+ * @param write_access  True if the file needs to be modified
+ * @return              Caller-owned partitioned file, or NULL on error
+ */
+partitioned_file_t *partitioned_file_reopen(const char *filename,
+					    bool write_access);
+
+/**
+ * Write a buffer's contents to its original region within a segmented file.
+ * This function should only be called on buffers originally retrieved by a call
+ * to partitioned_file_read_region() on the same partitioned file object. The
+ * contents of this buffer are copied back to the same region of the buffer and
+ * backing file that the region occupied before.
+ *
+ * @param file   Partitioned file to which to write the data
+ * @param buffer Modified buffer obtained from partitioned_file_read_region()
+ * @return       Whether the operation was successful
+ */
+bool partitioned_file_write_region(partitioned_file_t *file,
+						const struct buffer *buffer);
+
+/**
+ * Obtain one particular region of a segmented file.
+ * The result is owned by the partitioned_file_t and shared among every caller
+ * of this function. Thus, it is an error to buffer_delete() it; instead, clean
+ * up the entire partitioned_file_t once it's no longer needed with a single
+ * call to partitioned_file_close().
+ * Note that, if the buffer obtained from this function is modified, the changes
+ * will be reflected in any buffers handed out---whether earlier or later---for
+ * any region inclusive of the altered location(s). However, the backing file
+ * will not be updated until someone calls partitioned_file_write_region() on a
+ * buffer that includes the alterations.
+ *
+ * @param dest   Empty destination buffer for the data
+ * @param file   Partitioned file from which to read the data
+ * @param region Name of the desired FMAP region
+ * @return       Whether the copy was performed successfully
+ */
+bool partitioned_file_read_region(struct buffer *dest,
+			const partitioned_file_t *file, const char *region);
+
+/** @param file Partitioned file to flush and cleanup */
+void partitioned_file_close(partitioned_file_t *file);
+
+/** @return Whether the file is partitioned (i.e. not flat). */
+bool partitioned_file_is_partitioned(const partitioned_file_t *file);
+
+/** @return The image's overall filesize, regardless of whether it's flat. */
+size_t partitioned_file_total_size(const partitioned_file_t *file);
+
+/** @return Whether the specified region begins with the magic bytes. */
+bool partitioned_file_region_check_magic(const partitioned_file_t *file,
+		const char *region, const char *magic, size_t magic_len);
+
+/** @return Whether the specified region exists and contains nested regions. */
+bool partitioned_file_region_contains_nested(const partitioned_file_t *file,
+							const char *region);
+
+/** @return An immutable reference to the FMAP, or NULL for flat images. */
+const struct fmap *partitioned_file_get_fmap(const partitioned_file_t *file);
+
+/** @return Whether to include area in the running count. */
+typedef bool (*partitioned_file_fmap_selector_t)
+				(const struct fmap_area *area, const void *arg);
+
+/**
+ * Count the number of FMAP entries fulfilling a certain criterion.
+ * The result is always 0 if run on a flat (non-partitioned) image.
+ *
+ * @param file     File on whose FMAP entries the operation should be run
+ * @param callback Decider answering whether each individual region should count
+ * @param arg      Additional information to furnish to the decider on each call
+ * @return         The number of FMAP sections with that property
+ */
+unsigned partitioned_file_fmap_count(const partitioned_file_t *file,
+		partitioned_file_fmap_selector_t callback, const void *arg);
+
+/** Selector that counts every single FMAP section. */
+extern const partitioned_file_fmap_selector_t partitioned_file_fmap_select_all;
+
+/** Selector that counts FMAP sections that are descendants of fmap_area arg. */
+extern const partitioned_file_fmap_selector_t
+				partitioned_file_fmap_select_children_of;
+
+/** Selector that counts FMAP sections that contain the fmap_area arg. */
+extern const partitioned_file_fmap_selector_t
+					partitioned_file_fmap_select_parents_of;
+
+#endif
diff --git a/tools/cbfstool/region.c b/tools/cbfstool/region.c
new file mode 100644
index 0000000000..ca7b6efe4b
--- /dev/null
+++ b/tools/cbfstool/region.c
@@ -0,0 +1,516 @@
+/*
+ * This file is part of the coreboot project.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <commonlib/helpers.h>
+#include <commonlib/region.h>
+#include <string.h>
+
+static inline size_t region_end(const struct region *r)
+{
+	return region_sz(r) + region_offset(r);
+}
+
+int region_is_subregion(const struct region *p, const struct region *c)
+{
+	if (region_offset(c) < region_offset(p))
+		return 0;
+
+	if (region_end(c) > region_end(p))
+		return 0;
+
+	if (region_end(c) < region_offset(c))
+		return 0;
+
+	return 1;
+}
+
+static int normalize_and_ok(const struct region *outer, struct region *inner)
+{
+	inner->offset += region_offset(outer);
+	return region_is_subregion(outer, inner);
+}
+
+static const struct region_device *rdev_root(const struct region_device *rdev)
+{
+	if (rdev->root == NULL)
+		return rdev;
+	return rdev->root;
+}
+
+ssize_t rdev_relative_offset(const struct region_device *p,
+				const struct region_device *c)
+{
+	if (rdev_root(p) != rdev_root(c))
+		return -1;
+
+	if (!region_is_subregion(&p->region, &c->region))
+		return -1;
+
+	return region_device_offset(c) - region_device_offset(p);
+}
+
+void *rdev_mmap(const struct region_device *rd, size_t offset, size_t size)
+{
+	const struct region_device *rdev;
+	struct region req = {
+		.offset = offset,
+		.size = size,
+	};
+
+	if (!normalize_and_ok(&rd->region, &req))
+		return NULL;
+
+	rdev = rdev_root(rd);
+
+	if (rdev->ops->mmap == NULL)
+		return NULL;
+
+	return rdev->ops->mmap(rdev, req.offset, req.size);
+}
+
+int rdev_munmap(const struct region_device *rd, void *mapping)
+{
+	const struct region_device *rdev;
+
+	rdev = rdev_root(rd);
+
+	if (rdev->ops->munmap == NULL)
+		return -1;
+
+	return rdev->ops->munmap(rdev, mapping);
+}
+
+ssize_t rdev_readat(const struct region_device *rd, void *b, size_t offset,
+			size_t size)
+{
+	const struct region_device *rdev;
+	struct region req = {
+		.offset = offset,
+		.size = size,
+	};
+
+	if (!normalize_and_ok(&rd->region, &req))
+		return -1;
+
+	rdev = rdev_root(rd);
+
+	return rdev->ops->readat(rdev, b, req.offset, req.size);
+}
+
+ssize_t rdev_writeat(const struct region_device *rd, const void *b,
+			size_t offset, size_t size)
+{
+	const struct region_device *rdev;
+	struct region req = {
+		.offset = offset,
+		.size = size,
+	};
+
+	if (!normalize_and_ok(&rd->region, &req))
+		return -1;
+
+	rdev = rdev_root(rd);
+
+	if (rdev->ops->writeat == NULL)
+		return -1;
+
+	return rdev->ops->writeat(rdev, b, req.offset, req.size);
+}
+
+ssize_t rdev_eraseat(const struct region_device *rd, size_t offset,
+			size_t size)
+{
+	const struct region_device *rdev;
+	struct region req = {
+		.offset = offset,
+		.size = size,
+	};
+
+	if (!normalize_and_ok(&rd->region, &req))
+		return -1;
+
+	rdev = rdev_root(rd);
+
+	/* If the eraseat ptr is NULL we assume that the erase
+	 * function was completed successfully. */
+	if (rdev->ops->eraseat == NULL)
+		return size;
+
+	return rdev->ops->eraseat(rdev, req.offset, req.size);
+}
+
+int rdev_chain(struct region_device *child, const struct region_device *parent,
+		size_t offset, size_t size)
+{
+	struct region req = {
+		.offset = offset,
+		.size = size,
+	};
+
+	if (!normalize_and_ok(&parent->region, &req))
+		return -1;
+
+	/* Keep track of root region device. Note the offsets are relative
+	 * to the root device. */
+	child->root = rdev_root(parent);
+	child->ops = NULL;
+	child->region.offset = req.offset;
+	child->region.size = req.size;
+
+	return 0;
+}
+
+static void mem_region_device_init(struct mem_region_device *mdev,
+		const struct region_device_ops *ops, void *base, size_t size)
+{
+	memset(mdev, 0, sizeof(*mdev));
+	mdev->base = base;
+	mdev->rdev.ops = ops;
+	mdev->rdev.region.size = size;
+}
+
+void mem_region_device_ro_init(struct mem_region_device *mdev, void *base,
+				size_t size)
+{
+	return mem_region_device_init(mdev, &mem_rdev_ro_ops, base, size);
+}
+
+void mem_region_device_rw_init(struct mem_region_device *mdev, void *base,
+		size_t size)
+{
+	return mem_region_device_init(mdev, &mem_rdev_rw_ops, base, size);
+}
+
+void region_device_init(struct region_device *rdev,
+			const struct region_device_ops *ops, size_t offset,
+			size_t size)
+{
+	memset(rdev, 0, sizeof(*rdev));
+	rdev->root = NULL;
+	rdev->ops = ops;
+	rdev->region.offset = offset;
+	rdev->region.size = size;
+}
+
+static void xlate_region_device_init(struct xlate_region_device *xdev,
+			const struct region_device_ops *ops,
+			const struct region_device *access_dev,
+			size_t sub_offset, size_t sub_size,
+			size_t parent_size)
+{
+	memset(xdev, 0, sizeof(*xdev));
+	xdev->access_dev = access_dev;
+	xdev->sub_region.offset = sub_offset;
+	xdev->sub_region.size = sub_size;
+	region_device_init(&xdev->rdev, ops, 0, parent_size);
+}
+
+void xlate_region_device_ro_init(struct xlate_region_device *xdev,
+			      const struct region_device *access_dev,
+			      size_t sub_offset, size_t sub_size,
+			      size_t parent_size)
+{
+	xlate_region_device_init(xdev, &xlate_rdev_ro_ops, access_dev,
+			sub_offset, sub_size, parent_size);
+}
+
+void xlate_region_device_rw_init(struct xlate_region_device *xdev,
+			      const struct region_device *access_dev,
+			      size_t sub_offset, size_t sub_size,
+			      size_t parent_size)
+{
+	xlate_region_device_init(xdev, &xlate_rdev_rw_ops, access_dev,
+			sub_offset, sub_size, parent_size);
+}
+
+static void *mdev_mmap(const struct region_device *rd, size_t offset,
+			size_t size __unused)
+{
+	const struct mem_region_device *mdev;
+
+	mdev = container_of(rd, __typeof__(*mdev), rdev);
+
+	return &mdev->base[offset];
+}
+
+static int mdev_munmap(const struct region_device *rd __unused,
+			void *mapping __unused)
+{
+	return 0;
+}
+
+static ssize_t mdev_readat(const struct region_device *rd, void *b,
+				size_t offset, size_t size)
+{
+	const struct mem_region_device *mdev;
+
+	mdev = container_of(rd, __typeof__(*mdev), rdev);
+
+	memcpy(b, &mdev->base[offset], size);
+
+	return size;
+}
+
+static ssize_t mdev_writeat(const struct region_device *rd, const void *b,
+				size_t offset, size_t size)
+{
+	const struct mem_region_device *mdev;
+
+	mdev = container_of(rd, __typeof__(*mdev), rdev);
+
+	memcpy(&mdev->base[offset], b, size);
+
+	return size;
+}
+
+static ssize_t mdev_eraseat(const struct region_device *rd, size_t offset,
+				size_t size)
+{
+	const struct mem_region_device *mdev;
+
+	mdev = container_of(rd, __typeof__(*mdev), rdev);
+
+	memset(&mdev->base[offset], 0, size);
+
+	return size;
+}
+
+const struct region_device_ops mem_rdev_ro_ops = {
+	.mmap = mdev_mmap,
+	.munmap = mdev_munmap,
+	.readat = mdev_readat,
+};
+
+const struct region_device_ops mem_rdev_rw_ops = {
+	.mmap = mdev_mmap,
+	.munmap = mdev_munmap,
+	.readat = mdev_readat,
+	.writeat = mdev_writeat,
+	.eraseat = mdev_eraseat,
+};
+
+void mmap_helper_device_init(struct mmap_helper_region_device *mdev,
+				void *cache, size_t cache_size)
+{
+	mem_pool_init(&mdev->pool, cache, cache_size);
+}
+
+void *mmap_helper_rdev_mmap(const struct region_device *rd, size_t offset,
+				size_t size)
+{
+	struct mmap_helper_region_device *mdev;
+	void *mapping;
+
+	mdev = container_of((void *)rd, __typeof__(*mdev), rdev);
+
+	mapping = mem_pool_alloc(&mdev->pool, size);
+
+	if (mapping == NULL)
+		return NULL;
+
+	if (rd->ops->readat(rd, mapping, offset, size) != size) {
+		mem_pool_free(&mdev->pool, mapping);
+		return NULL;
+	}
+
+	return mapping;
+}
+
+int mmap_helper_rdev_munmap(const struct region_device *rd, void *mapping)
+{
+	struct mmap_helper_region_device *mdev;
+
+	mdev = container_of((void *)rd, __typeof__(*mdev), rdev);
+
+	mem_pool_free(&mdev->pool, mapping);
+
+	return 0;
+}
+
+static void *xlate_mmap(const struct region_device *rd, size_t offset,
+			size_t size)
+{
+	const struct xlate_region_device *xldev;
+	struct region req = {
+		.offset = offset,
+		.size = size,
+	};
+
+	xldev = container_of(rd, __typeof__(*xldev), rdev);
+
+	if (!region_is_subregion(&xldev->sub_region, &req))
+		return NULL;
+
+	offset -= region_offset(&xldev->sub_region);
+
+	return rdev_mmap(xldev->access_dev, offset, size);
+}
+
+static int xlate_munmap(const struct region_device *rd, void *mapping)
+{
+	const struct xlate_region_device *xldev;
+
+	xldev = container_of(rd, __typeof__(*xldev), rdev);
+
+	return rdev_munmap(xldev->access_dev, mapping);
+}
+
+static ssize_t xlate_readat(const struct region_device *rd, void *b,
+				size_t offset, size_t size)
+{
+	struct region req = {
+		.offset = offset,
+		.size = size,
+	};
+	const struct xlate_region_device *xldev;
+
+	xldev = container_of(rd, __typeof__(*xldev), rdev);
+
+	if (!region_is_subregion(&xldev->sub_region, &req))
+		return -1;
+
+	offset -= region_offset(&xldev->sub_region);
+
+	return rdev_readat(xldev->access_dev, b, offset, size);
+}
+
+static ssize_t xlate_writeat(const struct region_device *rd, const void *b,
+				size_t offset, size_t size)
+{
+	struct region req = {
+		.offset = offset,
+		.size = size,
+	};
+	const struct xlate_region_device *xldev;
+
+	xldev = container_of(rd, __typeof__(*xldev), rdev);
+
+	if (!region_is_subregion(&xldev->sub_region, &req))
+		return -1;
+
+	offset -= region_offset(&xldev->sub_region);
+
+	return rdev_writeat(xldev->access_dev, b, offset, size);
+}
+
+static ssize_t xlate_eraseat(const struct region_device *rd,
+				size_t offset, size_t size)
+{
+	struct region req = {
+		.offset = offset,
+		.size = size,
+	};
+	const struct xlate_region_device *xldev;
+
+	xldev = container_of(rd, __typeof__(*xldev), rdev);
+
+	if (!region_is_subregion(&xldev->sub_region, &req))
+		return -1;
+
+	offset -= region_offset(&xldev->sub_region);
+
+	return rdev_eraseat(xldev->access_dev, offset, size);
+}
+
+const struct region_device_ops xlate_rdev_ro_ops = {
+	.mmap = xlate_mmap,
+	.munmap = xlate_munmap,
+	.readat = xlate_readat,
+};
+
+const struct region_device_ops xlate_rdev_rw_ops = {
+	.mmap = xlate_mmap,
+	.munmap = xlate_munmap,
+	.readat = xlate_readat,
+	.writeat = xlate_writeat,
+	.eraseat = xlate_eraseat,
+};
+
+
+static void *incoherent_mmap(const struct region_device *rd, size_t offset,
+				size_t size)
+{
+	const struct incoherent_rdev *irdev;
+
+	irdev = container_of(rd, const struct incoherent_rdev, rdev);
+
+	return rdev_mmap(irdev->read, offset, size);
+}
+
+static int incoherent_munmap(const struct region_device *rd, void *mapping)
+{
+	const struct incoherent_rdev *irdev;
+
+	irdev = container_of(rd, const struct incoherent_rdev, rdev);
+
+	return rdev_munmap(irdev->read, mapping);
+}
+
+static ssize_t incoherent_readat(const struct region_device *rd, void *b,
+				size_t offset, size_t size)
+{
+	const struct incoherent_rdev *irdev;
+
+	irdev = container_of(rd, const struct incoherent_rdev, rdev);
+
+	return rdev_readat(irdev->read, b, offset, size);
+}
+
+static ssize_t incoherent_writeat(const struct region_device *rd, const void *b,
+			size_t offset, size_t size)
+{
+	const struct incoherent_rdev *irdev;
+
+	irdev = container_of(rd, const struct incoherent_rdev, rdev);
+
+	return rdev_writeat(irdev->write, b, offset, size);
+}
+
+static ssize_t incoherent_eraseat(const struct region_device *rd, size_t offset,
+				size_t size)
+{
+	const struct incoherent_rdev *irdev;
+
+	irdev = container_of(rd, const struct incoherent_rdev, rdev);
+
+	return rdev_eraseat(irdev->write, offset, size);
+}
+
+static const struct region_device_ops incoherent_rdev_ops = {
+	.mmap = incoherent_mmap,
+	.munmap = incoherent_munmap,
+	.readat = incoherent_readat,
+	.writeat = incoherent_writeat,
+	.eraseat = incoherent_eraseat,
+};
+
+const struct region_device *incoherent_rdev_init(struct incoherent_rdev *irdev,
+				const struct region *r,
+				const struct region_device *read,
+				const struct region_device *write)
+{
+	const size_t size = region_sz(r);
+
+	if (size != region_device_sz(read) || size != region_device_sz(write))
+		return NULL;
+
+	/* The region is represented as offset 0 to size. That way, the generic
+	 * rdev operations can be called on the read or write implementation
+	 * without any unnecessary translation because the offsets all start
+	 * at 0. */
+	region_device_init(&irdev->rdev, &incoherent_rdev_ops, 0, size);
+	irdev->read = read;
+	irdev->write = write;
+
+	return &irdev->rdev;
+}
diff --git a/tools/cbfstool/rmodule.c b/tools/cbfstool/rmodule.c
new file mode 100644
index 0000000000..80e89118e5
--- /dev/null
+++ b/tools/cbfstool/rmodule.c
@@ -0,0 +1,883 @@
+/*
+ * Copyright (C) 2014 Google, Inc.
+ * Copyright (C) 2018 Eltan B.V.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <inttypes.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#include "elfparsing.h"
+#include "rmodule.h"
+#include <commonlib/rmodule-defs.h>
+
+/*
+ * Architecture specific support operations.
+ */
+static int valid_reloc_386(Elf64_Rela *rel)
+{
+	int type;
+
+	type = ELF64_R_TYPE(rel->r_info);
+
+	/* Only these 2 relocations are expected to be found. */
+	return (type == R_386_32 || type == R_386_PC32);
+}
+
+static int should_emit_386(Elf64_Rela *rel)
+{
+	int type;
+
+	type = ELF64_R_TYPE(rel->r_info);
+
+	/* R_386_32 relocations are absolute. Must emit these. */
+	return (type == R_386_32);
+}
+
+static int valid_reloc_amd64(Elf64_Rela *rel)
+{
+	int type;
+
+	type = ELF64_R_TYPE(rel->r_info);
+
+	/* Only these 6 relocations are expected to be found. */
+	return (type == R_AMD64_64 ||
+		type == R_AMD64_PC64 ||
+		type == R_AMD64_32S ||
+		type == R_AMD64_32 ||
+		type == R_AMD64_PC32 ||
+	/*
+	 * binutils 2.31 introduced R_AMD64_PLT32 for non local
+	 * functions. As we don't care about procedure linkage
+	 * table entries handle it as R_X86_64_PC32.
+	 */
+		type == R_AMD64_PLT32);
+}
+
+static int should_emit_amd64(Elf64_Rela *rel)
+{
+	int type;
+
+	type = ELF64_R_TYPE(rel->r_info);
+
+	/* Only emit absolute relocations */
+	return (type == R_AMD64_64 ||
+		type == R_AMD64_32S ||
+		type == R_AMD64_32);
+}
+
+static int valid_reloc_arm(Elf64_Rela *rel)
+{
+	int type;
+
+	type = ELF64_R_TYPE(rel->r_info);
+
+	/* Only these 6 relocations are expected to be found. */
+	return (type == R_ARM_ABS32 || type == R_ARM_THM_PC22 ||
+                type == R_ARM_THM_JUMP24 || type == R_ARM_V4BX ||
+		type == R_ARM_CALL || type == R_ARM_JUMP24);
+}
+
+static int should_emit_arm(Elf64_Rela *rel)
+{
+	int type;
+
+	type = ELF64_R_TYPE(rel->r_info);
+
+	/* R_ARM_ABS32 relocations are absolute. Must emit these. */
+	return (type == R_ARM_ABS32);
+}
+
+static int valid_reloc_aarch64(Elf64_Rela *rel)
+{
+	int type;
+
+	type = ELF64_R_TYPE(rel->r_info);
+
+	return (type == R_AARCH64_ADR_PREL_PG_HI21 ||
+		type == R_AARCH64_ADD_ABS_LO12_NC  ||
+		type == R_AARCH64_LDST8_ABS_LO12_NC ||
+		type == R_AARCH64_CONDBR19 ||
+		type == R_AARCH64_JUMP26 ||
+		type == R_AARCH64_LDST32_ABS_LO12_NC ||
+		type == R_AARCH64_LDST64_ABS_LO12_NC ||
+		type == R_AARCH64_CALL26 ||
+		type == R_AARCH64_ABS64 ||
+		type == R_AARCH64_LD_PREL_LO19 ||
+		type == R_AARCH64_ADR_PREL_LO21);
+}
+
+static int should_emit_aarch64(Elf64_Rela *rel)
+{
+	int type;
+
+	type = ELF64_R_TYPE(rel->r_info);
+
+	return (type == R_AARCH64_ABS64);
+}
+
+static const struct arch_ops reloc_ops[] = {
+	{
+		.arch = EM_386,
+		.valid_type = valid_reloc_386,
+		.should_emit = should_emit_386,
+	},
+	{
+		.arch = EM_X86_64,
+		.valid_type = valid_reloc_amd64,
+		.should_emit = should_emit_amd64,
+	},
+	{
+		.arch = EM_ARM,
+		.valid_type = valid_reloc_arm,
+		.should_emit = should_emit_arm,
+	},
+	{
+		.arch = EM_AARCH64,
+		.valid_type = valid_reloc_aarch64,
+		.should_emit = should_emit_aarch64,
+	},
+};
+
+/*
+ * Relocation processing loops.
+ */
+
+static int for_each_reloc(struct rmod_context *ctx, struct reloc_filter *f,
+				int do_emit)
+{
+	Elf64_Half i;
+	struct parsed_elf *pelf = &ctx->pelf;
+
+	for (i = 0; i < pelf->ehdr.e_shnum; i++) {
+		Elf64_Shdr *shdr;
+		Elf64_Rela *relocs;
+		Elf64_Xword nrelocs;
+		Elf64_Xword j;
+
+		relocs = pelf->relocs[i];
+
+		/* No relocations in this section. */
+		if (relocs == NULL)
+			continue;
+
+		shdr = &pelf->shdr[i];
+		nrelocs = shdr->sh_size / shdr->sh_entsize;
+
+		for (j = 0; j < nrelocs; j++) {
+			int filter_emit = 1;
+			Elf64_Rela *r = &relocs[j];
+
+			if (!ctx->ops->valid_type(r)) {
+				ERROR("Invalid reloc type: %u\n",
+				      (unsigned int)ELF64_R_TYPE(r->r_info));
+				return -1;
+			}
+
+			/* Allow the provided filter to have precedence. */
+			if (f != NULL) {
+				filter_emit = f->filter(f, r);
+
+				if (filter_emit < 0)
+					return filter_emit;
+			}
+
+			if (filter_emit && ctx->ops->should_emit(r)) {
+				int n = ctx->nrelocs;
+				if (do_emit)
+					ctx->emitted_relocs[n] = r->r_offset;
+				ctx->nrelocs++;
+			}
+		}
+	}
+
+	return 0;
+}
+
+static int find_program_segment(struct rmod_context *ctx)
+{
+	int i;
+	int nsegments;
+	struct parsed_elf *pelf;
+	Elf64_Phdr *phdr = NULL;
+
+	pelf = &ctx->pelf;
+
+	/* There should only be a single loadable segment. */
+	nsegments = 0;
+	for (i = 0; i < pelf->ehdr.e_phnum; i++) {
+		if (pelf->phdr[i].p_type != PT_LOAD)
+			continue;
+		phdr = &pelf->phdr[i];
+		nsegments++;
+	}
+
+	if (nsegments != 1) {
+		ERROR("Unexepcted number of loadable segments: %d.\n",
+		      nsegments);
+		return -1;
+	}
+
+	INFO("Segment at 0x%0llx, file size 0x%0llx, mem size 0x%0llx.\n",
+	     (long long)phdr->p_vaddr, (long long)phdr->p_filesz,
+	     (long long)phdr->p_memsz);
+
+	ctx->phdr = phdr;
+
+	return 0;
+}
+
+static int
+filter_relocation_sections(struct rmod_context *ctx)
+{
+	int i;
+	const char *shstrtab;
+	struct parsed_elf *pelf;
+	const Elf64_Phdr *phdr;
+
+	pelf = &ctx->pelf;
+	phdr = ctx->phdr;
+	shstrtab = buffer_get(pelf->strtabs[pelf->ehdr.e_shstrndx]);
+
+	/*
+	 * Find all relocation sections that contain relocation entries
+	 * for sections that fall within the bounds of the segment. For
+	 * easier processing the pointer to the relocation array for the
+	 * sections that don't fall within the loadable program are NULL'd
+	 * out.
+	 */
+	for (i = 0; i < pelf->ehdr.e_shnum; i++) {
+		Elf64_Shdr *shdr;
+		Elf64_Word sh_info;
+		const char *section_name;
+
+		shdr = &pelf->shdr[i];
+
+		/* Ignore non-relocation sections. */
+		if (shdr->sh_type != SHT_RELA && shdr->sh_type != SHT_REL)
+			continue;
+
+		/* Obtain section which relocations apply. */
+		sh_info = shdr->sh_info;
+		shdr = &pelf->shdr[sh_info];
+
+		section_name = &shstrtab[shdr->sh_name];
+		DEBUG("Relocation section found for '%s' section.\n",
+		      section_name);
+
+		/* Do not process relocations for debug sections. */
+		if (strstr(section_name, ".debug") != NULL) {
+			pelf->relocs[i] = NULL;
+			continue;
+		}
+
+		/*
+		 * If relocations apply to a non program section ignore the
+		 * relocations for future processing.
+		 */
+		if (shdr->sh_type != SHT_PROGBITS) {
+			pelf->relocs[i] = NULL;
+			continue;
+		}
+
+		if (shdr->sh_addr < phdr->p_vaddr ||
+		    ((shdr->sh_addr + shdr->sh_size) >
+		     (phdr->p_vaddr + phdr->p_memsz))) {
+			ERROR("Relocations being applied to section %d not "
+			      "within segment region.\n", sh_info);
+			return -1;
+		}
+	}
+
+	return 0;
+}
+
+static int vaddr_cmp(const void *a, const void *b)
+{
+	const Elf64_Addr *pa = a;
+	const Elf64_Addr *pb = b;
+
+	if (*pa < *pb)
+		return -1;
+	if (*pa > *pb)
+		return 1;
+	return 0;
+}
+
+int rmodule_collect_relocations(struct rmod_context *ctx,
+				struct reloc_filter *f)
+{
+	Elf64_Xword nrelocs;
+
+	/*
+	 * The relocs array in the pelf should only contain relocations that
+	 * apply to the program. Count the number relocations. Then collect
+	 * them into the allocated buffer.
+	 */
+	if (for_each_reloc(ctx, f, 0))
+		return -1;
+
+	nrelocs = ctx->nrelocs;
+	INFO("%" PRIu64 " relocations to be emitted.\n", nrelocs);
+	if (!nrelocs)
+		return 0;
+
+	/* Reset the counter for indexing into the array. */
+	ctx->nrelocs = 0;
+	ctx->emitted_relocs = calloc(nrelocs, sizeof(Elf64_Addr));
+	/* Write out the relocations into the emitted_relocs array. */
+	if (for_each_reloc(ctx, f, 1))
+		return -1;
+
+	if (ctx->nrelocs != nrelocs) {
+		ERROR("Mismatch counted and emitted relocations: %zu vs %zu.\n",
+		      (size_t)nrelocs, (size_t)ctx->nrelocs);
+		return -1;
+	}
+
+	/* Sort the relocations by their address. */
+	qsort(ctx->emitted_relocs, nrelocs, sizeof(Elf64_Addr), vaddr_cmp);
+
+	return 0;
+}
+
+static int
+populate_sym(struct rmod_context *ctx, const char *sym_name, Elf64_Addr *addr,
+             int nsyms, const char *strtab, int optional)
+{
+	int i;
+	Elf64_Sym *syms;
+
+	syms = ctx->pelf.syms;
+
+	for (i = 0; i < nsyms; i++) {
+		if (syms[i].st_name == 0)
+			continue;
+		if (strcmp(sym_name, &strtab[syms[i].st_name]))
+			continue;
+		DEBUG("%s -> 0x%llx\n", sym_name, (long long)syms[i].st_value);
+		*addr = syms[i].st_value;
+		return 0;
+	}
+
+	if (optional) {
+		DEBUG("optional symbol '%s' not found.\n", sym_name);
+		*addr = 0;
+		return 0;
+	}
+
+	ERROR("symbol '%s' not found.\n", sym_name);
+	return -1;
+}
+
+static int populate_rmodule_info(struct rmod_context *ctx)
+{
+	int i;
+	const char *strtab;
+	struct parsed_elf *pelf;
+	Elf64_Ehdr *ehdr;
+	int nsyms;
+
+	pelf = &ctx->pelf;
+	ehdr = &pelf->ehdr;
+
+	/* Obtain the string table. */
+	strtab = NULL;
+	for (i = 0; i < ehdr->e_shnum; i++) {
+		if (ctx->pelf.strtabs[i] == NULL)
+			continue;
+		/* Don't use the section headers' string table. */
+		if (i == ehdr->e_shstrndx)
+			continue;
+		strtab = buffer_get(ctx->pelf.strtabs[i]);
+		break;
+	}
+
+	if (strtab == NULL) {
+		ERROR("No string table found.\n");
+		return -1;
+	}
+
+	/* Determine number of symbols. */
+	nsyms = 0;
+	for (i = 0; i < ehdr->e_shnum; i++) {
+		if (pelf->shdr[i].sh_type != SHT_SYMTAB)
+			continue;
+
+		nsyms = pelf->shdr[i].sh_size / pelf->shdr[i].sh_entsize;
+		break;
+	}
+
+	if (populate_sym(ctx, "_rmodule_params", &ctx->parameters_begin,
+	                 nsyms, strtab, 1))
+		return -1;
+
+	if (populate_sym(ctx, "_ermodule_params", &ctx->parameters_end,
+	                 nsyms, strtab, 1))
+		return -1;
+
+	if (populate_sym(ctx, "_bss", &ctx->bss_begin, nsyms, strtab, 0))
+		return -1;
+
+	if (populate_sym(ctx, "_ebss", &ctx->bss_end, nsyms, strtab, 0))
+		return -1;
+
+	return 0;
+}
+
+static int
+add_section(struct elf_writer *ew, struct buffer *data, const char *name,
+            Elf64_Addr addr, Elf64_Word size)
+{
+	Elf64_Shdr shdr;
+	int ret;
+
+	memset(&shdr, 0, sizeof(shdr));
+	if (data != NULL) {
+		shdr.sh_type = SHT_PROGBITS;
+		shdr.sh_flags = SHF_ALLOC | SHF_WRITE | SHF_EXECINSTR;
+	} else {
+		shdr.sh_type = SHT_NOBITS;
+		shdr.sh_flags = SHF_ALLOC;
+	}
+	shdr.sh_addr = addr;
+	shdr.sh_offset = addr;
+	shdr.sh_size = size;
+
+	ret = elf_writer_add_section(ew, &shdr, data, name);
+
+	if (ret)
+		ERROR("Could not add '%s' section.\n", name);
+
+	return ret;
+}
+
+static int
+write_elf(const struct rmod_context *ctx, const struct buffer *in,
+          struct buffer *out)
+{
+	int ret;
+	int bit64;
+	size_t loc;
+	size_t rmod_data_size;
+	struct elf_writer *ew;
+	struct buffer rmod_data;
+	struct buffer rmod_header;
+	struct buffer program;
+	struct buffer relocs;
+	Elf64_Xword total_size;
+	Elf64_Addr addr;
+	Elf64_Ehdr ehdr;
+
+	bit64 = ctx->pelf.ehdr.e_ident[EI_CLASS] == ELFCLASS64;
+
+	/*
+	 * 3 sections will be added  to the ELF file.
+	 * +------------------+
+	 * |  rmodule header  |
+	 * +------------------+
+	 * |     program      |
+	 * +------------------+
+	 * |   relocations    |
+	 * +------------------+
+	 */
+
+	/* Create buffer for header and relocations. */
+	rmod_data_size = sizeof(struct rmodule_header);
+	if (bit64)
+		rmod_data_size += ctx->nrelocs * sizeof(Elf64_Addr);
+	else
+		rmod_data_size += ctx->nrelocs * sizeof(Elf32_Addr);
+
+	if (buffer_create(&rmod_data, rmod_data_size, "rmod"))
+		return -1;
+
+	buffer_splice(&rmod_header, &rmod_data,
+	              0, sizeof(struct rmodule_header));
+	buffer_clone(&relocs, &rmod_data);
+	buffer_seek(&relocs, sizeof(struct rmodule_header));
+
+	/* Reset current location. */
+	buffer_set_size(&rmod_header, 0);
+	buffer_set_size(&relocs, 0);
+
+	/* Program contents. */
+	buffer_splice(&program, in, ctx->phdr->p_offset, ctx->phdr->p_filesz);
+
+	/* Create ELF writer with modified entry point. */
+	memcpy(&ehdr, &ctx->pelf.ehdr, sizeof(ehdr));
+	ew = elf_writer_init(&ehdr);
+
+	if (ew == NULL) {
+		ERROR("Failed to create ELF writer.\n");
+		buffer_delete(&rmod_data);
+		return -1;
+	}
+
+	/* Write out rmodule_header. */
+	ctx->xdr->put16(&rmod_header, RMODULE_MAGIC);
+	ctx->xdr->put8(&rmod_header, RMODULE_VERSION_1);
+	ctx->xdr->put8(&rmod_header, 0);
+	/* payload_begin_offset */
+	loc = sizeof(struct rmodule_header);
+	ctx->xdr->put32(&rmod_header, loc);
+	/* payload_end_offset */
+	loc += ctx->phdr->p_filesz;
+	ctx->xdr->put32(&rmod_header, loc);
+	/* relocations_begin_offset */
+	ctx->xdr->put32(&rmod_header, loc);
+	/* relocations_end_offset */
+	if (bit64)
+		loc += ctx->nrelocs * sizeof(Elf64_Addr);
+	else
+		loc += ctx->nrelocs * sizeof(Elf32_Addr);
+	ctx->xdr->put32(&rmod_header, loc);
+	/* module_link_start_address */
+	ctx->xdr->put32(&rmod_header, ctx->phdr->p_vaddr);
+	/* module_program_size */
+	ctx->xdr->put32(&rmod_header, ctx->phdr->p_memsz);
+	/* module_entry_point */
+	ctx->xdr->put32(&rmod_header, ctx->pelf.ehdr.e_entry);
+	/* parameters_begin */
+	ctx->xdr->put32(&rmod_header, ctx->parameters_begin);
+	/* parameters_end */
+	ctx->xdr->put32(&rmod_header, ctx->parameters_end);
+	/* bss_begin */
+	ctx->xdr->put32(&rmod_header, ctx->bss_begin);
+	/* bss_end */
+	ctx->xdr->put32(&rmod_header, ctx->bss_end);
+	/* padding[4] */
+	ctx->xdr->put32(&rmod_header, 0);
+	ctx->xdr->put32(&rmod_header, 0);
+	ctx->xdr->put32(&rmod_header, 0);
+	ctx->xdr->put32(&rmod_header, 0);
+
+	/* Write the relocations. */
+	for (unsigned i = 0; i < ctx->nrelocs; i++) {
+		if (bit64)
+			ctx->xdr->put64(&relocs, ctx->emitted_relocs[i]);
+		else
+			ctx->xdr->put32(&relocs, ctx->emitted_relocs[i]);
+	}
+
+	total_size = 0;
+	addr = 0;
+
+	/*
+	 * There are 2 cases to deal with. The program has a large NOBITS
+	 * section and the relocations can fit entirely within occupied memory
+	 * region for the program. The other is that the relocations increase
+	 * the memory footprint of the program if it was loaded directly into
+	 * the region it would run. The rmodule header is a fixed cost that
+	 * is considered a part of the program.
+	 */
+	total_size += buffer_size(&rmod_header);
+	if (buffer_size(&relocs) + ctx->phdr->p_filesz > ctx->phdr->p_memsz) {
+		total_size += buffer_size(&relocs);
+		total_size += ctx->phdr->p_filesz;
+	} else {
+		total_size += ctx->phdr->p_memsz;
+	}
+
+	ret = add_section(ew, &rmod_header, ".header", addr,
+	                  buffer_size(&rmod_header));
+	if (ret < 0)
+		goto out;
+	addr += buffer_size(&rmod_header);
+
+	ret = add_section(ew, &program, ".program", addr, ctx->phdr->p_filesz);
+	if (ret < 0)
+		goto out;
+	addr += ctx->phdr->p_filesz;
+
+	if (ctx->nrelocs) {
+		ret = add_section(ew, &relocs, ".relocs", addr,
+				  buffer_size(&relocs));
+		if (ret < 0)
+			goto out;
+		addr += buffer_size(&relocs);
+	}
+
+	if (total_size != addr) {
+		ret = add_section(ew, NULL, ".empty", addr, total_size - addr);
+		if (ret < 0)
+			goto out;
+	}
+
+	/*
+	 * Ensure last section has a memory usage that meets the required
+	 * total size of the program in memory.
+	 */
+
+	ret = elf_writer_serialize(ew, out);
+	if (ret < 0)
+		ERROR("Failed to serialize ELF to buffer.\n");
+
+out:
+	buffer_delete(&rmod_data);
+	elf_writer_destroy(ew);
+
+	return ret;
+}
+
+int rmodule_init(struct rmod_context *ctx, const struct buffer *elfin)
+{
+	struct parsed_elf *pelf;
+	size_t i;
+	int ret;
+
+	ret = -1;
+	memset(ctx, 0, sizeof(*ctx));
+	pelf = &ctx->pelf;
+
+	if (parse_elf(elfin, pelf, ELF_PARSE_ALL)) {
+		ERROR("Couldn't parse ELF!\n");
+		return -1;
+	}
+
+	/* Only allow executables to be turned into rmodules. */
+	if (pelf->ehdr.e_type != ET_EXEC) {
+		ERROR("ELF is not an executable: %u.\n", pelf->ehdr.e_type);
+		goto out;
+	}
+
+	/* Determine if architecture is supported. */
+	for (i = 0; i < ARRAY_SIZE(reloc_ops); i++) {
+		if (reloc_ops[i].arch == pelf->ehdr.e_machine) {
+			ctx->ops = &reloc_ops[i];
+			break;
+		}
+	}
+
+	if (ctx->ops == NULL) {
+		ERROR("ELF is unsupported arch: %u.\n", pelf->ehdr.e_machine);
+		goto out;
+	}
+
+	/* Set the endian ops. */
+	if (ctx->pelf.ehdr.e_ident[EI_DATA] == ELFDATA2MSB)
+		ctx->xdr = &xdr_be;
+	else
+		ctx->xdr = &xdr_le;
+
+	if (find_program_segment(ctx))
+		goto out;
+
+	if (filter_relocation_sections(ctx))
+		goto out;
+
+	ret = 0;
+
+out:
+	return ret;
+}
+
+void rmodule_cleanup(struct rmod_context *ctx)
+{
+	free(ctx->emitted_relocs);
+	parsed_elf_destroy(&ctx->pelf);
+}
+
+int rmodule_create(const struct buffer *elfin, struct buffer *elfout)
+{
+	struct rmod_context ctx;
+	int ret = -1;
+
+	if (rmodule_init(&ctx, elfin))
+		goto out;
+
+	if (rmodule_collect_relocations(&ctx, NULL))
+		goto out;
+
+	if (populate_rmodule_info(&ctx))
+		goto out;
+
+	if (write_elf(&ctx, elfin, elfout))
+		goto out;
+
+	ret = 0;
+
+out:
+	rmodule_cleanup(&ctx);
+	return ret;
+}
+
+static void rmod_deserialize(struct rmodule_header *rmod, struct buffer *buff,
+				struct xdr *xdr)
+{
+	rmod->magic = xdr->get16(buff);
+	rmod->version = xdr->get8(buff);
+	rmod->type = xdr->get8(buff);
+	rmod->payload_begin_offset = xdr->get32(buff);
+	rmod->payload_end_offset = xdr->get32(buff);
+	rmod->relocations_begin_offset = xdr->get32(buff);
+	rmod->relocations_end_offset = xdr->get32(buff);
+	rmod->module_link_start_address = xdr->get32(buff);
+	rmod->module_program_size = xdr->get32(buff);
+	rmod->module_entry_point = xdr->get32(buff);
+	rmod->parameters_begin = xdr->get32(buff);
+	rmod->parameters_end = xdr->get32(buff);
+	rmod->bss_begin = xdr->get32(buff);
+	rmod->bss_end = xdr->get32(buff);
+	rmod->padding[0] = xdr->get32(buff);
+	rmod->padding[1] = xdr->get32(buff);
+	rmod->padding[2] = xdr->get32(buff);
+	rmod->padding[3] = xdr->get32(buff);
+}
+
+int rmodule_stage_to_elf(Elf64_Ehdr *ehdr, struct buffer *buff)
+{
+	struct buffer reader;
+	struct buffer elf_out;
+	struct rmodule_header rmod;
+	struct xdr *xdr;
+	struct elf_writer *ew;
+	Elf64_Shdr shdr;
+	int bit64;
+	size_t payload_sz;
+	const char *section_name = ".program";
+	const size_t input_sz = buffer_size(buff);
+
+	buffer_clone(&reader, buff);
+
+	xdr = (ehdr->e_ident[EI_DATA] == ELFDATA2MSB) ? &xdr_be : &xdr_le;
+	bit64 = ehdr->e_ident[EI_CLASS] == ELFCLASS64;
+
+	rmod_deserialize(&rmod, &reader, xdr);
+
+	/* Indicate that file is not an rmodule if initial checks fail. */
+	if (rmod.magic != RMODULE_MAGIC)
+		return 1;
+	if (rmod.version != RMODULE_VERSION_1)
+		return 1;
+
+	if (rmod.payload_begin_offset > input_sz ||
+	    rmod.payload_end_offset > input_sz ||
+	    rmod.relocations_begin_offset > input_sz ||
+	    rmod.relocations_end_offset > input_sz) {
+		ERROR("Rmodule fields out of bounds.\n");
+		return -1;
+	}
+
+	ehdr->e_entry = rmod.module_entry_point;
+	ew = elf_writer_init(ehdr);
+
+	if (ew == NULL)
+		return -1;
+
+	payload_sz = rmod.payload_end_offset - rmod.payload_begin_offset;
+	memset(&shdr, 0, sizeof(shdr));
+	shdr.sh_type = SHT_PROGBITS;
+	shdr.sh_flags = SHF_WRITE | SHF_ALLOC | SHF_EXECINSTR;
+	shdr.sh_addr = rmod.module_link_start_address;
+	shdr.sh_size = payload_sz;
+	buffer_splice(&reader, buff, rmod.payload_begin_offset, payload_sz);
+
+	if (elf_writer_add_section(ew, &shdr, &reader, section_name)) {
+		ERROR("Unable to add ELF section: %s\n", section_name);
+		elf_writer_destroy(ew);
+		return -1;
+	}
+
+	if (payload_sz != rmod.module_program_size) {
+		struct buffer b;
+
+		buffer_init(&b, NULL, NULL, 0);
+		memset(&shdr, 0, sizeof(shdr));
+		shdr.sh_type = SHT_NOBITS;
+		shdr.sh_flags = SHF_WRITE | SHF_ALLOC;
+		shdr.sh_addr = rmod.module_link_start_address + payload_sz;
+		shdr.sh_size = rmod.module_program_size - payload_sz;
+		if (elf_writer_add_section(ew, &shdr, &b, ".empty")) {
+			ERROR("Unable to add ELF section: .empty\n");
+			elf_writer_destroy(ew);
+			return -1;
+		}
+	}
+
+	/* Provide a section symbol so the relcoations can reference that. */
+	if (elf_writer_add_symbol(ew, section_name, section_name, shdr.sh_addr,
+					0, STB_LOCAL, STT_SECTION)) {
+		ERROR("Unable to add section symbol to ELF.\n");
+		elf_writer_destroy(ew);
+		return -1;
+	}
+
+	/* Add symbols for the parameters if they are non-zero. */
+	if (rmod.parameters_begin != rmod.parameters_end) {
+		int ret = 0;
+
+		ret |= elf_writer_add_symbol(ew, "_rmodule_params",
+						section_name,
+						rmod.parameters_begin, 0,
+						STB_GLOBAL, STT_NOTYPE);
+		ret |= elf_writer_add_symbol(ew, "_ermodule_params",
+						section_name,
+						rmod.parameters_end, 0,
+						STB_GLOBAL, STT_NOTYPE);
+
+		if (ret != 0) {
+			ERROR("Unable to add module params symbols to ELF\n");
+			elf_writer_destroy(ew);
+			return -1;
+		}
+	}
+
+	if (elf_writer_add_symbol(ew, "_bss", section_name, rmod.bss_begin, 0,
+					STB_GLOBAL, STT_NOTYPE) ||
+	    elf_writer_add_symbol(ew, "_ebss", section_name, rmod.bss_end, 0,
+					STB_GLOBAL, STT_NOTYPE)) {
+		ERROR("Unable to add bss symbols to ELF\n");
+		elf_writer_destroy(ew);
+		return -1;
+	}
+
+	ssize_t relocs_sz = rmod.relocations_end_offset;
+	relocs_sz -= rmod.relocations_begin_offset;
+	buffer_splice(&reader, buff, rmod.relocations_begin_offset, relocs_sz);
+	while (relocs_sz > 0) {
+		Elf64_Addr addr;
+
+		if (bit64) {
+			relocs_sz -= sizeof(Elf64_Addr);
+			addr = xdr->get64(&reader);
+		} else {
+			relocs_sz -= sizeof(Elf32_Addr);
+			addr = xdr->get32(&reader);
+		}
+
+		/* Skip any relocations that are below the link address. */
+		if (addr < rmod.module_link_start_address)
+			continue;
+
+		if (elf_writer_add_rel(ew, section_name, addr)) {
+			ERROR("Relocation addition failure.\n");
+			elf_writer_destroy(ew);
+			return -1;
+		}
+	}
+
+	if (elf_writer_serialize(ew, &elf_out)) {
+		ERROR("ELF writer serialize failure.\n");
+		elf_writer_destroy(ew);
+		return -1;
+	}
+
+	elf_writer_destroy(ew);
+
+	/* Flip buffer with the created ELF one. */
+	buffer_delete(buff);
+	*buff = elf_out;
+
+	return 0;
+}
diff --git a/tools/cbfstool/rmodule.h b/tools/cbfstool/rmodule.h
new file mode 100644
index 0000000000..abd8c027ac
--- /dev/null
+++ b/tools/cbfstool/rmodule.h
@@ -0,0 +1,95 @@
+/*
+ * Copyright (C) 2014 Google, Inc.
+ * Copyright (C) 2018 Eltan B.V.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef TOOL_RMODULE_H
+#define TOOL_RMODULE_H
+
+#include "elfparsing.h"
+#include "common.h"
+
+struct arch_ops {
+	int arch;
+	/* Determine if relocation is a valid type for the architecture. */
+	int (*valid_type)(Elf64_Rela *rel);
+	/* Determine if relocation should be emitted. */
+	int (*should_emit)(Elf64_Rela *rel);
+};
+
+/*
+ * The fields in rmod_context are read-only to the user. These are
+ * exposed for easy shareability.
+ */
+struct rmod_context {
+	/* Ops to process relocations. */
+	const struct arch_ops *ops;
+
+	/* endian conversion ops */
+	struct xdr *xdr;
+
+	/* Parsed ELF structure. */
+	struct parsed_elf pelf;
+	/* Program segment. */
+	Elf64_Phdr *phdr;
+
+	/* Collection of relocation addresses fixup in the module. */
+	Elf64_Xword nrelocs;
+	Elf64_Addr *emitted_relocs;
+
+	/* The following fields are addresses within the linked program.  */
+	Elf64_Addr parameters_begin;
+	Elf64_Addr parameters_end;
+	Elf64_Addr bss_begin;
+	Elf64_Addr bss_end;
+};
+
+struct reloc_filter {
+	/* Return < 0 on error. 0 to ignore relocation and 1 to include
+	 * relocation. */
+	int (*filter)(struct reloc_filter *f, const Elf64_Rela *r);
+	/* Pointer for filter provides */
+	void *context;
+};
+
+/*
+ * Parse an ELF file within the elfin buffer and fill in the elfout buffer
+ * with a created rmodule in ELF format. Return 0 on success, < 0 on error.
+ */
+int rmodule_create(const struct buffer *elfin, struct buffer *elfout);
+
+/*
+ * Initialize an rmodule context from an ELF buffer. Returns 0 on scucess, < 0
+ * on error.
+ */
+int rmodule_init(struct rmod_context *ctx, const struct buffer *elfin);
+
+/*
+ * Collect all the relocations that apply to the program in
+ * nrelocs/emitted_relocs. One can optionally provide a reloc_filter object
+ * to help in relocation filtering. The filter function will be called twice:
+ * once for counting and once for emitting. The same response should be
+ * provided for each call. Returns 0 on success, < 0 on error.
+ */
+int rmodule_collect_relocations(struct rmod_context *c, struct reloc_filter *f);
+
+/* Clean up the memory consumed by the rmodule context. */
+void rmodule_cleanup(struct rmod_context *ctx);
+
+/*
+ * Create an ELF file from the passed in rmodule in the buffer. The buffer
+ * contents will be replaced with an ELF file. Returns 1 if buff doesn't
+ * contain an rmodule and < 0 on failure, 0 on success.
+ */
+int rmodule_stage_to_elf(Elf64_Ehdr *ehdr, struct buffer *buff);
+
+#endif /* TOOL_RMODULE_H */
diff --git a/tools/cbfstool/swab.h b/tools/cbfstool/swab.h
new file mode 100644
index 0000000000..a45a7673d9
--- /dev/null
+++ b/tools/cbfstool/swab.h
@@ -0,0 +1,56 @@
+#ifndef _SWAB_H
+#define _SWAB_H
+
+/*
+ * linux/byteorder/swab.h
+ * Byte-swapping, independently from CPU endianness
+ *	swabXX[ps]?(foo)
+ *
+ * Francois-Rene Rideau <fare@tunes.org> 19971205
+ *    separated swab functions from cpu_to_XX,
+ *    to clean up support for bizarre-endian architectures.
+ *
+ * See asm-i386/byteorder.h and suches for examples of how to provide
+ * architecture-dependent optimized versions
+ *
+ */
+
+#if !defined(__APPLE__) && !defined(__NetBSD__)
+#define ntohl(x)	(is_big_endian() ? (uint32_t)(x) : swab32(x))
+#define htonl(x)	(is_big_endian() ? (uint32_t)(x) : swab32(x))
+#else
+#include <arpa/inet.h>
+#endif
+#define ntohll(x)	(is_big_endian() ? (uint64_t)(x) : swab64(x))
+#define htonll(x)	(is_big_endian() ? (uint64_t)(x) : swab64(x))
+
+/* casts are necessary for constants, because we never know how for sure
+ * how U/UL/ULL map to __u16, __u32, __u64. At least not in a portable way.
+ */
+#define swab16(x) \
+	((unsigned short)( \
+		(((unsigned short)(x) & (unsigned short)0x00ffU) << 8) | \
+		(((unsigned short)(x) & (unsigned short)0xff00U) >> 8) ))
+
+#define swab32(x) \
+	((unsigned int)( \
+		(((unsigned int)(x) & (unsigned int)0x000000ffUL) << 24) | \
+		(((unsigned int)(x) & (unsigned int)0x0000ff00UL) <<  8) | \
+		(((unsigned int)(x) & (unsigned int)0x00ff0000UL) >>  8) | \
+		(((unsigned int)(x) & (unsigned int)0xff000000UL) >> 24) ))
+
+#define swab64(x) \
+	((uint64_t)( \
+		(((uint64_t)(x) & (uint64_t)0x00000000000000ffULL) << 56) | \
+		(((uint64_t)(x) & (uint64_t)0x000000000000ff00ULL) << 40) | \
+		(((uint64_t)(x) & (uint64_t)0x0000000000ff0000ULL) << 24) | \
+		(((uint64_t)(x) & (uint64_t)0x00000000ff000000ULL) <<  8) | \
+		(((uint64_t)(x) & (uint64_t)0x000000ff00000000ULL) >>  8) | \
+		(((uint64_t)(x) & (uint64_t)0x0000ff0000000000ULL) >> 24) | \
+		(((uint64_t)(x) & (uint64_t)0x00ff000000000000ULL) >> 40) | \
+		(((uint64_t)(x) & (uint64_t)0xff00000000000000ULL) >> 56) ))
+
+/* common.c */
+int is_big_endian(void);
+
+#endif /* _SWAB_H */
diff --git a/tools/cbfstool/valstr.c b/tools/cbfstool/valstr.c
new file mode 100644
index 0000000000..4843962f1b
--- /dev/null
+++ b/tools/cbfstool/valstr.c
@@ -0,0 +1,66 @@
+/*
+ * Copyright 2010, Google Inc.
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *     * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <inttypes.h>
+#include <string.h>
+#include <strings.h>
+
+#include <valstr.h>
+
+const char *val2str_default(uint32_t val, const struct valstr *vs,
+			    const char *def_str)
+{
+	int i;
+
+	for (i = 0; vs[i].str; i++) {
+		if (vs[i].val == val)
+			return vs[i].str;
+	}
+
+	return def_str;
+}
+
+const char *val2str(uint32_t val, const struct valstr *vs)
+{
+	return val2str_default(val, vs, "Unknown");
+}
+
+uint32_t str2val(const char *str, const struct valstr *vs)
+{
+	int i;
+
+	for (i = 0; vs[i].str; i++) {
+		if (strcasecmp(vs[i].str, str) == 0)
+			return vs[i].val;
+	}
+
+	return vs[i].val;
+}
diff --git a/tools/cbfstool/vboot/2api.h b/tools/cbfstool/vboot/2api.h
new file mode 100644
index 0000000000..982d4772a0
--- /dev/null
+++ b/tools/cbfstool/vboot/2api.h
@@ -0,0 +1,804 @@
+/* Copyright (c) 2013 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * APIs between calling firmware and vboot_reference
+ *
+ * General notes:
+ *
+ * TODO: split this file into a vboot_entry_points.h file which contains the
+ * entry points for the firmware to call vboot_reference, and a
+ * vboot_firmware_exports.h which contains the APIs to be implemented by the
+ * calling firmware and exported to vboot_reference.
+ *
+ * Notes:
+ *    * Assumes this code is never called in the S3 resume path.  TPM resume
+ *      must be done elsewhere, and VB2_NV_DEBUG_RESET_MODE is ignored.
+ */
+
+#ifndef VBOOT_REFERENCE_2API_H_
+#define VBOOT_REFERENCE_2API_H_
+
+#include "2constants.h"
+#include "2crypto.h"
+#include "2fw_hash_tags.h"
+#include "2gbb_flags.h"
+#include "2id.h"
+#include "2recovery_reasons.h"
+#include "2return_codes.h"
+
+/* TODO(chromium:972956): Remove once coreboot is using updated names */
+#define secdata secdata_firmware
+#define secdatak secdata_kernel
+#define vb2api_secdata_check vb2api_secdata_firmware_check
+#define vb2api_secdata_create vb2api_secdata_firmware_create
+#define vb2api_secdatak_check vb2api_secdata_kernel_check
+#define vb2api_secdatak_create vb2api_secdata_kernel_create
+
+/* Modes for vb2ex_tpm_set_mode. */
+enum vb2_tpm_mode {
+	/*
+	 * TPM is enabled tentatively, and may be set to either
+	 * ENABLED or DISABLED mode.
+	 */
+	VB2_TPM_MODE_ENABLED_TENTATIVE = 0,
+
+	/* TPM is enabled, and mode may not be changed. */
+	VB2_TPM_MODE_ENABLED = 1,
+
+	/* TPM is disabled, and mode may not be changed. */
+	VB2_TPM_MODE_DISABLED = 2,
+};
+
+/* Flags for vb2_context.
+ *
+ * Unless otherwise noted, flags are set by verified boot and may be read (but
+ * not set or cleared) by the caller.
+ */
+enum vb2_context_flags {
+
+	/*
+	 * Verified boot has changed nvdata[].  Caller must save nvdata[] back
+	 * to its underlying storage, then may clear this flag.
+	 */
+	VB2_CONTEXT_NVDATA_CHANGED = (1 << 0),
+
+	/*
+	 * Verified boot has changed secdata_firmware[].  Caller must save
+	 * secdata_firmware[] back to its underlying storage, then may clear
+	 * this flag.
+	 */
+	VB2_CONTEXT_SECDATA_FIRMWARE_CHANGED = (1 << 1),
+	/* TODO: Remove once coreboot has switched over */
+	VB2_CONTEXT_SECDATA_CHANGED = (1 << 1),
+
+	/* Recovery mode is requested this boot */
+	VB2_CONTEXT_RECOVERY_MODE = (1 << 2),
+
+	/* Developer mode is requested this boot */
+	VB2_CONTEXT_DEVELOPER_MODE = (1 << 3),
+
+	/*
+	 * Force recovery mode due to physical user request.  Caller may set
+	 * this flag when initializing the context.
+	 */
+	VB2_CONTEXT_FORCE_RECOVERY_MODE = (1 << 4),
+
+	/*
+	 * Force developer mode enabled.  Caller may set this flag when
+	 * initializing the context.  Previously used for forcing developer
+	 * mode with physical dev switch.
+	 *
+	 * Deprecated as part of chromium:942901.
+	 */
+	VB2_CONTEXT_DEPRECATED_FORCE_DEVELOPER_MODE = (1 << 5),
+
+	/* Using firmware slot B.  If this flag is clear, using slot A. */
+	VB2_CONTEXT_FW_SLOT_B = (1 << 6),
+
+	/* RAM should be cleared by caller this boot */
+	VB2_CONTEXT_CLEAR_RAM = (1 << 7),
+
+	/* Wipeout by the app should be requested. */
+	VB2_CONTEXT_FORCE_WIPEOUT_MODE = (1 << 8),
+
+	/* Erase TPM developer mode state if it is enabled. */
+	VB2_CONTEXT_DISABLE_DEVELOPER_MODE = (1 << 9),
+
+	/*
+	 * Verified boot has changed secdata_kernel[].  Caller must save
+	 * secdata_kernel[] back to its underlying storage, then may clear
+	 * this flag.
+	 */
+	VB2_CONTEXT_SECDATA_KERNEL_CHANGED = (1 << 10),
+
+	/*
+	 * Allow kernel verification to roll forward the version in
+	 * secdata_kernel[].  Caller may set this flag before calling
+	 * vb2api_kernel_phase3().
+	 */
+	VB2_CONTEXT_ALLOW_KERNEL_ROLL_FORWARD = (1 << 11),
+
+	/*
+	 * Boot optimistically: don't touch failure counters.  Caller may set
+	 * this flag when initializing the context.
+	 */
+	VB2_CONTEXT_NOFAIL_BOOT = (1 << 12),
+
+	/*
+	 * Secdata is not ready this boot, but should be ready next boot.  It
+	 * would like to reboot.  The decision whether to reboot or not must be
+	 * deferred until vboot, because rebooting all the time before then
+	 * could cause a device with malfunctioning secdata to get stuck in an
+	 * unrecoverable crash loop.
+	 */
+	VB2_CONTEXT_SECDATA_WANTS_REBOOT = (1 << 13),
+
+	/*
+	 * Boot is S3->S0 resume, not S5->S0 normal boot.  Caller may set this
+	 * flag when initializing the context.
+	 */
+	VB2_CONTEXT_S3_RESUME = (1 << 14),
+
+	/*
+	 * System supports EC software sync.  Caller may set this flag at any
+	 * time before calling VbSelectAndLoadKernel().
+	 */
+	VB2_CONTEXT_EC_SYNC_SUPPORTED = (1 << 15),
+
+	/*
+	 * EC software sync is slow to update; warning screen should be
+	 * displayed.  Caller may set this flag at any time before calling
+	 * VbSelectAndLoadKernel().
+	 */
+	VB2_CONTEXT_EC_SYNC_SLOW = (1 << 16),
+
+	/*
+	 * EC firmware supports early firmware selection; two EC images exist,
+	 * and EC may have already verified and jumped to EC-RW prior to EC
+	 * software sync.
+	 */
+	VB2_CONTEXT_EC_EFS = (1 << 17),
+
+	/*
+	 * NV storage uses data format V2.  Data is size VB2_NVDATA_SIZE_V2,
+	 * not VB2_NVDATA_SIZE.
+	 *
+	 * Caller must set this flag when initializing the context to use V2.
+	 * (Vboot cannot infer the data size from the data itself, because the
+	 * data provided by the caller could be uninitialized.)
+	 */
+	VB2_CONTEXT_NVDATA_V2 = (1 << 18),
+
+	/* Allow vendor data to be set via the vendor data ui. */
+	VB2_CONTEXT_VENDOR_DATA_SETTABLE = (1 << 19),
+
+	/*
+	 * Caller may set this before running vb2api_fw_phase1.  In this case,
+	 * it means: "Display is available on this boot.  Please advertise
+	 * as such to downstream vboot code and users."
+	 *
+	 * vboot may also set this before returning from vb2api_fw_phase1.
+	 * In this case, it means: "Please initialize display so that it is
+	 * available to downstream vboot code and users."  This is used when
+	 * vboot encounters some internally-generated request for display
+	 * support.
+	 */
+	VB2_CONTEXT_DISPLAY_INIT = (1 << 20),
+
+	/*
+	 * Caller may set this before running vb2api_kernel_phase1.  It means
+	 * that there is no FWMP on this system, and thus default values should
+	 * be used instead.
+	 *
+	 * Caller should *not* set this when FWMP is available but invalid.
+	 */
+	VB2_CONTEXT_NO_SECDATA_FWMP = (1 << 21),
+};
+
+/*
+ * Context for firmware verification.  Pass this to all vboot APIs.
+ *
+ * Caller may relocate this between calls to vboot APIs.
+ */
+struct vb2_context {
+	/**********************************************************************
+	 * Fields which must be initialized by caller.
+	 */
+
+	/*
+	 * Flags; see vb2_context_flags.  Some flags may only be set by caller
+	 * prior to calling vboot functions.
+	 */
+	uint32_t flags;
+
+	/*
+	 * Work buffer, and length in bytes.  Caller may relocate this between
+	 * calls to vboot APIs; it contains no internal pointers.  Caller must
+	 * not examine the contents of this work buffer directly.
+	 */
+	uint8_t *workbuf;
+	uint32_t workbuf_size;
+
+	/*
+	 * Non-volatile data.  Caller must fill this from some non-volatile
+	 * location before calling vb2api_fw_phase1.  If the
+	 * VB2_CONTEXT_NVDATA_CHANGED flag is set when a vb2api function
+	 * returns, caller must save the data back to the non-volatile location
+	 * and then clear the flag.
+	 */
+	uint8_t nvdata[VB2_NVDATA_SIZE_V2];
+
+	/*
+	 * Secure data for firmware verification stage.  Caller must fill this
+	 * from some secure non-volatile location before calling
+	 * vb2api_fw_phase1.  If the VB2_CONTEXT_SECDATA_CHANGED flag is set
+	 * when a function returns, caller must save the data back to the
+	 * secure non-volatile location and then clear the flag.
+	 */
+	uint8_t secdata_firmware[VB2_SECDATA_FIRMWARE_SIZE];
+
+	/*
+	 * Context pointer for use by caller.  Verified boot never looks at
+	 * this.  Put context here if you need it for APIs that verified boot
+	 * may call (vb2ex_...() functions).
+	 */
+	void *non_vboot_context;
+
+	/**********************************************************************
+	 * Fields caller may examine after calling vb2api_fw_phase1().  Caller
+	 * must set these fields to 0 before calling any vboot functions.
+	 */
+
+	/*
+	 * Amount of work buffer used so far.  Verified boot sub-calls use
+	 * this to know where the unused work area starts.  Caller may use
+	 * this between calls to vboot APIs to know how much data must be
+	 * copied when relocating the work buffer.
+	 */
+	uint32_t workbuf_used;
+
+	/**********************************************************************
+	 * Fields caller must initialize before calling vb2api_kernel_phase1().
+	 */
+
+	/*
+	 * Secure data for kernel verification stage.  Caller must fill this
+	 * from some secure non-volatile location before calling
+	 * vb2api_kernel_phase1.  If the VB2_CONTEXT_SECDATA_KERNEL_CHANGED
+	 * flag is set when a function returns, caller must save the data back
+	 * to the secure non-volatile location and then clear the flag.
+	 */
+	uint8_t secdata_kernel[VB2_SECDATA_KERNEL_SIZE];
+
+	/*
+	 * Firmware management parameters (FWMP) secure data.  Caller must fill
+	 * this from some secure non-volatile location before calling
+	 * vb2api_kernel_phase1.  Since FWMP is a variable-size space, caller
+	 * should initially fill in VB2_SECDATA_FWMP_MIN_SIZE bytes, and call
+	 * vb2_secdata_fwmp_check() to see whether more should be read.  If the
+	 * VB2_CONTEXT_SECDATA_FWMP_CHANGED flag is set when a function
+	 * returns, caller must save the data back to the secure non-volatile
+	 * location and then clear the flag.
+	 */
+	uint8_t secdata_fwmp[VB2_SECDATA_FWMP_MAX_SIZE];
+};
+
+/* Resource index for vb2ex_read_resource() */
+enum vb2_resource_index {
+
+	/* Google binary block */
+	VB2_RES_GBB,
+
+	/*
+	 * Firmware verified boot block (keyblock+preamble).  Use
+	 * VB2_CONTEXT_FW_SLOT_B to determine whether this refers to slot A or
+	 * slot B; vboot will set that flag to the proper state before reading
+	 * the vblock.
+	 */
+	VB2_RES_FW_VBLOCK,
+
+	/*
+	 * Kernel verified boot block (keyblock+preamble) for the current
+	 * kernel partition.  Used only by vb2api_kernel_load_vblock().
+	 * Contents are allowed to change between calls to that function (to
+	 * allow multiple kernels to be examined).
+	 */
+	VB2_RES_KERNEL_VBLOCK,
+};
+
+/* Digest ID for vbapi_get_pcr_digest() */
+enum vb2_pcr_digest {
+	/* Digest based on current developer and recovery mode flags */
+	BOOT_MODE_PCR,
+
+	/* SHA-256 hash digest of HWID, from GBB */
+	HWID_DIGEST_PCR,
+};
+
+/******************************************************************************
+ * APIs provided by verified boot.
+ *
+ * At a high level, call functions in the order described below.  After each
+ * call, examine vb2_context.flags to determine whether nvdata or secdata
+ * needs to be written.
+ *
+ * If you need to cause the boot process to fail at any point, call
+ * vb2api_fail().  Then check vb2_context.flags to see what data needs to be
+ * written.  Then reboot.
+ *
+ *	Load nvdata from wherever you keep it.
+ *
+ *	Load secdata_firmware from wherever you keep it.
+ *
+ *      	If it wasn't there at all (for example, this is the first boot
+ *		of a new system in the factory), call
+ *		vb2api_secdata_firmware_create() to initialize the data.
+ *
+ *		If access to your storage is unreliable (reads/writes may
+ *		contain corrupt data), you may call
+ *		vb2api_secdata_firmware_check() to determine if the data was
+ *		valid, and retry reading if it wasn't.  (In that case, you
+ *		should also read back and check the data after any time you
+ *		write it, to make sure it was written correctly.)
+ *
+ *	Call vb2api_fw_phase1().  At present, this nominally decides whether
+ *	recovery mode is needed this boot.
+ *
+ *	Call vb2api_fw_phase2().  At present, this nominally decides which
+ *	firmware slot will be attempted (A or B).
+ *
+ *	Call vb2api_fw_phase3().  At present, this nominally verifies the
+ *	firmware keyblock and preamble.
+ *
+ *	Lock down wherever you keep secdata_firmware.  It should no longer be
+ *	writable this boot.
+ *
+ *	Verify the hash of each section of code/data you need to boot the RW
+ *	firmware.  For each section:
+ *
+ *		Call vb2_init_hash() to see if the hash exists.
+ *
+ *		Load the data for the section.  Call vb2_extend_hash() on the
+ *		data as you load it.  You can load it all at once and make one
+ *		call, or load and hash-extend a block at a time.
+ *
+ *		Call vb2_check_hash() to see if the hash is valid.
+ *
+ *			If it is valid, you may use the data and/or execute
+ *			code from that section.
+ *
+ *			If the hash was invalid, you must reboot.
+ *
+ * At this point, firmware verification is done, and vb2_context contains the
+ * kernel key needed to verify the kernel.  That context should be preserved
+ * and passed on to kernel selection.  The kernel selection process may be
+ * done by the same firmware image, or may be done by the RW firmware.  The
+ * recommended order is:
+ *
+ *	Load secdata_kernel from wherever you keep it.
+ *
+ *      	If it wasn't there at all (for example, this is the first boot
+ *		of a new system in the factory), call
+ *		vb2api_secdata_kernel_create() to initialize the data.
+ *
+ *		If access to your storage is unreliable (reads/writes may
+ *		contain corrupt data), you may call
+ *		vb2api_secdata_kernel_check() to determine if the data was
+ *		valid, and retry reading if it wasn't.  (In that case, you
+ *		should also read back and check the data after any time you
+*		write it, to make sure it was written correctly.)
+ *
+ *	Call vb2api_kernel_phase1().  At present, this decides which key to
+ *	use to verify kernel data - the recovery key from the GBB, or the
+ *	kernel subkey from the firmware verification stage.
+ *
+ *	Kernel phase 2 is finding loading, and verifying the kernel partition.
+ *
+ *	Find a boot device (you're on your own here).
+ *
+ *	Call vb2api_load_kernel_vblock() for each kernel partition on the
+ *	boot device, until one succeeds.
+ *
+ *	When that succeeds, call vb2api_get_kernel_size() to determine where
+ *	the kernel is located in the stream and how big it is.  Load or map
+ *	the kernel.  (Again, you're on your own.  This is the responsibility of
+ *	the caller so that the caller can choose whether to allocate a buffer,
+ *	load the kernel data into a predefined area of RAM, or directly map a
+ *	kernel file into the address space.  Note that technically it doesn't
+ *	matter whether the kernel data is even in the same file or stream as
+ *	the vblock, as long as the caller loads the right data.
+ *
+ *	Call vb2api_verify_kernel_data() on the kernel data.
+ *
+ *	If you ran out of kernels before finding a good one, call vb2api_fail()
+ *	with an appropriate recovery reason.
+ *
+ *	Set the VB2_CONTEXT_ALLOW_KERNEL_ROLL_FORWARD flag if the current
+ *	kernel partition has the successful flag (that is, it's already known
+ *	or assumed to be a functional kernel partition).
+ *
+ *	Call vb2api_kernel_phase3().  This cleans up from kernel verification
+ *	and updates the secure data if needed.
+ *
+ *	Lock down wherever you keep secdata_kernel.  It should no longer be
+ *	writable this boot.
+ */
+
+/**
+ * Check the validity of firmware secure storage context.
+ *
+ * Checks version and CRC.
+ *
+ * @param ctx		Context pointer
+ * @return VB2_SUCCESS, or non-zero error code if error.
+ */
+vb2_error_t vb2api_secdata_firmware_check(struct vb2_context *ctx);
+
+/**
+ * Create fresh data in firmware secure storage context.
+ *
+ * Use this only when initializing the secure storage context on a new machine
+ * the first time it boots.  Do NOT simply use this if
+ * vb2api_secdata_firmware_check() (or any other API in this library) fails;
+ * that could allow the secure data to be rolled back to an insecure state.
+ *
+ * @param ctx		Context pointer
+ * @return size of created firmware secure storage data in bytes
+ */
+uint32_t vb2api_secdata_firmware_create(struct vb2_context *ctx);
+
+/**
+ * Check the validity of kernel secure storage context.
+ *
+ * Checks version, UID, and CRC.
+ *
+ * @param ctx		Context pointer
+ * @return VB2_SUCCESS, or non-zero error code if error.
+ */
+vb2_error_t vb2api_secdata_kernel_check(struct vb2_context *ctx);
+
+/**
+ * Create fresh data in kernel secure storage context.
+ *
+ * Use this only when initializing the secure storage context on a new machine
+ * the first time it boots.  Do NOT simply use this if
+ * vb2api_secdata_kernel_check() (or any other API in this library) fails; that
+ * could allow the secure data to be rolled back to an insecure state.
+ *
+ * @param ctx		Context pointer
+ * @return size of created kernel secure storage data in bytes
+ */
+uint32_t vb2api_secdata_kernel_create(struct vb2_context *ctx);
+
+/**
+ * Check the validity of firmware management parameters (FWMP) space.
+ *
+ * Checks size, version, and CRC.  If the struct size is larger than the size
+ * passed in, the size pointer is set to the expected full size of the struct,
+ * and VB2_ERROR_SECDATA_FWMP_INCOMPLETE is returned.  The caller should
+ * re-read the returned number of bytes, and call this function again.
+ *
+ * @param ctx		Context pointer
+ * @param size		Amount of struct which has been read
+ * @return VB2_SUCCESS, or non-zero error code if error.
+ */
+vb2_error_t vb2api_secdata_fwmp_check(struct vb2_context *ctx, uint8_t *size);
+
+/**
+ * Report firmware failure to vboot.
+ *
+ * If the failure occurred after choosing a firmware slot, and the other
+ * firmware slot is not known-bad, try the other firmware slot after reboot.
+ *
+ * If the failure occurred before choosing a firmware slot, or both slots have
+ * failed in successive boots, request recovery.
+ *
+ * This may be called before vb2api_phase1() to indicate errors in the boot
+ * process prior to the start of vboot.  On return, the calling firmware should
+ * check for updates to secdata and/or nvdata, then reboot.
+ *
+ * @param reason	Recovery reason
+ * @param subcode	Recovery subcode
+ */
+void vb2api_fail(struct vb2_context *ctx, uint8_t reason, uint8_t subcode);
+
+/**
+ * Firmware selection, phase 1.
+ *
+ * If the returned error is VB2_ERROR_API_PHASE1_RECOVERY, the calling firmware
+ * should jump directly to recovery-mode firmware without rebooting.
+ *
+ * For other errors, the calling firmware should check for updates to secdata
+ * and/or nvdata, then reboot.
+ *
+ * @param ctx		Vboot context
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2api_fw_phase1(struct vb2_context *ctx);
+
+/**
+ * Firmware selection, phase 2.
+ *
+ * On error, the calling firmware should check for updates to secdata and/or
+ * nvdata, then reboot.
+ *
+ * @param ctx		Vboot context
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2api_fw_phase2(struct vb2_context *ctx);
+
+/**
+ * Firmware selection, phase 3.
+ *
+ * On error, the calling firmware should check for updates to secdata and/or
+ * nvdata, then reboot.
+ *
+ * On success, the calling firmware should lock down secdata before continuing
+ * with the boot process.
+ *
+ * @param ctx		Vboot context
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2api_fw_phase3(struct vb2_context *ctx);
+
+/**
+ * Same, but for new-style structs.
+ */
+vb2_error_t vb21api_fw_phase3(struct vb2_context *ctx);
+
+/**
+ * Initialize hashing data for the specified tag.
+ *
+ * @param ctx		Vboot context
+ * @param tag		Tag to start hashing (enum vb2_hash_tag)
+ * @param size		If non-null, expected size of data for tag will be
+ *			stored here on output.
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2api_init_hash(struct vb2_context *ctx, uint32_t tag,
+			     uint32_t *size);
+
+/**
+ * Same, but for new-style structs.
+ */
+vb2_error_t vb21api_init_hash(struct vb2_context *ctx, const struct vb2_id *id,
+			      uint32_t *size);
+
+/**
+ * Extend the hash started by vb2api_init_hash() with additional data.
+ *
+ * (This is the same for both old and new style structs.)
+ *
+ * @param ctx		Vboot context
+ * @param buf		Data to hash
+ * @param size		Size of data in bytes
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2api_extend_hash(struct vb2_context *ctx, const void *buf,
+			       uint32_t size);
+
+/**
+ * Check the hash value started by vb2api_init_hash().
+ *
+ * @param ctx		Vboot context
+ * @return VB2_SUCCESS, or error code on error.
+ */
+int vb2api_check_hash(struct vb2_context *ctx);
+
+/**
+ * Same, but for new-style structs.
+ */
+vb2_error_t vb21api_check_hash(struct vb2_context *ctx);
+
+/**
+ * Check the hash value started by vb2api_init_hash() while retrieving
+ * calculated digest.
+ *
+ * @param ctx			Vboot context
+ * @param digest_out		optional pointer to buffer to store digest
+ * @param digest_out_size	optional size of buffer to store digest
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2api_check_hash_get_digest(struct vb2_context *ctx,
+					 void *digest_out,
+					 uint32_t digest_out_size);
+
+/**
+ * Get a PCR digest
+ *
+ * @param ctx		Vboot context
+ * @param which_digest	PCR index of the digest
+ * @param dest		Destination where the digest is copied.
+ * 			Recommended size is VB2_PCR_DIGEST_RECOMMENDED_SIZE.
+ * @param dest_size	IN: size of the buffer pointed by dest
+ * 			OUT: size of the copied digest
+ * @return VB2_SUCCESS, or error code on error
+ */
+vb2_error_t vb2api_get_pcr_digest(struct vb2_context *ctx,
+				  enum vb2_pcr_digest which_digest,
+				  uint8_t *dest, uint32_t *dest_size);
+
+/**
+ * Prepare for kernel verification stage.
+ *
+ * Must be called before other vb2api kernel functions.
+ *
+ * @param ctx		Vboot context
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2api_kernel_phase1(struct vb2_context *ctx);
+
+/**
+ * Load the verified boot block (vblock) for a kernel.
+ *
+ * This function may be called multiple times, to load and verify the
+ * vblocks from multiple kernel partitions.
+ *
+ * @param ctx		Vboot context
+ * @param stream	Kernel stream
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2api_load_kernel_vblock(struct vb2_context *ctx);
+
+/**
+ * Get the size and offset of the kernel data for the most recent vblock.
+ *
+ * Valid after a successful call to vb2api_load_kernel_vblock().
+ *
+ * @param ctx		Vboot context
+ * @param offset_ptr	Destination for offset in bytes of kernel data as
+ *			reported by vblock.
+ * @param size_ptr      Destination for size of kernel data in bytes.
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2api_get_kernel_size(struct vb2_context *ctx,
+				   uint32_t *offset_ptr, uint32_t *size_ptr);
+
+/**
+ * Verify kernel data using the previously loaded kernel vblock.
+ *
+ * Valid after a successful call to vb2api_load_kernel_vblock().  This allows
+ * the caller to load or map the kernel data, as appropriate, and pass the
+ * pointer to the kernel data into vboot.
+ *
+ * @param ctx		Vboot context
+ * @param buf		Pointer to kernel data
+ * @param size		Size of kernel data in bytes
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2api_verify_kernel_data(struct vb2_context *ctx, const void *buf,
+				      uint32_t size);
+
+/**
+ * Clean up after kernel verification.
+ *
+ * Call this after successfully loading a vblock and verifying kernel data,
+ * or if you've run out of boot devices and/or kernel partitions.
+ *
+ * This cleans up intermediate data structures in the vboot context, and
+ * updates the version in the secure data if necessary.
+ */
+vb2_error_t vb2api_kernel_phase3(struct vb2_context *ctx);
+
+/**
+ * Read the hardware ID from the GBB, and store it onto the given buffer.
+ *
+ * @param ctx		Vboot context.
+ * @param hwid		Buffer to store HWID, which will be null-terminated.
+ * @param size		Maximum size of HWID including null terminator.  HWID
+ * 			length may not exceed 256 (VB2_GBB_HWID_MAX_SIZE), so
+ * 			this value is suggested.  If size is too small, then
+ * 			VB2_ERROR_INVALID_PARAMETER is returned.  Actual size
+ * 			of the output HWID string is returned in this pointer,
+ * 			also including null terminator.
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2api_gbb_read_hwid(struct vb2_context *ctx, char *hwid,
+				 uint32_t *size);
+
+/**
+ * Retrieve current GBB flags.
+ *
+ * See enum vb2_gbb_flag in 2gbb_flags.h for a list of all GBB flags.
+ *
+ * @param ctx		Vboot context.
+ *
+ * @return vb2_gbb_flags_t representing current GBB flags.
+ */
+vb2_gbb_flags_t vb2api_gbb_get_flags(struct vb2_context *ctx);
+
+/*****************************************************************************/
+/* APIs provided by the caller to verified boot */
+
+/**
+ * Clear the TPM owner.
+ *
+ * @param ctx		Vboot context
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2ex_tpm_clear_owner(struct vb2_context *ctx);
+
+/**
+ * Read a verified boot resource.
+ *
+ * @param ctx		Vboot context
+ * @param index		Resource index to read
+ * @param offset	Byte offset within resource to start at
+ * @param buf		Destination for data
+ * @param size		Amount of data to read
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2ex_read_resource(struct vb2_context *ctx,
+				enum vb2_resource_index index, uint32_t offset,
+				void *buf, uint32_t size);
+
+/**
+ * Print debug output
+ *
+ * This should work like printf().  If func!=NULL, it will be a string with
+ * the current function name; that can be used to generate prettier debug
+ * output.  If func==NULL, don't print any extra header/trailer so that this
+ * can be used to composite a bigger output string from several calls - for
+ * example, when doing a hex dump.
+ *
+ * @param func		Function name generating output, or NULL.
+ * @param fmt		Printf format string
+ */
+void vb2ex_printf(const char *func, const char *fmt, ...);
+
+/**
+ * Initialize the hardware crypto engine to calculate a block-style digest.
+ *
+ * @param hash_alg	Hash algorithm to use
+ * @param data_size	Expected total size of data to hash
+ * @return VB2_SUCCESS, or non-zero error code (HWCRYPTO_UNSUPPORTED not fatal).
+ */
+vb2_error_t vb2ex_hwcrypto_digest_init(enum vb2_hash_algorithm hash_alg,
+				       uint32_t data_size);
+
+/**
+ * Extend the hash in the hardware crypto engine with another block of data.
+ *
+ * @param buf		Next data block to hash
+ * @param size		Length of data block in bytes
+ * @return VB2_SUCCESS, or non-zero error code.
+ */
+vb2_error_t vb2ex_hwcrypto_digest_extend(const uint8_t *buf, uint32_t size);
+
+/**
+ * Finalize the digest in the hardware crypto engine and extract the result.
+ *
+ * @param digest	Destination buffer for resulting digest
+ * @param digest_size	Length of digest buffer in bytes
+ * @return VB2_SUCCESS, or non-zero error code.
+ */
+vb2_error_t vb2ex_hwcrypto_digest_finalize(uint8_t *digest,
+					   uint32_t digest_size);
+
+/*
+ * Set the current TPM mode value, and validate that it was changed.  If one
+ * of the following occurs, the function call fails:
+ *   - TPM does not understand the instruction (old version)
+ *   - TPM has already left the TpmModeEnabledTentative mode
+ *   - TPM responds with a mode other than the requested mode
+ *   - Some other communication error occurs
+ *  Otherwise, the function call succeeds.
+ *
+ * @param mode_val       Desired TPM mode to set.  May be one of ENABLED
+ *                       or DISABLED from vb2_tpm_mode enum.
+ * @returns VB2_SUCCESS, or non-zero error code.
+ */
+vb2_error_t vb2ex_tpm_set_mode(enum vb2_tpm_mode mode_val);
+
+/*
+ * Abort vboot flow due to a failed assertion or broken assumption.
+ *
+ * Likely due to caller misusing vboot (e.g. calling API functions
+ * out-of-order, filling in vb2_context fields inappropriately).
+ * Implementation should reboot or halt the machine, or fall back to some
+ * alternative boot flow.  Retrying vboot is unlikely to succeed.
+ */
+void vb2ex_abort(void);
+
+#endif  /* VBOOT_REFERENCE_2API_H_ */
diff --git a/tools/cbfstool/vboot/2common.h b/tools/cbfstool/vboot/2common.h
new file mode 100644
index 0000000000..e15b59fdbd
--- /dev/null
+++ b/tools/cbfstool/vboot/2common.h
@@ -0,0 +1,303 @@
+/* Copyright (c) 2014 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * Common functions between firmware and kernel verified boot.
+ */
+
+#ifndef VBOOT_REFERENCE_2COMMON_H_
+#define VBOOT_REFERENCE_2COMMON_H_
+
+#include "2api.h"
+#include "2gbb.h"
+#include "2return_codes.h"
+#include "2sha.h"
+#include "2struct.h"
+#include "2sysincludes.h"
+
+struct vb2_public_key;
+
+/*
+ * Return the min/max of A and B.  This is used in macros which calculate the
+ * required buffer size, so can't be turned into a static inline function.
+ */
+#define VB2_MIN(a, b) ({ \
+	typeof(a) __vb2_min_a = (a); \
+	typeof(b) __vb2_min_b = (b); \
+	__vb2_min_a < __vb2_min_b ? __vb2_min_a : __vb2_min_b; \
+	})
+#define VB2_MAX(a, b) ({ \
+	typeof(a) __vb2_max_a = (a); \
+	typeof(b) __vb2_max_b = (b); \
+	__vb2_max_a > __vb2_max_b ? __vb2_max_a : __vb2_max_b; \
+	})
+
+/* Return the number of elements in an array */
+#ifndef ARRAY_SIZE
+#define ARRAY_SIZE(a) (sizeof(a) / sizeof((a)[0]))
+#endif
+
+/* Platform-dependent debug/assert output macros. */
+#define VB2_DEBUG(format, args...) \
+	vb2ex_printf(__func__, format, ## args)
+
+#define VB2_DEBUG_RAW(format, args...) \
+	vb2ex_printf(NULL, format, ## args)
+
+#define VB2_ASSERT(expr) do { \
+	if (!(expr)) { \
+		VB2_DEBUG("assertion failed: %s at %s:%d\n", \
+			  #expr, __FILE__, __LINE__); \
+		vb2ex_abort(); \
+		for (;;); \
+	} \
+} while (0)
+
+#define VB2_DIE(format, args...) do { \
+	VB2_DEBUG(format, ## args); \
+	vb2ex_abort(); \
+	for (;;); \
+} while (0)
+
+/*
+ * Define test_mockable and for mocking functions when compiled for Chrome OS
+ * environment (that is, not for firmware).
+ */
+#ifndef test_mockable
+#ifdef CHROMEOS_ENVIRONMENT
+#define test_mockable __attribute__((weak))
+#else
+#define test_mockable
+#endif
+#endif
+
+// Have a generic fall-through for different versions of C/C++.
+// Taken from boringssl.
+#if defined(__cplusplus) && __cplusplus >= 201703L
+#define VBOOT_FALLTHROUGH [[fallthrough]]
+#elif defined(__cplusplus) && __cplusplus >= 201103L && defined(__clang__)
+#define VBOOT_FALLTHROUGH [[clang::fallthrough]]
+#elif defined(__cplusplus) && __cplusplus >= 201103L && defined(__GNUC__) && \
+    __GNUC__ >= 7
+#define VBOOT_FALLTHROUGH [[gnu::fallthrough]]
+#elif defined(__GNUC__) && __GNUC__ >= 7 // gcc 7
+#define VBOOT_FALLTHROUGH __attribute__ ((fallthrough))
+#elif defined(__clang__)
+#if __has_attribute(fallthrough)
+#define VBOOT_FALLTHROUGH __attribute__ ((fallthrough))
+#else // clang versions that do not support fallthrough.
+#define VBOOT_FALLTHROUGH
+#endif
+#else // C++11 on gcc 6, and all other cases
+#define VBOOT_FALLTHROUGH
+#endif
+
+/**
+ * Round up a number to a multiple of VB2_WORKBUF_ALIGN
+ *
+ * @param v		Number to round up
+ * @return The number, rounded up.
+ */
+static __inline uint32_t vb2_wb_round_up(uint32_t v)
+{
+	return (v + VB2_WORKBUF_ALIGN - 1) & ~(VB2_WORKBUF_ALIGN - 1);
+}
+
+/* Work buffer */
+struct vb2_workbuf {
+	uint8_t *buf;
+	uint32_t size;
+};
+
+/**
+ * Initialize a work buffer.
+ *
+ * @param wb		Work buffer to init
+ * @param buf		Pointer to work buffer data
+ * @param size		Size of work buffer data in bytes
+ */
+void vb2_workbuf_init(struct vb2_workbuf *wb, uint8_t *buf, uint32_t size);
+
+/**
+ * Allocate space in a work buffer.
+ *
+ * Note that the returned buffer will always be aligned to VB2_WORKBUF_ALIGN.
+ *
+ * The work buffer acts like a stack, and detailed tracking of allocs and frees
+ * is not done.  The caller must track the size of each allocation and free via
+ * vb2_workbuf_free() in the reverse order they were allocated.
+ *
+ * An acceptable alternate workflow inside a function is to pass in a const
+ * work buffer, then make a local copy.  Allocations done to the local copy
+ * then don't change the passed-in work buffer, and will effectively be freed
+ * when the local copy goes out of scope.
+ *
+ * @param wb		Work buffer
+ * @param size		Requested size in bytes
+ * @return A pointer to the allocated space, or NULL if error.
+ */
+void *vb2_workbuf_alloc(struct vb2_workbuf *wb, uint32_t size);
+
+/**
+ * Reallocate space in a work buffer.
+ *
+ * Note that the returned buffer will always be aligned to VB2_WORKBUF_ALIGN.
+ * The work buffer acts like a stack, so this must only be done to the most
+ * recently allocated buffer.
+ *
+ * @param wb		Work buffer
+ * @param oldsize	Old allocation size in bytes
+ * @param newsize	Requested size in bytes
+ * @return A pointer to the allocated space, or NULL if error.
+ */
+void *vb2_workbuf_realloc(struct vb2_workbuf *wb, uint32_t oldsize,
+			  uint32_t newsize);
+
+/**
+ * Free the preceding allocation.
+ *
+ * Note that the work buffer acts like a stack, and detailed tracking of
+ * allocs and frees is not done.  The caller must track the size of each
+ * allocation and free them in reverse order.
+ *
+ * @param wb		Work buffer
+ * @param size		Size of data to free
+ */
+void vb2_workbuf_free(struct vb2_workbuf *wb, uint32_t size);
+
+/* Check if a pointer is aligned on an align-byte boundary */
+#define vb2_aligned(ptr, align) (!(((uintptr_t)(ptr)) & ((align) - 1)))
+
+/**
+ * Safer memcmp() for use in crypto.
+ *
+ * Compares the buffers to see if they are equal.  Time taken to perform
+ * the comparison is dependent only on the size, not the relationship of
+ * the match between the buffers.  Note that unlike memcmp(), this only
+ * indicates inequality, not which buffer is lesser.
+ *
+ * @param s1		First buffer
+ * @param s2		Second buffer
+ * @param size		Number of bytes to compare
+ * @return 0 if match or size=0, non-zero if at least one byte mismatched.
+ */
+vb2_error_t vb2_safe_memcmp(const void *s1, const void *s2, size_t size);
+
+/**
+ * Align a buffer and check its size.
+ *
+ * @param **ptr		Pointer to pointer to align
+ * @param *size		Points to size of buffer pointed to by *ptr
+ * @param align		Required alignment (must be power of 2)
+ * @param want_size	Required size
+ * @return VB2_SUCCESS, or non-zero if error.
+ */
+vb2_error_t vb2_align(uint8_t **ptr, uint32_t *size, uint32_t align,
+		      uint32_t want_size);
+
+/**
+ * Return offset of ptr from base.
+ *
+ * @param base		Base pointer
+ * @param ptr		Pointer at some offset from base
+ * @return The offset of ptr from base.
+ */
+ptrdiff_t vb2_offset_of(const void *base, const void *ptr);
+
+/**
+ * Return member of given object.
+ *
+ * @param parent	Pointer to parent object
+ * @param offset	Offset from base
+ * @return Pointer to child object.
+ */
+void *vb2_member_of(void *parent, ptrdiff_t offset);
+
+/**
+ * Return expected signature size for a signature/hash algorithm pair
+ *
+ * @param sig_alg	Signature algorithm
+ * @param hash_alg	Hash algorithm
+ * @return The signature size, or zero if error / unsupported algorithm.
+ */
+uint32_t vb2_sig_size(enum vb2_signature_algorithm sig_alg,
+		      enum vb2_hash_algorithm hash_alg);
+
+/**
+ * Return a key ID for an unsigned hash algorithm.
+ *
+ * @param hash_alg	Hash algorithm to return key for
+ * @return A pointer to the key ID for that hash algorithm with
+ *	   sig_alg=VB2_SIG_NONE, or NULL if error.
+ */
+const struct vb2_id *vb2_hash_id(enum vb2_hash_algorithm hash_alg);
+
+/* Size of work buffer sufficient for vb2_verify_digest() worst case. */
+#define VB2_VERIFY_DIGEST_WORKBUF_BYTES VB2_VERIFY_RSA_DIGEST_WORKBUF_BYTES
+
+/* Size of work buffer sufficient for vb2_verify_data() worst case. */
+#define VB2_VERIFY_DATA_WORKBUF_BYTES					\
+	(VB2_SHA512_DIGEST_SIZE +					\
+	 VB2_MAX(VB2_VERIFY_DIGEST_WORKBUF_BYTES,			\
+		 sizeof(struct vb2_digest_context)))
+
+/* Size of work buffer sufficient for vb2_verify_keyblock() worst case. */
+#define VB2_KEY_BLOCK_VERIFY_WORKBUF_BYTES VB2_VERIFY_DATA_WORKBUF_BYTES
+
+/* Size of work buffer sufficient for vb2_verify_fw_preamble() worst case. */
+#define VB2_VERIFY_FIRMWARE_PREAMBLE_WORKBUF_BYTES VB2_VERIFY_DATA_WORKBUF_BYTES
+
+/*
+ * Size of work buffer sufficient for vb2_verify_kernel_preamble() worst
+ * case.
+ */
+#define VB2_VERIFY_KERNEL_PREAMBLE_WORKBUF_BYTES VB2_VERIFY_DATA_WORKBUF_BYTES
+
+/**
+ * Verify the data pointed to by a subfield is inside the parent data.
+ *
+ * The subfield has a header pointed to by member, and a separate data
+ * field at an offset relative to the header.  That is:
+ *
+ *   struct parent {
+ *     (possibly other parent fields)
+ *     struct member {
+ *        (member header fields)
+ *     };
+ *     (possibly other parent fields)
+ *   };
+ *   (possibly some other parent data)
+ *   (member data)
+ *   (possibly some other parent data)
+ *
+ * @param parent		Parent data
+ * @param parent_size		Parent size in bytes
+ * @param member		Subfield header
+ * @param member_size		Size of subfield header in bytes
+ * @param member_data_offset	Offset of member data from start of member
+ * @param member_data_size	Size of member data in bytes
+ * @return VB2_SUCCESS, or non-zero if error.
+ */
+vb2_error_t vb2_verify_member_inside(const void *parent, size_t parent_size,
+				     const void *member, size_t member_size,
+				     ptrdiff_t member_data_offset,
+				     size_t member_data_size);
+
+/*
+ * Helper function to get data pointed to by a public key.
+ */
+const uint8_t *vb2_packed_key_data(const struct vb2_packed_key *key);
+
+/**
+ * Verify a packed key is fully contained in its parent data
+ *
+ * @param parent	Parent data
+ * @param parent_size	Parent size in bytes
+ * @param key		Packed key pointer
+ * @return VB2_SUCCESS, or non-zero if error.
+ */
+int vb2_verify_packed_key_inside(const void *parent,
+				 uint32_t parent_size,
+				 const struct vb2_packed_key *key);
+
+#endif  /* VBOOT_REFERENCE_2COMMON_H_ */
diff --git a/tools/cbfstool/vboot/2constants.h b/tools/cbfstool/vboot/2constants.h
new file mode 100644
index 0000000000..3f80b9ae3f
--- /dev/null
+++ b/tools/cbfstool/vboot/2constants.h
@@ -0,0 +1,83 @@
+/* Copyright 2019 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * General vboot-related constants.
+ *
+ * Constants that need to be exposed to assembly files or linker scripts
+ * may be placed here and imported via vb2_constants.h.
+ */
+
+#ifndef VBOOT_REFERENCE_2CONSTANTS_H_
+#define VBOOT_REFERENCE_2CONSTANTS_H_
+
+/*
+ * Size of non-volatile data used by vboot.
+ *
+ * If you only support non-volatile data format V1, then use VB2_NVDATA_SIZE.
+ * If you support V2, use VB2_NVDATA_SIZE_V2 and set context flag
+ * VB2_CONTEXT_NVDATA_V2.
+ */
+#define VB2_NVDATA_SIZE 16
+#define VB2_NVDATA_SIZE_V2 64
+
+/* Size of secure data spaces used by vboot */
+#define VB2_SECDATA_FIRMWARE_SIZE 10
+#define VB2_SECDATA_KERNEL_SIZE 13
+#define VB2_SECDATA_FWMP_MIN_SIZE 40
+#define VB2_SECDATA_FWMP_MAX_SIZE 64
+
+/* TODO(chromium:972956): Remove once coreboot is using updated names */
+#define VB2_SECDATA_SIZE 10
+#define VB2_SECDATAK_SIZE 13
+
+/*
+ * Recommended size of work buffer for firmware verification stage.
+ *
+ * TODO: The recommended size really depends on which key algorithms are
+ * used.  Should have a better / more accurate recommendation than this.
+ */
+#define VB2_FIRMWARE_WORKBUF_RECOMMENDED_SIZE (12 * 1024)
+
+/*
+ * Recommended size of work buffer for kernel verification stage.
+ *
+ * This is bigger because vboot 2.0 kernel preambles are usually padded to
+ * 64 KB.
+ *
+ * TODO: The recommended size really depends on which key algorithms are
+ * used.  Should have a better / more accurate recommendation than this.
+ */
+#define VB2_KERNEL_WORKBUF_RECOMMENDED_SIZE (80 * 1024)
+
+/* Recommended buffer size for vb2api_get_pcr_digest. */
+#define VB2_PCR_DIGEST_RECOMMENDED_SIZE 32
+
+/*
+ * Alignment for work buffer pointers/allocations should be useful for any
+ * data type. When declaring workbuf buffers on the stack, the caller should
+ * use explicit alignment to avoid run-time errors. For example:
+ *
+ *    int foo(void)
+ *    {
+ *        struct vb2_workbuf wb;
+ *        uint8_t buf[NUM] __attribute__ ((aligned (VB2_WORKBUF_ALIGN)));
+ *        wb.buf = buf;
+ *        wb.size = sizeof(buf);
+ */
+
+/* We might get away with using __alignof__(void *), but since GCC defines a
+ * macro for us we'll be safe and use that. */
+#define VB2_WORKBUF_ALIGN __BIGGEST_ALIGNMENT__
+
+/* Maximum length of a HWID in bytes, counting terminating null. */
+#define VB2_GBB_HWID_MAX_SIZE 256
+
+/* Type and offset of flags member in vb2_gbb_header struct. */
+#define VB2_GBB_FLAGS_OFFSET 12
+#ifndef __ASSEMBLER__
+#include <stdint.h>
+typedef uint32_t vb2_gbb_flags_t;
+#endif
+
+#endif  /* VBOOT_REFERENCE_2CONSTANTS_H_ */
diff --git a/tools/cbfstool/vboot/2crypto.h b/tools/cbfstool/vboot/2crypto.h
new file mode 100644
index 0000000000..f595fd4ffd
--- /dev/null
+++ b/tools/cbfstool/vboot/2crypto.h
@@ -0,0 +1,76 @@
+/* Copyright (c) 2014 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * Crypto constants for verified boot
+ */
+
+#ifndef VBOOT_REFERENCE_2CRYPTO_H_
+#define VBOOT_REFERENCE_2CRYPTO_H_
+
+#include <stdint.h>
+
+/* Verified boot crypto algorithms */
+enum vb2_crypto_algorithm {
+	VB2_ALG_RSA1024_SHA1   = 0,
+	VB2_ALG_RSA1024_SHA256 = 1,
+	VB2_ALG_RSA1024_SHA512 = 2,
+	VB2_ALG_RSA2048_SHA1   = 3,
+	VB2_ALG_RSA2048_SHA256 = 4,
+	VB2_ALG_RSA2048_SHA512 = 5,
+	VB2_ALG_RSA4096_SHA1   = 6,
+	VB2_ALG_RSA4096_SHA256 = 7,
+	VB2_ALG_RSA4096_SHA512 = 8,
+	VB2_ALG_RSA8192_SHA1   = 9,
+	VB2_ALG_RSA8192_SHA256 = 10,
+	VB2_ALG_RSA8192_SHA512 = 11,
+	VB2_ALG_RSA2048_EXP3_SHA1   = 12,
+	VB2_ALG_RSA2048_EXP3_SHA256 = 13,
+	VB2_ALG_RSA2048_EXP3_SHA512 = 14,
+	VB2_ALG_RSA3072_EXP3_SHA1   = 15,
+	VB2_ALG_RSA3072_EXP3_SHA256 = 16,
+	VB2_ALG_RSA3072_EXP3_SHA512 = 17,
+	/* Number of algorithms */
+	VB2_ALG_COUNT
+};
+
+/* Algorithm types for signatures */
+enum vb2_signature_algorithm {
+	/* Invalid or unsupported signature type */
+	VB2_SIG_INVALID = 0,
+
+	/*
+	 * No signature algorithm.  The digest is unsigned.  See
+	 * VB2_ID_NONE_* for key IDs to use with this algorithm.
+	 */
+	VB2_SIG_NONE = 1,
+
+	/* RSA algorithms of the given length in bits (1024-8192) */
+	VB2_SIG_RSA1024 = 2,  /* Warning!  This is likely to be deprecated! */
+	VB2_SIG_RSA2048 = 3,
+	VB2_SIG_RSA4096 = 4,
+	VB2_SIG_RSA8192 = 5,
+	VB2_SIG_RSA2048_EXP3 = 6,
+	VB2_SIG_RSA3072_EXP3 = 7,
+
+	/* Last index. Don't add anything below. */
+	VB2_SIG_ALG_COUNT,
+};
+
+/* Algorithm types for hash digests */
+enum vb2_hash_algorithm {
+	/* Invalid or unsupported digest type */
+	VB2_HASH_INVALID = 0,
+
+	/* SHA-1.  Warning: This is likely to be deprecated soon! */
+	VB2_HASH_SHA1 = 1,
+
+	/* SHA-256 and SHA-512 */
+	VB2_HASH_SHA256 = 2,
+	VB2_HASH_SHA512 = 3,
+
+	/* Last index. Don't add anything below. */
+	VB2_HASH_ALG_COUNT,
+};
+
+#endif  /* VBOOT_REFERENCE_2CRYPTO_H_ */
diff --git a/tools/cbfstool/vboot/2fw_hash_tags.h b/tools/cbfstool/vboot/2fw_hash_tags.h
new file mode 100644
index 0000000000..1ecec6e093
--- /dev/null
+++ b/tools/cbfstool/vboot/2fw_hash_tags.h
@@ -0,0 +1,41 @@
+/* Copyright (c) 2014 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * Firmware hash tags for verified boot
+ */
+
+#ifndef VBOOT_REFERENCE_2FW_HASH_TAGS_H_
+#define VBOOT_REFERENCE_2FW_HASH_TAGS_H_
+
+#include <stdint.h>
+
+/*
+ * Tags for types of hashable data.
+ *
+ * Note that not every firmware image will contain every tag.
+ *
+ * TODO: These are the ones that vboot specifically knows about given the
+ * current data structures.  In the future, I'd really like the vboot preamble
+ * to contain an arbitrary list of tags and their hashes, so that we can hash
+ * ram init, main RW body, EC-RW for software sync, etc. all separately.
+ */
+enum vb2_hash_tag {
+	/* Invalid hash tag; never present in table */
+	VB2_HASH_TAG_INVALID = 0,
+
+	/* Firmware body */
+	VB2_HASH_TAG_FW_BODY = 1,
+
+	/* Kernel data key */
+	VB2_HASH_TAG_KERNEL_DATA_KEY = 2,
+
+	/*
+	 * Tags over 0x40000000 are reserved for use by the calling firmware,
+	 * which may associate them with arbitrary types of RW firmware data
+	 * that it wants to track.
+	 */
+	VB2_HASH_TAG_CALLER_BASE = 0x40000000
+};
+
+#endif  /* VBOOT_REFERENCE_2FW_HASH_TAGS_H_ */
diff --git a/tools/cbfstool/vboot/2gbb.h b/tools/cbfstool/vboot/2gbb.h
new file mode 100644
index 0000000000..58da66378c
--- /dev/null
+++ b/tools/cbfstool/vboot/2gbb.h
@@ -0,0 +1,46 @@
+/* Copyright 2019 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * GBB accessor functions.
+ */
+
+#ifndef VBOOT_REFERENCE_2GBB_H_
+#define VBOOT_REFERENCE_2GBB_H_
+
+#include "2common.h"
+
+struct vb2_packed_key;
+struct vb2_workbuf;
+
+/**
+ * Read the root key from the GBB, and store it onto the given workbuf.
+ *
+ * @param ctx		Vboot context.
+ * @param keyp		Returns a pointer to the key. The caller may discard
+ *			workbuf state if it wants to free the key.
+ * @param size		If pointer is non-NULL, returns the total size of key,
+ * 			including data.
+ * @param wb		Workbuf for data storage.
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2_gbb_read_root_key(struct vb2_context *ctx,
+				  struct vb2_packed_key **keyp, uint32_t *size,
+				  struct vb2_workbuf *wb);
+
+/**
+ * Read the recovery key from the GBB, and store it onto the given workbuf.
+ *
+ * @param ctx		Vboot context.
+ * @param keyp		Returns a pointer to the key. The caller may discard
+ *			workbuf state if it wants to free the key.
+ * @param size		If pointer is non-NULL, returns the total size of key,
+ * 			including data.
+ * @param wb		Workbuf for data storage.
+ * @return VB2_SUCCESS, or error code on error.
+ */
+vb2_error_t vb2_gbb_read_recovery_key(struct vb2_context *ctx,
+				      struct vb2_packed_key **keyp,
+				      uint32_t *size, struct vb2_workbuf *wb);
+
+#endif  /* VBOOT_REFERENCE_2GBB_H_ */
diff --git a/tools/cbfstool/vboot/2gbb_flags.h b/tools/cbfstool/vboot/2gbb_flags.h
new file mode 100644
index 0000000000..600ac89e68
--- /dev/null
+++ b/tools/cbfstool/vboot/2gbb_flags.h
@@ -0,0 +1,87 @@
+/* Copyright 2019 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * Flags for vb2_gbb_header.flags.
+ *
+ * Should be imported externally via vb2_api.h.
+ */
+
+#ifndef VBOOT_REFERENCE_2GBB_FLAGS_H_
+#define VBOOT_REFERENCE_2GBB_FLAGS_H_
+
+enum vb2_gbb_flag {
+	/*
+	 * Reduce the dev screen delay to 2 sec from 30 sec to speed up
+	 * factory.
+	 */
+	VB2_GBB_FLAG_DEV_SCREEN_SHORT_DELAY = 1 << 0,
+
+	/*
+	 * BIOS should load option ROMs from arbitrary PCI devices. We'll never
+	 * enable this ourselves because it executes non-verified code, but if
+	 * a customer wants to void their warranty and set this flag in the
+	 * read-only flash, they should be able to do so.
+	 *
+	 * (TODO: Currently not supported. Mark as deprecated/unused?)
+	 */
+	VB2_GBB_FLAG_LOAD_OPTION_ROMS = 1 << 1,
+
+	/*
+	 * The factory flow may need the BIOS to boot a non-ChromeOS kernel if
+	 * the dev-switch is on. This flag allows that.
+	 *
+	 * (TODO: Currently not supported. Mark as deprecated/unused?)
+	 */
+	VB2_GBB_FLAG_ENABLE_ALTERNATE_OS = 1 << 2,
+
+	/*
+	 * Force dev switch on, regardless of physical/keyboard dev switch
+	 * position.
+	 */
+	VB2_GBB_FLAG_FORCE_DEV_SWITCH_ON = 1 << 3,
+
+	/* Allow booting from USB in dev mode even if dev_boot_usb=0. */
+	VB2_GBB_FLAG_FORCE_DEV_BOOT_USB = 1 << 4,
+
+	/* Disable firmware rollback protection. */
+	VB2_GBB_FLAG_DISABLE_FW_ROLLBACK_CHECK = 1 << 5,
+
+	/* Allow Enter key to trigger dev->tonorm screen transition */
+	VB2_GBB_FLAG_ENTER_TRIGGERS_TONORM = 1 << 6,
+
+	/* Allow booting Legacy OSes in dev mode even if dev_boot_legacy=0. */
+	VB2_GBB_FLAG_FORCE_DEV_BOOT_LEGACY = 1 << 7,
+
+	/* Allow booting using alternate keys for FAFT servo testing */
+	VB2_GBB_FLAG_FAFT_KEY_OVERIDE = 1 << 8,
+
+	/* Disable EC software sync */
+	VB2_GBB_FLAG_DISABLE_EC_SOFTWARE_SYNC = 1 << 9,
+
+	/* Default to booting legacy OS when dev screen times out */
+	VB2_GBB_FLAG_DEFAULT_DEV_BOOT_LEGACY = 1 << 10,
+
+	/* Disable PD software sync */
+	VB2_GBB_FLAG_DISABLE_PD_SOFTWARE_SYNC = 1 << 11,
+
+	/* Disable shutdown on lid closed */
+	VB2_GBB_FLAG_DISABLE_LID_SHUTDOWN = 1 << 12,
+
+	/*
+	 * Allow full fastboot capability in firmware even if
+	 * dev_boot_fastboot_full_cap=0.  Deprecated; see chromium:995172.
+	 */
+	VB2_GBB_FLAG_DEPRECATED_FORCE_DEV_BOOT_FASTBOOT_FULL_CAP = 1 << 13,
+
+	/* Recovery mode always assumes manual recovery, even if EC_IN_RW=1 */
+	VB2_GBB_FLAG_FORCE_MANUAL_RECOVERY = 1 << 14,
+
+	/* Disable FWMP */
+	VB2_GBB_FLAG_DISABLE_FWMP = 1 << 15,
+
+	/* Enable USB Device Controller */
+	VB2_GBB_FLAG_ENABLE_UDC = 1 << 16,
+};
+
+#endif  /* VBOOT_REFERENCE_2GBB_FLAGS_H_ */
diff --git a/tools/cbfstool/vboot/2id.h b/tools/cbfstool/vboot/2id.h
new file mode 100644
index 0000000000..d1897fda4f
--- /dev/null
+++ b/tools/cbfstool/vboot/2id.h
@@ -0,0 +1,37 @@
+/* Copyright 2015 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * Key ID, used to quickly match keys with signatures. There's not a standard
+ * fingerprint for private keys, so we're using the sha1sum of the public key
+ * in our keyb format. Pretty much anything would work as long as it's
+ * resistant to collisions and easy to compare.
+ */
+
+#ifndef VBOOT_REFERENCE_2ID_H_
+#define VBOOT_REFERENCE_2ID_H_
+
+#include <stdint.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif  /* __cplusplus */
+
+#define VB2_ID_NUM_BYTES 20
+
+struct vb2_id {
+	uint8_t raw[VB2_ID_NUM_BYTES];
+} __attribute__((packed));
+
+#define EXPECTED_ID_SIZE VB2_ID_NUM_BYTES
+
+/* IDs to use for "keys" with sig_alg==VB2_SIG_NONE */
+#define VB2_ID_NONE_SHA1   {{0x00, 0x01,}}
+#define VB2_ID_NONE_SHA256 {{0x02, 0x56,}}
+#define VB2_ID_NONE_SHA512 {{0x05, 0x12,}}
+
+#ifdef __cplusplus
+}
+#endif  /* __cplusplus */
+
+#endif  /* VBOOT_REFERENCE_2ID_H_ */
diff --git a/tools/cbfstool/vboot/2recovery_reasons.h b/tools/cbfstool/vboot/2recovery_reasons.h
new file mode 100644
index 0000000000..6d9a272743
--- /dev/null
+++ b/tools/cbfstool/vboot/2recovery_reasons.h
@@ -0,0 +1,253 @@
+/* Copyright (c) 2014 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * Recovery reasons
+ */
+
+#ifndef VBOOT_REFERENCE_2RECOVERY_REASONS_H_
+#define VBOOT_REFERENCE_2RECOVERY_REASONS_H_
+
+/* Recovery reason codes */
+enum vb2_nv_recovery {
+	/* Recovery not requested. */
+	VB2_RECOVERY_NOT_REQUESTED = 0x00,
+
+	/*
+	 * Recovery requested from legacy utility.  (Prior to the NV storage
+	 * spec, recovery mode was a single bitfield; this value is reserved so
+	 * that scripts which wrote 1 to the recovery field are distinguishable
+	 * from scripts whch use the recovery reasons listed here.
+	 */
+	VB2_RECOVERY_LEGACY = 0x01,
+
+	/* User manually requested recovery via recovery button */
+	VB2_RECOVERY_RO_MANUAL = 0x02,
+
+	/*
+	 * RW firmware failed signature check (neither RW firmware slot was
+	 * valid)
+	 */
+	VB2_RECOVERY_RO_INVALID_RW = 0x03,
+
+	/* S3 resume failed */
+	VB2_RECOVERY_RO_S3_RESUME = 0x04,
+
+	/* TPM error in read-only firmware (deprecated) */
+	VB2_RECOVERY_DEP_RO_TPM_ERROR = 0x05,
+
+	/* Shared data error in read-only firmware */
+	VB2_RECOVERY_RO_SHARED_DATA = 0x06,
+
+	/* Test error from S3Resume() */
+	VB2_RECOVERY_RO_TEST_S3 = 0x07,
+
+	/* Test error from LoadFirmwareSetup() (deprecated) */
+	VB2_RECOVERY_RO_TEST_LFS = 0x08,
+
+	/* Test error from LoadFirmware() (deprecated) */
+	VB2_RECOVERY_RO_TEST_LF = 0x09,
+
+	/*
+	 * RW firmware failed signature check (neither RW firmware slot was
+	 * valid).  Recovery reason is VB2_RECOVERY_RO_INVALID_RW_CHECK_MIN +
+	 * the check value for the slot which came closest to validating; see
+	 * VBSD_LF_CHECK_* in vboot_struct.h.
+	 */
+	VB2_RECOVERY_RO_INVALID_RW_CHECK_MIN = 0x10,
+
+	/* Latest tried RW firmware keyblock verification failed */
+	VB2_RECOVERY_FW_KEYBLOCK = 0x13,
+
+	/* Latest tried RW firmware key version too old */
+	VB2_RECOVERY_FW_KEY_ROLLBACK = 0x14,
+
+	/* Latest tried RW firmware preamble verification failed */
+	VB2_RECOVERY_FW_PREAMBLE = 0x16,
+
+	/* Latest tried RW firmware version too old */
+	VB2_RECOVERY_FW_ROLLBACK = 0x17,
+
+	/* Latest tried RW firmware body verification failed */
+	VB2_RECOVERY_FW_BODY = 0x1b,
+
+	/* Highest reason for failed RW firmware signature check */
+	VB2_RECOVERY_RO_INVALID_RW_CHECK_MAX = 0x1f,
+
+	/*
+	 * Firmware boot failure outside of verified boot (RAM init, missing
+	 * SSD, etc.).
+	 */
+	VB2_RECOVERY_RO_FIRMWARE = 0x20,
+
+	/*
+	 * Recovery mode TPM initialization requires a system reboot.  The
+	 * system was already in recovery mode for some other reason when this
+	 * happened.
+	 */
+	VB2_RECOVERY_RO_TPM_REBOOT = 0x21,
+
+	/* EC software sync - other error */
+	VB2_RECOVERY_EC_SOFTWARE_SYNC = 0x22,
+
+	/* EC software sync - unable to determine active EC image */
+	VB2_RECOVERY_EC_UNKNOWN_IMAGE = 0x23,
+
+	/* EC software sync - error obtaining EC image hash (deprecated) */
+	VB2_RECOVERY_DEP_EC_HASH = 0x24,
+
+	/* EC software sync - error obtaining expected EC image */
+	VB2_RECOVERY_EC_EXPECTED_IMAGE = 0x25,
+
+	/* EC software sync - error updating EC */
+	VB2_RECOVERY_EC_UPDATE = 0x26,
+
+	/* EC software sync - unable to jump to EC-RW */
+	VB2_RECOVERY_EC_JUMP_RW = 0x27,
+
+	/* EC software sync - unable to protect / unprotect EC-RW */
+	VB2_RECOVERY_EC_PROTECT = 0x28,
+
+	/* EC software sync - error obtaining expected EC hash */
+	VB2_RECOVERY_EC_EXPECTED_HASH = 0x29,
+
+	/* EC software sync - expected EC image doesn't match hash */
+	VB2_RECOVERY_EC_HASH_MISMATCH = 0x2a,
+
+	/* New error codes from VB2 */
+	/* TODO: may need to add strings for these in the original fwlib */
+
+	/* Firmware secure data initialization error */
+	VB2_RECOVERY_SECDATA_FIRMWARE_INIT = 0x2b,
+
+	/* GBB header is bad */
+	VB2_RECOVERY_GBB_HEADER = 0x2c,
+
+	/* Unable to clear TPM owner */
+	VB2_RECOVERY_TPM_CLEAR_OWNER = 0x2d,
+
+	/* Error determining/updating virtual dev switch */
+	VB2_RECOVERY_DEV_SWITCH = 0x2e,
+
+	/* Error determining firmware slot */
+	VB2_RECOVERY_FW_SLOT = 0x2f,
+
+	/* Error updating AUX firmware */
+	VB2_RECOVERY_AUX_FW_UPDATE = 0x30,
+
+	/* Unspecified/unknown error in read-only firmware */
+	VB2_RECOVERY_RO_UNSPECIFIED = 0x3f,
+
+	/*
+	 * User manually requested recovery by pressing a key at developer
+	 * warning screen
+	 */
+	VB2_RECOVERY_RW_DEV_SCREEN = 0x41,
+
+	/* No OS kernel detected */
+	VB2_RECOVERY_RW_NO_OS = 0x42,
+
+	/* OS kernel failed signature check */
+	VB2_RECOVERY_RW_INVALID_OS = 0x43,
+
+	/* TPM error in rewritable firmware (deprecated) */
+	VB2_RECOVERY_DEP_RW_TPM_ERROR = 0x44,
+
+	/* RW firmware in dev mode, but dev switch is off */
+	VB2_RECOVERY_RW_DEV_MISMATCH = 0x45,
+
+	/* Shared data error in rewritable firmware */
+	VB2_RECOVERY_RW_SHARED_DATA = 0x46,
+
+	/* Test error from LoadKernel() */
+	VB2_RECOVERY_RW_TEST_LK = 0x47,
+
+	/* No bootable disk found (deprecated)*/
+	VB2_RECOVERY_DEP_RW_NO_DISK = 0x48,
+
+	/* Rebooting did not correct TPM_E_FAIL or TPM_E_FAILEDSELFTEST  */
+	VB2_RECOVERY_TPM_E_FAIL = 0x49,
+
+	/* TPM setup error in read-only firmware */
+	VB2_RECOVERY_RO_TPM_S_ERROR = 0x50,
+
+	/* TPM write error in read-only firmware */
+	VB2_RECOVERY_RO_TPM_W_ERROR = 0x51,
+
+	/* TPM lock error in read-only firmware */
+	VB2_RECOVERY_RO_TPM_L_ERROR = 0x52,
+
+	/* TPM update error in read-only firmware */
+	VB2_RECOVERY_RO_TPM_U_ERROR = 0x53,
+
+	/* TPM read error in rewritable firmware */
+	VB2_RECOVERY_RW_TPM_R_ERROR = 0x54,
+
+	/* TPM write error in rewritable firmware */
+	VB2_RECOVERY_RW_TPM_W_ERROR = 0x55,
+
+	/* TPM lock error in rewritable firmware */
+	VB2_RECOVERY_RW_TPM_L_ERROR = 0x56,
+
+	/* EC software sync unable to get EC image hash */
+	VB2_RECOVERY_EC_HASH_FAILED = 0x57,
+
+	/* EC software sync invalid image hash size */
+	VB2_RECOVERY_EC_HASH_SIZE    = 0x58,
+
+	/* Unspecified error while trying to load kernel */
+	VB2_RECOVERY_LK_UNSPECIFIED  = 0x59,
+
+	/* No bootable storage device in system */
+	VB2_RECOVERY_RW_NO_DISK      = 0x5a,
+
+	/* No bootable kernel found on disk */
+	VB2_RECOVERY_RW_NO_KERNEL    = 0x5b,
+
+	/* BCB related error in RW firmware */
+	VB2_RECOVERY_RW_BCB_ERROR    = 0x5c,
+
+	/* New error codes from VB2 */
+	/* TODO: may need to add strings for these in the original fwlib */
+
+	/* Kernel secure data initialization error */
+	VB2_RECOVERY_SECDATA_KERNEL_INIT = 0x5d,
+
+	/* Fastboot mode requested in firmware */
+	VB2_RECOVERY_DEPRECATED_FW_FASTBOOT     = 0x5e,
+
+	/* Recovery hash space lock error in RO firmware */
+	VB2_RECOVERY_RO_TPM_REC_HASH_L_ERROR = 0x5f,
+
+	/* Failed to disable the TPM [prior to running untrusted code] */
+	VB2_RECOVERY_TPM_DISABLE_FAILED = 0x60,
+
+	/* Alt FW Failed hash verification */
+	VB2_RECOVERY_ALTFW_HASH_FAILED = 0x61,
+
+	/* Unspecified/unknown error in rewritable firmware */
+	VB2_RECOVERY_RW_UNSPECIFIED  = 0x7f,
+
+	/* DM-verity error */
+	VB2_RECOVERY_KE_DM_VERITY    = 0x81,
+
+	/* Unspecified/unknown error in kernel */
+	VB2_RECOVERY_KE_UNSPECIFIED  = 0xbf,
+
+	/* Recovery mode test from user-mode */
+	VB2_RECOVERY_US_TEST         = 0xc1,
+
+	/* Recovery requested by user-mode via BCB */
+	VB2_RECOVERY_BCB_USER_MODE   = 0xc2,
+
+	/* Fastboot mode requested by user-mode */
+	VB2_RECOVERY_DEPRECATED_US_FASTBOOT     = 0xc3,
+
+	/* User requested recovery for training memory and rebooting. */
+	VB2_RECOVERY_TRAIN_AND_REBOOT = 0xc4,
+
+	/* Unspecified/unknown error in user-mode */
+	VB2_RECOVERY_US_UNSPECIFIED  = 0xff,
+};
+
+#endif  /* VBOOT_REFERENCE_2RECOVERY_REASONS_H_ */
diff --git a/tools/cbfstool/vboot/2return_codes.h b/tools/cbfstool/vboot/2return_codes.h
new file mode 100644
index 0000000000..ed34109e38
--- /dev/null
+++ b/tools/cbfstool/vboot/2return_codes.h
@@ -0,0 +1,922 @@
+/* Copyright (c) 2014 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef VBOOT_REFERENCE_2RETURN_CODES_H_
+#define VBOOT_REFERENCE_2RETURN_CODES_H_
+
+#include "2sysincludes.h"
+
+/*
+ * Functions which return an error all return this type.  This is a 32-bit
+ * value rather than an int so it's consistent across different architectures.
+ */
+typedef uint32_t vb2_error_t;
+
+/*
+ * Return codes from verified boot functions.
+ *
+ * Note that other values may be passed through from vb2ex_*() calls; see
+ * the comment for VB2_ERROR_EX below.
+ */
+enum vb2_return_code {
+	/* Success - no error */
+	VB2_SUCCESS = 0,
+
+	/*
+	 * All vboot2 error codes start at a large offset from zero, to reduce
+	 * the risk of overlap with other error codes (TPM, etc.).
+	 */
+	VB2_ERROR_BASE = 0x10000000,
+
+	/* Unknown / unspecified error */
+	VB2_ERROR_UNKNOWN = VB2_ERROR_BASE + 1,
+
+	/* Mock error for testing */
+	VB2_ERROR_MOCK,
+
+	/**********************************************************************
+	 * vboot1-style errors
+	 * TODO: deprecate these once they have all moved over to vboot2 style
+	 */
+	/* Unable to initialize shared data */
+	VBERROR_INIT_SHARED_DATA              = 0x10001,
+	/* Unable to set boot mode state in TPM */
+	VBERROR_TPM_SET_BOOT_MODE_STATE       = 0x10006,
+	/* Calling firmware needs to perform a reboot. */
+	VBERROR_REBOOT_REQUIRED               = 0x10007,
+	/* Unable to set up TPM */
+	VBERROR_TPM_FIRMWARE_SETUP            = 0x10008,
+	/* Unable to read kernel versions from TPM */
+	VBERROR_TPM_READ_KERNEL               = 0x10009,
+	/* Unable to write kernel versions to TPM */
+	VBERROR_TPM_WRITE_KERNEL              = 0x1000B,
+	/* Unable to lock kernel versions in TPM */
+	VBERROR_TPM_LOCK_KERNEL               = 0x1000C,
+	/* Calling firmware requested shutdown via VbExIsShutdownRequested() */
+	VBERROR_SHUTDOWN_REQUESTED            = 0x1000D,
+	/* Unable to find a boot device on which to look for a kernel */
+	VBERROR_NO_DISK_FOUND                 = 0x1000E,
+	/* No OS kernel found on any boot device */
+	VBERROR_NO_KERNEL_FOUND               = 0x1000F,
+	/* All OS kernels found were invalid (corrupt, improperly signed...) */
+	VBERROR_INVALID_KERNEL_FOUND          = 0x10010,
+	/* VbSelectAndLoadKernel() requested recovery mode */
+	VBERROR_LOAD_KERNEL_RECOVERY          = 0x10011,
+	/* Other error inside VbSelectAndLoadKernel() */
+	VBERROR_LOAD_KERNEL                   = 0x10012,
+	/* Invalid Google binary block */
+	VBERROR_INVALID_GBB                   = 0x10013,
+	/* Invalid bitmap volume */
+	VBERROR_INVALID_BMPFV                 = 0x10014,
+	/* Invalid screen index */
+	VBERROR_INVALID_SCREEN_INDEX          = 0x10015,
+	/* VbExBeep() can't make sound in the background */
+	VBERROR_NO_BACKGROUND_SOUND           = 0x10019,
+	/* Need EC to reboot to read-only code to switch RW slot */
+	VBERROR_EC_REBOOT_TO_SWITCH_RW        = 0x1001A,
+	/* Need EC to reboot to read-only code */
+	VBERROR_EC_REBOOT_TO_RO_REQUIRED      = 0x10022,
+	/* No image present */
+	VBERROR_NO_IMAGE_PRESENT              = 0x10026,
+	/* failed to draw screen */
+	VBERROR_SCREEN_DRAW                   = 0x10027,
+	/* Error reading FWMP from TPM (note: not present is not an error) */
+	VBERROR_TPM_READ_FWMP                 = 0x10029,
+	/* Peripheral busy. Cannot upgrade firmware at present. */
+	VBERROR_PERIPHERAL_BUSY               = 0x10030,
+	/* Error writing VPD */
+	VBERROR_VPD_WRITE                     = 0x10032,
+	/* Detachable UI internal functions may return the following codes */
+	/* No error; return to UI loop */
+	VBERROR_KEEP_LOOPING			= 0x30000,
+
+	/**********************************************************************
+	 * SHA errors
+	 */
+	VB2_ERROR_SHA = VB2_ERROR_BASE + 0x010000,
+
+	/* Bad algorithm in vb2_digest_init() */
+	VB2_ERROR_SHA_INIT_ALGORITHM,
+
+	/* Bad algorithm in vb2_digest_extend() */
+	VB2_ERROR_SHA_EXTEND_ALGORITHM,
+
+	/* Bad algorithm in vb2_digest_finalize() */
+	VB2_ERROR_SHA_FINALIZE_ALGORITHM,
+
+	/* Digest size buffer too small in vb2_digest_finalize() */
+	VB2_ERROR_SHA_FINALIZE_DIGEST_SIZE,
+
+	/**********************************************************************
+	 * RSA errors
+	 */
+	VB2_ERROR_RSA = VB2_ERROR_BASE + 0x020000,
+
+	/* Padding mismatch in vb2_check_padding() */
+	VB2_ERROR_RSA_PADDING,
+
+	/* Bad algorithm in vb2_check_padding() */
+	VB2_ERROR_RSA_PADDING_ALGORITHM,
+
+	/* Null param passed to vb2_verify_digest() */
+	VB2_ERROR_RSA_VERIFY_PARAM,
+
+	/* Bad algorithm in vb2_verify_digest() */
+	VB2_ERROR_RSA_VERIFY_ALGORITHM,
+
+	/* Bad signature length in vb2_verify_digest() */
+	VB2_ERROR_RSA_VERIFY_SIG_LEN,
+
+	/* Work buffer too small in vb2_verify_digest() */
+	VB2_ERROR_RSA_VERIFY_WORKBUF,
+
+	/* Digest mismatch in vb2_verify_digest() */
+	VB2_ERROR_RSA_VERIFY_DIGEST,
+
+	/* Bad size calculation in vb2_check_padding() */
+	VB2_ERROR_RSA_PADDING_SIZE,
+
+	/**********************************************************************
+	 * NV storage errors
+	 */
+	VB2_ERROR_NV = VB2_ERROR_BASE + 0x030000,
+
+	/* Bad header in vb2_nv_check_crc() */
+	VB2_ERROR_NV_HEADER,
+
+	/* Bad CRC in vb2_nv_check_crc() */
+	VB2_ERROR_NV_CRC,
+
+	/**********************************************************************
+	 * Secure data storage errors
+	 */
+	VB2_ERROR_SECDATA = VB2_ERROR_BASE + 0x040000,
+
+	/* Bad CRC in vb2api_secdata_firmware_check() */
+	VB2_ERROR_SECDATA_FIRMWARE_CRC,
+
+	/* Bad struct version in vb2api_secdata_firmware_check() */
+	VB2_ERROR_SECDATA_FIRMWARE_VERSION,
+
+	/* Invalid param in vb2_secdata_firmware_get() */
+	VB2_ERROR_SECDATA_FIRMWARE_GET_PARAM,
+
+	/* Invalid param in vb2_secdata_firmware_set() */
+	VB2_ERROR_SECDATA_FIRMWARE_SET_PARAM,
+
+	/* Invalid flags passed to vb2_secdata_firmware_set() */
+	VB2_ERROR_SECDATA_FIRMWARE_SET_FLAGS,
+
+	/* Called vb2_secdata_firmware_get() with uninitialized secdata */
+	VB2_ERROR_SECDATA_FIRMWARE_GET_UNINITIALIZED,
+
+	/* Called vb2_secdata_firmware_set() with uninitialized secdata */
+	VB2_ERROR_SECDATA_FIRMWARE_SET_UNINITIALIZED,
+
+	/* Bad CRC in vb2api_secdata_kernel_check() */
+	VB2_ERROR_SECDATA_KERNEL_CRC,
+
+	/* Bad struct version in vb2_secdata_kernel_init() */
+	VB2_ERROR_SECDATA_KERNEL_VERSION,
+
+	/* Bad uid in vb2_secdata_kernel_init() */
+	VB2_ERROR_SECDATA_KERNEL_UID,
+
+	/* Invalid param in vb2_secdata_kernel_get() */
+	VB2_ERROR_SECDATA_KERNEL_GET_PARAM,
+
+	/* Invalid param in vb2_secdata_kernel_set() */
+	VB2_ERROR_SECDATA_KERNEL_SET_PARAM,
+
+	/* Invalid flags passed to vb2_secdata_kernel_set() */
+	VB2_ERROR_SECDATA_KERNEL_SET_FLAGS,
+
+	/* Called vb2_secdata_kernel_get() with uninitialized secdata_kernel */
+	VB2_ERROR_SECDATA_KERNEL_GET_UNINITIALIZED,
+
+	/* Called vb2_secdata_kernel_set() with uninitialized secdata_kernel */
+	VB2_ERROR_SECDATA_KERNEL_SET_UNINITIALIZED,
+
+	/* Bad size in vb2api_secdata_fwmp_check() */
+	VB2_ERROR_SECDATA_FWMP_SIZE,
+
+	/* Incomplete structure in vb2api_secdata_fwmp_check() */
+	VB2_ERROR_SECDATA_FWMP_INCOMPLETE,
+
+	/* Bad CRC in vb2api_secdata_fwmp_check() */
+	VB2_ERROR_SECDATA_FWMP_CRC,
+
+	/* Bad struct version in vb2_secdata_fwmp_check() */
+	VB2_ERROR_SECDATA_FWMP_VERSION,
+
+	/**********************************************************************
+	 * Common code errors
+	 */
+	VB2_ERROR_COMMON = VB2_ERROR_BASE + 0x050000,
+
+	/* Buffer is smaller than alignment offset in vb2_align() */
+	VB2_ERROR_ALIGN_BIGGER_THAN_SIZE,
+
+	/* Buffer is smaller than request in vb2_align() */
+	VB2_ERROR_ALIGN_SIZE,
+
+	/* Parent wraps around in vb2_verify_member_inside() */
+	VB2_ERROR_INSIDE_PARENT_WRAPS,
+
+	/* Member wraps around in vb2_verify_member_inside() */
+	VB2_ERROR_INSIDE_MEMBER_WRAPS,
+
+	/* Member outside parent in vb2_verify_member_inside() */
+	VB2_ERROR_INSIDE_MEMBER_OUTSIDE,
+
+	/* Member data wraps around in vb2_verify_member_inside() */
+	VB2_ERROR_INSIDE_DATA_WRAPS,
+
+	/* Member data outside parent in vb2_verify_member_inside() */
+	VB2_ERROR_INSIDE_DATA_OUTSIDE,
+
+	/* Unsupported signature algorithm in vb2_unpack_key_buffer() */
+	VB2_ERROR_UNPACK_KEY_SIG_ALGORITHM,                      /* 0x150008 */
+
+	/* Bad key size in vb2_unpack_key_buffer() */
+	VB2_ERROR_UNPACK_KEY_SIZE,
+
+	/* Bad key alignment in vb2_unpack_key_buffer() */
+	VB2_ERROR_UNPACK_KEY_ALIGN,
+
+	/* Bad key array size in vb2_unpack_key_buffer() */
+	VB2_ERROR_UNPACK_KEY_ARRAY_SIZE,
+
+	/* Bad algorithm in vb2_verify_data() */
+	VB2_ERROR_VDATA_ALGORITHM,
+
+	/* Incorrect signature size for algorithm in vb2_verify_data() */
+	VB2_ERROR_VDATA_SIG_SIZE,
+
+	/* Data smaller than length of signed data in vb2_verify_data() */
+	VB2_ERROR_VDATA_NOT_ENOUGH_DATA,
+
+	/* Not enough work buffer for digest in vb2_verify_data() */
+	VB2_ERROR_VDATA_WORKBUF_DIGEST,
+
+	/* Not enough work buffer for hash temp data in vb2_verify_data() */
+	VB2_ERROR_VDATA_WORKBUF_HASHING,                         /* 0x150010 */
+
+	/*
+	 * Bad digest size in vb2_verify_data() - probably because algorithm
+	 * is bad.
+	 */
+	VB2_ERROR_VDATA_DIGEST_SIZE,
+
+	/* Unsupported hash algorithm in vb2_unpack_key_buffer() */
+	VB2_ERROR_UNPACK_KEY_HASH_ALGORITHM,
+
+	/* Member data overlaps member header */
+	VB2_ERROR_INSIDE_DATA_OVERLAP,
+
+	/* Unsupported packed key struct version */
+	VB2_ERROR_UNPACK_KEY_STRUCT_VERSION,
+
+	/*
+	 * Buffer too small for total, fixed size, or description reported in
+	 * common header, or member data checked via
+	 * vb21_verify_common_member().
+	 */
+	VB2_ERROR_COMMON_TOTAL_SIZE,
+	VB2_ERROR_COMMON_FIXED_SIZE,
+	VB2_ERROR_COMMON_DESC_SIZE,
+	VB2_ERROR_COMMON_MEMBER_SIZE,                            /* 0x150018 */
+
+	/*
+	 * Total, fixed, description, or member offset/size not a multiple of
+	 * 32 bits.
+	 */
+	VB2_ERROR_COMMON_TOTAL_UNALIGNED,
+	VB2_ERROR_COMMON_FIXED_UNALIGNED,
+	VB2_ERROR_COMMON_DESC_UNALIGNED,
+	VB2_ERROR_COMMON_MEMBER_UNALIGNED,
+
+	/* Common struct description or member data wraps address space */
+	VB2_ERROR_COMMON_DESC_WRAPS,
+	VB2_ERROR_COMMON_MEMBER_WRAPS,
+
+	/* Common struct description is not null-terminated */
+	VB2_ERROR_COMMON_DESC_TERMINATOR,
+
+	/* Member data overlaps previous data */
+	VB2_ERROR_COMMON_MEMBER_OVERLAP,                         /* 0x150020 */
+
+	/* Signature bad magic number */
+	VB2_ERROR_SIG_MAGIC,
+
+	/* Signature incompatible version */
+	VB2_ERROR_SIG_VERSION,
+
+	/* Signature header doesn't fit */
+	VB2_ERROR_SIG_HEADER_SIZE,
+
+	/* Signature unsupported algorithm */
+	VB2_ERROR_SIG_ALGORITHM,
+
+	/* Signature bad size for algorithm */
+	VB2_ERROR_SIG_SIZE,
+
+	/* Wrong amount of data signed */
+	VB2_ERROR_VDATA_SIZE,
+
+	/* Digest mismatch */
+	VB2_ERROR_VDATA_VERIFY_DIGEST,
+
+	/* Key algorithm doesn't match signature algorithm */
+	VB2_ERROR_VDATA_ALGORITHM_MISMATCH,
+
+	/* Bad magic number in vb2_unpack_key_buffer() */
+	VB2_ERROR_UNPACK_KEY_MAGIC,
+
+	/* Null public key buffer passed to vb2_unpack_key_buffer() */
+	VB2_ERROR_UNPACK_KEY_BUFFER,
+
+	/**********************************************************************
+	 * Keyblock verification errors (all in vb2_verify_keyblock())
+	 */
+	VB2_ERROR_KEYBLOCK = VB2_ERROR_BASE + 0x060000,
+
+	/* Data buffer too small for header */
+	VB2_ERROR_KEYBLOCK_TOO_SMALL_FOR_HEADER,
+
+	/* Magic number not present */
+	VB2_ERROR_KEYBLOCK_MAGIC,
+
+	/* Header version incompatible */
+	VB2_ERROR_KEYBLOCK_HEADER_VERSION,
+
+	/* Data buffer too small for keyblock */
+	VB2_ERROR_KEYBLOCK_SIZE,
+
+	/* Signature data offset outside keyblock */
+	VB2_ERROR_KEYBLOCK_SIG_OUTSIDE,
+
+	/* Signature signed more data than size of keyblock */
+	VB2_ERROR_KEYBLOCK_SIGNED_TOO_MUCH,
+
+	/* Signature signed less data than size of keyblock header */
+	VB2_ERROR_KEYBLOCK_SIGNED_TOO_LITTLE,
+
+	/* Signature invalid */
+	VB2_ERROR_KEYBLOCK_SIG_INVALID,
+
+	/* Data key outside keyblock */
+	VB2_ERROR_KEYBLOCK_DATA_KEY_OUTSIDE,
+
+	/* Data key outside signed part of keyblock */
+	VB2_ERROR_KEYBLOCK_DATA_KEY_UNSIGNED,
+
+	/* Signature signed wrong amount of data */
+	VB2_ERROR_KEYBLOCK_SIGNED_SIZE,
+
+	/* No signature matching key ID */
+	VB2_ERROR_KEYBLOCK_SIG_ID,
+
+	/**********************************************************************
+	 * Preamble verification errors (all in vb2_verify_preamble())
+	 */
+	VB2_ERROR_PREAMBLE = VB2_ERROR_BASE + 0x070000,
+
+	/* Preamble data too small to contain header */
+	VB2_ERROR_PREAMBLE_TOO_SMALL_FOR_HEADER,
+
+	/* Header version incompatible */
+	VB2_ERROR_PREAMBLE_HEADER_VERSION,
+
+	/* Header version too old */
+	VB2_ERROR_PREAMBLE_HEADER_OLD,
+
+	/* Data buffer too small for preamble */
+	VB2_ERROR_PREAMBLE_SIZE,
+
+	/* Signature data offset outside preamble */
+	VB2_ERROR_PREAMBLE_SIG_OUTSIDE,
+
+	/* Signature signed more data than size of preamble */
+	VB2_ERROR_PREAMBLE_SIGNED_TOO_MUCH,
+
+	/* Signature signed less data than size of preamble header */
+	VB2_ERROR_PREAMBLE_SIGNED_TOO_LITTLE,
+
+	/* Signature invalid */
+	VB2_ERROR_PREAMBLE_SIG_INVALID,
+
+	/* Body signature outside preamble */
+	VB2_ERROR_PREAMBLE_BODY_SIG_OUTSIDE,
+
+	/* Kernel subkey outside preamble */
+	VB2_ERROR_PREAMBLE_KERNEL_SUBKEY_OUTSIDE,
+
+	/* Bad magic number */
+	VB2_ERROR_PREAMBLE_MAGIC,
+
+	/* Hash is signed */
+	VB2_ERROR_PREAMBLE_HASH_SIGNED,
+
+	/* Bootloader outside signed portion of body */
+	VB2_ERROR_PREAMBLE_BOOTLOADER_OUTSIDE,
+
+	/* Vmlinuz header outside signed portion of body */
+	VB2_ERROR_PREAMBLE_VMLINUZ_HEADER_OUTSIDE,
+
+	/**********************************************************************
+	 * Misc higher-level code errors
+	 */
+	VB2_ERROR_MISC = VB2_ERROR_BASE + 0x080000,
+
+	/* Work buffer too small in vb2_init_context() */
+	VB2_ERROR_INITCTX_WORKBUF_SMALL,
+
+	/* Work buffer unaligned in vb2_init_context() */
+	VB2_ERROR_INITCTX_WORKBUF_ALIGN,
+
+	/* Work buffer too small in GBB-related function */
+	VB2_ERROR_GBB_WORKBUF,
+
+	/* Bad magic number in vb2_read_gbb_header() */
+	VB2_ERROR_GBB_MAGIC,
+
+	/* Incompatible version in vb2_read_gbb_header() */
+	VB2_ERROR_GBB_VERSION,
+
+	/* Old version in vb2_read_gbb_header() */
+	VB2_ERROR_GBB_TOO_OLD,
+
+	/* Header size too small in vb2_read_gbb_header() */
+	VB2_ERROR_GBB_HEADER_SIZE,
+
+	/* Work buffer too small for root key in vb2_load_fw_keyblock() */
+	VB2_ERROR_FW_KEYBLOCK_WORKBUF_ROOT_KEY,
+
+	/* Work buffer too small for header in vb2_load_fw_keyblock() */
+	VB2_ERROR_FW_KEYBLOCK_WORKBUF_HEADER,
+
+	/* Work buffer too small for keyblock in vb2_load_fw_keyblock() */
+	VB2_ERROR_FW_KEYBLOCK_WORKBUF,
+
+	/* Keyblock version out of range in vb2_load_fw_keyblock() */
+	VB2_ERROR_FW_KEYBLOCK_VERSION_RANGE,
+
+	/* Keyblock version rollback in vb2_load_fw_keyblock() */
+	VB2_ERROR_FW_KEYBLOCK_VERSION_ROLLBACK,
+
+	/* Missing firmware data key in vb2_load_fw_preamble() */
+	VB2_ERROR_FW_PREAMBLE2_DATA_KEY,
+
+	/* Work buffer too small for header in vb2_load_fw_preamble() */
+	VB2_ERROR_FW_PREAMBLE2_WORKBUF_HEADER,
+
+	/* Work buffer too small for preamble in vb2_load_fw_preamble() */
+	VB2_ERROR_FW_PREAMBLE2_WORKBUF,
+
+	/* Firmware version out of range in vb2_load_fw_preamble() */
+	VB2_ERROR_FW_PREAMBLE_VERSION_RANGE,
+
+	/* Firmware version rollback in vb2_load_fw_preamble() */
+	VB2_ERROR_FW_PREAMBLE_VERSION_ROLLBACK,
+
+	/* Not enough space in work buffer for resource object */
+	VB2_ERROR_READ_RESOURCE_OBJECT_BUF,
+
+	/* Work buffer too small for header in vb2_load_kernel_keyblock() */
+	VB2_ERROR_KERNEL_KEYBLOCK_WORKBUF_HEADER,
+
+	/* Work buffer too small for keyblock in vb2_load_kernel_keyblock() */
+	VB2_ERROR_KERNEL_KEYBLOCK_WORKBUF,
+
+	/* Keyblock version out of range in vb2_load_kernel_keyblock() */
+	VB2_ERROR_KERNEL_KEYBLOCK_VERSION_RANGE,
+
+	/* Keyblock version rollback in vb2_load_kernel_keyblock() */
+	VB2_ERROR_KERNEL_KEYBLOCK_VERSION_ROLLBACK,
+
+	/*
+	 * Keyblock flags don't match current mode in
+	 * vb2_load_kernel_keyblock().
+	 */
+	VB2_ERROR_KERNEL_KEYBLOCK_DEV_FLAG,
+	VB2_ERROR_KERNEL_KEYBLOCK_REC_FLAG,
+
+	/* Missing firmware data key in vb2_load_kernel_preamble() */
+	VB2_ERROR_KERNEL_PREAMBLE2_DATA_KEY,
+
+	/* Work buffer too small for header in vb2_load_kernel_preamble() */
+	VB2_ERROR_KERNEL_PREAMBLE2_WORKBUF_HEADER,
+
+	/* Work buffer too small for preamble in vb2_load_kernel_preamble() */
+	VB2_ERROR_KERNEL_PREAMBLE2_WORKBUF,
+
+	/* Kernel version out of range in vb2_load_kernel_preamble() */
+	VB2_ERROR_KERNEL_PREAMBLE_VERSION_RANGE,
+
+	/* Kernel version rollback in vb2_load_kernel_preamble() */
+	VB2_ERROR_KERNEL_PREAMBLE_VERSION_ROLLBACK,
+
+	/* Kernel preamble not loaded before calling vb2api_get_kernel_size() */
+	VB2_ERROR_API_GET_KERNEL_SIZE_PREAMBLE,
+
+	/* Unable to unpack kernel subkey in vb2_verify_vblock() */
+	VB2_ERROR_VBLOCK_KERNEL_SUBKEY,
+
+	/*
+	 * Got a self-signed kernel in vb2_verify_vblock(), but need an
+	 * officially signed one.
+	 */
+	VB2_ERROR_VBLOCK_SELF_SIGNED,
+
+	/* Invalid keyblock hash in vb2_verify_vblock() */
+	VB2_ERROR_VBLOCK_KEYBLOCK_HASH,
+
+	/* Invalid keyblock in vb2_verify_vblock() */
+	VB2_ERROR_VBLOCK_KEYBLOCK,
+
+	/* Wrong developer key hash in vb2_verify_vblock() */
+	VB2_ERROR_VBLOCK_DEV_KEY_HASH,
+
+	/* Work buffer too small in vb2_load_partition() */
+	VB2_ERROR_LOAD_PARTITION_WORKBUF,
+
+	/* Unable to read vblock in vb2_load_partition() */
+	VB2_ERROR_LOAD_PARTITION_READ_VBLOCK,
+
+	/* Unable to verify vblock in vb2_load_partition() */
+	VB2_ERROR_LOAD_PARTITION_VERIFY_VBLOCK,
+
+	/* Kernel body offset too large in vb2_load_partition() */
+	VB2_ERROR_LOAD_PARTITION_BODY_OFFSET,
+
+	/* Kernel body too big in vb2_load_partition() */
+	VB2_ERROR_LOAD_PARTITION_BODY_SIZE,
+
+	/* Unable to read kernel body in vb2_load_partition() */
+	VB2_ERROR_LOAD_PARTITION_READ_BODY,
+
+	/* Unable to unpack data key in vb2_load_partition() */
+	VB2_ERROR_LOAD_PARTITION_DATA_KEY,
+
+	/* Unable to verify body in vb2_load_partition() */
+	VB2_ERROR_LOAD_PARTITION_VERIFY_BODY,
+
+	/* Unable to get EC image hash in ec_sync_phase1() */
+	VB2_ERROR_EC_HASH_IMAGE,
+
+	/* Unable to get expected EC image hash in ec_sync_phase1() */
+	VB2_ERROR_EC_HASH_EXPECTED,
+
+	/* Expected and image hashes are different size in ec_sync_phase1() */
+	VB2_ERROR_EC_HASH_SIZE,
+
+	/* Incompatible version for vb2_shared_data structure being loaded */
+	VB2_ERROR_SHARED_DATA_VERSION,
+
+	/* Bad magic number in vb2_shared_data structure */
+	VB2_ERROR_SHARED_DATA_MAGIC,
+
+	/* Some part of GBB data is invalid */
+	VB2_ERROR_GBB_INVALID,
+
+	/* Invalid parameter */
+	VB2_ERROR_INVALID_PARAMETER,
+
+	/**********************************************************************
+	 * API-level errors
+	 */
+	VB2_ERROR_API = VB2_ERROR_BASE + 0x090000,
+
+	/* Bad tag in vb2api_init_hash() */
+	VB2_ERROR_API_INIT_HASH_TAG,
+
+	/* Preamble not present in vb2api_init_hash() */
+	VB2_ERROR_API_INIT_HASH_PREAMBLE,
+
+	/* Work buffer too small in vb2api_init_hash() */
+	VB2_ERROR_API_INIT_HASH_WORKBUF,
+
+	/* Missing firmware data key in vb2api_init_hash() */
+	VB2_ERROR_API_INIT_HASH_DATA_KEY,
+
+	/* Uninitialized work area in vb2api_extend_hash() */
+	VB2_ERROR_API_EXTEND_HASH_WORKBUF,
+
+	/* Too much data hashed in vb2api_extend_hash() */
+	VB2_ERROR_API_EXTEND_HASH_SIZE,
+
+	/* Preamble not present in vb2api_check_hash() */
+	VB2_ERROR_API_CHECK_HASH_PREAMBLE,
+
+	/* Uninitialized work area in vb2api_check_hash() */
+	VB2_ERROR_API_CHECK_HASH_WORKBUF,
+
+	/* Wrong amount of data hashed in vb2api_check_hash() */
+	VB2_ERROR_API_CHECK_HASH_SIZE,
+
+	/* Work buffer too small in vb2api_check_hash() */
+	VB2_ERROR_API_CHECK_HASH_WORKBUF_DIGEST,
+
+	/* Bad tag in vb2api_check_hash() */
+	VB2_ERROR_API_CHECK_HASH_TAG,
+
+	/* Missing firmware data key in vb2api_check_hash() */
+	VB2_ERROR_API_CHECK_HASH_DATA_KEY,
+
+	/* Signature size mismatch in vb2api_check_hash() */
+	VB2_ERROR_API_CHECK_HASH_SIG_SIZE,
+
+	/* Phase one needs recovery mode */
+	VB2_ERROR_API_PHASE1_RECOVERY,
+
+	/* Bad tag in vb2api_check_hash() */
+	VB2_ERROR_API_INIT_HASH_ID,
+
+	/* Signature mismatch in vb2api_check_hash() */
+	VB2_ERROR_API_CHECK_HASH_SIG,
+
+	/* Invalid enum vb2_pcr_digest requested to vb2api_get_pcr_digest */
+	VB2_ERROR_API_PCR_DIGEST,
+
+	/* Buffer size for the digest is too small for vb2api_get_pcr_digest */
+	VB2_ERROR_API_PCR_DIGEST_BUF,
+
+	/* Work buffer too small for recovery key in vb2api_kernel_phase1() */
+	VB2_ERROR_API_KPHASE1_WORKBUF_REC_KEY,
+
+	/* Firmware preamble not present for vb2api_kernel_phase1() */
+	VB2_ERROR_API_KPHASE1_PREAMBLE,
+
+	/* Wrong amount of kernel data in vb2api_verify_kernel_data() */
+	VB2_ERROR_API_VERIFY_KDATA_SIZE,
+
+	/* Kernel preamble not present for vb2api_verify_kernel_data() */
+	VB2_ERROR_API_VERIFY_KDATA_PREAMBLE,
+
+	/* Insufficient workbuf for hashing in vb2api_verify_kernel_data() */
+	VB2_ERROR_API_VERIFY_KDATA_WORKBUF,
+
+	/* Bad data key in vb2api_verify_kernel_data() */
+	VB2_ERROR_API_VERIFY_KDATA_KEY,
+
+	/* Phase one passing through secdata's request to reboot */
+	VB2_ERROR_API_PHASE1_SECDATA_REBOOT,
+
+	/* Digest buffer passed into vb2api_check_hash incorrect. */
+	VB2_ERROR_API_CHECK_DIGEST_SIZE,
+
+	/**********************************************************************
+	 * Errors which may be generated by implementations of vb2ex functions.
+	 * Implementation may also return its own specific errors, which should
+	 * NOT be in the range VB2_ERROR_BASE...VB2_ERROR_MAX to avoid
+	 * conflicting with future vboot2 error codes.
+	 */
+	VB2_ERROR_EX = VB2_ERROR_BASE + 0x0a0000,
+
+	/* Read resource not implemented
+	 * Deprecated: use VB2_ERROR_EX_UNIMPLEMENTED (chromium:944804) */
+	VB2_ERROR_EX_DEPRECATED_READ_RESOURCE_UNIMPLEMENTED,
+
+	/* Resource index not found */
+	VB2_ERROR_EX_READ_RESOURCE_INDEX,
+
+	/* Size of resource not big enough for requested offset and/or size */
+	VB2_ERROR_EX_READ_RESOURCE_SIZE,
+
+	/* TPM clear owner failed */
+	VB2_ERROR_EX_TPM_CLEAR_OWNER,
+
+	/* TPM clear owner not implemented
+	 * Deprecated: use VB2_ERROR_EX_UNIMPLEMENTED (chromium:944804) */
+	VB2_ERROR_DEPRECATED_EX_TPM_CLEAR_OWNER_UNIMPLEMENTED,
+
+	/* Hardware crypto engine doesn't support this algorithm (non-fatal) */
+	VB2_ERROR_EX_HWCRYPTO_UNSUPPORTED,
+
+	/* TPM does not understand this command */
+	VB2_ERROR_EX_TPM_NO_SUCH_COMMAND,
+
+	/* vb2ex function is unimplemented (stubbed in 2lib/2stub.c) */
+	VB2_ERROR_EX_UNIMPLEMENTED,
+
+	/**********************************************************************
+	 * Errors generated by host library (non-firmware) start here.
+	 */
+	VB2_ERROR_HOST_BASE = 0x20000000,
+
+	/**********************************************************************
+	 * Errors generated by host library misc functions
+	 */
+	VB2_ERROR_HOST_MISC = VB2_ERROR_HOST_BASE + 0x010000,
+
+	/* Unable to open file in read_file() */
+	VB2_ERROR_READ_FILE_OPEN,
+
+	/* Bad size in read_file() */
+	VB2_ERROR_READ_FILE_SIZE,
+
+	/* Unable to allocate buffer in read_file() */
+	VB2_ERROR_READ_FILE_ALLOC,
+
+	/* Unable to read data in read_file() */
+	VB2_ERROR_READ_FILE_DATA,
+
+	/* Unable to open file in write_file() */
+	VB2_ERROR_WRITE_FILE_OPEN,
+
+	/* Unable to write data in write_file() */
+	VB2_ERROR_WRITE_FILE_DATA,
+
+	/* Unable to convert string to struct vb_id */
+	VB2_ERROR_STR_TO_ID,
+
+	/**********************************************************************
+	 * Errors generated by host library key functions
+	 */
+	VB2_ERROR_HOST_KEY = VB2_ERROR_HOST_BASE + 0x020000,
+
+	/* Unable to allocate key  in vb2_private_key_read_pem() */
+	VB2_ERROR_READ_PEM_ALLOC,
+
+	/* Unable to open .pem file in vb2_private_key_read_pem() */
+	VB2_ERROR_READ_PEM_FILE_OPEN,
+
+	/* Bad RSA data from .pem file in vb2_private_key_read_pem() */
+	VB2_ERROR_READ_PEM_RSA,
+
+	/* Unable to set private key description */
+	VB2_ERROR_PRIVATE_KEY_SET_DESC,
+
+	/* Bad magic number in vb2_private_key_unpack() */
+	VB2_ERROR_UNPACK_PRIVATE_KEY_MAGIC,
+
+	/* Bad common header in vb2_private_key_unpack() */
+	VB2_ERROR_UNPACK_PRIVATE_KEY_HEADER,
+
+	/* Bad key data in vb2_private_key_unpack() */
+	VB2_ERROR_UNPACK_PRIVATE_KEY_DATA,
+
+	/* Bad struct version in vb2_private_key_unpack() */
+	VB2_ERROR_UNPACK_PRIVATE_KEY_STRUCT_VERSION,
+
+	/* Unable to allocate buffer in vb2_private_key_unpack() */
+	VB2_ERROR_UNPACK_PRIVATE_KEY_ALLOC,
+
+	/* Unable to unpack RSA key in vb2_private_key_unpack() */
+	VB2_ERROR_UNPACK_PRIVATE_KEY_RSA,
+
+	/* Unable to set description in vb2_private_key_unpack() */
+	VB2_ERROR_UNPACK_PRIVATE_KEY_DESC,
+
+	/* Bad bare hash key in vb2_private_key_unpack() */
+	VB2_ERROR_UNPACK_PRIVATE_KEY_HASH,
+
+	/* Unable to create RSA data in vb2_private_key_write() */
+	VB2_ERROR_PRIVATE_KEY_WRITE_RSA,
+
+	/* Unable to allocate packed key buffer in vb2_private_key_write() */
+	VB2_ERROR_PRIVATE_KEY_WRITE_ALLOC,
+
+	/* Unable to write file in vb2_private_key_write() */
+	VB2_ERROR_PRIVATE_KEY_WRITE_FILE,
+
+	/* Bad algorithm in vb2_private_key_hash() */
+	VB2_ERROR_PRIVATE_KEY_HASH,
+
+	/* Unable to determine key size in vb2_public_key_alloc() */
+	VB2_ERROR_PUBLIC_KEY_ALLOC_SIZE,
+
+	/* Unable to allocate buffer in vb2_public_key_alloc() */
+	VB2_ERROR_PUBLIC_KEY_ALLOC,
+
+	/* Unable to set public key description */
+	VB2_ERROR_PUBLIC_KEY_SET_DESC,
+
+	/* Unable to read key data in vb2_public_key_read_keyb() */
+	VB2_ERROR_READ_KEYB_DATA,
+
+	/* Wrong amount of data read in vb2_public_key_read_keyb() */
+	VB2_ERROR_READ_KEYB_SIZE,
+
+	/* Unable to allocate key buffer in vb2_public_key_read_keyb() */
+	VB2_ERROR_READ_KEYB_ALLOC,
+
+	/* Error unpacking RSA arrays in vb2_public_key_read_keyb() */
+	VB2_ERROR_READ_KEYB_UNPACK,
+
+	/* Unable to read key data in vb2_packed_key_read() */
+	VB2_ERROR_READ_PACKED_KEY_DATA,
+
+	/* Bad key data in vb2_packed_key_read() */
+	VB2_ERROR_READ_PACKED_KEY,
+
+	/* Unable to determine key size in vb2_public_key_pack() */
+	VB2_ERROR_PUBLIC_KEY_PACK_SIZE,
+
+	/* Bad hash algorithm in vb2_public_key_hash() */
+	VB2_ERROR_PUBLIC_KEY_HASH,
+
+	/* Bad key size in vb2_copy_packed_key() */
+	VB2_ERROR_COPY_KEY_SIZE,
+
+	/* Unable to convert back to vb1 crypto algorithm */
+	VB2_ERROR_VB1_CRYPTO_ALGORITHM,
+
+	/* Unable to allocate packed key */
+	VB2_ERROR_PACKED_KEY_ALLOC,
+
+	/* Unable to copy packed key */
+	VB2_ERROR_PACKED_KEY_COPY,
+
+	/**********************************************************************
+	 * Errors generated by host library signature functions
+	 */
+	VB2_ERROR_HOST_SIG = VB2_ERROR_HOST_BASE + 0x030000,
+
+	/* Bad hash algorithm in vb2_digest_info() */
+	VB2_ERROR_DIGEST_INFO,
+
+	/*
+	 * Unable to determine signature size for key algorithm in
+	 * vb2_sig_size_for_key().
+	 */
+	VB2_ERROR_SIG_SIZE_FOR_KEY,
+
+	/* Bad signature size in vb2_sign_data() */
+	VB2_SIGN_DATA_SIG_SIZE,
+
+	/* Unable to get digest info in vb2_sign_data() */
+	VB2_SIGN_DATA_DIGEST_INFO,
+
+	/* Unable to get digest size in vb2_sign_data() */
+	VB2_SIGN_DATA_DIGEST_SIZE,
+
+	/* Unable to allocate digest buffer in vb2_sign_data() */
+	VB2_SIGN_DATA_DIGEST_ALLOC,
+
+	/* Unable to initialize digest in vb2_sign_data() */
+	VB2_SIGN_DATA_DIGEST_INIT,
+
+	/* Unable to extend digest in vb2_sign_data() */
+	VB2_SIGN_DATA_DIGEST_EXTEND,
+
+	/* Unable to finalize digest in vb2_sign_data() */
+	VB2_SIGN_DATA_DIGEST_FINALIZE,
+
+	/* RSA encrypt failed in vb2_sign_data() */
+	VB2_SIGN_DATA_RSA_ENCRYPT,
+
+	/* Not enough buffer space to hold signature in vb2_sign_object() */
+	VB2_SIGN_OBJECT_OVERFLOW,
+
+	/**********************************************************************
+	 * Errors generated by host library keyblock functions
+	 */
+	VB2_ERROR_HOST_KEYBLOCK = VB2_ERROR_HOST_BASE + 0x040000,
+
+	/* Unable to determine signature sizes for vb2_create_keyblock() */
+	VB2_KEYBLOCK_CREATE_SIG_SIZE,
+
+	/* Unable to pack data key for vb2_create_keyblock() */
+	VB2_KEYBLOCK_CREATE_DATA_KEY,
+
+	/* Unable to allocate buffer in vb2_create_keyblock() */
+	VB2_KEYBLOCK_CREATE_ALLOC,
+
+	/* Unable to sign keyblock in vb2_create_keyblock() */
+	VB2_KEYBLOCK_CREATE_SIGN,
+
+	/**********************************************************************
+	 * Errors generated by host library firmware preamble functions
+	 */
+	VB2_ERROR_HOST_FW_PREAMBLE = VB2_ERROR_HOST_BASE + 0x050000,
+
+	/* Unable to determine signature sizes for vb2_create_fw_preamble() */
+	VB2_FW_PREAMBLE_CREATE_SIG_SIZE,
+
+	/* Unable to allocate buffer in vb2_create_fw_preamble() */
+	VB2_FW_PREAMBLE_CREATE_ALLOC,
+
+	/* Unable to sign preamble in vb2_create_fw_preamble() */
+	VB2_FW_PREAMBLE_CREATE_SIGN,
+
+	/**********************************************************************
+	 * Errors generated by unit test functions
+	 */
+	VB2_ERROR_UNIT_TEST = VB2_ERROR_HOST_BASE + 0x060000,
+
+	/* Unable to open an input file needed for a unit test */
+	VB2_ERROR_TEST_INPUT_FILE,
+
+	/**********************************************************************
+	 * Highest non-zero error generated inside vboot library.  Note that
+	 * error codes passed through vboot when it calls external APIs may
+	 * still be outside this range.
+	 */
+	VB2_ERROR_MAX = VB2_ERROR_BASE + 0x1fffffff,
+};
+
+#endif  /* VBOOT_REFERENCE_2RETURN_CODES_H_ */
diff --git a/tools/cbfstool/vboot/2sha.h b/tools/cbfstool/vboot/2sha.h
new file mode 100644
index 0000000000..646c7c17a9
--- /dev/null
+++ b/tools/cbfstool/vboot/2sha.h
@@ -0,0 +1,229 @@
+/* Copyright (c) 2014 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * These APIs may be called by external firmware as well as vboot.  External
+ * firmware must NOT include this header file directly; instead, import
+ * the external-facing vb2_sha.h.  This is permissible because the
+ * SHA library routines below don't interact with the rest of vboot.
+ */
+
+#ifndef VBOOT_REFERENCE_2SHA_H_
+#define VBOOT_REFERENCE_2SHA_H_
+
+#include "2crypto.h"
+#include "2return_codes.h"
+
+/* Hash algorithms may be disabled individually to save code space */
+
+#ifndef VB2_SUPPORT_SHA1
+#define VB2_SUPPORT_SHA1 1
+#endif
+
+#ifndef VB2_SUPPORT_SHA256
+#define VB2_SUPPORT_SHA256 1
+#endif
+
+#ifndef VB2_SUPPORT_SHA512
+#define VB2_SUPPORT_SHA512 1
+#endif
+
+/* These are set to the biggest values among the supported hash algorithms.
+ * They have to be updated as we add new hash algorithms */
+#define VB2_MAX_DIGEST_SIZE	VB2_SHA512_DIGEST_SIZE
+#define VB2_MAX_BLOCK_SIZE	VB2_SHA512_BLOCK_SIZE
+#define VB2_INVALID_ALG_NAME	"INVALID"
+
+#define VB2_SHA1_DIGEST_SIZE 20
+#define VB2_SHA1_BLOCK_SIZE 64
+#define VB2_SHA1_ALG_NAME	"SHA1"
+
+/* Context structs for hash algorithms */
+
+struct vb2_sha1_context {
+	uint32_t count;
+	uint32_t state[5];
+#if defined(HAVE_ENDIAN_H) && defined(HAVE_LITTLE_ENDIAN)
+	union {
+		uint8_t b[VB2_SHA1_BLOCK_SIZE];
+		uint32_t w[VB2_SHA1_BLOCK_SIZE / sizeof(uint32_t)];
+	} buf;
+#else
+	uint8_t buf[VB2_SHA1_BLOCK_SIZE];
+#endif
+};
+
+#define VB2_SHA256_DIGEST_SIZE 32
+#define VB2_SHA256_BLOCK_SIZE 64
+#define VB2_SHA256_ALG_NAME	"SHA256"
+
+struct vb2_sha256_context {
+	uint32_t h[8];
+	uint32_t total_size;
+	uint32_t size;
+	uint8_t block[2 * VB2_SHA256_BLOCK_SIZE];
+};
+
+#define VB2_SHA512_DIGEST_SIZE 64
+#define VB2_SHA512_BLOCK_SIZE 128
+#define VB2_SHA512_ALG_NAME	"SHA512"
+
+struct vb2_sha512_context {
+	uint64_t h[8];
+	uint32_t total_size;
+	uint32_t size;
+	uint8_t block[2 * VB2_SHA512_BLOCK_SIZE];
+};
+
+/* Hash algorithm independent digest context; includes all of the above. */
+struct vb2_digest_context {
+	/* Context union for all algorithms */
+	union {
+#if VB2_SUPPORT_SHA1
+		struct vb2_sha1_context sha1;
+#endif
+#if VB2_SUPPORT_SHA256
+		struct vb2_sha256_context sha256;
+#endif
+#if VB2_SUPPORT_SHA512
+		struct vb2_sha512_context sha512;
+#endif
+	};
+
+	/* Current hash algorithm */
+	enum vb2_hash_algorithm hash_alg;
+
+	/* 1 if digest is computed with vb2ex_hwcrypto routines, else 0 */
+	int using_hwcrypto;
+};
+
+/**
+ * Initialize a hash context.
+ *
+ * @param ctx		Hash context
+ */
+void vb2_sha1_init(struct vb2_sha1_context *ctx);
+void vb2_sha256_init(struct vb2_sha256_context *ctx);
+void vb2_sha512_init(struct vb2_sha512_context *ctx);
+
+/**
+ * Update (extend) a hash.
+ *
+ * @param ctx		Hash context
+ * @param data		Data to hash
+ * @param size		Length of data in bytes
+ */
+void vb2_sha1_update(struct vb2_sha1_context *ctx,
+		     const uint8_t *data,
+		     uint32_t size);
+void vb2_sha256_update(struct vb2_sha256_context *ctx,
+		       const uint8_t *data,
+		       uint32_t size);
+void vb2_sha512_update(struct vb2_sha512_context *ctx,
+		       const uint8_t *data,
+		       uint32_t size);
+
+/**
+ * Finalize a hash digest.
+ *
+ * @param ctx		Hash context
+ * @param digest	Destination for hash; must be VB_SHA*_DIGEST_SIZE bytes
+ */
+void vb2_sha1_finalize(struct vb2_sha1_context *ctx, uint8_t *digest);
+void vb2_sha256_finalize(struct vb2_sha256_context *ctx, uint8_t *digest);
+void vb2_sha512_finalize(struct vb2_sha512_context *ctx, uint8_t *digest);
+
+/**
+ * Hash-extend data
+ *
+ * @param from	Hash to be extended. It has to be the hash size.
+ * @param by	Block to be extended by. It has to be the hash block size.
+ * @param to	Destination for extended data
+ */
+void vb2_sha256_extend(const uint8_t *from, const uint8_t *by, uint8_t *to);
+
+/**
+ * Convert vb2_crypto_algorithm to vb2_hash_algorithm.
+ *
+ * @param algorithm	Crypto algorithm (vb2_crypto_algorithm)
+ *
+ * @return The hash algorithm for that crypto algorithm, or VB2_HASH_INVALID if
+ * the crypto algorithm or its corresponding hash algorithm is invalid or not
+ * supported.
+ */
+enum vb2_hash_algorithm vb2_crypto_to_hash(uint32_t algorithm);
+
+/**
+ * Return the size of the digest for a hash algorithm.
+ *
+ * @param hash_alg	Hash algorithm
+ * @return The size of the digest, or 0 if error.
+ */
+vb2_error_t vb2_digest_size(enum vb2_hash_algorithm hash_alg);
+
+/**
+ * Return the block size of a hash algorithm.
+ *
+ * @param hash_alg	Hash algorithm
+ * @return The block size of the algorithm, or 0 if error.
+ */
+vb2_error_t vb2_hash_block_size(enum vb2_hash_algorithm alg);
+
+/**
+ * Return the name of a hash algorithm
+ *
+ * @param alg	Hash algorithm ID
+ * @return	String containing a hash name or VB2_INVALID_ALG_NAME
+ * 		if <alg> is invalid.
+ */
+const char *vb2_get_hash_algorithm_name(enum vb2_hash_algorithm alg);
+
+/**
+ * Initialize a digest context for doing block-style digesting.
+ *
+ * @param dc		Digest context
+ * @param hash_alg	Hash algorithm
+ * @return VB2_SUCCESS, or non-zero on error.
+ */
+vb2_error_t vb2_digest_init(struct vb2_digest_context *dc,
+			    enum vb2_hash_algorithm hash_alg);
+
+/**
+ * Extend a digest's hash with another block of data.
+ *
+ * @param dc		Digest context
+ * @param buf		Data to hash
+ * @param size		Length of data in bytes
+ * @return VB2_SUCCESS, or non-zero on error.
+ */
+vb2_error_t vb2_digest_extend(struct vb2_digest_context *dc, const uint8_t *buf,
+			      uint32_t size);
+
+/**
+ * Finalize a digest and store the result.
+ *
+ * The destination digest should be at least vb2_digest_size(algorithm).
+ *
+ * @param dc		Digest context
+ * @param digest	Destination for digest
+ * @param digest_size	Length of digest buffer in bytes.
+ * @return VB2_SUCCESS, or non-zero on error.
+ */
+vb2_error_t vb2_digest_finalize(struct vb2_digest_context *dc,
+				uint8_t *digest, uint32_t digest_size);
+
+/**
+ * Calculate the digest of a buffer and store the result.
+ *
+ * @param buf		Data to hash
+ * @param size		Length of data in bytes
+ * @param hash_alg	Hash algorithm
+ * @param digest	Destination for digest
+ * @param digest_size	Length of digest buffer in bytes.
+ * @return VB2_SUCCESS, or non-zero on error.
+ */
+vb2_error_t vb2_digest_buffer(const uint8_t *buf, uint32_t size,
+			      enum vb2_hash_algorithm hash_alg, uint8_t *digest,
+			      uint32_t digest_size);
+
+#endif  /* VBOOT_REFERENCE_2SHA_H_ */
diff --git a/tools/cbfstool/vboot/2struct.h b/tools/cbfstool/vboot/2struct.h
new file mode 100644
index 0000000000..52d905ae7a
--- /dev/null
+++ b/tools/cbfstool/vboot/2struct.h
@@ -0,0 +1,340 @@
+/* Copyright (c) 2014 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * Vboot data structures.
+ *
+ * Note: Many of the structs have pairs of 32-bit fields and reserved fields.
+ * This is to be backwards-compatible with older verified boot data which used
+ * 64-bit fields (when we thought that hey, UEFI is 64-bit so all our fields
+ * should be too).
+ *
+ * Offsets should be padded to 32-bit boundaries, since some architectures
+ * have trouble with accessing unaligned integers.
+ */
+
+#ifndef VBOOT_REFERENCE_2STRUCT_H_
+#define VBOOT_REFERENCE_2STRUCT_H_
+
+#include "2constants.h"
+#include "2crypto.h"
+#include "2sysincludes.h"
+
+/*
+ * Key block flags.
+ *
+ *The following flags set where the key is valid.  Not used by firmware
+ * verification; only kernel verification.
+ */
+#define VB2_KEY_BLOCK_FLAG_DEVELOPER_0  0x01 /* Developer switch off */
+#define VB2_KEY_BLOCK_FLAG_DEVELOPER_1  0x02 /* Developer switch on */
+#define VB2_KEY_BLOCK_FLAG_RECOVERY_0   0x04 /* Not recovery mode */
+#define VB2_KEY_BLOCK_FLAG_RECOVERY_1   0x08 /* Recovery mode */
+#define VB2_GBB_HWID_DIGEST_SIZE	32
+
+/****************************************************************************/
+
+/* Flags for vb2_shared_data.flags */
+enum vb2_shared_data_flags {
+	/* User has explicitly and physically requested recovery */
+	VB2_SD_FLAG_MANUAL_RECOVERY = (1 << 0),
+
+	/* Developer mode is enabled */
+	VB2_SD_FLAG_DEV_MODE_ENABLED = (1 << 1),
+
+	/*
+	 * TODO: might be nice to add flags for why dev mode is enabled - via
+	 * gbb, virtual dev switch, or forced on for testing.
+	 */
+
+	/* Kernel keyblock was verified by signature (not just hash) */
+	VB2_SD_FLAG_KERNEL_SIGNED = (1 << 2),
+
+	/* Software sync needs to update EC-RO, EC-RW, or PD-RW respectively */
+	VB2_SD_FLAG_ECSYNC_EC_RO = (1 << 3),
+	VB2_SD_FLAG_ECSYNC_EC_RW = (1 << 4),
+	VB2_SD_FLAG_ECSYNC_PD_RW = (1 << 5),
+
+	/* Software sync says EC / PD running RW */
+	VB2_SD_FLAG_ECSYNC_EC_IN_RW = (1 << 6),
+	VB2_SD_FLAG_ECSYNC_PD_IN_RW = (1 << 7),
+
+	/* Display is available on this boot */
+	VB2_SD_FLAG_DISPLAY_AVAILABLE = (1 << 8),
+};
+
+/* Flags for vb2_shared_data.status */
+enum vb2_shared_data_status {
+	/* Reinitialized NV data due to invalid checksum */
+	VB2_SD_STATUS_NV_REINIT = (1 << 0),
+
+	/* NV data has been initialized */
+	VB2_SD_STATUS_NV_INIT = (1 << 1),
+
+	/* Secure data initialized */
+	VB2_SD_STATUS_SECDATA_FIRMWARE_INIT = (1 << 2),
+
+	/* Chose a firmware slot */
+	VB2_SD_STATUS_CHOSE_SLOT = (1 << 3),
+
+	/* Secure data kernel version space initialized */
+	VB2_SD_STATUS_SECDATA_KERNEL_INIT = (1 << 4),
+
+	/* FWMP secure data initialized */
+	VB2_SD_STATUS_SECDATA_FWMP_INIT = (1 << 5),
+};
+
+/* "V2SD" = vb2_shared_data.magic */
+#define VB2_SHARED_DATA_MAGIC 0x44533256
+
+/* Current version of vb2_shared_data struct */
+#define VB2_SHARED_DATA_VERSION_MAJOR 1
+#define VB2_SHARED_DATA_VERSION_MINOR 0
+
+/*
+ * Data shared between vboot API calls.  Stored at the start of the work
+ * buffer.
+ */
+struct vb2_shared_data {
+	/* Magic number for struct (VB2_SHARED_DATA_MAGIC) */
+	uint32_t magic;
+
+	/* Version of this structure */
+	uint16_t struct_version_major;
+	uint16_t struct_version_minor;
+
+	/* Flags; see enum vb2_shared_data_flags */
+	uint32_t flags;
+
+	/*
+	 * Reason we are in recovery mode this boot (enum vb2_nv_recovery), or
+	 * 0 if we aren't.
+	 */
+	uint32_t recovery_reason;
+
+	/* Firmware slot used last boot (0=A, 1=B) */
+	uint32_t last_fw_slot;
+
+	/* Result of last boot (enum vb2_fw_result) */
+	uint32_t last_fw_result;
+
+	/* Firmware slot used this boot */
+	uint32_t fw_slot;
+
+	/*
+	 * Version for this slot (top 16 bits = key, lower 16 bits = firmware).
+	 *
+	 * TODO: Make this a union to allow getting/setting those versions
+	 * separately?
+	 */
+	uint32_t fw_version;
+
+	/* Version from secdata_firmware (must be <= fw_version to boot). */
+	uint32_t fw_version_secdata;
+
+	/*
+	 * Status flags for this boot; see enum vb2_shared_data_status.  Status
+	 * is "what we've done"; flags above are "decisions we've made".
+	 */
+	uint32_t status;
+
+	/* Offset from start of this struct to GBB header */
+	uint32_t gbb_offset;
+
+	/**********************************************************************
+	 * Data from kernel verification stage.
+	 *
+	 * TODO: shouldn't be part of the main struct, since that needlessly
+	 * uses more memory during firmware verification.
+	 */
+
+	/*
+	 * Version for the current kernel (top 16 bits = key, lower 16 bits =
+	 * kernel preamble).
+	 *
+	 * TODO: Make this a union to allow getting/setting those versions
+	 * separately?
+	 */
+	uint32_t kernel_version;
+
+	/* Version from secdata_kernel (must be <= kernel_version to boot) */
+	uint32_t kernel_version_secdata;
+
+	/**********************************************************************
+	 * Temporary variables used during firmware verification.  These don't
+	 * really need to persist through to the OS, but there's nowhere else
+	 * we can put them.
+	 */
+
+	/* Offset of preamble from start of vblock */
+	uint32_t vblock_preamble_offset;
+
+	/*
+	 * Offset and size of packed data key in work buffer.  Size is 0 if
+	 * data key is not stored in the work buffer.
+	 */
+	uint32_t data_key_offset;
+	uint32_t data_key_size;
+
+	/*
+	 * Offset and size of firmware preamble in work buffer.  Size is 0 if
+	 * preamble is not stored in the work buffer.
+	 */
+	uint32_t preamble_offset;
+	uint32_t preamble_size;
+
+	/*
+	 * Offset and size of hash context in work buffer.  Size is 0 if
+	 * hash context is not stored in the work buffer.
+	 */
+	uint32_t hash_offset;
+	uint32_t hash_size;
+
+	/*
+	 * Current tag we're hashing
+	 *
+	 * For new structs, this is the offset of the vb2_signature struct
+	 * in the work buffer.
+	 *
+	 * TODO: rename to hash_sig_offset when vboot1 structs are deprecated.
+	 */
+	uint32_t hash_tag;
+
+	/* Amount of data we still expect to hash */
+	uint32_t hash_remaining_size;
+
+	/**********************************************************************
+	 * Temporary variables used during kernel verification.  These don't
+	 * really need to persist through to the OS, but there's nowhere else
+	 * we can put them.
+	 *
+	 * TODO: make a union with the firmware verification temp variables,
+	 * or make both of them workbuf-allocated sub-structs, so that we can
+	 * overlap them so kernel variables don't bloat firmware verification
+	 * stage memory requirements.
+	 */
+
+	/*
+	 * Vboot1 shared data header.  This data should eventually get folded
+	 * directly into the kernel portion of this struct.
+	 */
+	struct VbSharedDataHeader *vbsd;
+
+	/*
+	 * Offset and size of packed kernel key in work buffer.  Size is 0 if
+	 * subkey is not stored in the work buffer.  Note that kernel key may
+	 * be inside the firmware preamble.
+	 */
+	uint32_t kernel_key_offset;
+	uint32_t kernel_key_size;
+} __attribute__((packed));
+
+/****************************************************************************/
+
+/* Signature at start of the GBB
+ * Note that if you compile in the signature as is, you are likely to break any
+ * tools that search for the signature. */
+#define VB2_GBB_SIGNATURE "$GBB"
+#define VB2_GBB_SIGNATURE_SIZE 4
+#define VB2_GBB_XOR_CHARS "****"
+/* TODO: can we write a macro to produce this at compile time? */
+#define VB2_GBB_XOR_SIGNATURE { 0x0e, 0x6d, 0x68, 0x68 }
+
+/* VB2 GBB struct version */
+#define VB2_GBB_MAJOR_VER      1
+#define VB2_GBB_MINOR_VER      2
+/* v1.2 - added fields for sha256 digest of the HWID */
+
+struct vb2_gbb_header {
+	/* Fields present in version 1.1 */
+	uint8_t  signature[VB2_GBB_SIGNATURE_SIZE]; /* VB2_GBB_SIGNATURE */
+	uint16_t major_version;   /* See VB2_GBB_MAJOR_VER */
+	uint16_t minor_version;   /* See VB2_GBB_MINOR_VER */
+	uint32_t header_size;     /* Size of GBB header in bytes */
+
+	/* Flags (see enum vb2_gbb_flag in 2gbb_flags.h) */
+	vb2_gbb_flags_t flags;
+
+	/* Offsets (from start of header) and sizes (in bytes) of components */
+	uint32_t hwid_offset;		/* HWID */
+	uint32_t hwid_size;
+	uint32_t rootkey_offset;	/* Root key */
+	uint32_t rootkey_size;
+	uint32_t bmpfv_offset;		/* BMP FV; deprecated in current FW */
+	uint32_t bmpfv_size;
+	uint32_t recovery_key_offset;	/* Recovery key */
+	uint32_t recovery_key_size;
+
+	/* Added in version 1.2 */
+	uint8_t  hwid_digest[VB2_GBB_HWID_DIGEST_SIZE];	/* SHA-256 of HWID */
+
+	/* Pad to match EXPECTED_VB2_GBB_HEADER_SIZE.  Initialize to 0. */
+	uint8_t  pad[48];
+} __attribute__((packed));
+
+#define EXPECTED_VB2_GBB_HEADER_SIZE 128
+
+/* VB2_GBB_FLAGS_OFFSET exposed in 2constants.h */
+_Static_assert(VB2_GBB_FLAGS_OFFSET == offsetof(struct vb2_gbb_header, flags),
+	       "VB2_GBB_FLAGS_OFFSET set incorrectly");
+
+/*
+ * Root key hash for Ryu devices only.  Contains the hash of the root key.
+ * This will be embedded somewhere inside the RO part of the firmware, so that
+ * it can verify the GBB contains only the official root key.
+ */
+
+#define RYU_ROOT_KEY_HASH_MAGIC "RtKyHash"
+#define RYU_ROOT_KEY_HASH_MAGIC_INVCASE "rTkYhASH"
+#define RYU_ROOT_KEY_HASH_MAGIC_SIZE 8
+
+#define RYU_ROOT_KEY_HASH_VERSION_MAJOR 1
+#define RYU_ROOT_KEY_HASH_VERSION_MINOR 0
+
+struct vb2_ryu_root_key_hash {
+	/* Magic number (RYU_ROOT_KEY_HASH_MAGIC) */
+	uint8_t magic[RYU_ROOT_KEY_HASH_MAGIC_SIZE];
+
+	/* Version of this struct */
+	uint16_t header_version_major;
+	uint16_t header_version_minor;
+
+	/*
+	 * Length of this struct, in bytes, including any variable length data
+	 * which follows (there is none, yet).
+	 */
+	uint32_t struct_size;
+
+	/*
+	 * SHA-256 hash digest of the entire root key section from the GBB.  If
+	 * all 0 bytes, all root keys will be treated as if matching.
+	 */
+	uint8_t root_key_hash_digest[32];
+};
+
+#define EXPECTED_VB2_RYU_ROOT_KEY_HASH_SIZE 48
+
+/* Packed public key data */
+struct vb2_packed_key {
+	/* Offset of key data from start of this struct */
+	uint32_t key_offset;
+	uint32_t reserved0;
+
+	/* Size of key data in bytes (NOT strength of key in bits) */
+	uint32_t key_size;
+	uint32_t reserved1;
+
+	/* Signature algorithm used by the key (enum vb2_crypto_algorithm) */
+	uint32_t algorithm;
+	uint32_t reserved2;
+
+	/* Key version */
+	uint32_t key_version;
+	uint32_t reserved3;
+
+	/* TODO: when redoing this struct, add a text description of the key */
+} __attribute__((packed));
+
+#define EXPECTED_VB2_PACKED_KEY_SIZE 32
+
+#endif  /* VBOOT_REFERENCE_2STRUCT_H_ */
diff --git a/tools/cbfstool/vboot/2sysincludes.h b/tools/cbfstool/vboot/2sysincludes.h
new file mode 100644
index 0000000000..c23054a119
--- /dev/null
+++ b/tools/cbfstool/vboot/2sysincludes.h
@@ -0,0 +1,28 @@
+/* Copyright (c) 2014 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+/*
+ * System includes for vboot reference library.  This is the ONLY
+ * place in firmware/ where system headers may be included via
+ * #include <...>, so that there's only one place that needs to be
+ * fixed up for platforms which don't have all the system includes.
+ */
+
+#ifndef VBOOT_REFERENCE_2SYSINCLUDES_H_
+#define VBOOT_REFERENCE_2SYSINCLUDES_H_
+
+#include <ctype.h>
+#include <inttypes.h>  /* For PRIu64 */
+#include <stddef.h>
+#include <stdint.h>
+#include <stdlib.h>
+#include <string.h>
+
+#if defined(HAVE_ENDIAN_H) && defined(HAVE_LITTLE_ENDIAN)
+#include <byteswap.h>
+#include <memory.h>
+#endif
+
+#endif  /* VBOOT_REFERENCE_2SYSINCLUDES_H_ */
diff --git a/tools/cbfstool/vboot/fmap.h b/tools/cbfstool/vboot/fmap.h
new file mode 100644
index 0000000000..4fddaae872
--- /dev/null
+++ b/tools/cbfstool/vboot/fmap.h
@@ -0,0 +1,57 @@
+/* Copyright (c) 2011 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef VBOOT_REFERENCE_FMAP_H_
+#define VBOOT_REFERENCE_FMAP_H_
+
+#include <inttypes.h>
+#include <stddef.h>
+
+/* FMAP structs. See http://code.google.com/p/flashmap/wiki/FmapSpec */
+#define FMAP_NAMELEN 32
+#define FMAP_SIGNATURE "__FMAP__"
+#define FMAP_SIGNATURE_SIZE 8
+#define FMAP_SEARCH_STRIDE 4
+#define FMAP_VER_MAJOR 1
+typedef struct _FmapHeader {
+	/* Avoid endian issues in signature... */
+	char        fmap_signature[FMAP_SIGNATURE_SIZE];
+	uint8_t     fmap_ver_major;
+	uint8_t     fmap_ver_minor;
+	uint64_t    fmap_base;
+	uint32_t    fmap_size;
+	char        fmap_name[FMAP_NAMELEN];
+	uint16_t    fmap_nareas;
+} __attribute__((packed)) FmapHeader;
+
+enum fmap_flags {
+	FMAP_AREA_STATIC	= 1 << 0,
+	FMAP_AREA_COMPRESSED	= 1 << 1,
+	FMAP_AREA_RO		= 1 << 2,
+	/* Should be preserved on update or rollback. */
+	FMAP_AREA_PRESERVE	= 1 << 3,
+};
+
+typedef struct _FmapAreaHeader {
+	uint32_t area_offset;
+	uint32_t area_size;
+	char     area_name[FMAP_NAMELEN];
+	uint16_t area_flags;
+} __attribute__((packed)) FmapAreaHeader;
+
+
+/* Find and point to the FMAP header within the buffer */
+FmapHeader *fmap_find(uint8_t *ptr, size_t size);
+
+/* Search for an area by name, return pointer to its beginning */
+uint8_t *fmap_find_by_name(uint8_t *ptr, size_t size,
+			   /* optional, will call fmap_find() if NULL */
+			   FmapHeader *fmap,
+			   /* The area name to search for */
+			   const char *name,
+			   /* optional, return pointer to entry if not NULL */
+			   FmapAreaHeader **ah);
+
+#endif  /* VBOOT_REFERENCE_FMAP_H_ */
diff --git a/tools/cbfstool/vboot/kv_pair.h b/tools/cbfstool/vboot/kv_pair.h
new file mode 100644
index 0000000000..1185a08d52
--- /dev/null
+++ b/tools/cbfstool/vboot/kv_pair.h
@@ -0,0 +1,157 @@
+/*
+ * Copyright 2010, Google Inc.
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *    * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *    * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *    * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * Alternatively, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") version 2 as published by the Free
+ * Software Foundation.
+ */
+
+#ifndef FLASHMAP_LIB_KV_PAIR_H__
+#define FLASHMAP_LIB_KV_PAIR_H__
+
+#include <stdio.h>
+#include <inttypes.h>
+#include <string.h>
+
+/* key=value string pair list */
+#define KV_PAIR_MAX_VALUE_LEN	   1024
+
+enum kv_pair_style {
+	KV_STYLE_PAIR,		/* key1="value1" key2="value2" */
+	KV_STYLE_VALUE,		/* | value1 | value2 | */
+	KV_STYLE_LONG,		/* key1		| value1 */
+				/* key2		| value2 */
+};
+
+struct kv_pair {
+	char *key;
+	char *value;
+	struct kv_pair *next;
+};
+
+extern enum kv_pair_style kv_pair_get_style(void);
+
+extern void kv_pair_set_style(enum kv_pair_style style);
+
+/*
+ * kv_pair_new	-  create new key=value pair
+ *
+ * returns pointer to new key=value pair
+ * returns NULL to indicate error
+ */
+extern struct kv_pair *kv_pair_new(void);
+
+/*
+ * kv_pair_add	-  add new key=value pair to list
+ *
+ * @kv_list:	key=value pair list
+ * @key:	key string
+ * @value:	value string
+ *
+ * returns pointer to new key=value pair
+ * returns NULL to indicate error
+ */
+extern struct kv_pair *kv_pair_add(struct kv_pair *kv_list,
+				   const char *key, const char *value);
+
+/*
+ * kv_pair_add_bool  -	add new boolean kvpair to list
+ *
+ * @kv_list:	key=value pair list
+ * @key:	key string
+ * @value:	value
+ *
+ * returns pointer to new key=value pair
+ * returns NULL to indicate error
+ */
+extern struct kv_pair *kv_pair_add_bool(struct kv_pair *kv_list,
+					const char *key, int value);
+
+/*
+ * kv_pair_fmt	-  add key=value pair based on printf format
+ *		   NOTE: uses variable argument list
+ *
+ * @kv_list:	list of key=value pairs
+ * @kv_key:	key string
+ * @format:	printf-style format for value input
+ * @...:	arguments to format
+ *
+ * returns pointer to new key=value pair
+ * returns NULL to indicate error
+ */
+extern struct kv_pair *kv_pair_fmt(struct kv_pair *kv_list,
+				   const char *kv_key, const char *format, ...)
+#if defined(_WIN32) || (_WIN64)
+				   __attribute__((format(gnu_printf, 3, 4)));
+#else
+				   __attribute__((format(printf, 3, 4)));
+#endif
+
+/*
+ * kv_pair_free  -  clean a key=value pair list
+ *
+ * @kv_list:	pointer to key=value list
+ */
+extern void kv_pair_free(struct kv_pair *kv_list);
+
+/*
+ * kv_pair_print  -  print a key=value pair list
+ *
+ * @kv_list:	pointer to key=value list
+ * @style:	print style
+ */
+extern void kv_pair_print_to_file(FILE* fp, struct kv_pair *kv_list,
+				  enum kv_pair_style style);
+
+/*
+ * kv_pair_print  -  print a key=value pair list to gsys output
+ *
+ * @kv_list:	pointer to key=value list
+ */
+extern void kv_pair_print(struct kv_pair *kv_list);
+
+
+/*
+ * kv_pair_get_value  -  return first value with key match
+ *
+ * @kv_list:	pointer to key=value list
+ * @kv_key:	key string
+ */
+extern const char *kv_pair_get_value(struct kv_pair *kv_list,
+				     const char *kv_key);
+
+/*
+ * kv_pair_size  -  return number of kv pairs in the chain
+ *
+ * @kv_list:	pointer to key=value list
+ */
+extern int kv_pair_size(struct kv_pair *kv_list);
+
+#endif /* FLASHMAP_LIB_KV_PAIR_H__ */
diff --git a/tools/cbfstool/vboot/vb2_api.h b/tools/cbfstool/vboot/vb2_api.h
new file mode 100644
index 0000000000..efa96e14e0
--- /dev/null
+++ b/tools/cbfstool/vboot/vb2_api.h
@@ -0,0 +1,42 @@
+/* Copyright (c) 2014 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * APIs between calling firmware and vboot_reference
+ *
+ * DO NOT INCLUDE THE HEADERS BELOW DIRECTLY!  ONLY INCLUDE THIS FILE!
+ *
+ * Using vb2_api.h as the single point of contact between calling firmware and
+ * vboot allows subsequent refactoring of vboot (renaming of headers, etc.)
+ * without churning other projects' source code.
+ *
+ * #define NEED_VB20_INTERNALS
+ *   Allows the caller to peek into vboot2 data structures, by including a
+ *   specific set of extra header files listed in vb2_api.h.  Including this
+ *   switch means the caller is broken and should be fixed.  The existence of
+ *   this switch is a bug, and it should be removed when it is no longer used.
+ */
+
+#ifndef VBOOT_REFERENCE_VB2_API_H_
+#define VBOOT_REFERENCE_VB2_API_H_
+
+/* Standard APIs */
+#include "2api.h"
+
+/*
+ * Coreboot should not need access to vboot2 internals.  But right now it does.
+ * At least this forces it to do so through a relatively narrow hole so vboot2
+ * refactoring can continue.
+ *
+ * Please do not rip this into a wider hole, or expect this hole to continue.
+ *
+ * TODO: Make cleaner APIs to this stuff.
+ */
+#ifdef NEED_VB20_INTERNALS
+#include "../2lib/include/2nvstorage.h"
+#include "../2lib/include/2nvstorage_fields.h"
+#include "../2lib/include/2struct.h"
+#include "../lib20/include/vb2_struct.h"
+#endif
+
+#endif  /* VBOOT_REFERENCE_VB2_API_H_ */
diff --git a/tools/cbfstool/vboot/vb2_sha.h b/tools/cbfstool/vboot/vb2_sha.h
new file mode 100644
index 0000000000..42c6d274fd
--- /dev/null
+++ b/tools/cbfstool/vboot/vb2_sha.h
@@ -0,0 +1,13 @@
+/* Copyright 2019 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ *
+ * This header may be imported to expose vboot SHA implementation.
+ */
+
+#ifndef VBOOT_REFERENCE_VB2_SHA_H_
+#define VBOOT_REFERENCE_VB2_SHA_H_
+
+#include "2sha.h"
+
+#endif  /* VBOOT_REFERENCE_VB2_SHA_H_ */
diff --git a/tools/cbfstool/xdr.c b/tools/cbfstool/xdr.c
new file mode 100644
index 0000000000..06cc91f409
--- /dev/null
+++ b/tools/cbfstool/xdr.c
@@ -0,0 +1,152 @@
+ /*
+ * cbfstool, CLI utility for CBFS file manipulation
+ *
+ * Copyright 2013 Google Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <ctype.h>
+#include <unistd.h>
+#include <stdint.h>
+#include "common.h"
+
+size_t bgets(struct buffer *input, void *output, size_t len)
+{
+	len = input->size < len ? input->size : len;
+	memmove(output, input->data, len);
+	input->data += len;
+	input->size -= len;
+	return len;
+}
+
+size_t bputs(struct buffer *b, const void *data, size_t len)
+{
+	memmove(&b->data[b->size], data, len);
+	b->size += len;
+	return len;
+}
+
+/* The assumption in all this code is that we're given a pointer to enough data.
+ * Hence, we do not check for underflow.
+ */
+static uint8_t get8(struct buffer *input)
+{
+	uint8_t ret = *input->data++;
+	input->size--;
+	return ret;
+}
+
+static uint16_t get16be(struct buffer *input)
+{
+	uint16_t ret;
+	ret = get8(input) << 8;
+	ret |= get8(input);
+	return ret;
+}
+
+static uint32_t get32be(struct buffer *input)
+{
+	uint32_t ret;
+	ret = get16be(input) << 16;
+	ret |= get16be(input);
+	return ret;
+}
+
+static uint64_t get64be(struct buffer *input)
+{
+	uint64_t ret;
+	ret = get32be(input);
+	ret <<= 32;
+	ret |= get32be(input);
+	return ret;
+}
+
+static void put8(struct buffer *input, uint8_t val)
+{
+	input->data[input->size] = val;
+	input->size++;
+}
+
+static void put16be(struct buffer *input, uint16_t val)
+{
+	put8(input, val >> 8);
+	put8(input, val);
+}
+
+static void put32be(struct buffer *input, uint32_t val)
+{
+	put16be(input, val >> 16);
+	put16be(input, val);
+}
+
+static void put64be(struct buffer *input, uint64_t val)
+{
+	put32be(input, val >> 32);
+	put32be(input, val);
+}
+
+static uint16_t get16le(struct buffer *input)
+{
+	uint16_t ret;
+	ret = get8(input);
+	ret |= get8(input) << 8;
+	return ret;
+}
+
+static uint32_t get32le(struct buffer *input)
+{
+	uint32_t ret;
+	ret = get16le(input);
+	ret |= get16le(input) << 16;
+	return ret;
+}
+
+static uint64_t get64le(struct buffer *input)
+{
+	uint64_t ret;
+	uint32_t low;
+	low = get32le(input);
+	ret = get32le(input);
+	ret <<= 32;
+	ret |= low;
+	return ret;
+}
+
+static void put16le(struct buffer *input, uint16_t val)
+{
+	put8(input, val);
+	put8(input, val >> 8);
+}
+
+static void put32le(struct buffer *input, uint32_t val)
+{
+	put16le(input, val);
+	put16le(input, val >> 16);
+}
+
+static void put64le(struct buffer *input, uint64_t val)
+{
+	put32le(input, val);
+	put32le(input, val >> 32);
+}
+
+struct xdr xdr_be = {
+	get8, get16be, get32be, get64be,
+	put8, put16be, put32be, put64be
+};
+
+struct xdr xdr_le = {
+	get8, get16le, get32le, get64le,
+	put8, put16le, put32le, put64le
+};
diff --git a/tools/cbfstool/xxhash.c b/tools/cbfstool/xxhash.c
new file mode 100644
index 0000000000..845b52cddb
--- /dev/null
+++ b/tools/cbfstool/xxhash.c
@@ -0,0 +1,962 @@
+/*
+xxHash - Fast Hash algorithm
+Copyright (C) 2012-2015, Yann Collet
+
+BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+
+* Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+* Redistributions in binary form must reproduce the above
+copyright notice, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+You can contact the author at :
+- xxHash source repository : https://github.com/Cyan4973/xxHash
+*/
+
+
+/**************************************
+*  Tuning parameters
+**************************************/
+/* XXH_FORCE_MEMORY_ACCESS
+ * By default, access to unaligned memory is controlled by `memcpy()`, which is safe and portable.
+ * Unfortunately, on some target/compiler combinations, the generated assembly is sub-optimal.
+ * The below switch allow to select different access method for improved performance.
+ * Method 0 (default) : use `memcpy()`. Safe and portable.
+ * Method 1 : `__packed` statement. It depends on compiler extension (ie, not portable).
+ *            This method is safe if your compiler supports it, and *generally* as fast or faster than `memcpy`.
+ * Method 2 : direct access. This method is portable but violate C standard.
+ *            It can generate buggy code on targets which generate assembly depending on alignment.
+ *            But in some circumstances, it's the only known way to get the most performance (ie GCC + ARMv6)
+ * See http://stackoverflow.com/a/32095106/646947 for details.
+ * Prefer these methods in priority order (0 > 1 > 2)
+ */
+#ifndef XXH_FORCE_MEMORY_ACCESS   /* can be defined externally, on command line for example */
+#  if defined(__GNUC__) && ( defined(__ARM_ARCH_6__) || defined(__ARM_ARCH_6J__) || defined(__ARM_ARCH_6K__) || defined(__ARM_ARCH_6Z__) || defined(__ARM_ARCH_6ZK__) || defined(__ARM_ARCH_6T2__) )
+#    define XXH_FORCE_MEMORY_ACCESS 2
+#  elif defined(__INTEL_COMPILER) || \
+  (defined(__GNUC__) && ( defined(__ARM_ARCH_7__) || defined(__ARM_ARCH_7A__) || defined(__ARM_ARCH_7R__) || defined(__ARM_ARCH_7M__) || defined(__ARM_ARCH_7S__) ))
+#    define XXH_FORCE_MEMORY_ACCESS 1
+#  endif
+#endif
+
+/* XXH_ACCEPT_NULL_INPUT_POINTER :
+ * If the input pointer is a null pointer, xxHash default behavior is to trigger a memory access error, since it is a bad pointer.
+ * When this option is enabled, xxHash output for null input pointers will be the same as a null-length input.
+ * By default, this option is disabled. To enable it, uncomment below define :
+ */
+/* #define XXH_ACCEPT_NULL_INPUT_POINTER 1 */
+
+/* XXH_FORCE_NATIVE_FORMAT :
+ * By default, xxHash library provides endian-independent Hash values, based on little-endian convention.
+ * Results are therefore identical for little-endian and big-endian CPU.
+ * This comes at a performance cost for big-endian CPU, since some swapping is required to emulate little-endian format.
+ * Should endian-independance be of no importance for your application, you may set the #define below to 1,
+ * to improve speed for Big-endian CPU.
+ * This option has no impact on Little_Endian CPU.
+ */
+#define XXH_FORCE_NATIVE_FORMAT 0
+
+/* XXH_USELESS_ALIGN_BRANCH :
+ * This is a minor performance trick, only useful with lots of very small keys.
+ * It means : don't make a test between aligned/unaligned, because performance will be the same.
+ * It saves one initial branch per hash.
+ */
+#if defined(__i386) || defined(_M_IX86) || defined(__x86_64__) || defined(_M_X64)
+#  define XXH_USELESS_ALIGN_BRANCH 1
+#endif
+
+
+/**************************************
+*  Compiler Specific Options
+***************************************/
+#ifdef _MSC_VER    /* Visual Studio */
+#  pragma warning(disable : 4127)      /* disable: C4127: conditional expression is constant */
+#  define FORCE_INLINE static __forceinline
+#else
+#  if defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L   /* C99 */
+#    ifdef __GNUC__
+#      define FORCE_INLINE static inline __attribute__((always_inline))
+#    else
+#      define FORCE_INLINE static inline
+#    endif
+#  else
+#    define FORCE_INLINE static
+#  endif /* __STDC_VERSION__ */
+#endif
+
+
+/**************************************
+*  Includes & Memory related functions
+***************************************/
+#include "lz4/lib/xxhash.h"
+/* Modify the local functions below should you wish to use some other memory routines */
+/* for malloc(), free() */
+#include <stdlib.h>
+static void* XXH_malloc(size_t s) { return malloc(s); }
+static void  XXH_free  (void* p)  { free(p); }
+/* for memcpy() */
+#include <string.h>
+static void* XXH_memcpy(void* dest, const void* src, size_t size) { return memcpy(dest,src,size); }
+
+
+/**************************************
+*  Basic Types
+***************************************/
+#if defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L   /* C99 */
+# include <stdint.h>
+  typedef uint8_t  BYTE;
+  typedef uint16_t U16;
+  typedef uint32_t U32;
+  typedef  int32_t S32;
+  typedef uint64_t U64;
+#else
+  typedef unsigned char      BYTE;
+  typedef unsigned short     U16;
+  typedef unsigned int       U32;
+  typedef   signed int       S32;
+  typedef unsigned long long U64;
+#endif
+
+
+#if (defined(XXH_FORCE_MEMORY_ACCESS) && (XXH_FORCE_MEMORY_ACCESS==2))
+
+/* Force direct memory access. Only works on CPU which support unaligned memory access in hardware */
+static U32 XXH_read32(const void* memPtr) { return *(const U32*) memPtr; }
+static U64 XXH_read64(const void* memPtr) { return *(const U64*) memPtr; }
+
+#elif (defined(XXH_FORCE_MEMORY_ACCESS) && (XXH_FORCE_MEMORY_ACCESS==1))
+
+/* __pack instructions are safer, but compiler specific, hence potentially problematic for some compilers */
+/* currently only defined for gcc and icc */
+typedef union { U32 u32; U64 u64; } __packed unalign;
+
+static U32 XXH_read32(const void* ptr) { return ((const unalign*)ptr)->u32; }
+static U64 XXH_read64(const void* ptr) { return ((const unalign*)ptr)->u64; }
+
+#else
+
+/* portable and safe solution. Generally efficient.
+ * see : http://stackoverflow.com/a/32095106/646947
+ */
+
+static U32 XXH_read32(const void* memPtr)
+{
+    U32 val;
+    memcpy(&val, memPtr, sizeof(val));
+    return val;
+}
+
+static U64 XXH_read64(const void* memPtr)
+{
+    U64 val;
+    memcpy(&val, memPtr, sizeof(val));
+    return val;
+}
+
+#endif // XXH_FORCE_DIRECT_MEMORY_ACCESS
+
+
+/******************************************
+*  Compiler-specific Functions and Macros
+******************************************/
+#define GCC_VERSION (__GNUC__ * 100 + __GNUC_MINOR__)
+
+/* Note : although _rotl exists for minGW (GCC under windows), performance seems poor */
+#if defined(_MSC_VER)
+#  define XXH_rotl32(x,r) _rotl(x,r)
+#  define XXH_rotl64(x,r) _rotl64(x,r)
+#else
+#  define XXH_rotl32(x,r) ((x << r) | (x >> (32 - r)))
+#  define XXH_rotl64(x,r) ((x << r) | (x >> (64 - r)))
+#endif
+
+#if defined(_MSC_VER)     /* Visual Studio */
+#  define XXH_swap32 _byteswap_ulong
+#  define XXH_swap64 _byteswap_uint64
+#elif GCC_VERSION >= 403
+#  define XXH_swap32 __builtin_bswap32
+#  define XXH_swap64 __builtin_bswap64
+#else
+static U32 XXH_swap32 (U32 x)
+{
+    return  ((x << 24) & 0xff000000 ) |
+            ((x <<  8) & 0x00ff0000 ) |
+            ((x >>  8) & 0x0000ff00 ) |
+            ((x >> 24) & 0x000000ff );
+}
+static U64 XXH_swap64 (U64 x)
+{
+    return  ((x << 56) & 0xff00000000000000ULL) |
+            ((x << 40) & 0x00ff000000000000ULL) |
+            ((x << 24) & 0x0000ff0000000000ULL) |
+            ((x << 8)  & 0x000000ff00000000ULL) |
+            ((x >> 8)  & 0x00000000ff000000ULL) |
+            ((x >> 24) & 0x0000000000ff0000ULL) |
+            ((x >> 40) & 0x000000000000ff00ULL) |
+            ((x >> 56) & 0x00000000000000ffULL);
+}
+#endif
+
+
+/***************************************
+*  Architecture Macros
+***************************************/
+typedef enum { XXH_bigEndian=0, XXH_littleEndian=1 } XXH_endianness;
+
+/* XXH_CPU_LITTLE_ENDIAN can be defined externally, for example one the compiler command line */
+#ifndef XXH_CPU_LITTLE_ENDIAN
+    static const int one = 1;
+#   define XXH_CPU_LITTLE_ENDIAN   (*(const char*)(&one))
+#endif
+
+
+/*****************************
+*  Memory reads
+*****************************/
+typedef enum { XXH_aligned, XXH_unaligned } XXH_alignment;
+
+FORCE_INLINE U32 XXH_readLE32_align(const void* ptr, XXH_endianness endian, XXH_alignment align)
+{
+    if (align==XXH_unaligned)
+        return endian==XXH_littleEndian ? XXH_read32(ptr) : XXH_swap32(XXH_read32(ptr));
+    else
+        return endian==XXH_littleEndian ? *(const U32*)ptr : XXH_swap32(*(const U32*)ptr);
+}
+
+FORCE_INLINE U32 XXH_readLE32(const void* ptr, XXH_endianness endian)
+{
+    return XXH_readLE32_align(ptr, endian, XXH_unaligned);
+}
+
+FORCE_INLINE U64 XXH_readLE64_align(const void* ptr, XXH_endianness endian, XXH_alignment align)
+{
+    if (align==XXH_unaligned)
+        return endian==XXH_littleEndian ? XXH_read64(ptr) : XXH_swap64(XXH_read64(ptr));
+    else
+        return endian==XXH_littleEndian ? *(const U64*)ptr : XXH_swap64(*(const U64*)ptr);
+}
+
+FORCE_INLINE U64 XXH_readLE64(const void* ptr, XXH_endianness endian)
+{
+    return XXH_readLE64_align(ptr, endian, XXH_unaligned);
+}
+
+
+/***************************************
+*  Macros
+***************************************/
+#define XXH_STATIC_ASSERT(c)   { enum { XXH_static_assert = 1/(!!(c)) }; }    /* use only *after* variable declarations */
+
+
+/***************************************
+*  Constants
+***************************************/
+#define PRIME32_1   2654435761U
+#define PRIME32_2   2246822519U
+#define PRIME32_3   3266489917U
+#define PRIME32_4    668265263U
+#define PRIME32_5    374761393U
+
+#define PRIME64_1 11400714785074694791ULL
+#define PRIME64_2 14029467366897019727ULL
+#define PRIME64_3  1609587929392839161ULL
+#define PRIME64_4  9650029242287828579ULL
+#define PRIME64_5  2870177450012600261ULL
+
+
+/*****************************
+*  Simple Hash Functions
+*****************************/
+FORCE_INLINE U32 XXH32_endian_align(const void* input, size_t len, U32 seed, XXH_endianness endian, XXH_alignment align)
+{
+    const BYTE* p = (const BYTE*)input;
+    const BYTE* bEnd = p + len;
+    U32 h32;
+#define XXH_get32bits(p) XXH_readLE32_align(p, endian, align)
+
+#ifdef XXH_ACCEPT_NULL_INPUT_POINTER
+    if (p==NULL)
+    {
+        len=0;
+        bEnd=p=(const BYTE*)(size_t)16;
+    }
+#endif
+
+    if (len>=16)
+    {
+        const BYTE* const limit = bEnd - 16;
+        U32 v1 = seed + PRIME32_1 + PRIME32_2;
+        U32 v2 = seed + PRIME32_2;
+        U32 v3 = seed + 0;
+        U32 v4 = seed - PRIME32_1;
+
+        do
+        {
+            v1 += XXH_get32bits(p) * PRIME32_2;
+            v1 = XXH_rotl32(v1, 13);
+            v1 *= PRIME32_1;
+            p+=4;
+            v2 += XXH_get32bits(p) * PRIME32_2;
+            v2 = XXH_rotl32(v2, 13);
+            v2 *= PRIME32_1;
+            p+=4;
+            v3 += XXH_get32bits(p) * PRIME32_2;
+            v3 = XXH_rotl32(v3, 13);
+            v3 *= PRIME32_1;
+            p+=4;
+            v4 += XXH_get32bits(p) * PRIME32_2;
+            v4 = XXH_rotl32(v4, 13);
+            v4 *= PRIME32_1;
+            p+=4;
+        }
+        while (p<=limit);
+
+        h32 = XXH_rotl32(v1, 1) + XXH_rotl32(v2, 7) + XXH_rotl32(v3, 12) + XXH_rotl32(v4, 18);
+    }
+    else
+    {
+        h32  = seed + PRIME32_5;
+    }
+
+    h32 += (U32) len;
+
+    while (p+4<=bEnd)
+    {
+        h32 += XXH_get32bits(p) * PRIME32_3;
+        h32  = XXH_rotl32(h32, 17) * PRIME32_4 ;
+        p+=4;
+    }
+
+    while (p<bEnd)
+    {
+        h32 += (*p) * PRIME32_5;
+        h32 = XXH_rotl32(h32, 11) * PRIME32_1 ;
+        p++;
+    }
+
+    h32 ^= h32 >> 15;
+    h32 *= PRIME32_2;
+    h32 ^= h32 >> 13;
+    h32 *= PRIME32_3;
+    h32 ^= h32 >> 16;
+
+    return h32;
+}
+
+
+unsigned int XXH32 (const void* input, size_t len, unsigned int seed)
+{
+#if 0
+    /* Simple version, good for code maintenance, but unfortunately slow for small inputs */
+    XXH32_state_t state;
+    XXH32_reset(&state, seed);
+    XXH32_update(&state, input, len);
+    return XXH32_digest(&state);
+#else
+    XXH_endianness endian_detected = (XXH_endianness)XXH_CPU_LITTLE_ENDIAN;
+
+#  if !defined(XXH_USELESS_ALIGN_BRANCH)
+    if ((((size_t)input) & 3) == 0)   /* Input is 4-bytes aligned, leverage the speed benefit */
+    {
+        if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)
+            return XXH32_endian_align(input, len, seed, XXH_littleEndian, XXH_aligned);
+        else
+            return XXH32_endian_align(input, len, seed, XXH_bigEndian, XXH_aligned);
+    }
+#  endif
+
+    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)
+        return XXH32_endian_align(input, len, seed, XXH_littleEndian, XXH_unaligned);
+    else
+        return XXH32_endian_align(input, len, seed, XXH_bigEndian, XXH_unaligned);
+#endif
+}
+
+FORCE_INLINE U64 XXH64_endian_align(const void* input, size_t len, U64 seed, XXH_endianness endian, XXH_alignment align)
+{
+    const BYTE* p = (const BYTE*)input;
+    const BYTE* bEnd = p + len;
+    U64 h64;
+#define XXH_get64bits(p) XXH_readLE64_align(p, endian, align)
+
+#ifdef XXH_ACCEPT_NULL_INPUT_POINTER
+    if (p==NULL)
+    {
+        len=0;
+        bEnd=p=(const BYTE*)(size_t)32;
+    }
+#endif
+
+    if (len>=32)
+    {
+        const BYTE* const limit = bEnd - 32;
+        U64 v1 = seed + PRIME64_1 + PRIME64_2;
+        U64 v2 = seed + PRIME64_2;
+        U64 v3 = seed + 0;
+        U64 v4 = seed - PRIME64_1;
+
+        do
+        {
+            v1 += XXH_get64bits(p) * PRIME64_2;
+            p+=8;
+            v1 = XXH_rotl64(v1, 31);
+            v1 *= PRIME64_1;
+            v2 += XXH_get64bits(p) * PRIME64_2;
+            p+=8;
+            v2 = XXH_rotl64(v2, 31);
+            v2 *= PRIME64_1;
+            v3 += XXH_get64bits(p) * PRIME64_2;
+            p+=8;
+            v3 = XXH_rotl64(v3, 31);
+            v3 *= PRIME64_1;
+            v4 += XXH_get64bits(p) * PRIME64_2;
+            p+=8;
+            v4 = XXH_rotl64(v4, 31);
+            v4 *= PRIME64_1;
+        }
+        while (p<=limit);
+
+        h64 = XXH_rotl64(v1, 1) + XXH_rotl64(v2, 7) + XXH_rotl64(v3, 12) + XXH_rotl64(v4, 18);
+
+        v1 *= PRIME64_2;
+        v1 = XXH_rotl64(v1, 31);
+        v1 *= PRIME64_1;
+        h64 ^= v1;
+        h64 = h64 * PRIME64_1 + PRIME64_4;
+
+        v2 *= PRIME64_2;
+        v2 = XXH_rotl64(v2, 31);
+        v2 *= PRIME64_1;
+        h64 ^= v2;
+        h64 = h64 * PRIME64_1 + PRIME64_4;
+
+        v3 *= PRIME64_2;
+        v3 = XXH_rotl64(v3, 31);
+        v3 *= PRIME64_1;
+        h64 ^= v3;
+        h64 = h64 * PRIME64_1 + PRIME64_4;
+
+        v4 *= PRIME64_2;
+        v4 = XXH_rotl64(v4, 31);
+        v4 *= PRIME64_1;
+        h64 ^= v4;
+        h64 = h64 * PRIME64_1 + PRIME64_4;
+    }
+    else
+    {
+        h64  = seed + PRIME64_5;
+    }
+
+    h64 += (U64) len;
+
+    while (p+8<=bEnd)
+    {
+        U64 k1 = XXH_get64bits(p);
+        k1 *= PRIME64_2;
+        k1 = XXH_rotl64(k1,31);
+        k1 *= PRIME64_1;
+        h64 ^= k1;
+        h64 = XXH_rotl64(h64,27) * PRIME64_1 + PRIME64_4;
+        p+=8;
+    }
+
+    if (p+4<=bEnd)
+    {
+        h64 ^= (U64)(XXH_get32bits(p)) * PRIME64_1;
+        h64 = XXH_rotl64(h64, 23) * PRIME64_2 + PRIME64_3;
+        p+=4;
+    }
+
+    while (p<bEnd)
+    {
+        h64 ^= (*p) * PRIME64_5;
+        h64 = XXH_rotl64(h64, 11) * PRIME64_1;
+        p++;
+    }
+
+    h64 ^= h64 >> 33;
+    h64 *= PRIME64_2;
+    h64 ^= h64 >> 29;
+    h64 *= PRIME64_3;
+    h64 ^= h64 >> 32;
+
+    return h64;
+}
+
+
+unsigned long long XXH64 (const void* input, size_t len, unsigned long long seed)
+{
+#if 0
+    /* Simple version, good for code maintenance, but unfortunately slow for small inputs */
+    XXH64_state_t state;
+    XXH64_reset(&state, seed);
+    XXH64_update(&state, input, len);
+    return XXH64_digest(&state);
+#else
+    XXH_endianness endian_detected = (XXH_endianness)XXH_CPU_LITTLE_ENDIAN;
+
+#  if !defined(XXH_USELESS_ALIGN_BRANCH)
+    if ((((size_t)input) & 7)==0)   /* Input is aligned, let's leverage the speed advantage */
+    {
+        if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)
+            return XXH64_endian_align(input, len, seed, XXH_littleEndian, XXH_aligned);
+        else
+            return XXH64_endian_align(input, len, seed, XXH_bigEndian, XXH_aligned);
+    }
+#  endif
+
+    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)
+        return XXH64_endian_align(input, len, seed, XXH_littleEndian, XXH_unaligned);
+    else
+        return XXH64_endian_align(input, len, seed, XXH_bigEndian, XXH_unaligned);
+#endif
+}
+
+/****************************************************
+*  Advanced Hash Functions
+****************************************************/
+
+/*** Allocation ***/
+typedef struct
+{
+    U64 total_len;
+    U32 seed;
+    U32 v1;
+    U32 v2;
+    U32 v3;
+    U32 v4;
+    U32 mem32[4];   /* defined as U32 for alignment */
+    U32 memsize;
+} XXH_istate32_t;
+
+typedef struct
+{
+    U64 total_len;
+    U64 seed;
+    U64 v1;
+    U64 v2;
+    U64 v3;
+    U64 v4;
+    U64 mem64[4];   /* defined as U64 for alignment */
+    U32 memsize;
+} XXH_istate64_t;
+
+
+XXH32_state_t* XXH32_createState(void)
+{
+    XXH_STATIC_ASSERT(sizeof(XXH32_state_t) >= sizeof(XXH_istate32_t));   /* A compilation error here means XXH32_state_t is not large enough */
+    return (XXH32_state_t*)XXH_malloc(sizeof(XXH32_state_t));
+}
+XXH_errorcode XXH32_freeState(XXH32_state_t* statePtr)
+{
+    XXH_free(statePtr);
+    return XXH_OK;
+}
+
+XXH64_state_t* XXH64_createState(void)
+{
+    XXH_STATIC_ASSERT(sizeof(XXH64_state_t) >= sizeof(XXH_istate64_t));   /* A compilation error here means XXH64_state_t is not large enough */
+    return (XXH64_state_t*)XXH_malloc(sizeof(XXH64_state_t));
+}
+XXH_errorcode XXH64_freeState(XXH64_state_t* statePtr)
+{
+    XXH_free(statePtr);
+    return XXH_OK;
+}
+
+
+/*** Hash feed ***/
+
+XXH_errorcode XXH32_reset(XXH32_state_t* state_in, unsigned int seed)
+{
+    XXH_istate32_t* state = (XXH_istate32_t*) state_in;
+    state->seed = seed;
+    state->v1 = seed + PRIME32_1 + PRIME32_2;
+    state->v2 = seed + PRIME32_2;
+    state->v3 = seed + 0;
+    state->v4 = seed - PRIME32_1;
+    state->total_len = 0;
+    state->memsize = 0;
+    return XXH_OK;
+}
+
+XXH_errorcode XXH64_reset(XXH64_state_t* state_in, unsigned long long seed)
+{
+    XXH_istate64_t* state = (XXH_istate64_t*) state_in;
+    state->seed = seed;
+    state->v1 = seed + PRIME64_1 + PRIME64_2;
+    state->v2 = seed + PRIME64_2;
+    state->v3 = seed + 0;
+    state->v4 = seed - PRIME64_1;
+    state->total_len = 0;
+    state->memsize = 0;
+    return XXH_OK;
+}
+
+
+FORCE_INLINE XXH_errorcode XXH32_update_endian (XXH32_state_t* state_in, const void* input, size_t len, XXH_endianness endian)
+{
+    XXH_istate32_t* state = (XXH_istate32_t *) state_in;
+    const BYTE* p = (const BYTE*)input;
+    const BYTE* const bEnd = p + len;
+
+#ifdef XXH_ACCEPT_NULL_INPUT_POINTER
+    if (input==NULL) return XXH_ERROR;
+#endif
+
+    state->total_len += len;
+
+    if (state->memsize + len < 16)   /* fill in tmp buffer */
+    {
+        XXH_memcpy((BYTE*)(state->mem32) + state->memsize, input, len);
+        state->memsize += (U32)len;
+        return XXH_OK;
+    }
+
+    if (state->memsize)   /* some data left from previous update */
+    {
+        XXH_memcpy((BYTE*)(state->mem32) + state->memsize, input, 16-state->memsize);
+        {
+            const U32* p32 = state->mem32;
+            state->v1 += XXH_readLE32(p32, endian) * PRIME32_2;
+            state->v1 = XXH_rotl32(state->v1, 13);
+            state->v1 *= PRIME32_1;
+            p32++;
+            state->v2 += XXH_readLE32(p32, endian) * PRIME32_2;
+            state->v2 = XXH_rotl32(state->v2, 13);
+            state->v2 *= PRIME32_1;
+            p32++;
+            state->v3 += XXH_readLE32(p32, endian) * PRIME32_2;
+            state->v3 = XXH_rotl32(state->v3, 13);
+            state->v3 *= PRIME32_1;
+            p32++;
+            state->v4 += XXH_readLE32(p32, endian) * PRIME32_2;
+            state->v4 = XXH_rotl32(state->v4, 13);
+            state->v4 *= PRIME32_1;
+            p32++;
+        }
+        p += 16-state->memsize;
+        state->memsize = 0;
+    }
+
+    if (p <= bEnd-16)
+    {
+        const BYTE* const limit = bEnd - 16;
+        U32 v1 = state->v1;
+        U32 v2 = state->v2;
+        U32 v3 = state->v3;
+        U32 v4 = state->v4;
+
+        do
+        {
+            v1 += XXH_readLE32(p, endian) * PRIME32_2;
+            v1 = XXH_rotl32(v1, 13);
+            v1 *= PRIME32_1;
+            p+=4;
+            v2 += XXH_readLE32(p, endian) * PRIME32_2;
+            v2 = XXH_rotl32(v2, 13);
+            v2 *= PRIME32_1;
+            p+=4;
+            v3 += XXH_readLE32(p, endian) * PRIME32_2;
+            v3 = XXH_rotl32(v3, 13);
+            v3 *= PRIME32_1;
+            p+=4;
+            v4 += XXH_readLE32(p, endian) * PRIME32_2;
+            v4 = XXH_rotl32(v4, 13);
+            v4 *= PRIME32_1;
+            p+=4;
+        }
+        while (p<=limit);
+
+        state->v1 = v1;
+        state->v2 = v2;
+        state->v3 = v3;
+        state->v4 = v4;
+    }
+
+    if (p < bEnd)
+    {
+        XXH_memcpy(state->mem32, p, bEnd-p);
+        state->memsize = (int)(bEnd-p);
+    }
+
+    return XXH_OK;
+}
+
+XXH_errorcode XXH32_update (XXH32_state_t* state_in, const void* input, size_t len)
+{
+    XXH_endianness endian_detected = (XXH_endianness)XXH_CPU_LITTLE_ENDIAN;
+
+    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)
+        return XXH32_update_endian(state_in, input, len, XXH_littleEndian);
+    else
+        return XXH32_update_endian(state_in, input, len, XXH_bigEndian);
+}
+
+
+
+FORCE_INLINE U32 XXH32_digest_endian (const XXH32_state_t* state_in, XXH_endianness endian)
+{
+    const XXH_istate32_t* state = (const XXH_istate32_t*) state_in;
+    const BYTE * p = (const BYTE*)state->mem32;
+    const BYTE* bEnd = (const BYTE*)(state->mem32) + state->memsize;
+    U32 h32;
+
+    if (state->total_len >= 16)
+    {
+        h32 = XXH_rotl32(state->v1, 1) + XXH_rotl32(state->v2, 7) + XXH_rotl32(state->v3, 12) + XXH_rotl32(state->v4, 18);
+    }
+    else
+    {
+        h32  = state->seed + PRIME32_5;
+    }
+
+    h32 += (U32) state->total_len;
+
+    while (p+4<=bEnd)
+    {
+        h32 += XXH_readLE32(p, endian) * PRIME32_3;
+        h32  = XXH_rotl32(h32, 17) * PRIME32_4;
+        p+=4;
+    }
+
+    while (p<bEnd)
+    {
+        h32 += (*p) * PRIME32_5;
+        h32 = XXH_rotl32(h32, 11) * PRIME32_1;
+        p++;
+    }
+
+    h32 ^= h32 >> 15;
+    h32 *= PRIME32_2;
+    h32 ^= h32 >> 13;
+    h32 *= PRIME32_3;
+    h32 ^= h32 >> 16;
+
+    return h32;
+}
+
+
+unsigned int XXH32_digest (const XXH32_state_t* state_in)
+{
+    XXH_endianness endian_detected = (XXH_endianness)XXH_CPU_LITTLE_ENDIAN;
+
+    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)
+        return XXH32_digest_endian(state_in, XXH_littleEndian);
+    else
+        return XXH32_digest_endian(state_in, XXH_bigEndian);
+}
+
+
+FORCE_INLINE XXH_errorcode XXH64_update_endian (XXH64_state_t* state_in, const void* input, size_t len, XXH_endianness endian)
+{
+    XXH_istate64_t * state = (XXH_istate64_t *) state_in;
+    const BYTE* p = (const BYTE*)input;
+    const BYTE* const bEnd = p + len;
+
+#ifdef XXH_ACCEPT_NULL_INPUT_POINTER
+    if (input==NULL) return XXH_ERROR;
+#endif
+
+    state->total_len += len;
+
+    if (state->memsize + len < 32)   /* fill in tmp buffer */
+    {
+        XXH_memcpy(((BYTE*)state->mem64) + state->memsize, input, len);
+        state->memsize += (U32)len;
+        return XXH_OK;
+    }
+
+    if (state->memsize)   /* some data left from previous update */
+    {
+        XXH_memcpy(((BYTE*)state->mem64) + state->memsize, input, 32-state->memsize);
+        {
+            const U64* p64 = state->mem64;
+            state->v1 += XXH_readLE64(p64, endian) * PRIME64_2;
+            state->v1 = XXH_rotl64(state->v1, 31);
+            state->v1 *= PRIME64_1;
+            p64++;
+            state->v2 += XXH_readLE64(p64, endian) * PRIME64_2;
+            state->v2 = XXH_rotl64(state->v2, 31);
+            state->v2 *= PRIME64_1;
+            p64++;
+            state->v3 += XXH_readLE64(p64, endian) * PRIME64_2;
+            state->v3 = XXH_rotl64(state->v3, 31);
+            state->v3 *= PRIME64_1;
+            p64++;
+            state->v4 += XXH_readLE64(p64, endian) * PRIME64_2;
+            state->v4 = XXH_rotl64(state->v4, 31);
+            state->v4 *= PRIME64_1;
+            p64++;
+        }
+        p += 32-state->memsize;
+        state->memsize = 0;
+    }
+
+    if (p+32 <= bEnd)
+    {
+        const BYTE* const limit = bEnd - 32;
+        U64 v1 = state->v1;
+        U64 v2 = state->v2;
+        U64 v3 = state->v3;
+        U64 v4 = state->v4;
+
+        do
+        {
+            v1 += XXH_readLE64(p, endian) * PRIME64_2;
+            v1 = XXH_rotl64(v1, 31);
+            v1 *= PRIME64_1;
+            p+=8;
+            v2 += XXH_readLE64(p, endian) * PRIME64_2;
+            v2 = XXH_rotl64(v2, 31);
+            v2 *= PRIME64_1;
+            p+=8;
+            v3 += XXH_readLE64(p, endian) * PRIME64_2;
+            v3 = XXH_rotl64(v3, 31);
+            v3 *= PRIME64_1;
+            p+=8;
+            v4 += XXH_readLE64(p, endian) * PRIME64_2;
+            v4 = XXH_rotl64(v4, 31);
+            v4 *= PRIME64_1;
+            p+=8;
+        }
+        while (p<=limit);
+
+        state->v1 = v1;
+        state->v2 = v2;
+        state->v3 = v3;
+        state->v4 = v4;
+    }
+
+    if (p < bEnd)
+    {
+        XXH_memcpy(state->mem64, p, bEnd-p);
+        state->memsize = (int)(bEnd-p);
+    }
+
+    return XXH_OK;
+}
+
+XXH_errorcode XXH64_update (XXH64_state_t* state_in, const void* input, size_t len)
+{
+    XXH_endianness endian_detected = (XXH_endianness)XXH_CPU_LITTLE_ENDIAN;
+
+    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)
+        return XXH64_update_endian(state_in, input, len, XXH_littleEndian);
+    else
+        return XXH64_update_endian(state_in, input, len, XXH_bigEndian);
+}
+
+
+
+FORCE_INLINE U64 XXH64_digest_endian (const XXH64_state_t* state_in, XXH_endianness endian)
+{
+    const XXH_istate64_t * state = (const XXH_istate64_t *) state_in;
+    const BYTE * p = (const BYTE*)state->mem64;
+    const BYTE* bEnd = (const BYTE*)state->mem64 + state->memsize;
+    U64 h64;
+
+    if (state->total_len >= 32)
+    {
+        U64 v1 = state->v1;
+        U64 v2 = state->v2;
+        U64 v3 = state->v3;
+        U64 v4 = state->v4;
+
+        h64 = XXH_rotl64(v1, 1) + XXH_rotl64(v2, 7) + XXH_rotl64(v3, 12) + XXH_rotl64(v4, 18);
+
+        v1 *= PRIME64_2;
+        v1 = XXH_rotl64(v1, 31);
+        v1 *= PRIME64_1;
+        h64 ^= v1;
+        h64 = h64*PRIME64_1 + PRIME64_4;
+
+        v2 *= PRIME64_2;
+        v2 = XXH_rotl64(v2, 31);
+        v2 *= PRIME64_1;
+        h64 ^= v2;
+        h64 = h64*PRIME64_1 + PRIME64_4;
+
+        v3 *= PRIME64_2;
+        v3 = XXH_rotl64(v3, 31);
+        v3 *= PRIME64_1;
+        h64 ^= v3;
+        h64 = h64*PRIME64_1 + PRIME64_4;
+
+        v4 *= PRIME64_2;
+        v4 = XXH_rotl64(v4, 31);
+        v4 *= PRIME64_1;
+        h64 ^= v4;
+        h64 = h64*PRIME64_1 + PRIME64_4;
+    }
+    else
+    {
+        h64  = state->seed + PRIME64_5;
+    }
+
+    h64 += (U64) state->total_len;
+
+    while (p+8<=bEnd)
+    {
+        U64 k1 = XXH_readLE64(p, endian);
+        k1 *= PRIME64_2;
+        k1 = XXH_rotl64(k1,31);
+        k1 *= PRIME64_1;
+        h64 ^= k1;
+        h64 = XXH_rotl64(h64,27) * PRIME64_1 + PRIME64_4;
+        p+=8;
+    }
+
+    if (p+4<=bEnd)
+    {
+        h64 ^= (U64)(XXH_readLE32(p, endian)) * PRIME64_1;
+        h64 = XXH_rotl64(h64, 23) * PRIME64_2 + PRIME64_3;
+        p+=4;
+    }
+
+    while (p<bEnd)
+    {
+        h64 ^= (*p) * PRIME64_5;
+        h64 = XXH_rotl64(h64, 11) * PRIME64_1;
+        p++;
+    }
+
+    h64 ^= h64 >> 33;
+    h64 *= PRIME64_2;
+    h64 ^= h64 >> 29;
+    h64 *= PRIME64_3;
+    h64 ^= h64 >> 32;
+
+    return h64;
+}
+
+
+unsigned long long XXH64_digest (const XXH64_state_t* state_in)
+{
+    XXH_endianness endian_detected = (XXH_endianness)XXH_CPU_LITTLE_ENDIAN;
+
+    if ((endian_detected==XXH_littleEndian) || XXH_FORCE_NATIVE_FORMAT)
+        return XXH64_digest_endian(state_in, XXH_littleEndian);
+    else
+        return XXH64_digest_endian(state_in, XXH_bigEndian);
+}
+
+
-- 
2.23.0

